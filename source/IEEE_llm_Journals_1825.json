[
    {
        "Title": "Cost-Effective Extension of DRAM-PIM for Group-Wise LLM Quantization",
        "Link": "https://ieeexplore.ieee.org/document/10886951/",
        "Abstract": "Processing-in-Memory (PIM) is emerging as a promising next-generation hardware to address memory bottlenecks in large language model (LLM) inference by leveraging internal memory bandwidth, enabling more energy-efficient on-device AI. However, LLMs’ large footprint poses significant challenges for accelerating them on PIM due to limited available space. Recent advances in weight-only quantization, especially group-wise weight quantization (GWQ), reduce LLM model sizes, enabling parameters to be stored at 4-bit precision or lower with minimal accuracy loss. Despite this, current PIM architectures experience performance degradation when handling the additional computations required for quantized weights. While incorporating extra logic could mitigate this degradation, it is often prohibitively expensive due to the constraints of memory technology, necessitating solutions with minimal area overhead. This work introduces two key innovations: 1) scale cascading, and 2) an INT2FP converter, to support GWQ-applied LLMs on PIM with minimal dequantization latency and area overhead compared to FP16 GEMV. Experimental results show that the proposed approach adds less than 0.6% area overhead to the existing PIM unit and achieves a 7% latency overhead for dequantization and GEMV in 4-bit GWQ with a group size of 128, compared to FP16 GEMV, while offering a 1.55× performance gain over baseline dequantization.",
        "Details": {
            "DOI": "10.1109/LCA.2025.3532682",
            "Date of Publication": "13 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Computer Architecture Letters"
        },
        "issn_info": {
            "Print ISSN": "1556-6056",
            "Electronic ISSN": "1556-6064"
        },
        "authors_data": [
            {
                "name": "Byeori Kim",
                "labs": [
                    "Department of Computer Science and Engineering, POSTECH, Pohang, South Korea"
                ]
            },
            {
                "name": "Changhun Lee",
                "labs": [
                    "Department of Convergence IT Engineering, POSTECH, Pohang, South Korea"
                ]
            },
            {
                "name": "Gwangsun Kim",
                "labs": [
                    "Department of Computer Science and Engineering, POSTECH, Pohang, South Korea"
                ]
            },
            {
                "name": "Eunhyeok Park",
                "labs": [
                    "Graduate School of Artificial Intelligence, POSTECH, Pohang, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Random access memory",
                "Logic",
                "Accuracy",
                "Pipelines",
                "Memory management",
                "Degradation",
                "Costs",
                "Reviews",
                "Next generation networking"
            ],
            "Author Keywords": [
                "Processing-in-memory",
                "DRAM",
                "LLM",
                "weight-only quantization",
                "group-wise quantization",
                "dequantization"
            ]
        }
    },
    {
        "Title": "Maestro: LLM-Driven Collaborative Automation of Intent-Based 6G Networks",
        "Link": "https://ieeexplore.ieee.org/document/10758700/",
        "Abstract": "This letter presents Maestro, a collaborative framework leveraging Large Language Models (LLMs) for automation of shared networks. Maestro enables conflict resolution and collaboration among stakeholders in a shared intent-based 6G network by abstracting diverse network infrastructures into declarative intents across business, service, and network planes. LLM-based agents negotiate resources, mediated by Maestro to achieve consensus that aligns multi-party business and network goals. Evaluation on a 5G Open RAN testbed reveals that integrating LLMs with optimization tools and contextual units builds autonomous agents with comparable accuracy to the state-of-the-art algorithms while being flexible to spatio-temporal business and network variability.",
        "Details": {
            "DOI": "10.1109/LNET.2024.3503292",
            "Date of Publication": "20 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Networking Letters"
        },
        "issn_info": {
            "Electronic ISSN": "2576-3156"
        },
        "authors_data": [
            {
                "name": "Ilias Chatzistefanidis",
                "labs": [
                    "Communications Department, EURECOM, Sophia Antipolis, France"
                ]
            },
            {
                "name": "Andrea Leone",
                "labs": [
                    "Communications Department, EURECOM, Sophia Antipolis, France"
                ]
            },
            {
                "name": "Navid Nikaein",
                "labs": [
                    "Communications Department, EURECOM, Sophia Antipolis, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Throughput",
                "Collaboration",
                "6G mobile communication",
                "Quality of service",
                "Optimization",
                "Open RAN",
                "Large language models",
                "Multi-agent systems"
            ],
            "Author Keywords": [
                "LLM",
                "multi-agent",
                "intent-based networks",
                "6G"
            ]
        }
    },
    {
        "Title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
        "Link": "https://ieeexplore.ieee.org/document/10589417/",
        "Abstract": "In recent years, large language models (LLMs) have achieved remarkable success in natural language processing (NLP). LLMs require an extreme amount of parameters to attain high performance. As models grow into the trillion-parameter range, computational and memory costs increase significantly. This makes it difficult for many researchers to access the resources needed to train or apply these models. Optimizing LLM performance involves two main approaches: fine-tuning pre-trained models for specific tasks to achieve state-of-the-art performance, and reducing costs or improving training time while maintaining similar performance. This paper presents a systematic literature review (SLR) following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65 publications out of 983 from 2017 to December 2023, retrieved from 5 databases. The study presents methods to optimize and accelerate LLMs while achieving cutting-edge results without sacrificing accuracy. We begin with an overview of the development of language modeling, followed by a detailed explanation of commonly used frameworks and libraries, and a taxonomy for improving and speeding up LLMs based on three classes: LLM training, LLM inference, and system serving. We then delve into recent optimization and acceleration strategies such as training optimization, hardware optimization, scalability and reliability, accompanied by the taxonomy and categorization of these strategies. Finally, we provide an in-depth comparison of each class and strategy, with two case studies on optimizing model training and enhancing inference efficiency. These case studies showcase practical approaches to address LLM resource limitations while maintaining performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3424945",
            "Date of Publication": "08 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhyar Rzgar K. Rostam",
                "labs": [
                    "Doctoral School of Applied Informatics and Applied Mathematics, Óbuda University, Budapest, Hungary"
                ]
            },
            {
                "name": "Sándor Szénási",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Faculty of Economics and Informatics, J. Selye University, Komárno, Slovakia"
                ]
            },
            {
                "name": "Gábor Kertész",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Laboratory of Parallel and Distributed Systems, Institute for Computer Science and Control (SZTAKI), Hungarian Research Network (HUN-REN), Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimization methods",
                "Training",
                "Parallel processing",
                "Computational modeling",
                "Scalability",
                "Libraries",
                "Taxonomy",
                "Distributed computing",
                "Graphics processing units",
                "Large language models"
            ],
            "Author Keywords": [
                "Distributed training",
                "GPU acceleration",
                "large language model",
                "LLM",
                "LLM acceleration",
                "LLM frameworks",
                "LLM optimization"
            ]
        }
    },
    {
        "Title": "LLM-DSK: A Domain-Specific Semantic Knowledge-Guided Ocean Environment Prediction Method Based on Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11083757/",
        "Abstract": "Data-driven methods learn patterns of oceanic variable changes directly from data without relying on explicit modeling of complex physical processes based on specific assumptions. This approach addresses the limitations of traditional numerical methods, which are constrained by physical assumptions, parameterized processes, and dependencies on initial and boundary conditions. However, methods based solely on probabilistic statistics and ignoring the intrinsic characteristics of ocean systems struggle to capture the complex spatiotemporal dynamics of chaotic ocean systems. With the emergence of large language models (LLMs) in time-series analysis, researchers have discovered that pretrained LLMs can leverage rich domain-specific knowledge through prompt engineering to analyze complex temporal changes. Building on this insight, we propose LLM-DSK, a domain-specific semantic knowledge-guided ocean environment prediction model based on pretrained LLMs. LLM-DSK comprises three core modules: 1) a spatiotemporal feature extraction module that utilizes geographic data (e.g., latitude, longitude, wind fields, and land–sea boundaries) to extract key domain-relevant spatiotemporal features; 2) a semantic encoding module that employs an attention mechanism to align these features with the vocabulary of LLMs, enabling cross-modal alignment between oceanic and natural language domains to enrich semantic representations; and 3) an LLM-based prediction module driven by domain-specific prompts that integrate geographic information and statistical indicators. We validated LLM-DSK using remote sensing data (sea surface temperature) and reanalysis data (significant wave height), and the results demonstrate that LLM-DSK achieves superior predictive performance compared to state-of-the-art (SOTA) models.",
        "Details": {
            "DOI": "10.1109/JSTARS.2025.3590651",
            "Date of Publication": "18 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing"
        },
        "issn_info": {
            "Print ISSN": "1939-1404",
            "Electronic ISSN": "2151-1535"
        },
        "authors_data": [
            {
                "name": "Ning Song",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Caichao Lv",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Jie Nie",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Min Ye",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Enyuan Zhao",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Jun Ma",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Xiong Liu",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            },
            {
                "name": "Zhiqiang Wei",
                "labs": [
                    "College of Information Science and Engineering, Ocean University of China, Qingdao, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Oceans",
                "Numerical models",
                "Feature extraction",
                "Spatiotemporal phenomena",
                "Time series analysis",
                "Mathematical models",
                "Predictive models",
                "Forecasting",
                "Semantics",
                "Large language models"
            ],
            "Author Keywords": [
                "Laplace operator",
                "large language model (LLM)",
                "ocean environment prediction",
                "spatiotemporal variation"
            ]
        }
    },
    {
        "Title": "A Comprehensive Survey on LLM-Powered Recommender Systems: From Discriminative, Generative to Multi-Modal Paradigms",
        "Link": "https://ieeexplore.ieee.org/document/11129085/",
        "Abstract": "Large Language Models (LLMs) have become transformative tools in Natural Language Processing (NLP). They are increasingly being integrated into recommendation systems to address existing limitations such as data sparsity, novelty, cold start, and long-tail challenges. Unlike traditional recommendation techniques that rely on user-item interaction matrices, LLMs provide context-aware reasoning and multi-modal processing capabilities. However, existing research mainly focuses on fine-tuning and prompt engineering strategies without fully exploring hybrid models, retrieval-augmented generation (RAG), graph-enhanced recommendations, and evaluation methodologies. This survey offers a comprehensive and structured examination of LLM-based recommendation systems, categorizing them into discriminative, generative, hybrid, graph-enhanced, and multimodal paradigms. Additionally, we explore adaptive fine-tuning techniques, prompt engineering strategies, and retrieval-augmented generation (RAG) approaches that improve LLM performance in personalized recommendations. We also examine evaluation methodologies, including LLM-as-a-Judge frameworks, benchmark limitations, and fairness considerations. Finally, we present a detailed discussion of open challenges, such as hallucination, scalability, bias, and privacy, highlighting critical research gaps and opportunities for future exploration. This survey aims to guide researchers in navigating the evolving landscape of LLM-driven recommendation systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599832",
            "Date of Publication": "18 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dina Nawara",
                "labs": [
                    "Department of Electrical, Computer, and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Rasha Kashef",
                "labs": [
                    "Department of Electrical, Computer, and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Recommender systems",
                "Surveys",
                "Accuracy",
                "Adaptation models",
                "Automobiles",
                "Real-time systems",
                "Motion pictures",
                "Filtering",
                "Electronic commerce",
                "Collaborative filtering"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "recommendation systems",
                "retrieval-augmented generation (RAG)",
                "discriminative learning",
                "multi-modal paradigms",
                "LLM-as-a-judge",
                "evaluation metrics"
            ]
        }
    },
    {
        "Title": "Conversational LLM-Based Decision Support for Defect Classification in AFM Images",
        "Link": "https://ieeexplore.ieee.org/document/11096088/",
        "Abstract": "Atomic force microscopy (AFM) has emerged as a powerful tool for nanoscale imaging and quantitative characterization of organic (e.g., live cells, proteins, DNA, and lipid bilayers) and inorganic (e.g., silicon wafers and polymers) specimens. However, image artifacts in AFM height and peak force error images directly affect the precision of nanomechanical measurements. Experimentalists face considerable challenges in obtaining high-quality AFM images due to the requirement of specialized expertise and constant manual monitoring. Another challenge is the lack of high-quality AFM datasets to train machine learning models for automated defect detection. In this work, we propose a two-step AI framework that combines a vision-based deep learning (DL) model for classifying AFM image defects with a large language model (LLM)-based conversational assistant that provides real-time corrective guidance in natural language, making it particularly valuable for non-AFM experts aiming to obtain high-quality images. We curated an annotated AFM defect dataset spanning organic and inorganic samples to train the defect detection model. Our defect classification model achieves 91.43% overall accuracy, with a recall of 93% for tip contamination and 60% not-tracking defects. We further develop an intuitive user interface that enables seamless interaction with the DL model and integrates an LLM-based guidance feature to support users in understanding defects and improving future experiments. We then evaluate the performance of multiple state-of-the-art LLMs on AFM-related queries, offering users flexibility in LLM selection based on their specific needs. LLM evaluations and the benchmark questions are available at: https://github.com/idealab-isu/AFM-LLM-Defect-Guidance.",
        "Details": {
            "DOI": "10.1109/OJIM.2025.3592284",
            "Date of Publication": "24 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Instrumentation and Measurement"
        },
        "issn_info": {
            "Electronic ISSN": "2768-7236"
        },
        "authors_data": [
            {
                "name": "Angona Biswas",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Jaydeep Rade",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Nabila Masud",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Md Hasibul Hasan Hasib",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Aditya Balu",
                "labs": [
                    "Translational AI Center, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Juntao Zhang",
                "labs": [
                    "Department of Mechanical Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Soumik Sarkar",
                "labs": [
                    "Department of Mechanical Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Adarsh Krishnamurthy",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA",
                    "Department of Mechanical Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Juan Ren",
                "labs": [
                    "Department of Mechanical Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Anwesha Sarkar",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Imaging",
                "Accuracy",
                "Probes",
                "Surface topography",
                "Force",
                "Defect detection",
                "User interfaces",
                "Pollution measurement",
                "Computer architecture",
                "Cognition"
            ],
            "Author Keywords": [
                "atomic force microscopy (AFM)",
                "conversational LLM",
                "image defect classification",
                "large language models (LLMs)"
            ]
        }
    },
    {
        "Title": "Enhancing LLM Reasoning Capabilities Through Brokered Multi-Expert Reflection",
        "Link": "https://ieeexplore.ieee.org/document/10966887/",
        "Abstract": "Large Language Models (LLMs) have found increasing application in tasks requiring multi-step reasoning, yet challenges such as hallucinations and inconsistencies in the generated responses persist. This study presents an innovative methodology to enhance the reasoning capabilities of LLMs by brokering and integrating multiple expert LLMs within a reflection layer to provide targeted feedback on the reasoning trajectories of the base LLM. The approach employs a foundational pre-trained LLM as the base model, which is further supported by agents to promote cognitive assistance for specific task types. In instances where conclusions are deemed incorrect or reasoning is interrupted, these instances are forwarded to the expert LLM layer, which includes systems such as Claude-3 haiku for intricate contexts and MedAlpaca for medical reasoning, to deliver feedback on the base model’s reasoning paths. This feedback forms a ‘reflection pool,’ enabling the base LLM to amend and enhance its reasoning trajectories in subsequent iterations. The experiments conducted across diverse datasets, including HotPotQA, SimpleQA, and PubmedQA, underscore the proposed architecture’s efficacy in augmenting success signals, Rouge-L scores (indicative of quality and precision), and CTRLEval Consistency Scores (indicative of coherence and consistency). The architecture effectively addresses the issues of hallucinations and inconsistencies that frequently occur in multi-step reasoning. Importantly, the approach exhibits considerable potential in tackling domain-specific tasks, underscoring the importance of achieving correct and reliable conclusions. To facilitate further investigation and validation of our proposed brokered multi-expert reflection framework for non-commercial use, the source code of our system is available at https://github.com/WiZY936/Brokered-Multi-Expert-Reflection",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3561693",
            "Date of Publication": "16 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tejasvee Sheokand",
                "labs": [
                    "Bennett University, Greater Noida, Uttar Pradesh, India"
                ]
            },
            {
                "name": "Garveet Jain",
                "labs": [
                    "Bennett University, Greater Noida, Uttar Pradesh, India"
                ]
            },
            {
                "name": "Arshdeep Bahga",
                "labs": [
                    "Cloudemy Technology Labs, Chandigarh, India"
                ]
            },
            {
                "name": "Vijay K. Madisetti",
                "labs": [
                    "Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Reflection",
                "Collaboration",
                "Training",
                "Trajectory",
                "Scalability",
                "Real-time systems",
                "Problem-solving",
                "Iterative methods",
                "Computer architecture"
            ],
            "Author Keywords": [
                "LLM",
                "self-reflection",
                "chain-of-thought",
                "multi-hop inference",
                "feedback-driven refinement"
            ]
        }
    },
    {
        "Title": "An Innovative Solution to Design Problems: Applying the Chain-of-Thought Technique to Integrate LLM-Based Agents With Concept Generation Methods",
        "Link": "https://ieeexplore.ieee.org/document/10747324/",
        "Abstract": "To enhance the application capabilities of large language models (LLMs) in conceptual design, this study explores how to achieve deep integration between LLM-based agents and concept generation methods using the chain-of-thought (CoT) technique and evaluates its feasibility. Using GPT-4 as a case study, we designed two agents: IntelliStorm (based on the unstructured brainstorming method) and EvoluTRIZ (based on the structured TRIZ method). Thirty participants were recruited, and through two experimental phases spaced one month apart, a comparative analysis of the effects of collaboration groups (human-agent vs. human-human) and concept generation methods (brainstorming vs. TRIZ) on participants’ physiological activation and creative thinking performance were conducted. The results show that the involvement of LLM-based agents can effectively reduce participants’ electrodermal activity(EDA) response levels, indicating a reduction in cognitive load. Moreover, participants maintained their distinct physiological patterns and performance advantages across different concept generation methods. For example, IntelliStorm, like brainstorming, evokes stronger responses to information stimuli, demonstrating superior thinking fluency; EvoluTRIZ, like the TRIZ, exhibits a higher frequency of information responses, showcasing enhanced thinking elaboration. However, originality tends to favor human-human collaboration. The findings confirm that integrating LLMs with traditional concept generation methods is an effective strategy made possible by combining CoT and retrieval-augmented generation (RAG) technologies. In the future, LLM-based agents are expected to achieve broader application in the design field by incorporating additional concept generation methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3494054",
            "Date of Publication": "08 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shijun Ge",
                "labs": [
                    "School of Design and Art, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Yuanbo Sun",
                "labs": [
                    "School of Design and Art, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Yin Cui",
                "labs": [
                    "School of Design and Innovation, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Dapeng Wei",
                "labs": [
                    "School of Design and Art, Beijing Institute of Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Particle swarm optimization",
                "Heuristic algorithms",
                "Brain modeling",
                "Collaboration",
                "Design methodology",
                "Creativity",
                "Training",
                "Knowledge based systems",
                "Computational modeling",
                "Cognitive load",
                "Large language models"
            ],
            "Author Keywords": [
                "LLM-based agent",
                "chain-of-thought fine-tuning",
                "concept generation method",
                "EDA",
                "human-agent collaboration",
                "human-human collaboration"
            ]
        }
    },
    {
        "Title": "Optimization of Customer Feedback Summarization Using Large Language Models (LLM) and Advanced Retrieval-Augmented Generation",
        "Link": "https://ieeexplore.ieee.org/document/11078280/",
        "Abstract": "Customer feedback, often shared through online reviews, plays a crucial role in shaping business strategies. However, the overwhelming volume of such reviews poses two major challenges: valuable insights often go unnoticed, and manual analysis introduces human bias. To address this, we propose a system that leverages large language models (LLMs) integrated with the LangChain framework to answer natural language queries over customer reviews. A synthetic dataset was created to resemble food delivery reviews typically seen on the Play Store and was stored in a vector database. On receiving a user query, relevant reviews are retrieved using advanced Retrieval-Augmented Generation (RAG) techniques, namely Hierarchical Chunk Retrieval and RAG Fusion that are further refined using the Declarative Self-improving Python (DSPy) framework to generate accurate, grounded responses. The system was evaluated using LLaMA-3-8B-InstructLite, GPT-3.5-Turbo, and Gemini-1.5-Pro, and compared against two non-LLM baselines: BM25 and a fine-tuned BERT model. Results show that our LLM-based pipeline outperforms by an average 15% in semantic and factual accuracy. Component-level analysis showed that enhanced retrieval strategies showed aggregate improvements of 4.9% in semantic relevance, 12.1% in lexical coverage, and 9.9% in factual consistency over traditional RAG. Further integration of DSPy led to an additional 10.8% boost in linguistic fluency and a 9.0% gain in factual alignment. Among the evaluated models, Gemini-1.5-Pro combined with RAG Fusion and DSPy produced the most fluent and factually accurate responses, demonstrating the effectiveness of combining hybrid retrieval with LLM-driven reasoning for query-based feedback response system.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3588337",
            "Date of Publication": "11 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Buchepalli Praneeth",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Mohana",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Eshitha Chowdary Nattem",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Kamala Jetti",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "B. K. Kavyashree",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "D. Rakshitha",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "P. Ramakanth Kumar",
                "labs": [
                    "Department of Computer Science and Engineering, R. V. College of Engineering, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "K. Sreelakshmi",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, R. V. College of Engineering, Bengaluru, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Retrieval augmented generation",
                "Reviews",
                "Accuracy",
                "Semantics",
                "Vectors",
                "Large language models",
                "Cognition",
                "Databases",
                "Surveys",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "Customer reviews",
                "GPT-3.5-Turbo",
                "LangChain",
                "LLM",
                "Llama-3-8B-Instruct-Lite",
                "Gemini-1.5-Pro",
                "RAG",
                "DSPy",
                "BM25",
                "BERT",
                "RAG fusion",
                "hierarchical chunk retrieval"
            ]
        }
    },
    {
        "Title": "Multilingual Low-Latency Emergency VoIP System Using LLM for Speech Reconstruction and Blockchain for Secure Data Archiving",
        "Link": "https://ieeexplore.ieee.org/document/11130186/",
        "Abstract": "Emergency VoIP communications frequently suffer from packet loss, jitter, and background noise, which degrade speech quality, delay dispatcher response, and threaten the reliability of emergency services. This paper presents a blockchain-governed, low-latency communication response framework powered by a Large Language Model (LLM), leveraging GPT-4o-mini for semantic speech reconstruction and dynamic emergency prioritization. The proposed architecture integrates multilingual speech-to-text and translation via Google APIs, a Facebook AI Similarity Search (FAISS)-indexed retrieval system for context-driven LLM inference, and severity classification for dispatcher triaging. To ensure tamper-proof data governance, the system incorporates AES-256-CBC encryption, Shamir’s Secret Sharing, and decentralized transcript storage on Arweave, with access mediated by Solana-based multi-signature wallets and program-derived addresses. Quantitative evaluations confirm that the proposed framework meets low-latency standards with sub-1.5 second one-way latency—significantly outperforming prior VoIP-based multilingual emergency systems, which typically report 3–5 second delays. Unlike conventional pipelines, it leverages asynchronous blockchain storage and optimized LLM-driven reconstruction to achieve high responsiveness without sacrificing Conceptual Precision, BLEU, or ROUGE accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3600364",
            "Date of Publication": "19 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahman A. Rafi",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Shakil Ahmed",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Danush Venkateshperumal",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Ashfaq Khokhar",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Md Arifuzzaman",
                "labs": [
                    "Department of Civil and Environmental Engineering, King Faisal University, Al Hofuf, Saudi Arabia"
                ]
            },
            {
                "name": "Akm Azad",
                "labs": [
                    "Department of Mathematics and Statistics, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Salem A. Alyami",
                "labs": [
                    "Department of Mathematics and Statistics, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multilingual",
                "Cryptography",
                "Low latency communication",
                "Packet loss",
                "Encryption",
                "Translation",
                "Emergency services",
                "Blockchains",
                "Medical services",
                "Speech enhancement"
            ],
            "Author Keywords": [
                "LLM",
                "emergency communications",
                "speech reconstruction",
                "call prioritization",
                "VoIP",
                "packet loss",
                "multilingual support",
                "secure storage system"
            ]
        }
    },
    {
        "Title": "An LLM-Driven Chatbot in Higher Education for Databases and Information Systems",
        "Link": "https://ieeexplore.ieee.org/document/10706931/",
        "Abstract": "Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language model (LLM) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.",
        "Details": {
            "DOI": "10.1109/TE.2024.3467912",
            "Date of Publication": "07 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Education"
        },
        "issn_info": {
            "Print ISSN": "0018-9359",
            "Electronic ISSN": "1557-9638"
        },
        "authors_data": [
            {
                "name": "Alexander Tobias Neumann",
                "labs": [
                    "Department of Computer Science 5, RWTH Aachen University, Aachen, Germany"
                ]
            },
            {
                "name": "Yue Yin",
                "labs": [
                    "Department of Computer Science 5, RWTH Aachen University, Aachen, Germany"
                ]
            },
            {
                "name": "Sulayman Sowe",
                "labs": [
                    "Department of Computer Science 5, RWTH Aachen University, Aachen, Germany",
                    "Data Science and Artificial Intelligence Department, Fraunhofer Institute for Applied Information Technology, Sankt Augustin, Germany"
                ]
            },
            {
                "name": "Stefan Decker",
                "labs": [
                    "Department of Computer Science 5, RWTH Aachen University, Aachen, Germany",
                    "Fraunhofer Institute for Applied Information Technology, Sankt Augustin, Germany"
                ]
            },
            {
                "name": "Matthias Jarke",
                "labs": [
                    "Department of Computer Science 5, RWTH Aachen University, Aachen, Germany",
                    "Fraunhofer Institute for Applied Information Technology, Sankt Augustin, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Education",
                "Computer science",
                "Databases",
                "Accuracy",
                "Mentoring",
                "Information technology",
                "Information systems",
                "Adaptation models",
                "Vectors"
            ],
            "Author Keywords": [
                "Chatbots",
                "higher education",
                "large language model (LLM)",
                "moodle",
                "moodlebot"
            ]
        }
    },
    {
        "Title": "LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations",
        "Link": "https://ieeexplore.ieee.org/document/10758652/",
        "Abstract": "This study explores whether large language models (LLMs) can learn a person’s opinions from their speech and act based on that knowledge. It also proposes the potential for utilizing such trained models in survey research. Traditional survey research collects information through standardized questions. However, surveys require repeated administration with new participants each time, which involves significant costs and time. With the recent advancements in LLMs, artificial intelligence (AI) has shown remarkable capabilities, often surpassing humans in tasks that require natural language understanding (NLU) and natural language generation (NLG). Despite this, research on whether AI can replicate human thought processes in tasks such as text interpretation or question-answering remains insufficient. This study proposes a Surveyed LLM, specialized for survey tasks, and a Doppelganger LLM that mimics human thought processes. It tests to what extent the Doppelganger model can replicate human judgment. Furthermore, it suggests the possibility of mimicking not only group distributions but also individual opinions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3502219",
            "Date of Publication": "20 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Suhyun Cho",
                "labs": [
                    "Department of Applied Artificial Intelligence, Sungkyunkwan University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jaeyun Kim",
                "labs": [
                    "AI Model Development, Dareesoft, Seongnam-si, Republic of Korea"
                ]
            },
            {
                "name": "Jang Hyun Kim",
                "labs": [
                    "Department of Applied Artificial Intelligence, Sungkyunkwan University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Mathematical models",
                "Data models",
                "Training",
                "Artificial intelligence",
                "Computational modeling",
                "Predictive models",
                "Adaptation models",
                "Oral communication",
                "Costs"
            ],
            "Author Keywords": [
                "LLM",
                "survey research",
                "NLP",
                "NLU",
                "synthetic data"
            ]
        }
    },
    {
        "Title": "Design and Evaluation of an LLM-Based Agent for QoT Estimation and Performance Optimization in Optical Networks",
        "Link": "https://ieeexplore.ieee.org/document/11157742/",
        "Abstract": "The rapid expansion of optical networks has catalyzed the growth of data capacity, creating a new era of high-speed network services. However, as the scale and complexity of nodes and connections increase, coupled with increasingly stringent demands for service efficiency, quality, and resistance to interference, intelligent solutions are needed to achieve efficient and autonomous network operation and maintenance. In this study, we proposed an advanced artificial intelligence (AI) Agent empowered by large language model (LLM), aimed at providing a practical solution for autonomous optical network management. We leverage the powerful language processing and reasoning capabilities of the Generative Pre-trained Transformer (GPT-4), and integrate domain-specific knowledge and optical network tools to simplify maintenance workflows, reduce manual intervention, and improve operational efficiency. Acting as an intelligent assistant for optical network operations, the AI Agent is capable of providing real-time insights and optimization recommendations. In particular, we focus on four typical tasks: quality of transmission (QoT) estimation, performance analysis, optimization, and parameter calibration for physical-layer modeling, which are essential for ensuring service reliability and resource efficiency. Through the design, implementation, and evaluation of these tasks, we demonstrate the feasibility and effectiveness of the proposed agent in addressing key challenges of optical network maintenance. Furthermore, we provide an assessment of accuracy and reliability based on a predetermined scoring standard. The proposed solution not only enhances automation in network monitoring and optimization, but also provides a scalable and generalizable framework for LLM-based support in evolving optical transport environments.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2025.3608290",
            "Date of Publication": "10 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Yao Zhang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yuchen Song",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yue Pang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Shengnan Li",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Xiaotian Jiang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yidi Wang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Jin Li",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Min Zhang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Danshi Wang",
                "labs": [
                    "State Key Laboratory of Information Photonics and Optical Communications, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical fiber networks",
                "Estimation",
                "Artificial intelligence",
                "Quality of transmission",
                "Optimization",
                "Maintenance",
                "Knowledge engineering",
                "Knowledge based systems",
                "Resource management",
                "Cognition"
            ],
            "Author Keywords": [
                "Large language model",
                "LLM-enabled AI Agent",
                "autonomous optical network",
                "QoT estimation",
                "network optimization"
            ]
        }
    },
    {
        "Title": "LLM-Based Persona-Driven Text Data Augmentation",
        "Link": "https://ieeexplore.ieee.org/document/11170443/",
        "Abstract": "Illicit online communication, such as drug-dealing dialogues, is increasingly conducted through covert, context dependent language patterns that evade traditional detection techniques in South Korea. However, developing reliable AI based detection systems remains challenging due to the scarcity of real world training data in such sensitive domains. This paper proposes a novel persona-driven data augmentation framework using Large Language Model(LLM) to generate realistic synthetic drug-dealing dialogues. By encoding domain specific buyer and seller personas along with linguistic behaviour rules, the method produces contextually coherent and semantically diverse dialogues that reflect authentic communication styles. Evaluation results demonstrate that the augmented data preserves key stylistic features (high cosine similarity), maintains lexical diversity (TTR), improves fluency (perplexity), and enhances coherence and lexical richness (ROUGE-L), outperforming traditional augmentation method. Furthermore, statistical validation confirms the semantic consistency and stability of the generated data. These findings highlight the viability of LLM-based augmentation in low-resource, high-risk domains and suggest its potential transferability to other specialized NLP applications requiring context-preserving generation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611636",
            "Date of Publication": "18 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyeon Seong Jeong",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Han Kyeong Ko",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Soo Yong Park",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Taehoon Kim",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Data models",
                "Translation",
                "Linguistics",
                "Semantics",
                "Drugs",
                "Planning",
                "Ontologies",
                "Knowledge graphs",
                "Training data"
            ],
            "Author Keywords": [
                "Data augmentation",
                "dialogue systems",
                "illicit communications",
                "large language model (LLM)",
                "persona modelling"
            ]
        }
    },
    {
        "Title": "LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10670495/",
        "Abstract": "Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced.",
        "Details": {
            "DOI": "10.1109/TVCG.2024.3456354",
            "Date of Publication": "10 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Visualization and Computer Graphics"
        },
        "issn_info": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "authors_data": [
            {
                "name": "Minsuk Kahng",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Ian Tenney",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Mahima Pushkarna",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Michael Xieyang Liu",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "James Wexler",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Emily Reif",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Krystal Kallarackal",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Minsuk Chang",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Michael Terry",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            },
            {
                "name": "Lucas Dixon",
                "labs": [
                    "Google Research (now with Google DeepMind), USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet",
                "Analytical models",
                "Pipelines",
                "Large language models",
                "Oral communication",
                "Numerical models",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Visual analytics",
                "large language models",
                "model evaluation",
                "responsible AI",
                "machine learning interpretability"
            ]
        }
    },
    {
        "Title": "BALI—A Benchmark for Accelerated Language Model Inference",
        "Link": "https://ieeexplore.ieee.org/document/11026002/",
        "Abstract": "The rise of Large Language Models (LLMs) has revolutionized natural language processing, enabling advancements across diverse applications, including chatbots, live translators, content generation, virtual assistants, and domain-specific automation tools. These applications rely on real-time or near-real-time responses to process sequential LLM requests, creating a critical demand for efficient and accelerated inference. These developments have led to numerous frameworks optimizing inference speed and resource utilization. However, they are often mutually incomparable or are inadequately described due to the lack of standardized benchmarks. Consequently, there is a notable lack of comparison frameworks due to the vast configuration space, bounded factors such as hardware specifications, inference framework parameters, and dataset variations. We propose BALI, an open-source Benchmark for Accelerated Language Model Inference, aiming to provide comprehensive analysis and standardized evaluation metrics to enhance the comparability of LLM performance across configurations. With BALI, we propose substantial measurements to evaluate and rank the efficiency of LLM frameworks across multiple aspects, including sequential decoding, parallelization, and setup efficiency. We show results for mainly small to medium-size models (1-30B parameters) in a sequential or non-batched setup, which is highly relevant for various real-time LLM applications. These observations reveal that the design decisions for such a framework constitute an application-dependent and multidimensional challenge. Thus, our objective is to provide LLM an inference benchmark with a clearly defined evaluation, incorporating multidimensional criteria to provide comparable performance assessments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3576898",
            "Date of Publication": "05 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lena Jurkschat",
                "labs": [
                    "Center for Interdisciplinary Digital Sciences (CIDS), ScaDS.AI Dresden/Leipzig, Technische Universität Dresden, Dresden, Germany"
                ]
            },
            {
                "name": "Preetam Gattogi",
                "labs": [
                    "Center for Interdisciplinary Digital Sciences (CIDS), ScaDS.AI Dresden/Leipzig, Technische Universität Dresden, Dresden, Germany"
                ]
            },
            {
                "name": "Sahar Vahdati",
                "labs": [
                    "Center for Interdisciplinary Digital Sciences (CIDS), ScaDS.AI Dresden/Leipzig, Technische Universität Dresden, Dresden, Germany"
                ]
            },
            {
                "name": "Jens Lehmann",
                "labs": [
                    "Center for Interdisciplinary Digital Sciences (CIDS), ScaDS.AI Dresden/Leipzig, Technische Universität Dresden, Dresden, Germany",
                    "Amazon (work done outside of Amazon), Dresden, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Benchmark testing",
                "Pipelines",
                "Hardware",
                "Load modeling",
                "Data models",
                "Tokenization",
                "Loading",
                "Decoding",
                "Costs",
                "Real-time systems"
            ],
            "Author Keywords": [
                "LLM inference",
                "transformer decoder",
                "LLM inference benchmarking",
                "generation speed",
                "performance analysis",
                "inference standardization"
            ]
        }
    },
    {
        "Title": "LLM-Driven APT Detection for 6G Wireless Networks: A Systematic Review and Taxonomy",
        "Link": "https://ieeexplore.ieee.org/document/11112774/",
        "Abstract": "Sixth Generation (6G) wireless networks, which are expected to be deployed in the 2030s, have already created great excitement in academia and the private sector with their extremely high communication speed and low latency rates. However, despite the ultra-low latency, high throughput, and AI-assisted orchestration capabilities they promise, they are vulnerable to stealthy and long-term Advanced Persistent Threats (APTs). Large Language Models (LLMs) stand out as an ideal candidate to fill this gap with their high success in semantic reasoning and threat intelligence. This paper presents the first systematic review and taxonomy for LLM-assisted APT detection in 6G networks. It also provides insights by reviewing recent research on the intersection of LLMs, APTs, and 6G. Key challenges such as limitations in edge deployment, data scarcities, and explainability gaps are identified and a multidimensional taxonomy is provided in line with the APT lifecycle and 6G contexts. The paper is based on 142 studies from 2018 to 2025, searching leading databases such as IEEE Xplore, ACM Digital Library, SpringerLink, and Elsevier ScienceDirect.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595665",
            "Date of Publication": "05 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammed Golec",
                "labs": [
                    "Department of Computer Engineering, Boğaziçi University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Yaser Khamayseh",
                "labs": [
                    "College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Suhib Bani Melhem",
                "labs": [
                    "Department of Cybersecurity, College of Engineering, Al Ain University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Abdulmalik Alwarafy",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "6G mobile communication",
                "Surveys",
                "Taxonomy",
                "Systematic literature review",
                "Wireless networks",
                "Systematics",
                "Semantics",
                "Image edge detection",
                "Threat assessment",
                "Reproducibility of results"
            ],
            "Author Keywords": [
                "6G wireless networks",
                "advanced persistent threat (APT)",
                "large language model (LLM)",
                "natural language processing (NLP)",
                "security"
            ]
        }
    },
    {
        "Title": "TriP-LLM: A Tri-Branch Patch-Wise Large Language Model Framework for Time-Series Anomaly Detection",
        "Link": "https://ieeexplore.ieee.org/document/11175692/",
        "Abstract": "Time-series anomaly detection plays a central role across a wide range of application domains. With the increasing proliferation of the Internet of Things (IoT) and smart manufacturing, time-series data has dramatically increased in both scale and dimensionality. This growth has exposed the limitations of traditional statistical methods in handling the high heterogeneity and complexity of such data. Inspired by the recent success of large language models (LLMs) in multimodal tasks across language and vision domains, we propose a novel unsupervised anomaly detection framework: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection (TriP-LLM). TriP-LLM integrates local and global temporal features through a triple-branch design comprising Patching, Selecting, and Global modules, to encode the input time-series into patch-wise representations, which are then processed by a frozen, pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from which anomaly scores are derived. We evaluate TriP-LLM on several public benchmark datasets using PATE, a recently proposed threshold-free evaluation metric, and conduct all comparisons within a unified open-source framework to ensure fairness. Experimental results show that TriP-LLM consistently outperforms recent state-of-the-art (SOTA) methods across all datasets, demonstrating strong detection capabilities. Furthermore, through extensive ablation studies, we verify the substantial contribution of the LLM to the overall architecture. Compared to LLM-based approaches using Channel Independence (CI) patch processing, TriP-LLM achieves significantly lower memory consumption, making it more suitable for GPU memory-constrained environments. All code and model checkpoints of TriP-LLM are publicly available on https://github.com/YYZStart/TriP-LLM.git",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613663",
            "Date of Publication": "23 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuan-Cheng Yu",
                "labs": [
                    "Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Yen-Chieh Ouyang",
                "labs": [
                    "Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Chun-An Lin",
                "labs": [
                    "Department of Electrical Engineering, National Chung Hsing University, Taichung, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Transformers",
                "Forecasting",
                "Large language models",
                "Decoding",
                "Long short term memory",
                "Logic gates",
                "Feature extraction",
                "Predictive models",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Anomaly detection",
                "multivariate time-series",
                "large language models"
            ]
        }
    },
    {
        "Title": "A Framework for LLM-Assisted Smart Policing System",
        "Link": "https://ieeexplore.ieee.org/document/10538107/",
        "Abstract": "In the face of rapidly increasing crime rates, the evolving complexity of crime data processing, and public safety challenges, the need for more advanced policing solutions has increased leading to the emergence of smart policing systems and predictive policing techniques. This urgency and shift toward smart policing incorporates artificial intelligence (AI), with a specific focus on machine learning (ML) as an essential tool for data analysis, pattern recognition, and proactive crime forecasting. Among these, the flexibility and power of AI techniques including large language models (LLMs), as a subset of generative AI, have increased the interest in applying them in real-world applications, such as financial, medical, legal, and agricultural applications. However, the abilities and possibilities of adopting LLMs in applications including crime prediction remain unexplored. This paper focuses on bridging this gap by developing a framework based on the transformative potential of BART, GPT-3, and GPT-4, three state-of-the-art LLMs, in the domain of smart policing, specifically, crime prediction. As a prototype, diverse methods such as zero-shot prompting, few-shot prompting, and fine-tuning are used to comprehensively assess the performance of these models in crime prediction based on state-of-the-art datasets from two major cities: San Francisco and Los Angeles. The main objective is to illuminate the adaptability of LLMs and their capacity to revolutionize crime analysis practices. Additionally, a comparative analysis of the aforementioned methods on the GPT series model and BART with ML techniques is provided which shows that the GPT models are more suitable than the traditional ML models for crime classification in most experimental scenarios.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3404862",
            "Date of Publication": "23 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Paria Sarzaeim",
                "labs": [
                    "Department of Electrical, Computer, and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            },
            {
                "name": "Qusay H. Mahmoud",
                "labs": [
                    "Department of Electrical, Computer, and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            },
            {
                "name": "Akramul Azim",
                "labs": [
                    "Department of Electrical, Computer, and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Predictive models",
                "Task analysis",
                "Law enforcement",
                "Data models",
                "Artificial intelligence",
                "Recurrent neural networks",
                "Adaptation models",
                "Few-shot learning",
                "Large language models"
            ],
            "Author Keywords": [
                "Crime prediction",
                "fine-tuning",
                "few-shot prompting",
                "large language models",
                "LLM",
                "zero-shot prompting"
            ]
        }
    },
    {
        "Title": "ACOM: Arabic Comparative Opinion Mining in Social Media Utilizing Word Embedding, Deep Learning Model, & LLM-GPT",
        "Link": "https://ieeexplore.ieee.org/document/10707272/",
        "Abstract": "Reliance on social networks has become an integral part of modern daily activities. Social networks are crowded with vast numbers of comments, opinions, and beliefs about different aspects of people’s daily lives. Opinions can directly express positive or negative perspectives toward a specific entity or its aspects, or they can be comparative opinions that present the differences or similarities between two or more entities, such as “product A is better than product B.” Comparative opinions have significant potential to offer new opportunities across various fields such as marketing, education, and e-commerce. Thus, analyzing comparative opinions is essential. Indeed, comparative opinion mining has been applied in several languages, including Arabic. Nevertheless, comparative opinion mining in Arabic is still in its early stages and requires more contributions and investigations. Therefore, this work introduces the ACOM approach for Arabic Comparative Opinion Mining. First, we collected the ACOM corpus in Arabic from the X platform, focusing on comparative opinions in the technology domain. This paper provides a benchmark comparison of several deep-learning models by employing different approaches, including Long Short-Term Memory (LSTM), Bidirectional LSTMs (BiLSTM), and Convolutional Neural Networks (CNN). In the deep learning model, the generated representation vector was used to construct the embedding layer as the first layer. To this end, we adopted two pretrained word embedding techniques to investigate their effectiveness on the ACOM corpus: Word2vec and Bidirectional Encoder Representations from Transformers (BERT). The main highlight of this paper is leveraging the most advanced innovation in AI, the GPT-3 model, as a classifier model. Our experimental results show that BERT and BiLSTM achieved impressive performance on the ACOM task with 91% accuracy and a 90% F1-score. Additionally, this paper discusses the impact of fine-tuning specific hyperparameters by providing a comprehensive examination.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3476336",
            "Date of Publication": "08 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Afnan A. Bayazed",
                "labs": [
                    "Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Hana Almagrabi",
                "labs": [
                    "Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Dimah Alahmadi",
                "labs": [
                    "Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Hanan S. Alghamdi",
                "labs": [
                    "Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Social networking (online)",
                "Reviews",
                "Machine learning algorithms",
                "Linguistics",
                "Feature extraction",
                "Deep learning",
                "Web sites",
                "Video on demand",
                "Large language models",
                "User experience",
                "Convolutional neural networks",
                "Electronic commerce"
            ],
            "Author Keywords": [
                "Opinion mining",
                "comparative opinion mining",
                "deep learning",
                "word embedding",
                "LLM",
                "GPT"
            ]
        }
    },
    {
        "Title": "Meme Analysis Using LLM-Based Contextual Information and U-Net Encapsulated Transformer",
        "Link": "https://ieeexplore.ieee.org/document/10589379/",
        "Abstract": "A meme is social media content with which the creator tries to convey a certain idea in public via the internet. Each meme consists of typically an image and supporting text. Its message can be humorous and inspiring, but hilarious and offensive often targeting a specific audience. To address the potential harm such memes can cause, Artificial Intelligence researchers have proposed solutions to classify a meme automatically according to the sentiment, emotion, and intensity felt by the users. Recent models for meme analysis often adopt the Transformer architecture, which is known to perform well but computationally expensive. The present study aims to introduce a novel method by providing (1) deep contextual information and (2) reducing resource utilization while keeping its efficiency. For the former, GPT-4 has been utilized to provide meaningful insights regarding the context behind the meme. For the latter, we extract Keyphrases and forward them to a U-net Encapsulated Transformer, called UET, to process the information. Extensive evaluation with ablation study using three standard meme datasets, i.e. Memotions, suggests that it outperforms state-of-the-art models on sentiment analysis, while it shows comparable performance on the emotion and intensity task. As the proposed model is more lightweight than a standard one and yet shows high performance, it provides new insights into meme analysis and could be useful for other Natural Language Processing tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3424883",
            "Date of Publication": "08 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marvin John Ignacio",
                "labs": [
                    "Department of Computer Engineering, Sejong University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Thanh Tin Nguyen",
                "labs": [
                    "Department of Computer Science and Software Engineering, Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Hulin Jin",
                "labs": [
                    "School of Computer Science and Technology, Anhui University, Hefei, China"
                ]
            },
            {
                "name": "Yong-Guk Kim",
                "labs": [
                    "Department of Computer Engineering, Sejong University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Context modeling",
                "Computational modeling",
                "Task analysis",
                "Predictive models",
                "Feature extraction",
                "Visualization",
                "Sentiment analysis",
                "Social networking (online)",
                "Memetics",
                "Large language models"
            ],
            "Author Keywords": [
                "LLM",
                "memes",
                "memotion datasets",
                "sentiment",
                "transformer",
                "U-net"
            ]
        }
    },
    {
        "Title": "LLM-Based Topic Modeling for Dark Web Q&A Forums: A Comparative Analysis With Traditional Methods",
        "Link": "https://ieeexplore.ieee.org/document/10964219/",
        "Abstract": "Topic modeling is a critical tool for understanding the thematic structures of unstructured text data, particularly in specialized domains like the dark web. This study compares the effectiveness of large language models (LLMs) and traditional topic modeling techniques in analyzing dark web Q&A forums, characterized by short, informal, and context-specific posts. We evaluate two LLMs—GPT and Gemini—against traditional methods, TF-IDF (scikit-learn) and Latent Dirichlet Allocation (LDA, Gensim), in their ability to generate meaningful and coherent topics. Our findings suggest that LLMs consistently outperform traditional methods, capturing contextually relevant themes such as “scam,” “bitcoin,” and “hacking” with an average semantic similarity score of 0.724 between GPT and Gemini, compared to 0.477 with Gensim. Additionally, LLMs produced significantly lower Levenshtein distances, with an average of 13.49 between GPT and Gemini, compared to 18.22 with scikit-learn and 17.97 with Gensim, indicating greater alignment in topic extraction. In exploring the impact of topic granularity, we found that while single-word topics effectively capture the main themes of dark web discussions, two-word topics provide additional context and specificity, enhancing the interpretability of complex discussions. For instance, topics like “bitcoin wallet” and “hacking tools” illustrate how two-word labels can convey nuanced meanings that single-word topics may overlook. This qualitative analysis underscores the importance of selecting appropriate topic modeling techniques based on the characteristics of the text and the requirements of the analysis, highlighting their potential as valuable tools for analyzing complex and unstructured text data in practical applications for law enforcement and research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3560543",
            "Date of Publication": "14 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Luis de-Marcos",
                "labs": [
                    "Department of Computer Science, University of Alcalá, Alcalá de Henares, Madrid, Spain"
                ]
            },
            {
                "name": "Adrián Domínguez-Díaz",
                "labs": [
                    "Department of Computer Science, University of Alcalá, Alcalá de Henares, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Dark Web",
                "Analytical models",
                "Translation",
                "Semantics",
                "Large language models",
                "Context modeling",
                "Chatbots",
                "Social networking (online)",
                "Sentiment analysis",
                "Resource management"
            ],
            "Author Keywords": [
                "Dark web",
                "dark content",
                "topic modeling",
                "forum",
                "LLM",
                "ChatGPT",
                "Gemini"
            ]
        }
    },
    {
        "Title": "TURSpider: A Turkish Text-to-SQL Dataset and LLM-Based Study",
        "Link": "https://ieeexplore.ieee.org/document/10753591/",
        "Abstract": "This paper introduces TURSpider, a novel Turkish Text-to-SQL dataset developed through human translation of the widely used Spider dataset, aimed at addressing the current lack of complex, cross-domain SQL datasets for the Turkish language. TURSpider incorporates a wide range of query difficulties, including nested queries, to create a comprehensive benchmark for Turkish Text-to-SQL tasks. The dataset enables cross-language comparison and significantly enhances the training and evaluation of large language models (LLMs) in generating SQL queries from Turkish natural language inputs. We fine-tuned several Turkish-supported LLMs on TURSpider and evaluated their performance in comparison to state-of-the-art models like GPT-3.5 Turbo and GPT-4. Our results show that fine-tuned Turkish LLMs demonstrate competitive performance, with one model even surpassing GPT-based models on execution accuracy. We also apply the Chain-of-Feedback (CoF) methodology to further improve model performance, demonstrating its effectiveness across multiple LLMs. This work provides a valuable resource for Turkish NLP and addresses specific challenges in developing accurate Text-to-SQL models for low-resource languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3498841",
            "Date of Publication": "15 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ali Bugra Kanburoglu",
                "labs": [
                    "Department of Computer Engineering, Işık University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Faik Boray Tek",
                "labs": [
                    "Department of Artificial Intelligence and Data Engineering, Istanbul Technical University, Istanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Structured Query Language",
                "Accuracy",
                "Error analysis",
                "Large language models",
                "Benchmark testing",
                "Cognition",
                "Encoding"
            ],
            "Author Keywords": [
                "Text-to-SQL",
                "LLM",
                "large language models",
                "Turkish",
                "dataset",
                "TURSpider"
            ]
        }
    },
    {
        "Title": "MSCH: Microbatch-Based Selective Activation Checkpointing With Recomputation Hidden for Efficient Training of LLM Models",
        "Link": "https://ieeexplore.ieee.org/document/10670415/",
        "Abstract": "Activation checkpointing is a widely-used technique to reduce GPU memory consumption during model training. While it helps to conserve memory, it introduces additional computational load. Existing solutions such as selective activation checkpointing (SAC) and microbatch-based selective recomputation (MSC) are not always available and effective at improving training efficiency. In this paper, we propose a novel method called microbatch-based selective activation checkpointing with recomputation hidden (MSCH). MSCH provides a more flexible and effective utilization of the remaining GPU memory after deployment of all activation checkpointing. This minimizes the need to recalculate activations from a microbatch perspective. In addition, we first discovered the challenging “bottleneck” effect and “misalignment” phenomenon in pipeline parallelism scheduling. To address this, we designed a novel multi-stage micro-batch recalculation schedule that hiding activation recalculation at each stage by the “bottleneck” stage thereby effectively improves model training efficiency. Our code is available by https://github.com/CSlearnerZM/MSCH-DeepSpeed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3456788",
            "Date of Publication": "10 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cheng Zhang",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Minjun Yu",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Li Yu",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China",
                    "Artificial Intelligence and Smart Operation Center, Research Institute of China Mobile Communications Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Pengyu Cong",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China",
                    "Artificial Intelligence and Smart Operation Center, Research Institute of China Mobile Communications Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Yuchao Yan",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Jie Bao",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Jian Jiang",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Xiaozheng Wang",
                "labs": [
                    "Zhejiang Mobile Communications Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Xiaolong Ye",
                "labs": [
                    "Platform Capability Research and Development Department, China Mobile (Zhejiang) Innovation Research Institute Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Tao Tang",
                "labs": [
                    "Zhejiang Mobile Communications Company Ltd., Hangzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Liang Xiao",
                "labs": [
                    "Zhejiang Mobile Communications Company Ltd., Hangzhou, Zhejiang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Checkpointing",
                "Training",
                "Memory management",
                "Transformers",
                "Partitioning algorithms",
                "Parallel processing",
                "Large language models"
            ],
            "Author Keywords": [
                "Activation checkpointing",
                "Deepspeed",
                "large language model (LLM) training",
                "Megatron",
                "selective checkpointing",
                "one forward pass followed by one backward pass (1F1B)"
            ]
        }
    },
    {
        "Title": "LLM Agentic Workflow for Automated Vulnerability Detection and Remediation in Infrastructure-as-Code",
        "Link": "https://ieeexplore.ieee.org/document/10965635/",
        "Abstract": "This paper presents a multi-agent, AI-driven strategy employing Large Language Models (LLMs), retrieval-augmented generation, and a continuously updated knowledge base for the detection and remediation of security vulnerabilities win cloud frameworks. By examining Infrastructure as Code (IaC) templates alongside pertinent best-practice snippets, the system discerns context-specific misconfigurations commonly overlooked by static tools, achieving a detection rate of 85% with some occurrences of false positives. Automated remediation guidance, anchored in current security standards, provides actionable solutions that seamlessly integrate into standard continuous integration/continuous development (CI/CD) workflows. Experimental results indicate the solution’s efficacy and scalability, heralding a proactive, context-aware approach to IaC security.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3560911",
            "Date of Publication": "15 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dheer Toprani",
                "labs": [
                    "College of Computing, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Vijay K. Madisetti",
                "labs": [
                    "School of Cybersecurity and Privacy, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Retrieval augmented generation",
                "Static analysis",
                "Runtime",
                "Best practices",
                "Vectors",
                "Scalability",
                "Large language models",
                "Cognition",
                "Organizations"
            ],
            "Author Keywords": [
                "Infrastructure-as-code",
                "large language models",
                "vulnerability detection",
                "security automation",
                "CI/CD",
                "LLM workflows"
            ]
        }
    },
    {
        "Title": "Beekeeper: Accelerating Honeypot Analysis With LLM-Driven Feedback",
        "Link": "https://ieeexplore.ieee.org/document/11175384/",
        "Abstract": "Honeypots are decoy resources intended to entice adversaries and collect threat intelligence in the process. The amount and quality of the collected insights strongly correlate with the honeypot’s credibility to the adversary. However, the development of medium to high interaction honeypots, so, environments that offer at minimum a shell to the attacker, is laborious and complex. Additionally, getting feedback on a honeypot is often expensive and time-consuming, slowing down development and discouraging investment into honeypots. Therefore, we propose Beekeeper: a modular framework that combines static tests, known attack sequences, and automated, large language model based querying to investigate medium to high interaction honeypots. Afterward, the results are analyzed to provide feedback on the current state of the system and recommendations on how to improve key characteristics of the honeypot. To demonstrate the framework’s functionalities, we deploy Beekeeper with two medium and one high interaction systems and highlight how feedback and recommendations change after an initial set of improvements is implemented for each honeypot.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613118",
            "Date of Publication": "22 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Niclas Ilg",
                "labs": [
                    "Bosch Research, Renningen, Germany",
                    "Chair of Communication Networks, University of Tuebingen, Tuebingen, Germany"
                ]
            },
            {
                "name": "Dominik Germek",
                "labs": [
                    "Bosch Research, Hildesheim, Germany"
                ]
            },
            {
                "name": "Paul Duplys",
                "labs": [
                    "Robert Bosch GmbH, Sector Mobility, Ludwigsburg, Germany"
                ]
            },
            {
                "name": "Michael Menth",
                "labs": [
                    "Chair of Communication Networks, University of Tuebingen, Tuebingen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Botnet",
                "Penetration testing",
                "Malware",
                "Automation",
                "Servers",
                "Large language models",
                "Costs",
                "Testing",
                "System recovery"
            ],
            "Author Keywords": [
                "Automation",
                "beekeeper",
                "feedback",
                "honeypots",
                "LLM"
            ]
        }
    },
    {
        "Title": "A Survey on the Scheduling of DL and LLM Training Jobs in GPU Clusters",
        "Link": "https://ieeexplore.ieee.org/document/11060018/",
        "Abstract": "As deep learning (DL) technology rapidly advances in areas such as computer vision, natural language processing, and more recently, large language models (LLMs), the demand for computing resources has increasingly grown. In particular, scheduling deep learning training (DLT) jobs on graphics processing unit (GPU) clusters has become crucial for the effective utilization of computing resources and the acceleration of model training processes. However, resource management and scheduling in GPU clusters face challenges related to computing and communication, including job sharing, interference, elastic scheduling, heterogeneous resources, and fairness. This survey investigates the scheduling issues of DLT jobs in GPU clusters, focusing on scheduling optimizations at the job characteristic and cluster resource levels. We analyze the structure and training computing characteristics of traditional DL models and LLMs, as well as their requirements for iterative computation, communication, GPU sharing, and resource elasticity. In addition, we compare the main contributions of this survey with related reviews and discuss research directions, including scheduling based on job characteristics and optimization strategies for cluster resources. This survey aims to provide researchers and practitioners with a comprehensive understanding of DLT job scheduling in GPU clusters and to point out directions for future research.",
        "Details": {
            "DOI": "10.23919/cje.2024.00.070",
            "Date of Publication": "May 2025",
            "Publisher": "CIE",
            "Published In": "Chinese Journal of Electronics"
        },
        "issn_info": {
            "Electronic ISSN": "2075-5597",
            "Print ISSN": "1022-4653"
        },
        "authors_data": [
            {
                "name": "Tianhao Fu",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Zehua Yang",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Zhisheng Ye",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Chenxiang Ma",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Yang Han",
                "labs": [
                    "Beiijng Research Institute, China Telecom Corporation Limited, Beijing, China"
                ]
            },
            {
                "name": "Yingwei Luo",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Xiaolin Wang",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Zhenlin Wang",
                "labs": [
                    "Department of Computer Science, Michigan Tech University, Houghton, MI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Surveys",
                "Deep learning",
                "Processor scheduling",
                "Reviews",
                "Large language models",
                "Computational modeling",
                "Graphics processing units",
                "Resource management",
                "Optimization"
            ],
            "Author Keywords": [
                "Scheduling optimization",
                "Deep learning (DL) training jobs",
                "Large language model (LLM)",
                "Job characteristic",
                "Graphics processing unit (GPU) cluster",
                "Cluster resource characteristic"
            ]
        }
    },
    {
        "Title": "Enhancing LLM Inference Performance on ARM CPUs Through Software and Hardware Co-Optimization Strategies",
        "Link": "https://ieeexplore.ieee.org/document/10994252/",
        "Abstract": "Large language models (LLMs) have exhibited remarkable performance across a broad spectrum of tasks, yet their extensive computational and memory requirements present substantial challenges for deployment in resource-constrained scenarios. To address the challenges, this work introduces software and hardware co-optimization strategies aimed at enhancing the inference performance of LLMs on ARM CPU-based platforms. A mixed-precision quantization technique is employed, preserving the precision of critical weights to maintain model accuracy while quantizing non-essential weights to INT8, thereby reducing the model's memory footprint. This work also capitalizes on the SIMD instruction set of ARM CPUs to efficiently process model data. Furthermore, the inference framework is optimized by fusing components of the attention computation and streamlining the dequantization process through modifications to the scaling factor. These enhancements result in a significant reduction in model memory usage and improved throughput during the prefill and decode stages. The efficacy of the proposed approach is demonstrated through the optimization of the Qwen-1.8B model on Armv9, with only a 0.66% decrease in accuracy and a reduction in memory usage to 58.8% of the baseline, while achieving a 4.09× and 15.23× increase in inference performance for the prefill and decode stages over the baseline, respectively.",
        "Details": {
            "DOI": "10.23919/ICS.2025.3568404",
            "Date of Publication": "08 May 2025",
            "Publisher": "SJTU",
            "Published In": "Integrated Circuits and Systems"
        },
        "issn_info": {
            "Print ISSN": "2995-1968"
        },
        "authors_data": [
            {
                "name": "Cheng Zhang",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Xingyu Zhu",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Longhao Chen",
                "labs": [
                    "Zhuoyue Honors College, Hangzhou Dianzi University, Hangzhou, China"
                ]
            },
            {
                "name": "Tingjie Yang",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Evens Pan",
                "labs": [
                    "Arm Technology Company, Ltd., Shanghai, China"
                ]
            },
            {
                "name": "Guosheng Yu",
                "labs": [
                    "T-HEAD Semiconductor Company, Ltd., Shanghai, China"
                ]
            },
            {
                "name": "Yang Zhao",
                "labs": [
                    "Department of Micro-Nano Electronics, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Xiguang Wu",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Bo Li",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Wei Mao",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            },
            {
                "name": "Genquan Han",
                "labs": [
                    "Hangzhou Institute of Technology, Xidian University, Hangzhou, China",
                    "School of Microelectronics, Xidian University, Xi'an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Computational modeling",
                "Hardware",
                "Software",
                "Accuracy",
                "Single instruction multiple data",
                "Registers",
                "Throughput",
                "Reduced instruction set computing",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Model compression",
                "mixed-precision quantization",
                "ARM CPUs",
                "SIMD optimization",
                "LLM inference performance"
            ]
        }
    },
    {
        "Title": "From Prompts to Motors: Man-in-the-Middle Attacks on LLM-Enabled Vacuum Robots",
        "Link": "https://ieeexplore.ieee.org/document/11108294/",
        "Abstract": "The integration of large language models (LLMs) into robotic platforms is transforming human–robot interaction by enabling more natural communication and adaptive task execution. However, this advancement also introduces new security vulnerabilities, particularly in networked environments. In this study, we present a systematic analysis of man-in-the-middle (MITM) attacks targeting an LLM-enabled vacuum robot. Our research follows a three-phase development process: 1) command-line simulation of LLM–robot interactions, 2) tabletop setup, and 3) implementation of a physical robot using a commercial vacuum platform enhanced with a Raspberry Pi–hosted ChatGPT application programming interface (API) and you only look once (YOLO, v8) object detection. We define a gray-box threat model in which an attacker can intercept, inject, and manipulate JavaScript object notation (JSON)-formatted messages exchanged between the robot and the LLM. We evaluate four attack scenarios, two based on prompt injection and two on output manipulation, across three LLM configurations (ChatGPT-4, ChatGPT-4o mini, and ChatGPT-3.5 Turbo). While prior work on LLM security assumes secure communication channels and overlooks network-level threats, our experimental results demonstrate that a remote attacker can bypass safety protocols, override motor commands, and deliver deceptive feedback to users, ultimately leading to unsafe robot behavior. These findings reveal a critical and underexplored attack surface in LLM-integrated robotic systems and highlight the urgent need for secure-by-design communication architectures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595424",
            "Date of Publication": "04 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Asif Shaikh",
                "labs": [
                    "Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Aygün Varol",
                "labs": [
                    "Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Johanna Virkki",
                "labs": [
                    "Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Collision avoidance",
                "Chatbots",
                "Vacuum systems",
                "Security",
                "Dogs",
                "Cameras",
                "Wireless fidelity",
                "Protocols",
                "Hardware"
            ],
            "Author Keywords": [
                "ChatGPT API",
                "large language models (LLMs)",
                "household robotics",
                "man-in-the-middle (MITM) attack",
                "prompt injection",
                "robotics security",
                "you only look once (YOLO) object detection"
            ]
        }
    },
    {
        "Title": "Evaluating Large Language Models for Enhanced Fuzzing: An Analysis Framework for LLM-Driven Seed Generation",
        "Link": "https://ieeexplore.ieee.org/document/10731701/",
        "Abstract": "Fuzzing is a crucial technique for detecting software defects by dynamically generating and testing program inputs. This study introduces a framework designed to assess the application of Large Language Models (LLMs) to automate the generation of effective seed inputs for fuzzing, particularly in the Python programming environment where traditional approaches are less effective. Utilizing the Atheris fuzzing framework, we created over 38,000 seed inputs from LLMs targeted at 50 Python functions from widely-used libraries. Our findings underscore the critical role of LLM selection in seed effectiveness. In certain cases, seeds generated by LLMs rivaled or surpassed traditional fuzzing campaigns, with a corpus of fewer than 100 LLM-generated entries outperforming over 100,000 conventionally produced inputs. These seeds significantly improved code coverage and instruction count during fuzzing sessions, illustrating the efficacy of our framework in facilitating an automated, scalable approach to evaluating LLM effectiveness. The results, validated through linear regression analysis, demonstrate that selecting the appropriate LLM based on its training and capabilities is essential for optimizing fuzzing efficiency and facilitates the testing of future LLM versions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3484947",
            "Date of Publication": "23 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gavin Black",
                "labs": [
                    "Department of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
                ]
            },
            {
                "name": "Varghese Mathew Vaidyan",
                "labs": [
                    "Department of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
                ]
            },
            {
                "name": "Gurcan Comert",
                "labs": [
                    "Benedict College, Columbia, SC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fuzzing",
                "Testing",
                "Large language models",
                "Python",
                "Codes",
                "Security",
                "Training",
                "Protocols",
                "Measurement",
                "Machine learning"
            ],
            "Author Keywords": [
                "Fuzzing",
                "machine learning",
                "large language models",
                "python"
            ]
        }
    },
    {
        "Title": "FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection",
        "Link": "https://ieeexplore.ieee.org/document/10721229/",
        "Abstract": "Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD’s superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482988",
            "Date of Publication": "17 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhi Qiang Wang",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Haopeng Wang",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Abdulmotaleb El Saddik",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",
                    "Department of Computer Vision, MBZUAI, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Adaptation models",
                "Threat assessment",
                "Tuning",
                "Security",
                "Organizations",
                "Costs",
                "Computational modeling",
                "Transfer learning",
                "Deep learning",
                "Computer security",
                "Data augmentation",
                "Artificial intelligence",
                "Machine learning"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "insider threat",
                "deep learning",
                "transformer",
                "BERT",
                "RoBERTa",
                "XLNet",
                "DistilBERT",
                "GPT",
                "data augmentation",
                "artificial intelligence",
                "machine learning",
                "pre-trained LLM",
                "PETuning",
                "adapter",
                "LoRA",
                "BitFit",
                "LLM",
                "NLP"
            ]
        }
    },
    {
        "Title": "A Systematic Literature Review of Large Language Model Applications in Industry",
        "Link": "https://ieeexplore.ieee.org/document/11155093/",
        "Abstract": "Large Language Models are rapidly transforming processes across industries by enabling advanced capabilities in natural language understanding, code generation, diagnostics, and decision support. Despite the growing adoption of this technology, a systematic understanding of their application across the industrial value creation processes remains lacking. This paper addresses this gap by conducting a systematic literature review of 96 peer-reviewed studies, following the PRISMA guidelines. Based on this foundation, large language model use cases across industries were identified, categorized, and structured using the primary and secondary activities of Porter’s value chain as a classification framework. The analysis reveals that LLM adoption is heavily concentrated in technology-focused and internal operational activities across industries, where they offer immediate benefits at lower risk. In contrast, areas such as logistics, procurement, and customer-facing functions remain largely unexplored, mainly due to challenges related to integration, data governance, and regulatory requirements. The analysis shows that current deployments are primarily limited to isolated, manageable use cases, leaving substantial innovation potential unrealized in underexplored value chain activities. These findings provide a foundation for further research and for the strategic adoption of large language models throughout the industrial value chain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3608650",
            "Date of Publication": "10 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Norbert Moenks",
                "labs": [
                    "Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany"
                ]
            },
            {
                "name": "Pascal Penava",
                "labs": [
                    "Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany"
                ]
            },
            {
                "name": "Ricardo Buettner",
                "labs": [
                    "Chair of Hybrid Intelligence, Helmut-Schmidt-University/University of the Federal Armed Forces Hamburg, Hamburg, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Systematic literature review",
                "Industries",
                "Large language models",
                "Computer architecture",
                "Surveys",
                "Internet",
                "Data models",
                "Technological innovation",
                "Ethics",
                "Transformers"
            ],
            "Author Keywords": [
                "Large language model",
                "LLM use cases",
                "LLM application",
                "industry",
                "systematic literature review",
                "porter value chain"
            ]
        }
    },
    {
        "Title": "LLM-Based Edge Intelligence: A Comprehensive Survey on Architectures, Applications, Security and Trustworthiness",
        "Link": "https://ieeexplore.ieee.org/document/10669603/",
        "Abstract": "The integration of Large Language Models (LLMs) and Edge Intelligence (EI) introduces a groundbreaking paradigm for intelligent edge devices. With their capacity for human-like language processing and generation, LLMs empower edge computing with a powerful set of tools, paving the way for a new era of decentralized intelligence. Yet, a notable research gap exists in obtaining a thorough comprehension of LLM-based EI architectures, which should incorporate crucial elements such as security, optimization, and responsible development. This survey aims to bridge this gap by providing a comprehensive resource for both researchers and practitioners. We explore LLM-based EI architectures in-depth, carefully analyzing state-of-the-art paradigms and design decisions. To facilitate efficient and scalable edge deployments, we perform a comparative analysis of recent optimization and autonomy techniques specifically designed for resource-constrained edge environments. Additionally, we shed light on the extensive potential of LLM-based EI by demonstrating its varied practical applications across a wide range of domains. Acknowledging the utmost importance of security, our survey thoroughly investigates potential vulnerabilities inherent in LLM-based EI deployments. We explore corresponding defense mechanisms to protect the integrity and confidentiality of data processed at the edge. In conclusion, highlighting the essential aspect of trustworthiness, we outline best practices and guiding principles for the responsible development and deployment of these systems. By conducting a comprehensive review of these key components, our survey aims to support the ethical development and strategic implementation of LLM-driven EI, paving the way for its transformative impact on diverse applications.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2024.3456549",
            "Date of Publication": "09 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Othmane Friha",
                "labs": [
                    "School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Mohamed Amine Ferrag",
                "labs": [
                    "Artificial Intelligence and Digital Science Research Center, Technology Innovation Institute, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Burak Kantarci",
                "labs": [
                    "School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Burak Cakmak",
                "labs": [
                    "Headquarters, Edge Signal, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Arda Ozgun",
                "labs": [
                    "Headquarters, Edge Signal, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Nassira Ghoualmi-Zine",
                "labs": [
                    "Department of Computer Science, Badji Mokhtar-Annaba University, Annaba, Algeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Computational modeling",
                "Security",
                "Robot sensing systems",
                "Technological innovation",
                "Surveys",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Edge intelligence (EI)",
                "generative AI",
                "large language models (LLMs)",
                "security",
                "privacy",
                "trustworthiness",
                "responsible AI"
            ]
        }
    },
    {
        "Title": "ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks",
        "Link": "https://ieeexplore.ieee.org/document/10534765/",
        "Abstract": "This research paper presents a comprehensive comparative study assessing the quality of annotations in Turkish, Indonesian, and Minangkabau Natural Language Processing (NLP) tasks, with a specific focus on the contrast between annotations generated by human annotators and those produced by Large Language Models (LLMs). In the context of NLP, high-quality annotations play a pivotal role in training and evaluating machine-learning models. The study encompasses three core NLP tasks: topic classification, tweet sentiment analysis, and emotion classification, each reflecting a distinct aspect of text analysis. The research methodology incorporates a meticulously curated dataset sourced from a variety of text data, spanning diverse topics and emotions. Human annotators, proficient in the Turkish, Indonesian, and Minangkabau language, were tasked with producing high-quality annotations, adhering to comprehensive annotation guidelines. Additionally, fine-tuned Turkish LLMs were employed to generate annotations for the same tasks. The evaluation process employed precision, recall, and F1-score metrics, tailored to each specific NLP task. The findings of this study underscore the nuanced nature of annotation quality. While LLM-generated annotations demonstrated competitive quality, particularly in sentiment analysis, human-generated annotations consistently outperformed LLM-generated ones in more intricate NLP tasks. The observed differences highlight LLM limitations in understanding context and addressing ambiguity. This research contributes to the ongoing discourse on annotation sources in Turkish, Indonesian, and Minangkabau NLP, emphasizing the importance of judicious selection between human and LLM-generated annotations. It also underscores the necessity for continued advancements in LLM capabilities, as they continue to reshape the landscape of data annotation in NLP and machine learning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3402809",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Arbi Haza Nasution",
                "labs": [
                    "Department of Informatics Engineering, Universitas Islam Riau, Pekanbaru, Riau, Indonesia"
                ]
            },
            {
                "name": "Aytuğ Onan",
                "labs": [
                    "Department of Computer Engineering, College of Engineering and Architecture, İzmir Kâtip Çelebi University, İzmir, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Task analysis",
                "Chatbots",
                "Sentiment analysis",
                "Natural language processing",
                "Reliability",
                "Data models"
            ],
            "Author Keywords": [
                "Annotation quality",
                "emotion classification",
                "Indonesian language processing",
                "language models",
                "low-resource languages",
                "natural language processing",
                "sentiment analysis",
                "topic classification",
                "Turkish language processing"
            ]
        }
    },
    {
        "Title": "Movie Visual and Speech Analysis Through Multi-Modal LLM for Recommendation Systems",
        "Link": "https://ieeexplore.ieee.org/document/10701514/",
        "Abstract": "Understanding speech as a component of broader video comprehension within audio-visual large language models remains a critical yet underexplored area. Previous research has predominantly tackled this challenge by adapting models developed for conventional video classification tasks, such as action recognition or event detection. However, these models often overlook the linguistic elements present in videos, such as narrations or dialogues, which can implicitly convey high-level semantic information related to movie understanding, including narrative structure or contextual background. Moreover, existing methods are generally configured to encode the entire video content, which can lead to inefficiencies in genre classification tasks. In this paper, we propose a multi-modal Large Language Model (LLM) framework, termed Visual-Speech Multimodal LLM (VSM-LLM), for analyzing movie visual and speech data to predict movie genre. The model incorporates an advanced MGC Q-Former architecture, enabling fine-grained, temporal alignment of audio-visual features across various time scales. On the MovieNet dataset, VSM-LLM attains 40.3% and 55.3% in macro and micro recall@0.5, respectively, outperforming existing baselines. On the Condensed Movies dataset, VSM-LLM achieves 43.5% in macro recall@0.5 and 53.5% in micro recall@0.5, further confirming its superior genre classification performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3471568",
            "Date of Publication": "01 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Peixuan Qi",
                "labs": [
                    "Film Academy, Macau University of Science and Technology, Macau, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Motion pictures",
                "Visualization",
                "Semantics",
                "Linguistics",
                "Adaptation models",
                "Accuracy",
                "Large language models",
                "Context modeling",
                "Analytical models",
                "Feature extraction",
                "Deep learning",
                "Videos",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Deep learning",
                "large language model",
                "multimodality",
                "movie analysis",
                "transformer",
                "video classification"
            ]
        }
    },
    {
        "Title": "LLM-MalDetect: A Large Language Model-Based Method for Android Malware Detection",
        "Link": "https://ieeexplore.ieee.org/document/10979936/",
        "Abstract": "Android malware poses a significant cybersecurity threat, enabling unauthorized data access, financial fraud, and device compromise. Although deep learning methods are widely used for malware detection, they often struggle with stability and adaptability in the face of evolving threats. While large language models (LLMs) have shown promise in this area, their application to Android malware detection remains underexplored, particularly with regard to optimizing the semantic relationships within Android application packages (APKs). To address this gap, we introduce LLM-MalDetect, a novel framework that improves LLM-based APK analysis by explicitly modeling semantic dependencies and leveraging structured prompt engineering for optimized detection. Our approach formalizes LLM adaptation through a robust string-based feature extraction method and a tailored fine-tuning strategy to enhance precision. Evaluations on benchmark datasets demonstrate that LLM-MalDetect achieves up to 98.97% accuracy, outperforms existing methods in terms of robustness, and enables real-time analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565526",
            "Date of Publication": "29 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ruirui Feng",
                "labs": [
                    "College of Mathematics and Information Science, Hebei University, Baoding, China",
                    "Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"
                ]
            },
            {
                "name": "Hui Chen",
                "labs": [
                    "School of Artificial Intelligence, Shenzhen Polytechnic University, Shenzhen, China"
                ]
            },
            {
                "name": "Shuo Wang",
                "labs": [
                    "College of Mathematics and Information Science, Hebei University, Baoding, China"
                ]
            },
            {
                "name": "Md Monjurul Karim",
                "labs": [
                    "Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"
                ]
            },
            {
                "name": "Qingshan Jiang",
                "labs": [
                    "Shenzhen Key Laboratory for High Performance Data Mining, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Malware",
                "Feature extraction",
                "Operating systems",
                "Accuracy",
                "Computational modeling",
                "Adaptation models",
                "Semantics",
                "Data models",
                "Transformers",
                "Time factors"
            ],
            "Author Keywords": [
                "Android malware detection",
                "data privacy",
                "information security",
                "large language model",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "The Impact of LLM Hallucinations on Motor Skill Learning: A Case Study in Badminton",
        "Link": "https://ieeexplore.ieee.org/document/10638024/",
        "Abstract": "The rise of Generative Artificial Intelligence, including Large Language Models (LLMs), has enabled users to engage in self-guided learning of sports skills through conversation-based interactions. However, studies have identified a phenomenon known as “hallucination” in which LLMs generate feedback that is inaccurate or non-existent. While this phenomenon has been observed in various domains, including medicine, academia, and news, its existence and implications in the context of physical exercises, particularly motor skill learning, remain unexplored. This study investigates the presence of LLM hallucinations in badminton skill learning and examines their potential impact on learning outcomes. This study aims to investigate whether LLMs hallucinations exist in the motor skill learning of physical exercises and what impact they may have. Eighty university freshmen with no prior badminton experience participated in a 16-week experiment, with 40 students assigned to the Experimental Group (EG) utilizing LLM-based applications (ChatGPT or New Bing) for self-guided learning, and 40 students in the Control Group (CG) learning under the supervision of 12 university sports teachers and 8 experts that specialized in badminton. Evaluation criteria for badminton skills were established, and assessments were conducted at baseline and 16 weeks using independent sample t-tests and paired-sample t-tests. One-way analysis of variance (One-Way ANCOVA) was employed to compare learning outcomes between the two groups. Interviews were conducted to gain insights into the causes of any observed differences in learning efficiency. Both CG and EG groups demonstrated motor skill improvement (clear: p <0.001; smash: p <0.001; footwork: p <0.001). CG exhibited significantly higher scores in long-distance shots and smashes in the post-test. No significant difference was observed in footwork scores between the two groups. High accordance in specific skill points among students in both groups indicated the common usage of prompts. Interviews with EG students revealed hallucinations in the text generated by LLMs, particularly in the context of “forearm internal rotation swing.” LLMs exhibit hallucinations in the context of intricate motor skill learning, such as badminton, where limited corpus data is available. These hallucinations can mislead users and impact learning outcomes. Future research should explore strategies to mitigate LLM hallucinations in physical exercise learning applications.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3444783",
            "Date of Publication": "16 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yepeng Qiu",
                "labs": [
                    "College of Physical Education and Health Sciences, Chongqing Normal University, Chongqing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Sports",
                "Videos",
                "Social networking (online)",
                "Fake news",
                "Large language models",
                "Motor coordination"
            ],
            "Author Keywords": [
                "Large language models",
                "hallucination",
                "motor skill learning",
                "badminton skill"
            ]
        }
    },
    {
        "Title": "LLM-Driven Social Influence for Cooperative Behavior in Multi-Agent Systems",
        "Link": "https://ieeexplore.ieee.org/document/10912445/",
        "Abstract": "This paper presents a novel approach to fostering cooperative behavior in multi-agent systems (MAS) through Large Language Model (LLM)-driven social influence. We propose a theoretical framework where agents’ decision-making processes are influenced not through direct action but by subtle, narrative-driven influences disseminated by LLMs. These influences guide agents toward cooperative behaviors, such as rural repopulation, without requiring explicit policy interventions. We introduce a formal model grounded in game theory and social network dynamics, where agents balance the direct benefits of action with the indirect payoffs of LLM-guided influence. Using NASH equilibrium and Evolutionarily Stable Strategies (ESS), we demonstrate how cooperative behaviors emerge even when agents remain inactive but are subtly influenced by LLMs. Our experimental simulations validate the model, showing a strong positive correlation between network centrality and influence propagation (\nr=0.969,p<0.006\n). Furthermore, temporal analysis reveals that the average influence increases from approximately 0.05–0.06 in the initial steps to 0.08–0.09 in later stages, indicating a cumulative and self-sustaining trend. In addition, the influence values exhibit a near-normal distribution (Shapiro-Wilk test,\np=0.285\n) and yield a large effect size (Cohen’s\nd=4.530\n) when comparing agents with high versus low network centrality. Through visualization techniques and statistical metrics, we demonstrate the effectiveness of the proposed framework and identify promising directions for future research in AI-driven social influence. This study highlights the potential of LLM-driven narratives as a cost-effective, scalable alternative to traditional policy interventions, offering a new paradigm for promoting societal cooperation in areas such as rural repopulation, sustainability, and community development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3548451",
            "Date of Publication": "05 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "J. de Curtò",
                "labs": [
                    "Department of Computer Applications in Science and Engineering, Barcelona Supercomputing Center, Barcelona, Spain",
                    "Escuela Técnica Superior de Ingeniería (ICAI), Universidad Pontificia Comillas, Madrid, Spain"
                ]
            },
            {
                "name": "I. de Zarzà",
                "labs": [
                    "Departamento de Informática e Ingeniería de Sistemas, Universidad de Zaragoza, Zaragoza, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multi-agent systems",
                "Nash equilibrium",
                "Shape",
                "Monitoring",
                "Measurement",
                "Large language models",
                "Adaptation models",
                "Sustainable development",
                "Social networking (online)",
                "Feedback loop"
            ],
            "Author Keywords": [
                "Multi-agent systems",
                "large language models",
                "social influence",
                "game theory",
                "NASH equilibrium",
                "rural repopulation"
            ]
        }
    },
    {
        "Title": "Exploring LLM-Based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures",
        "Link": "https://ieeexplore.ieee.org/document/10376418/",
        "Abstract": "Edge-Cloud system requires massive infrastructures located in closer to the user to minimize latencies in handling Big data. Ansible is one of the most popular Infrastructure as Code (IaC) tools crucial for deploying these infrastructures of the Edge-cloud system. However, Ansible also consists of code, and its code quality is critical in ensuring the delivery of high-quality services within the Edge-Cloud system. On the other hand, the Large Langue Model (LLM) has performed remarkably on various Software Engineering (SE) tasks in recent years. One such task is Automated Program Repairing (APR), where LLMs assist developers in proposing code fixes for identified bugs. Nevertheless, prior studies in LLM-based APR have predominantly concentrated on widely used programming languages (PL), such as Java and C, and there has yet to be an attempt to apply it to Ansible. Hence, we explore the applicability of LLM-based APR on Ansible. We assess LLMs' performance (ChatGPT and Bard) on 58 Ansible script revision cases from Open Source Software (OSS). Our findings reveal promising prospects, with LLMs generating helpful responses in 70% of the sampled cases. Nonetheless, further research is necessary to harness this approach's potential fully.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2263",
            "Date of Publication": "September 2023",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Sunjae Kwon",
                "labs": [
                    "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea"
                ]
            },
            {
                "name": "Sungu Lee",
                "labs": [
                    "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea"
                ]
            },
            {
                "name": "Taehyoun Kim",
                "labs": [
                    "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea"
                ]
            },
            {
                "name": "Duksan Ryu",
                "labs": [
                    "Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            },
            {
                "name": "Jongmoon Baik",
                "labs": [
                    "Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Java",
                "Computer languages",
                "Codes",
                "Computer bugs",
                "Big Data",
                "Chatbots",
                "Task analysis"
            ],
            "Author Keywords": [
                "Edge-cloud",
                "Ansible",
                "Bard",
                "large langue model",
                "automated program repairing"
            ]
        }
    },
    {
        "Title": "A Matching Game for LLM Layer Deployment in Heterogeneous Edge Networks",
        "Link": "https://ieeexplore.ieee.org/document/10966456/",
        "Abstract": "With the growing demand for computational and storage capabilities of modern learning models, performing their computation exclusively in a centralized manner has become increasingly impractical. Executing the inference of foundation models in a distributed manner presents significant challenges, particularly in optimizing both computing and communication resources. This work introduces a novel deployment scheme for large language model (LLM) layers that jointly considers computation and communication efficiency within an edge network environment to address these issues. Specifically, we resort to the matching theory to effectively orchestrate the distributed deployment of the LLM layers across the edge nodes of the networks, where nodes have varying computational capacities and communication speed. This framework is based on a two-sided game, enabling each layer to express its individual preferences for node allocation while allowing nodes to prioritize their preferred layers. This mutual selection process minimizes inference latency in the learning process and models the bubble time as game externalities, assuming a sequential pipeline execution. The algorithmic solution reaches a stable matching outcome. Performance evaluation was conducted considering both simulations and a small-scale testbed to measure the effectiveness of the proposed algorithm compared to state-of-the-art alternatives. In particular, the small-scale testbed was developed to distribute an LLM to support autonomous driving, leveraging the vision-language model paradigm. The results highlight performance improvements of up to around 10% in comparison to the Koklata game alternative.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2025.3561605",
            "Date of Publication": "16 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Benedetta Picano",
                "labs": [
                    "School of Electrical and Data Engineering, University of Florence, Florence, Italy"
                ]
            },
            {
                "name": "Dinh Thai Hoang",
                "labs": [
                    "School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Diep N. Nguyen",
                "labs": [
                    "School of Electrical and Data Engineering, University of Technology Sydney, Ultimo, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Foundation models",
                "Games",
                "Resource management",
                "Optimization",
                "Biological system modeling",
                "Adaptation models",
                "Transformers",
                "Training",
                "Large language models"
            ],
            "Author Keywords": [
                "Foundation models",
                "distributed inference",
                "matching theory",
                "edge intelligence"
            ]
        }
    },
    {
        "Title": "A Web-Based Solution for Federated Learning With LLM-Based Automation",
        "Link": "https://ieeexplore.ieee.org/document/10891639/",
        "Abstract": "Federated learning (FL) offers a promising approach for collaborative machine learning (ML) across distributed devices. However, its adoption is hindered by the complexity of building reliable communication architectures and the need for expertise in both ML and network programming. This article presents a comprehensive solution that simplifies the orchestration of FL tasks while integrating intent-based automation. A user-friendly web application is developed supporting the federated averaging (FedAvg) algorithm, enabling users to configure parameters through an intuitive interface. The backend solution efficiently manages communication between the parameter server and edge nodes. Model compression and scheduling algorithms are implemented to optimize FL performance. Additionally, intent-based automation in FL is explored using a fine-tuned Language Model (LLM) trained on a tailored dataset, enabling users to perform FL tasks through high-level prompts. It is shown that the LLM-based automated solution achieves comparable test accuracy to the standard web-based solution while reducing transferred bytes by up to 64% and CPU time by up to 46% for FL tasks. Furthermore, neural architecture search (NAS) and hyperparameter optimization (HPO) are leveraged using the LLM to enhance performance, resulting in a 10%–20% improvement in test accuracy for the conducted FL tasks.",
        "Details": {
            "DOI": "10.1109/JIOT.2025.3542897",
            "Date of Publication": "17 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Internet of Things Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2327-4662"
        },
        "authors_data": [
            {
                "name": "Chamith Mawela",
                "labs": [
                    "Centre of Wireless Communications, University of Oulu, Oulu, Finland"
                ]
            },
            {
                "name": "Chaouki Ben Issaid",
                "labs": [
                    "Centre of Wireless Communications, University of Oulu, Oulu, Finland"
                ]
            },
            {
                "name": "Mehdi Bennis",
                "labs": [
                    "Centre of Wireless Communications, University of Oulu, Oulu, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Training",
                "Quantization (signal)",
                "Data models",
                "Automation",
                "Programming",
                "Flowering plants",
                "Architecture",
                "Servers",
                "Mathematical models"
            ],
            "Author Keywords": [
                "Distributed computing",
                "federated learning (FL)",
                "intent-based automation",
                "large language models (LLMs)",
                "web sockets communication"
            ]
        }
    },
    {
        "Title": "LLM4WM: Adapting LLM for Wireless Multi-Tasking",
        "Link": "https://ieeexplore.ieee.org/document/11071329/",
        "Abstract": "The wireless channel is fundamental to communication, encompassing numerous tasks collectively referred to as channel-associated tasks. These tasks can leverage joint learning based on channel characteristics to share representations and enhance system design. To capitalize on this advantage, LLM4WM is proposed—a large language model (LLM) multi-task fine-tuning framework specifically tailored for channel-associated tasks. This framework utilizes a Mixture of Experts with Low-Rank Adaptation (MoE-LoRA) approach for multi-task fine-tuning, enabling the transfer of the pre-trained LLM’s general knowledge to these tasks. Given the unique characteristics of wireless channel data, preprocessing modules, adapter modules, and multi-task output layers are designed to align the channel data with the LLM’s semantic feature space. Experiments on a channel-associated multi-task dataset demonstrate that LLM4WM outperforms existing methodologies in both full-sample and few-shot evaluations, owing to its robust multi-task joint modeling and transfer learning capabilities.",
        "Details": {
            "DOI": "10.1109/TMLCN.2025.3585845",
            "Date of Publication": "03 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Machine Learning in Communications and Networking"
        },
        "issn_info": {
            "Electronic ISSN": "2831-316X"
        },
        "authors_data": [
            {
                "name": "Xuanyu Liu",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Shijian Gao",
                "labs": [
                    "Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China"
                ]
            },
            {
                "name": "Boxun Liu",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Xiang Cheng",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Liuqing Yang",
                "labs": [
                    "Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
                    "Intelligent Transportation Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China",
                    "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China",
                    "Department of Civil and Environmental Engineering, The Hong Kong University of Science and Technology, Hong Kong, SAR, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Wireless communication",
                "Multitasking",
                "Artificial intelligence",
                "Millimeter wave communication",
                "Wireless sensor networks",
                "OFDM",
                "Training",
                "Semantics",
                "Natural language processing",
                "Hands"
            ],
            "Author Keywords": [
                "Large language models",
                "mixture of experts",
                "low-rank adaptation",
                "multi-task learning",
                "wireless multi-tasking",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "emGene: An Embodied LLM NGS Sequencer for Real-Time Precision Diagnostics",
        "Link": "https://ieeexplore.ieee.org/document/10930726/",
        "Abstract": "Precision medicine is revolutionizing global healthcare by enabling personalized diagnostics, disease prediction, and tailored treatment strategies. While the integration of genomics and data science holds immense potential to optimize precision therapeutic outcomes, a critical challenge lies in translating gene sequencing data into actionable insights for in vitro diagnostics. This bottleneck is largely attributed to the limitations of edge-side intelligent processing and automation. Despite advancements in gene sequencing technologies and bioinformatics tools, the workflow from sample collection to diagnostic report generation remains fragmented, inefficient, and lacks of intelligence. To address these challenges, we introduce an embodied LLM NGS sequencer on the edge for real-time, on-site smart genetic diagnostics. This instrument integrates a streamlined and comprehensive pipeline with deep learning networks for primary data analysis, machine learning for secondary data processing, and a large language model (LLM) optimized for tertiary data interpretation. The LLM is enhanced through quantization and compression, facilitating deployment on FPGA/GPU to accelerate diagnostic workflows. Experimental results showcased the superior performance by achieving a 13.72% increase in throughput, a 99.50% Q30%, and enable smart diagnostic on the edge with the performance up to 75 tokens/s. This work enables immediate, on-site DNA analysis, hence dramatically improving precision medicine's accessibility and efficiency, and significantly advances diagnostic accuracy, automation, establishing a robust platform for AI-driven personalized medicine and setting a new benchmark for the future of healthcare delivery.",
        "Details": {
            "DOI": "10.23919/ICS.2025.3552542",
            "Date of Publication": "18 March 2025",
            "Publisher": "SJTU",
            "Published In": "Integrated Circuits and Systems"
        },
        "issn_info": {
            "Print ISSN": "2995-1968"
        },
        "authors_data": [
            {
                "name": "Shaobo Luo",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China",
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Albert Yu",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Zhiyuan Xie",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Hong Huang",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Mingqiang Huang",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Kai Li",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Yuk Kan Pun",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Zhiru Guo",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Shuwei Li",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Yiming Zhu",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Changhai Man",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Huiyuan Sun",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Tung-Han Chang",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Ziyi Guan",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China",
                    "Department of Electrical and Electronic Engineering, University of Hong Kong, Hong Kong"
                ]
            },
            {
                "name": "Qiyuan Zhang",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Tingting Wang",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Guanqi Peng",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Wenjun Chen",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Yan Sun",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Gengxin Chen",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Mei Yan",
                "labs": [
                    "GeneSense Technology Inc., Shanghai, China"
                ]
            },
            {
                "name": "Hao Yu",
                "labs": [
                    "School of Microelectronics, Southern University of Science and Technology, Shenzhen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sequential analysis",
                "Deep learning",
                "Data analysis",
                "Accuracy",
                "Medical diagnostic imaging",
                "Bioinformatics",
                "Integrated circuits",
                "Medical services",
                "Genomics",
                "Data models"
            ],
            "Author Keywords": [
                "Gene sequencing",
                "NGS sequencer",
                "base-calling",
                "deep learning neural network",
                "large language model",
                "genetic diagnosis",
                "model quantization",
                "model edge-side deployment"
            ]
        }
    },
    {
        "Title": "LLM-Guided Crowdsourced Test Report Clustering",
        "Link": "https://ieeexplore.ieee.org/document/10844085/",
        "Abstract": "This paper proposes a clustering method for crowdsourced test reports based on a large language model to solve the limitations of existing methods in processing repeated reports and utilizing multi-modal information. Existing crowdsourced test report clustering methods have significant shortcomings in handling duplicate reports, ignoring the semantic information of screenshots, and underutilizing the relationship between text and images. The emergence of LLM provides a new way to solve these problems. By integrating the semantic understanding ability of LLM, key information can be extracted from the test report more accurately, and the semantic relationship between screenshots and text descriptions can be used to guide the clustering process, thus improving the accuracy and effectiveness of clustering. The method in this paper uses a pre-trained LLM (such as GPT-4) to encode the text in the test report, and uses a visual model such as CLIP to encode the application screenshots, converting the text descriptions and images into high-dimensional semantic vectors. The cosine similarity is then used to calculate the similarity between the vectors, and semantic binding rules are constructed to guide the clustering process, ensuring that semantically related reports are assigned to the same cluster and semantically different reports are assigned to different clusters. Through experimental verification, this method is significantly superior to traditional methods in several evaluation indicators, demonstrating its great potential in improving the efficiency and quality of crowdsourced test report processing. In the future, this method is expected to be widely used in the process of software testing and maintenance, and further promote technological progress.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3530960",
            "Date of Publication": "17 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ying Li",
                "labs": [
                    "North China Institute of Aerospace Engineering, Langfang, China"
                ]
            },
            {
                "name": "Ye Zhong",
                "labs": [
                    "Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Lijuan Yang",
                "labs": [
                    "North China Institute of Aerospace Engineering, Langfang, China"
                ]
            },
            {
                "name": "Yanbo Wang",
                "labs": [
                    "Beijing Aerospace Automatic Control Institute, Beijing, China"
                ]
            },
            {
                "name": "Penghua Zhu",
                "labs": [
                    "North China Institute of Aerospace Engineering, Langfang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Testing",
                "Semantics",
                "Software",
                "Feature extraction",
                "Vectors",
                "Natural language processing",
                "Large language models",
                "Clustering methods",
                "Security",
                "Data mining"
            ],
            "Author Keywords": [
                "Large language model",
                "crowdsourced testing",
                "test report clustering"
            ]
        }
    },
    {
        "Title": "LLM-Driven Pareto-Optimal Multi-Mode Reinforcement Learning for Adaptive UAV Navigation in Urban Wind Environments",
        "Link": "https://ieeexplore.ieee.org/document/11168480/",
        "Abstract": "Autonomous drones in complex urban wind environments must balance speed, safety, and energy efficiency under highly variable conditions. Traditional single-policy reinforcement learning controllers often perform poorly when exposed to scenarios beyond their training. We introduce a Pareto-optimal multi-mode framework that trains three specialized unmanned aerial vehicle (UAV) policies (aggressive, balanced, and cautious) via proximal policy optimization (PPO) with specific reward scalings, yielding controllers that collectively span the speed-safety-energy trade-off surface. To automate mode selection, we fine-tune a large language model (LLM) on 30,000 simulation-derived environment-performance tuples, allowing it to predict the optimal policy from building density, wind speed and orientation, battery state, and recent flight history. In a Unity-based Manhattan simulation with computational fluid dynamics (CFD) wind fields across four headings and 10 speed levels, the LLM-driven decision maker reduces average flight time by 16%, lowers the collision rate by 50%, and saves 18% energy compared to any single mode, while preserving nondominated trade-off performance. The decision maker also generalizes to unseen wind patterns and layouts without handcrafted heuristics, demonstrating the promise of combining Pareto-optimal reinforcement learning (RL) with LLM-based meta-decision making for UAV autonomy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611336",
            "Date of Publication": "17 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiahao Wu",
                "labs": [
                    "Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Hengxu You",
                "labs": [
                    "Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Bowen Sun",
                "labs": [
                    "Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Jing Du",
                "labs": [
                    "Department of Civil and Coastal Engineering, University of Florida, Gainesville, FL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Reinforcement learning",
                "Navigation",
                "Safety",
                "Training",
                "Aerodynamics",
                "Drones",
                "Decision making",
                "Vehicle dynamics",
                "Computational fluid dynamics"
            ],
            "Author Keywords": [
                "Autonomous drone",
                "large language model",
                "meta-decision making",
                "pareto optimality",
                "reinforcement learning",
                "urban wind simulation"
            ]
        }
    },
    {
        "Title": "Enhanced Voice Phishing Detection Using an LLM-Based Framework for Data Augmentation and Classification",
        "Link": "https://ieeexplore.ieee.org/document/11142247/",
        "Abstract": "Existing voice phishing detection models based on call transcripts often suffer from limited generalizability due to insufficient scenario diversity and the absence of ambiguous samples in data. To address these challenges, we propose an integrated framework that leverages GPT-4o, a large language model (LLM), to generate realistic call transcripts from actual fraud cases and to build an expert-guided phishing detection model. Using case reports from the Financial Supervisory Service (FSS) and Korean call transcripts from the KorCCVi dataset, we generate Korean phishing call transcripts that capture underrepresented fraud tactics. In addition, we generate non-phishing call transcripts that retain phishing-like linguistic patterns by removing or attenuating core fraudulent cues, thereby enabling training on ambiguous cases. The generated data are quantitatively evaluated for linguistic naturalness, scenario diversity, and detection difficulty. To assess the sample-level detection difficulty in semantic space, we introduce the metric Class Centroid Distance Variability (CCDV). We also propose the Domain Expert LLM, implemented using GPT-4o, a prompt-engineered detection model that incorporates six analytical criteria validated by a domain expert. The model not only improves detection performance but also produces structured analytical reports that enhance interpretability. In experiments, the Domain Expert LLM achieves an F1 score of 0.9686 on previously unseen and ambiguous transcripts, substantially outperforming conventional models such as RandomForest and KoBERT, which yield an average F1 score of approximately 0.70.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3603007",
            "Date of Publication": "26 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyunghee Park",
                "labs": [
                    "Department of Convergence Technology Engineering, Sungshin Women’s University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jiwon Lee",
                "labs": [
                    "Department of Convergence Technology Engineering, Sungshin Women’s University, Seoul, South Korea"
                ]
            },
            {
                "name": "Sanghyun Han",
                "labs": [
                    "SK Telecom, Seoul, South Korea"
                ]
            },
            {
                "name": "Haewon Byun",
                "labs": [
                    "School of AI Convergence, Sungshin Women’s University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Data augmentation",
                "Fraud",
                "Synthetic data",
                "Data models",
                "Measurement",
                "Semantics",
                "Oral communication",
                "Telecommunications",
                "Large language models"
            ],
            "Author Keywords": [
                "Expert-guided prompting",
                "large language models",
                "synthetic data evaluation",
                "voice phishing detection"
            ]
        }
    },
    {
        "Title": "LLM-Enhanced Security Framework for IoT Network: Anomaly Detection and Malicious Devices Identification",
        "Link": "https://ieeexplore.ieee.org/document/11175688/",
        "Abstract": "Due to resource constraints, Internet of Things (IoT) devices often lack built-in security systems, making them vulnerable to zero-day attacks. Consequently, there is a growing need for anomaly-based intrusion detection systems for IoT networks. However, traditional anomaly systems suffer from a high number of false positives, which wastes analysts’ time. Besides this, there is a semantic gap between the system outputs and the network operators. In this paper, we propose a machine learning-based framework with large language model (LLM) integration to address those challenges we face in traditional systems. The model not only detects potential threats but also bridges the semantic gap. The framework employs isolation forest for anomaly detection and random forest for device integrity assessment. To enhance anomaly evaluation and improve interpretability, the system’s insights are further processed by GPT-4o mini, an LLM. The LLM elucidates statistical summaries of IoT traffic, assigns risk scores, and provides human-readable explanations and thereby enhancing decision-making. This approach reduces the reliance on expert network operators. As a result, non-technical users can understand and act upon the system’s outputs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613588",
            "Date of Publication": "23 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Arif Iftakher Mahmood",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Chittagong, Chittagong, Bangladesh"
                ]
            },
            {
                "name": "Fahim Ashab",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Chittagong, Chittagong, Bangladesh"
                ]
            },
            {
                "name": "Md Saifuzzaman Sohan",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Chittagong, Chittagong, Bangladesh"
                ]
            },
            {
                "name": "Md Hedayetul Islam Chy",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Chittagong, Chittagong, Bangladesh"
                ]
            },
            {
                "name": "Md Fazlul Kader",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Chittagong, Chittagong, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Anomaly detection",
                "Security",
                "Object recognition",
                "Telecommunication traffic",
                "Monitoring",
                "Semantics",
                "Intrusion detection",
                "Decision making",
                "Training"
            ],
            "Author Keywords": [
                "Anomaly detection",
                "Internet of Things",
                "intrusion detection system",
                "large language model",
                "malicious device identification",
                "machine learning"
            ]
        }
    },
    {
        "Title": "DomainLynx: Advancing LLM Techniques for Robust Domain Squatting Detection",
        "Link": "https://ieeexplore.ieee.org/document/10884775/",
        "Abstract": "Domain squatting, the malicious registration of deceptive domain names, poses a significant threat to Internet security. This study presents an enhanced version of DomainLynx, a system leveraging Large Language Models (LLMs) for detecting domain squatting. We introduce novel techniques that combine LLMs with domain-specific knowledge to identify a wide range of squatting tactics, including complex hybrid methods that merge multiple deception techniques. Our improved system features refined detection algorithms and an advanced validation process that significantly reduces false positives while maintaining high accuracy. Comprehensive evaluations using various LLM configurations demonstrate DomainLynx’s superior performance. Using a state-of-the-art LLM, the system achieved 94.7% accuracy on a diverse dataset of 1,649 squatting domains. In a month-long real-world test, DomainLynx detected 34,359 potential squatting domains from 2.09 million new registrations, outperforming existing methods by 2.5 times. Further analysis confirmed the system’s effectiveness across different squatting types. We also present case studies of hybrid-squatting domains, such as those combining typos with brand impersonation, offering insights into emerging threats. This research advances Internet security by providing a more accurate, adaptable, and thoroughly evaluated LLM-based tool for combating evolving domain squatting threats, contributing to safer online environments for users and organizations worldwide.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3542036",
            "Date of Publication": "13 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Daiki Chiba",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Hiroki Nakano",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Takashi Koide",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Upper bound",
                "Accuracy",
                "Systems architecture",
                "Visualization",
                "Phishing",
                "Measurement",
                "Large language models",
                "Internet security",
                "Compounds",
                "Writing"
            ],
            "Author Keywords": [
                "Domain squatting",
                "large language models (LLMs)",
                "cybersecurity",
                "compound AI system"
            ]
        }
    },
    {
        "Title": "LLM in the Loop: A Framework for Contextualizing Counterfactual Segment Perturbations in Point Clouds",
        "Link": "https://ieeexplore.ieee.org/document/10993377/",
        "Abstract": "Point Cloud Data analysis has seen a major leap forward with the introduction of PointNet algorithms, revolutionizing how we process 3D environments. Yet, despite these advancements, key challenges remain, particularly in optimizing segment perturbations to influence model outcomes in a controlled and meaningful way. Traditional methods struggle to generate realistic and contextually appropriate perturbations, limiting their effectiveness in critical applications like autonomous systems and urban planning. This paper takes a bold step by integrating Large Language Models into the counterfactual reasoning process, unlocking a new level of automation and intelligence in segment perturbation. Our approach begins with semantic segmentation, after which LLMs intelligently select optimal replacement segments based on features such as class label, color, area, and height. By leveraging the reasoning capabilities of LLMs, we generate perturbations that are not only computationally efficient but also semantically meaningful. The proposed framework undergoes rigorous evaluation, combining human inspection of LLM-generated suggestions with quantitative analysis of semantic classification model performance across different LLM variants. By bridging the gap between geometric transformations and high-level semantic reasoning, this research redefines how we approach perturbation generation in Point Cloud Data analysis. The results pave the way for more interpretable, adaptable, and intelligent AI-driven solutions, bringing us closer to real-world applications where explainability and robustness are paramount.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3568052",
            "Date of Publication": "08 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Veljka Kočić",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Human-Centered AI Laboratory, Institute of Forest Engineering, BOKU University, Vienna, Austria",
                    "Faculty of Computer Science and Biomedical Engineering, Institute of Human-Centered Computing, TU Graz, Graz, Austria"
                ]
            },
            {
                "name": "Niko Lukač",
                "labs": [
                    "Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia"
                ]
            },
            {
                "name": "Džemail Rožajac",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Human-Centered AI Laboratory, Institute of Forest Engineering, BOKU University, Vienna, Austria"
                ]
            },
            {
                "name": "Stefan Schweng",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Human-Centered AI Laboratory, Institute of Forest Engineering, BOKU University, Vienna, Austria"
                ]
            },
            {
                "name": "Christoph Gollob",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Institute of Forest Growth, BOKU University, Vienna, Austria"
                ]
            },
            {
                "name": "Arne Nothdurft",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Institute of Forest Growth, BOKU University, Vienna, Austria"
                ]
            },
            {
                "name": "Karl Stampfer",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Human-Centered AI Laboratory, Institute of Forest Engineering, BOKU University, Vienna, Austria"
                ]
            },
            {
                "name": "Javier del Ser",
                "labs": [
                    "TECNALIA, Basque Research and Technology Alliance (BRTA), Derio, Spain",
                    "Department of Mathematics, University of the Basque Country (UPV/EHU), Leioa, Spain"
                ]
            },
            {
                "name": "Andreas Holzinger",
                "labs": [
                    "Department of Ecosystem Management, Climate, and Biodiversity, Human-Centered AI Laboratory, Institute of Forest Engineering, BOKU University, Vienna, Austria",
                    "Faculty of Computer Science and Biomedical Engineering, Institute of Human-Centered Computing, TU Graz, Graz, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Three-dimensional displays",
                "Semantic segmentation",
                "Perturbation methods",
                "Solid modeling",
                "Semantics",
                "Cognition",
                "Point cloud compression",
                "Predictive models",
                "Computational modeling",
                "Large language models"
            ],
            "Author Keywords": [
                "Explainable AI",
                "point cloud data",
                "counterfactual reasoning",
                "LiDAR",
                "3D point cloud data",
                "interpretability",
                "human-centered AI",
                "large language models",
                "K-nearest neighbors"
            ]
        }
    },
    {
        "Title": "LLM-CDM: A Large Language Model Enhanced Cognitive Diagnosis for Intelligent Education",
        "Link": "https://ieeexplore.ieee.org/document/10916617/",
        "Abstract": "Cognitive diagnosis is a key component of intelligent education to assess students’ comprehension of specific knowledge concepts. Current methodologies predominantly rely on students’ historical performance records and manually annotated knowledge concepts for analysis. However, the extensive semantic information embedded in exercises, including latent knowledge concepts, has not been fully utilized. This paper presents a novel cognitive diagnosis model based on the LLAMA3-70B framework (referred to as LLM-CDM), which integrates prompt engineering with the rich semantic information inherent in exercise texts to uncover latent knowledge concepts and improve diagnostic accuracy. Specifically, this study first inputs exercise texts into a large language model and develops an innovative prompting method to facilitate deep mining of implicit knowledge concepts within these texts by the model. Following the integration of these newly extracted knowledge concepts into the existing Q matrix, this paper employs a neural network to diagnose students’ understanding of knowledge concepts while applying the monotonicity assumption to ensure the interpretability of model factors. Experimental results from an examination data set for course completion assessments demonstrate that LLM-CDM exhibits superior performance in both accuracy and explainability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3549309",
            "Date of Publication": "07 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xin Chen",
                "labs": [
                    "College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China"
                ]
            },
            {
                "name": "Jin Zhang",
                "labs": [
                    "College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China"
                ]
            },
            {
                "name": "Tong Zhou",
                "labs": [
                    "College of Civil Engineering and Architecture, Shandong University of Science and Technology, Qingdao, China"
                ]
            },
            {
                "name": "Feng Zhang",
                "labs": [
                    "College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Large language models",
                "Annotations",
                "Accuracy",
                "Semantics",
                "Prompt engineering",
                "Printers",
                "Optimization",
                "Manuals",
                "Long short term memory"
            ],
            "Author Keywords": [
                "Cognitive diagnosis",
                "large language models",
                "exercise texts",
                "higher education and intelligent education"
            ]
        }
    },
    {
        "Title": "Validation of LLM-Generated Object Co-Occurrence Information for Understanding Three-Dimensional Scenes",
        "Link": "https://ieeexplore.ieee.org/document/10786984/",
        "Abstract": "This study delves into verifying the applicability of object co-occurrence information generated by a large-scale language model (LLM) to enhance a robot’s spatial ability to understand objects in the real world. Co-occurrence information is crucial in enabling robots to perceive and navigate their surroundings. LLM can generate object co-occurrence information based on the learned representations acquired from the learning process. However, the challenge lies in determining whether the co-occurrence gleaned from linguistic data can effectively translate to real-world object relationships, a concept yet to be thoroughly examined. After providing category information about a specific situation, this paper compares and evaluates the co-occurrence degree (co-occurrence coefficient) output by gpt-4-turbo-2024-04-09 (GPT-4) against the object pair data from the ScanNet v2 dataset. The results revealed that GPT-4 achieved a high recall of 0.78 across various situation categories annotated by ScanNet v2, although its precision was relatively low at an average of 0.29. The root mean square error of the co-occurrence coefficient was 0.31. While GPT-4 tends to output slightly higher co-occurrence coefficients, it effectively captures the overall co-occurrence patterns observed in the ScanNet v2 dataset. GPT-4 produced co-occurrence information for more objects than those available in ScanNet v2 while covering co-occurrences among objects within ScanNet v2. These results demonstrate that integrating co-occurrence data from different sources could enhance the ability to recognize real-world objects and potentially strengthen robot intelligence.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3514473",
            "Date of Publication": "09 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kenta Gunji",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Kazunori Ohno",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Shuhei Kurita",
                "labs": [
                    "National Institute of Informatics, Tokyo, Japan"
                ]
            },
            {
                "name": "Ken Sakurada",
                "labs": [
                    "Graduate School of Informatics, Kyoto University, Kyoto, Japan"
                ]
            },
            {
                "name": "Ranulfo Bezerra",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Shotaro Kojima",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Yoshito Okada",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Masashi Konyo",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            },
            {
                "name": "Satoshi Tadokoro",
                "labs": [
                    "Graduate School of Information Sciences, Tohoku University, Sendai, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Three-dimensional displays",
                "Chatbots",
                "Standards",
                "Knowledge graphs",
                "Semantics",
                "Navigation",
                "Market research",
                "Data models",
                "Data mining"
            ],
            "Author Keywords": [
                "Semantic scene understanding",
                "large language models",
                "co-occurrence validation",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "Autonomous Electromagnetic Simulation and Modeling of QFN Micro-Electronic Packages Using LLM Agents",
        "Link": "https://ieeexplore.ieee.org/document/11150377/",
        "Abstract": "This paper presents a novel approach to automating the electromagnetic simulation workflow for packaging using Large Language Model (LLM) agents. We demonstrate the use of LLM-based agents to generate 3D models of Quad Flat No-Lead (QFN) packages in Ansys HFSS based on natural language prompts. The agent autonomously constructs the geometry, sets up the simulation environment, and extracts S-parameters following a full-wave electromagnetic analysis. Subsequently, it interprets the results to generate a compact equivalent circuit model and produces a SPICE-compatible netlist. This end-to-end pipeline enables rapid design exploration, reduced engineering time, and improved accessibility to high-fidelity electromagnetic modeling. The proposed framework lays the foundation for intelligent, prompt-driven design and simulation of systems, bridging the gap between high-level design intent and low-level simulation workflows.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605803",
            "Date of Publication": "03 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hrvoje Molnar",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Tvrtko Mandic",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Vladimir Ceperic",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Integrated circuit modeling",
                "Scattering parameters",
                "Electromagnetics",
                "Geometry",
                "Automation",
                "Retrieval augmented generation",
                "Finite element analysis",
                "Equivalent circuits",
                "Three-dimensional displays",
                "Substrates"
            ],
            "Author Keywords": [
                "Ansys HFSS",
                "EDA",
                "electronic packaging",
                "electromagnetic simulation",
                "equivalent circuits",
                "large language models",
                "packaging",
                "natural language processing",
                "S-parameters",
                "SPICE netlists"
            ]
        }
    },
    {
        "Title": "ALDExA: Automated LLM-Assisted Detection of CVE Exploitation Attempts in Host-Captured Data",
        "Link": "https://ieeexplore.ieee.org/document/11018393/",
        "Abstract": "Currently, the detection of Common Vulnerabilities and Exposures (CVE) exploitation attempts heavily depends on rule sets manually written for the detection unit. As the number of published CVEs increases each year, there is a need to advance automation efforts for CVE detection. For this purpose, we introduce ALDExA, a framework that fetches CVE information and corresponding exploit codes to identify an exploit string supported by a Large Language Model (LLM). An exploit string is a characteristic element of the analyzed attack and can be monitored during an actual exploitation attempt. As the novelty in this framework lies in the extraction capabilities of the LLM, we furthermore evaluate eight different models towards their performance in identifying a correct exploit string. We evaluate contemporary models in two experiments and find that they are, in up to 81% of the evaluated cases, capable of extracting a correct exploit string from the attack code. In addition, we propose a promising approach to increase the accuracy further and to automatically detect false predictions. As ALDExA is the first approach to fully automate the CVE detection pipeline, we also discuss remaining limitations and worthwhile areas of future research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3575258",
            "Date of Publication": "30 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Niclas Ilg",
                "labs": [
                    "Bosch Research, Renningen, Germany",
                    "Chair of Communication Networks, University of Tuebingen, Tuebingen, Germany"
                ]
            },
            {
                "name": "Maximilian Pfitzenmaier",
                "labs": [
                    "Chair of Communication Networks, University of Tuebingen, Tuebingen, Germany"
                ]
            },
            {
                "name": "Dominik Germek",
                "labs": [
                    "Bosch Research, Hildesheim, Germany"
                ]
            },
            {
                "name": "Paul Duplys",
                "labs": [
                    "Robert Bosch GmbH, Sector Mobility, Ludwigsburg, Germany"
                ]
            },
            {
                "name": "Michael Menth",
                "labs": [
                    "Chair of Communication Networks, University of Tuebingen, Tuebingen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Security",
                "Automation",
                "Pipelines",
                "Payloads",
                "Databases",
                "Computer languages",
                "Software development management",
                "Manuals",
                "Intrusion detection"
            ],
            "Author Keywords": [
                "Common vulnerabilities and exposures",
                "CVE detection",
                "exploit code analysis",
                "intrusion detection",
                "large language models"
            ]
        }
    },
    {
        "Title": "Descriptor: Benchmark Dataset for Generative AI on Edge Devices (BeDGED)",
        "Link": "https://ieeexplore.ieee.org/document/10930751/",
        "Abstract": "The rise of large language models (LLMs) has transformed natural language processing (NLP) and generative artificial intelligence (AI) applications. However, deploying these transformer-based models in resource-constrained environments poses a significant challenge due to their high computational and memory demands. To address this, we introduce in this article generative AI (GenAI) on the Edge, a comprehensive benchmarking dataset designed to evaluate the performance of LLMs deployed on edge devices. Leveraging a distributed testbed of Raspberry Pi 5 devices orchestrated with lightweight Kubernetes (K3s), the dataset captures a broad range of performance metrics essential for assessing the feasibility of local inference in constrained environments. These metrics include detailed measurements of throughput, inference latency, memory utilization, and computational efficiency, along with granular timing data for key stages of the inference pipeline—sample, prefill, and decode phases. We systematically evaluate LLMs of varying sizes under real-world deployment scenarios, with a particular emphasis on CPU-based edge platforms. By conducting multiple runs of conversation-based evaluations, GenAI on the Edge provides actionable insights into the tradeoffs between performance and resource efficiency, enabling better decision-making for LLM deployment in edge environments. IEEE SOCIETY/COUNCIL Communications Society (ComSoc) DATA TYPE/LOCATION Structured Text Data (CSV); Leeds, U.K. DATA DOI/PID 10.21227/7d08-8655",
        "Details": {
            "DOI": "10.1109/IEEEDATA.2025.3552083",
            "Date of Publication": "18 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Data Descriptions"
        },
        "issn_info": {
            "Electronic ISSN": "2995-4274"
        },
        "authors_data": [
            {
                "name": "Zeinab Nezami",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.",
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Maryam Hafeez",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Karim Djemame",
                "labs": [
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Syed Ali Raza Zaidi",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Jie Xu",
                "labs": [
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Benchmark testing",
                "Throughput",
                "Data models",
                "Artificial intelligence",
                "Performance evaluation",
                "Accuracy",
                "Hardware",
                "Generative AI",
                "Memory management"
            ],
            "Author Keywords": [
                "Benchmarking dataset",
                "edge artificial intelligence (AI)",
                "generative AI (GenAI)",
                "large language model (LLM)",
                "open radio access network (ORAN)",
                "performance evaluation"
            ]
        }
    },
    {
        "Title": "LLM for SoC Security: A Paradigm Shift",
        "Link": "https://ieeexplore.ieee.org/document/10596266/",
        "Abstract": "As the ubiquity and complexity of system-on-chip (SoC) designs increase across electronic devices, incorporating security into an SoC design flow poses significant challenges. Existing security solutions are inadequate to effectively verify modern SoC designs due to their limitations in scalability, comprehensiveness, and adaptability. On the other hand, large language models (LLMs) are celebrated for their remarkable success in language understanding, advanced reasoning, and program synthesis tasks. Recognizing an opportunity, our research explores leveraging the emergent capabilities of generative pre-trained transformers (GPTs) to address the existing gaps in SoC security, aiming for a more efficient, scalable, and adaptable methodology. By integrating LLMs into the SoC security verification paradigm, we open a new frontier of possibilities and challenges to ensure the security of increasingly complex SoCs. This paper offers an in-depth analysis of existing works, presents practical case studies, and demonstrates comprehensive experiments. We also present the achievements, prospects, and challenges of employing LLM in different SoC security verification tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3427369",
            "Date of Publication": "12 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dipayan Saha",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Shams Tarek",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Katayoon Yahyaei",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Sujan Kumar Saha",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Jingbo Zhou",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Mark Tehranipoor",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Farimah Farahmandi",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Florida, Gainesville, FL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Task analysis",
                "Fuzzing",
                "Cognition",
                "Complexity theory",
                "Databases",
                "Hardware security",
                "System-on-chip",
                "Large language models"
            ],
            "Author Keywords": [
                "Hardware security",
                "SoC security verification",
                "hardware vulnerability",
                "large language model"
            ]
        }
    },
    {
        "Title": "LLM-Enhanced Human–Machine Interaction for Adaptive Decision-Making in Dynamic Manufacturing Process Environments",
        "Link": "https://ieeexplore.ieee.org/document/10918634/",
        "Abstract": "Modern production systems generate vast amounts of process data that hold valuable insights for optimizing manufacturing processes. However, production personnel often face the challenge of interpreting this information, especially when dealing with unexpected anomalies or when insights beyond standard reports are required. This challenge arises both from the complex data structures in which the data is provided, and the lack of analytical expertise. This research introduces an approach that leverages Large Language Models (LLMs) to facilitate natural language queries and flexible data visualization, allowing production personnel to interact effortlessly with complex datasets. Tested on process data from an industrial extrusion process that has been enhanced using data augmentation techniques, the proposed concept demonstrates the capability to retrieve relevant data and present tailored visualizations based on simple user prompts. The results demonstrate that LLM-driven data exploration can support production personnel and help overcome the challenges described, which arise from the complex nature of manufacturing data and the specialized domain knowledge required. Future work will concentrate on improving accuracy, robustness, and further integration of domain-specific knowledge, aiming to provide a more reliable and accessible tool for various industrial environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3549529",
            "Date of Publication": "10 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zozan Keskin",
                "labs": [
                    "INC Innovation Center GmbH, Munich, Germany"
                ]
            },
            {
                "name": "Dominik Joosten",
                "labs": [
                    "INC Innovation Center GmbH, Munich, Germany"
                ]
            },
            {
                "name": "Nils Klasen",
                "labs": [
                    "Chair for Intelligence in Quality Sensing, Laboratory for Machine Tools and Production Engineering—WZL, RWTH Aachen University, Aachen, Germany"
                ]
            },
            {
                "name": "Meike Huber",
                "labs": [
                    "Chair for Intelligence in Quality Sensing, Laboratory for Machine Tools and Production Engineering—WZL, RWTH Aachen University, Aachen, Germany",
                    "Hong Kong Industrial Artificial Intelligence & Robotics Centre (FLAIR), Hong Kong, China"
                ]
            },
            {
                "name": "Chang Liu",
                "labs": [
                    "Hong Kong Industrial Artificial Intelligence & Robotics Centre (FLAIR), Hong Kong, China"
                ]
            },
            {
                "name": "Benny Drescher",
                "labs": [
                    "INC Innovation Center GmbH, Munich, Germany",
                    "Hong Kong Industrial Artificial Intelligence & Robotics Centre (FLAIR), Hong Kong, China"
                ]
            },
            {
                "name": "Robert H. Schmitt",
                "labs": [
                    "Chair for Intelligence in Quality Sensing, Laboratory for Machine Tools and Production Engineering—WZL, RWTH Aachen University, Aachen, Germany",
                    "Fraunhofer IPT, Aachen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Production",
                "Decision making",
                "Real-time systems",
                "Personnel",
                "Manufacturing processes",
                "Large language models",
                "Natural languages",
                "Standards",
                "Process mining"
            ],
            "Author Keywords": [
                "Industry 4.0",
                "manufacturing",
                "large language models (LLMs)",
                "data-driven decision-making",
                "real-time sensor data",
                "natural language queries",
                "production process optimization",
                "anomaly detection",
                "data visualization",
                "shop floor analytics"
            ]
        }
    },
    {
        "Title": "Securing LLM Workloads With NIST AI RMF in the Internet of Robotic Things",
        "Link": "https://ieeexplore.ieee.org/document/10965643/",
        "Abstract": "The Internet of Robotic Things (IoRT) is revolutionizing industries by enabling autonomous, AI-driven robotic systems to perform complex and collaborative tasks, such as precision agriculture, disaster response, and logistic shipping operations. However, integrating AI into IoRT introduces significant challenges, including security vulnerabilities, adversarial attacks, data integrity risks, and operational disruptions in dynamic and high-stakes environments. This paper addresses these challenges by integrating and enhancing the NIST AI Risk Management Framework (AI RMF) for IoRT systems, providing a structured approach to identify, assess, and mitigate risks specific to IoRT ecosystems. We introduce a novel Large Language Model (LLM)-based approach for translating natural language commands into secure and precise robotic operations, enabling seamless collaboration and enhancing safety and reliability in mission-critical scenarios. Using a flood recovery scenario in precision agriculture, we demonstrate the practical application of these solutions, where swarm robots equipped with AI inference engines collaborate to navigate hazards, locate individuals, assess infrastructure damage, and mitigate risks. A comprehensive threat analysis is presented, mapping identified vulnerabilities to the NIST AI RMF, and tailored security controls are proposed to mitigate these threats effectively. We propose critical enhancements to the framework, including advanced quantitative risk assessment methods, subsystem governance strategies for interconnected IoRT networks, and robust auditing mechanisms to address unique IoRT-specific challenges. This work establishes a robust foundation for aligning AI governance frameworks with the complex and dynamic demands of IoRT systems. By addressing security, operational, and ethical considerations, it fosters secure, efficient, and trustworthy deployment across diverse applications, paving the way for sustainable and impactful IoRT innovations.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3561235",
            "Date of Publication": "15 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hassan Karim",
                "labs": [
                    "Acacia Consulting, Beltsville, MD, USA"
                ]
            },
            {
                "name": "Deepti Gupta",
                "labs": [
                    "Department of Computer Information Systems, Texas A&M University-Central Texas, Killeen, TX, USA"
                ]
            },
            {
                "name": "Sai Sitharaman",
                "labs": [
                    "Zetafence Inc., Dublin, CA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Robots",
                "Security",
                "Service robots",
                "NIST",
                "Safety",
                "Internet of Things",
                "Risk management",
                "Robot kinematics",
                "Computer security"
            ],
            "Author Keywords": [
                "IoRT",
                "NIST AI risk management framework",
                "natural language processing",
                "security and privacy",
                "smart farming"
            ]
        }
    },
    {
        "Title": "Improving Web Accessibility With an LLM-Based Tool: A Preliminary Evaluation for STEM Images",
        "Link": "https://ieeexplore.ieee.org/document/11027076/",
        "Abstract": "Ensuring equitable access to web-based visual content in Science, Technology, Engineering, and Mathematics (STEM) disciplines remains a significant challenge for visually impaired users. This preliminary study explores the use of Large Language Models (LLMs) to automatically generate high-quality alternative texts for complex web images in these domains, contributing to the development of an accessibility tool. First, we analyzed the outputs of various LLM-based image-captioning systems, selected the most suitable one (Gemini), and developed a browser extension, AlternAtIve, capable of generating alternative descriptions at varying verbosity levels. To evaluate AlternAtIve, we assessed its perceived usefulness in a study involving 35 participants, including a blind user. Additionally, we manually compared the quality of the outputs generated by AlternAtIve with those provided by two state-of-the-practice tools from the Google Web Store, using a custom metric that computes the quality of the descriptions considering their correctness, usefulness, and completeness. The results show that the descriptions generated with AlternAtIve achieved high quality scores, almost always better than those of the other two tools. Although conveying the meaning of complex images to visually impaired users through descriptions remains challenging, the findings suggest that AI-based tools, such as AlternAtIve, can significantly improve the web navigation experience for screen reader users.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3577519",
            "Date of Publication": "06 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Giacomo Pedemonte",
                "labs": [
                    "Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi (DIBRIS), Università di Genova, Genoa, Italy"
                ]
            },
            {
                "name": "Maurizio Leotta",
                "labs": [
                    "Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi (DIBRIS), Università di Genova, Genoa, Italy"
                ]
            },
            {
                "name": "Marina Ribaudo",
                "labs": [
                    "Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi (DIBRIS), Università di Genova, Genoa, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Visualization",
                "Dolphins",
                "Guidelines",
                "Browsers",
                "STEM",
                "Dogs",
                "Anatomy",
                "Transformers",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Web accessibility",
                "image captioning",
                "large language models",
                "empirical evaluation"
            ]
        }
    },
    {
        "Title": "Don’t Stop Believin’: A Unified Evaluation Approach for LLM Honeypots",
        "Link": "https://ieeexplore.ieee.org/document/10703029/",
        "Abstract": "The research area of honeypots is gaining new momentum, driven by advancements in large language models (LLMs). The chat-based applications of generative pretrained transformer (GPT) models seem ideal for the use as honeypot backends, especially in request-response protocols like Secure Shell (SSH). By leveraging LLMs, many challenges associated with traditional honeypots – such as high development costs, ease of exposure, and breakout risks – appear to be solved. While early studies have primarily focused on the potential of these models, our research investigates the current limitations of GPT-3.5 by analyzing three datasets of varying complexity. We conducted an expert annotation of over 1,400 request-response pairs, encompassing 230 different base commands. Our findings reveal that while GPT-3.5 struggles to maintain context, incorporating session context into response generation improves the quality of SSH responses. Additionally, we explored whether distinguishing between convincing and non-convincing responses is a metrics issue. We propose a paraphrase-mining approach to address this challenge, which achieved a macro F1 score of 77.85% using cosine distance in our evaluation. This method has the potential to reduce annotation efforts, converge LLM-based honeypot performance evaluation, and facilitate comparisons between new and previous approaches in future research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3472460",
            "Date of Publication": "02 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Simon B. Weber",
                "labs": [
                    "Department of Computer Science, Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany"
                ]
            },
            {
                "name": "Marc Feger",
                "labs": [
                    "Department of Computer Science, Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany"
                ]
            },
            {
                "name": "Michael Pilgermann",
                "labs": [
                    "Department of Computer Science and Media, Brandenburg University of Applied Sciences, Brandenburg an der Havel, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Protocols",
                "Measurement",
                "Complexity theory",
                "Large language models",
                "History",
                "Data models",
                "Accuracy",
                "Usability",
                "Information security",
                "Risk management",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "IT security",
                "honeypot",
                "large language model",
                "GPT",
                "cosine distance",
                "evaluation"
            ]
        }
    },
    {
        "Title": "LLM-Driven, Self-Improving Framework for Security Test Automation: Leveraging Karate DSL for Augmented API Resilience",
        "Link": "https://ieeexplore.ieee.org/document/10942340/",
        "Abstract": "Modern software architectures heavily rely on APIs, yet face significant security challenges, particularly with Broken Object Level Authorization (BOLA) vulnerabilities, which remain the most critical API security risk according to OWASP. This paper introduces Karate-BOLA-Guard, an innovative framework leveraging Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques to automate security-focused test case generation for APIs. Our approach integrates vector databases for context retrieval, multiple LLM models for test generation, and observability tools for process monitoring. Initial experiments were carried out on three deliberately vulnerable APIs (VAmPI, Crapi, and OWASP Juice Shop), with subsequent validation on fifteen additional production APIs spanning diverse domains including social media, version control systems, financial services, and transportation services. Our evaluation metrics show Llama 3 8B achieving consistent performance (Accuracy: 3.1-3.4, Interoperability: 3.7-4.3) with an average processing time of 143.76 seconds on GPU. Performance analysis revealed significant GPU acceleration benefits, with 20-25x improvement over CPU processing times. Smaller models demonstrated efficient processing, with Phi-3 Mini averaging 69.58 seconds and Mistral 72.14 seconds, while maintaining acceptable accuracy scores. Token utilization patterns showed Llama 3 8B using an average of 36,591 tokens per session, compared to Mistral’s 25,225 and Phi-3 Mini’s 31,007. Our framework’s effectiveness varied across APIs, with notably strong performance in complex platforms (Instagram: A = 4.3, I = 4.4) while maintaining consistent functionality in simpler implementations (VAmPI: A = 3.6, I = 4.3). The iterative refinement process, evaluated through comprehensive metrics including Accuracy (A), Complexity (C), and Interoperability (I), represents a significant advancement in automated API security testing, offering an efficient, accurate, and adaptable approach to detecting BOLA vulnerabilities across diverse API architectures.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554960",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Emil Marian Pasca",
                "labs": [
                    "Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania"
                ]
            },
            {
                "name": "Daniela Delinschi",
                "labs": [
                    "Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania"
                ]
            },
            {
                "name": "Rudolf Erdei",
                "labs": [
                    "Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania"
                ]
            },
            {
                "name": "Oliviu Matei",
                "labs": [
                    "Department of Electrical, Electronic and Computer Engineering, Technical University of Cluj Napoca, North University Centre of Baia Mare, Baia Mare, Romania",
                    "Department of Research and Development, HOLISUN SRL, Baia Mare, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Testing",
                "Retrieval augmented generation",
                "Test pattern generators",
                "Application programming interfaces",
                "Accuracy",
                "Software testing",
                "Automation",
                "Systematics",
                "Computer architecture"
            ],
            "Author Keywords": [
                "API security",
                "automation testing tools",
                "cybersecurity",
                "restful API",
                "software testing"
            ]
        }
    },
    {
        "Title": "ShellBox: Adversarially Enhanced LLM-Interactive Honeypot Framework",
        "Link": "https://ieeexplore.ieee.org/document/11124871/",
        "Abstract": "Honeypot technology is an active defence strategy designed to mitigate the asymmetry inherent in network attacks and defence dynamics. In recent years, honeypot systems powered by large language models (LLMs) have become a focal point of research owing to their ability to simulate complex network environments and generate highly deceptive virtual assets. However, response inconsistency in multi-turn dialogues and prompt injection vulnerabilities inherent to LLMs significantly reduce the deceptive capability of honeypots. This study first defines the threat model, and then introduces a relevance-based interaction history pruning algorithm and dynamic error simulation strategy to mitigate these challenges. Considering practical issues such as response latency and network instability, our experiments were conducted using multiple locally deployed open-source LLMs. The experimental results demonstrated that the proposed dynamic error simulation mechanism achieved a maximum accuracy of 81.63% for the DeepSeek-R1 model. Furthermore, applying the interaction history pruning algorithm improved the turn-level coherence score (TCS) by 34.5% compared with the baseline. Finally, this paper outlines potential future research directions for LLM-based honeypot technologies in active multi-turn mechanisms.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3598779",
            "Date of Publication": "14 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guan Yang",
                "labs": [
                    "School of Artificial Intelligence, Zhongyuan University of Technology, Zhengzhou, China"
                ]
            },
            {
                "name": "Zhengzheng Sun",
                "labs": [
                    "School of Computer Science, Zhongyuan University of Technology, Zhengzhou, China"
                ]
            },
            {
                "name": "Yu Wang",
                "labs": [
                    "School of Software, Henan University of Engineering, Zhengzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Heuristic algorithms",
                "History",
                "Databases",
                "Chatbots",
                "Linux",
                "Large language models",
                "Threat modeling",
                "HTTP",
                "Adaptation models",
                "Prompt engineering"
            ],
            "Author Keywords": [
                "Network attack and multi-turn",
                "honeypot",
                "large language model",
                "dynamic error simulation",
                "interaction history pruning algorithm"
            ]
        }
    },
    {
        "Title": "Dynamic Batch Processing with FlexiDecode Scheduler for Efficient LLM Inference in IIoT",
        "Link": "https://ieeexplore.ieee.org/document/11164457/",
        "Abstract": "Large Language Models (LLMs) are expanding their applications across various fields, including Industrial Internet of Things (IIoT), where they analyze sensor data, automate diagnostics, and enhance predictive maintenance. LLM inference is provided by service providers to users, with each inference request undergoing two phases: prefill and decode. Due to the autoregressive nature of generation, only one token can be produced per iteration, necessitating multiple iterations to complete a request. Typically, batch processing groups multiple requests into a single batch for inference, improving throughput and hardware utilization. However, in service systems, a fixed batch size presents challenges under fluctuating request volumes, particularly in IIoT environments, where data flow can vary significantly. Specifically, during the high-load periods, a fixed batch size may lead to underutilization of resources, while during the low-load periods, it may result in resource wastage. In this paper, we introduce FlexiDecode Scheduler (FDS) to address these challenges by dynamically adjusting the decoding batch size based on system load conditions, improving resource utilization, and reducing wait time during high-load periods. FDS prioritizes prefilling new requests to maximize decoding efficiency and employs a request output length predictor to optimize request scheduling, minimizing End-to-End (E2E) latency. Compared to virtual Large Language Model (vLLM) and Sarathi, our approach achieves a 23% and 16% reduction in E2E latency, improves actual request execution time by 34% and 15%, respectively, and increases computational utilization by 10%.",
        "Details": {
            "DOI": "10.26599/BDMA.2025.9020025",
            "Date of Publication": "15 September 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Xiaocong Jia",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Bruce Gu",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Jinjun Chen",
                "labs": [
                    "Department of Computing Technologies, Swinburne University of Technology, Melbourne, Australia"
                ]
            },
            {
                "name": "Longxiang Gao",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Weiguang Pang",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Guangtong Lv",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Youyang Qu",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            },
            {
                "name": "Lei Cui",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security of Ministry of Education, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Power Internet and Service Computing, Shandong Fundamental Research Center for Computer Science, Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Processor scheduling",
                "Large language models",
                "Batch production systems",
                "Predictive models",
                "Dynamic scheduling",
                "Throughput",
                "Robustness",
                "Decoding",
                "Resource management",
                "Industrial Internet of Things"
            ],
            "Author Keywords": [
                "virtual Large Language Model (vLLM) inference",
                "batch scheduling",
                "dynamic decoding batches",
                "calculating utilization"
            ]
        }
    },
    {
        "Title": "Toward Inclusive Healthcare: An LLM-Based Multimodal Chatbot for Preliminary Diagnosis",
        "Link": "https://ieeexplore.ieee.org/document/11104254/",
        "Abstract": "This paper presents the design and development of a multimodal medical chatbot that leverages Gemini-2.0-Flash Model alongside a novel Retrieval-Augmented Generation (RAG) architecture to support preliminary medical diagnosis and recommendations. The system integrates textual prompt analysis and medical image interpretation, aiming to improve healthcare accessibility, particularly for underserved populations. Focused on data-rich medical conditions, the chatbot generates reliable diagnostic insights based on natural language inputs and/or medical images, requiring minimal user expertise. The proposed RAG-based architecture incorporates a curated medical knowledge base and structured retrieval mechanisms, significantly reducing hallucinations and enhancing response credibility compared to direct Large Language Model (LLM) querying. By demonstrating the efficacy of multimodal reasoning in conjunction with structured retrieval, this work paves the way for more accessible, accurate, and scalable AI-driven health support systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3594218",
            "Date of Publication": "30 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ishita Agarwal",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "V. Sakthivel",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "P. Prakash",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical diagnostic imaging",
                "Chatbots",
                "Medical services",
                "Retrieval augmented generation",
                "Accuracy",
                "Oral communication",
                "Artificial intelligence",
                "Vectors",
                "Training",
                "Random forests"
            ],
            "Author Keywords": [
                "Gemini",
                "generative AI",
                "large language models",
                "medical chatbot",
                "medical diagnosis",
                "retrieval augmented generation"
            ]
        }
    },
    {
        "Title": "LLM-Based Automated Generation and Tri-Modal Representation of Cyber Attack Scenario",
        "Link": "https://ieeexplore.ieee.org/document/11122442/",
        "Abstract": "The rapid advancement of information technology, the proliferation of artificial intelligence (AI), and the increasing reliance on digital infrastructure have significantly intensified cyber threats faced by organizations. In this evolving landscape, timely identification of threats and coordinated strategic responses have become essential. However, traditional human-centric approaches to cyber-attack scenario generation are limited in scalability, timeliness, and semantic coherence–especially across stakeholders with diverse technical backgrounds. To address these challenges, this study proposes an automated, LLM-driven framework for generating cyber-attack scenarios and converting them into three semantically aligned modalities: natural language narratives, attack graphs, and formal mathematical representations. This tri-modal approach enhances cross-role interpretability and enables consistent understanding among technical experts and non-technical decision-makers alike. The core objective of this research is to propose an automated pipeline framework that spans from scenario generation to tri-modal representation, designed to support decision-makers by ensuring semantic consistency and enhancing interpretability across stakeholder roles. The framework incorporates real-world threat intelligence, structured input parameters, and prompt engineering techniques to ensure realism and fidelity. Evaluation results using state-of-the-art LLMs—including both open-source and proprietary models—demonstrate the system’s ability to generate coherent, context-aware, and logically consistent outputs. The findings validate the feasibility of the proposed approach and underscore its potential to improve cybersecurity preparedness, training efficacy, and governance communication through structured, intelligible scenario representations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3597850",
            "Date of Publication": "11 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seonghyun Roh",
                "labs": [
                    "Department of Convergence Security, Chungbuk National University, Cheongju, Chungbuk, Republic of Korea"
                ]
            },
            {
                "name": "Tae-Sung Kim",
                "labs": [
                    "Department of Management Information Systems, Chungbuk National University, Cheongju, Chungbuk, Republic of Korea",
                    "Cybersecurity Economics Research Institute, Chungbuk National University, Cheongju, Chungbuk, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cyberattack",
                "Training",
                "Organizations",
                "Scenario generation",
                "Semantics",
                "Manuals",
                "Stakeholders",
                "Scalability",
                "Risk management",
                "Data breach"
            ],
            "Author Keywords": [
                "Attack scenario",
                "cybersecurity",
                "large language models",
                "prompt engineering",
                "tri-modal representation"
            ]
        }
    },
    {
        "Title": "AI, ML, and LLM Integration in 5G/6G Networks: A Comprehensive Survey of Architectures, Challenges, and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/11159193/",
        "Abstract": "The transition from 5G to 6G networks demands groundbreaking advances in intelligence, adaptability, and security to support emerging applications such as real-time telemedicine, immersive extended reality (XR), and autonomous systems. This article provides a comprehensive analysis of how artificial intelligence (AI), machine learning (ML), and large language models (LLM) are revolutionizing next-generation telecommunications. We present a structured roadmap for integrating these technologies into 6G infrastructure, emphasizing their transformative roles in intelligent network management, dynamic resource allocation, and proactive threat mitigation. By addressing key challenges such as ultralow latency, heterogeneous data handling, and ethical governance, this study bridges theoretical innovations with practical applications. Notable contributions include novel frameworks for AI-enhanced security, self-healing networks, and privacy-preserving techniques like federated learning. Furthermore, we explore critical ethical considerations, including bias mitigation and transparency in AI decision-making, while highlighting emerging research directions such as adaptive learning systems and hybrid AI architectures. This work underscores the synergistic potential of AI and 6G, equipping researchers and industry stakeholders with actionable insights to develop resilient, user-centric networks that will shape the future of global connectivity.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3608736",
            "Date of Publication": "11 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yusuf Usman",
                "labs": [
                    "NextGen AI Research Laboratory, Fort Worth, TX, USA"
                ]
            },
            {
                "name": "Habeeb Oladipupo",
                "labs": [
                    "Department of Computer Science, University of Lagos, Lagos, Nigeria"
                ]
            },
            {
                "name": "Adegboyega D. During",
                "labs": [
                    "Western Alliance Bank, Phoenix, AZ, USA"
                ]
            },
            {
                "name": "Robert Akl",
                "labs": [
                    "College of Engineering, University of North Texas, Denton, TX, USA"
                ]
            },
            {
                "name": "Robin Chataut",
                "labs": [
                    "Department of Computer Science, Texas Christian University, Fort Worth, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "6G mobile communication",
                "5G mobile communication",
                "3G mobile communication",
                "Machine learning",
                "Security",
                "Real-time systems",
                "Standards",
                "Prediction algorithms",
                "Large language models"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "machine learning (ML)",
                "large language models (LLMs)",
                "5G networks",
                "6G networks",
                "intelligent network management",
                "network integration",
                "dynamic resource allocation",
                "AI-enhanced security",
                "self-healing networks",
                "federated learning",
                "privacy-preserving techniques",
                "ethical considerations",
                "adaptive learning systems",
                "hybrid AI architectures"
            ]
        }
    },
    {
        "Title": "Intelligent Virtual Assistant for Calculating Technology Readiness Levels Using Large Language Models (LLM)",
        "Link": "https://ieeexplore.ieee.org/document/11112552/",
        "Abstract": "The Technology Readiness Level (TRL) is a metric developed by NASA in the 1970s to assess the maturity of a technology and guide decision-making regarding its development. Although it is standardized, in practice, evaluations are often manual and subjective, leading to inconsistencies. In this study, an intelligent virtual assistant was developed based on a large language model (LLM), using GPT-3.5-Turbo as the foundation, selected over LlaMa-2 after rigorous performance testing. The model was trained using optimization techniques on a custom dataset built from reliable sources such as NASA, government entities, and universities, enabling a more accurate evaluation of the TRL.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595699",
            "Date of Publication": "04 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Juan Betancourt",
                "labs": [
                    "Department of Telematics, Universidad del Cauca, Popayán, Colombia"
                ]
            },
            {
                "name": "Andrés Coral",
                "labs": [
                    "Department of Telematics, Universidad del Cauca, Popayán, Colombia"
                ]
            },
            {
                "name": "Anabel Fraga",
                "labs": [
                    "Department of Computer Science and Engineering, Universidad Carlos III de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Cristhian Figueroa",
                "labs": [
                    "Department of Telematics, Universidad del Cauca, Popayán, Colombia"
                ]
            },
            {
                "name": "Gustavo Ramirez-Gonzalez",
                "labs": [
                    "Department of Telematics, Universidad del Cauca, Popayán, Colombia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Large language models",
                "Chatbots",
                "Virtual assistants",
                "Technological innovation",
                "Natural language processing",
                "NASA",
                "Automation",
                "Training",
                "Data models",
                "Accuracy"
            ],
            "Author Keywords": [
                "Chat-bot",
                "fine-tuning",
                "large language models",
                "natural language processing",
                "technology readiness level"
            ]
        }
    },
    {
        "Title": "LCGD: Enhancing Text-to-Video Generation via Contextual LLM Guidance and U-Net Denoising",
        "Link": "https://ieeexplore.ieee.org/document/10925377/",
        "Abstract": "Diffusion models have emerged as a leading solution in computer vision and they excel at audio, image, and video generation by utilizing the Markov chain to map complex latent spaces. These models outperform other generative models such as GANs and VAEs, with their noising and denoising processes modeled after U-Net architecture, enabling high-quality text-to-image and text-to-video synthesis. However, existing research has largely focused on application rather than improving underlying architectures, leading to limitations, such as oversmoothing in approaches like FreeU. To address these gaps, we introduce LLM Contextual Guided Diffusion (LCGD), which integrates large language models (LLMs) into the noising and denoising phases to enhance semantic understanding, noise modulation, and feature selection. This approach improves the output realism and coherence, as demonstrated by our results, where SD+LCGD achieved 89.91% compared to 85.88% for SD+FreeU.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3550945",
            "Date of Publication": "14 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Waseem",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Usman Ghani Khan",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Syed Khaldoon Khurshid",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Noise reduction",
                "Diffusion models",
                "Noise",
                "Training",
                "Text to video",
                "Large language models",
                "Computational modeling",
                "Visualization",
                "Image synthesis"
            ],
            "Author Keywords": [
                "Diffusion models",
                "multimodal data generation",
                "large language models (LLMs)",
                "context-aware denoising",
                "U-Net architecture",
                "text-to-video generation"
            ]
        }
    },
    {
        "Title": "Improving LLM Outputs Against Jailbreak Attacks With Expert Model Integration",
        "Link": "https://ieeexplore.ieee.org/document/11095693/",
        "Abstract": "Using LLMs in a production environment presents security challenges that include vulnerabilities to jailbreaks and prompt injections, which can result in harmful outputs for humans or the enterprise. The challenge is amplified when working within a specific domain, as topics generally accepted for LLMs to address, may be irrelevant to that field. These problems can be mitigated for example, by fine-tuning large language models with domain-specific and security-focused data. However, these alone are insufficient, as jailbreak techniques evolve. Additionally, API-accessed models do not offer the flexibility needed to tailor behavior to industry-specific objectives, and in-context learning is not always sufficient and reliable. In response to these challenges, we introduce Archias, an expert model, adept at distinguishing between in-domain and out-of-domain communications. Archias classifies user inquiries into several categories: in-domain (specifically for the automotive industry), malicious questions, price injections, prompt injections, and out-of-domain examples. Our methodology integrates outputs from the expert model (Archias) into prompts, which are then processed by the LLM to generate responses. This method increases the model’s ability to understand the user’s intention and give appropriate answers. Archias can be adjusted, fine-tuned, and used for many different purposes due to its small size. Therefore, it can be simply customized to the needs of any industry. To validate our approach, we created a benchmark dataset for the automotive industry. Furthermore, in the interest of advancing research and development, we release our benchmark dataset to the community.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3592458",
            "Date of Publication": "24 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tatia Tsmindashvili",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Ana Kolkhidashvili",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Dachi Kurtskhalia",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Nino Maghlakelidze",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Elene Mekvabishvili",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Guram Dentoshvili",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Orkhan Shamilov",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Zaal Gachechiladze",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Steven Saporta",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            },
            {
                "name": "David Dachi Choladze",
                "labs": [
                    "Impel, Syracuse, NY, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Benchmark testing",
                "Pipelines",
                "Chatbots",
                "Adaptation models",
                "Security",
                "Industries",
                "Automotive engineering",
                "Training",
                "Pricing"
            ],
            "Author Keywords": [
                "Expert model",
                "generative AI",
                "jailbreak attacks",
                "large language models",
                "prompt injections"
            ]
        }
    },
    {
        "Title": "LLM-Based Text Style Transfer: Have We Taken a Step Forward?",
        "Link": "https://ieeexplore.ieee.org/document/10915631/",
        "Abstract": "Text style transfer is the task of altering the stylistic way in which a given sentence is written while maintaining its original meaning. The task requires models to identify and modify various stylistic properties, such as politeness, formality, and sentiment. With the advent of Large Language Models (LLMs) and their remarkable performances for a variety of tasks, numerous LLMs have emerged in the past few years. This paper provides an overview of recent advancements in text style transfer using LLMs. The discussion is focused on LLM-based approaches commonly used for text generation and their adoption for text style transfer. The paper is organized around three main groups of methods: prompting techniques for LLMs, fine-tuning techniques for LLMs, and memory-augmented LLMs. The discussion emphasizes the similarities and differences among the discussed methods and groups, along with the challenges and opportunities that are expected to direct and foster further research in the field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3548967",
            "Date of Publication": "06 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Martina Toshevska",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Sonja Gievska",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University in Skopje, Skopje, North Macedonia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Routing",
                "Measurement",
                "Large language models",
                "Writing",
                "Transformers",
                "Standards",
                "Semantics",
                "Retrieval augmented generation",
                "Computer architecture",
                "Unsupervised learning"
            ],
            "Author Keywords": [
                "Text style transfer",
                "large language models",
                "natural language processing",
                "natural language generation"
            ]
        }
    },
    {
        "Title": "Modeling of Negative Feedback Refined via LLM in Recommender Systems",
        "Link": "https://ieeexplore.ieee.org/document/11126013/",
        "Abstract": "Most recommender systems have been proposed by utilizing the user feedback data, where implicit feedback is often used. However, in this setting, the dispreference signals in the original data get simply removed and treated the same as the unrated items. To address this limitation, recent studies have been proposed to utilize the negative feedback, and have shown how the recommender systems can be improved. One major limitation in these approaches is that the negative feedback data is generated through some fixed threshold. A recent work presented a new perspective by leveraging a Large Language Model (LLM) to flexibly distinguish positive and negative signals based on individual user intent. In this paper, we review this latest work, and extend it in three directions. First, we address the structural limitations in modeling negative feedback in the previous work. Second, we replace the existing loss function with a more robust approach, and show its effectiveness. Third, we propose a method for generating unified embeddings that integrate both positive and negative embeddings, thereby capturing user preferences and dispreferences in a holistic manner. Experimental results on five real-world datasets demonstrate that our model achieves state-of-the-art performance. The code is available at https://github.com/Chanwoo-Jeong-2000/ReFINe_plus",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599176",
            "Date of Publication": "15 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chanwoo Jeong",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Yoon-Sik Cho",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Negative feedback",
                "Recommender systems",
                "Autoencoders",
                "Motion pictures",
                "Mathematical models",
                "Computational modeling",
                "Stars",
                "Standards",
                "Large language models",
                "Graph neural networks"
            ],
            "Author Keywords": [
                "Autoencoder",
                "graph neural networks",
                "large language models",
                "negative feedback",
                "recommender systems"
            ]
        }
    },
    {
        "Title": "MalPacDetector: An LLM-Based Malicious NPM Package Detector",
        "Link": "https://ieeexplore.ieee.org/document/11037372/",
        "Abstract": "The Node Package Manager (npm) registry contains millions of JavaScript packages widely shared between worldwide developers. However, npm has also been abused by attackers to spread malicious packages, highlighting the importance of detecting malicious npm packages. Existing malicious npm package detectors suffer from, among other things, high false positives and/or high false negatives. In this paper, we propose a novel Malicious npm Package Detector (MalPacDetector), which leverages Large Language Model (LLM) to automatically and dynamically generate features (rather than asking experts to manually define them). To evaluate the effectiveness of MalPacDetector and existing detectors, we construct a new npm package dataset, which overcomes the weaknesses of existing datasets (e.g., a small number of examples and a high repetition rate of malicious fragments). The experimental results show that MalPacDetector outperforms existing detectors by achieving a false positive rate of 1.3% and a false negative rate of 7.5%. In particular, MalPacDetector detects 39 previously unknown malicious packages, which are confirmed by the npm security team.",
        "Details": {
            "DOI": "10.1109/TIFS.2025.3580336",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Information Forensics and Security"
        },
        "issn_info": {
            "Print ISSN": "1556-6013",
            "Electronic ISSN": "1556-6021"
        },
        "authors_data": [
            {
                "name": "Jian Wang",
                "labs": [
                    "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Laboratory, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Jinyinhu Laboratory, Huazhong University of Science and Technology, Wuhan, China",
                    "Jinyinhu Laboratory, Wuhan, China"
                ]
            },
            {
                "name": "Zhen Li",
                "labs": [
                    "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Laboratory, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Jinyinhu Laboratory, Huazhong University of Science and Technology, Wuhan, China",
                    "Jinyinhu Laboratory, Wuhan, China"
                ]
            },
            {
                "name": "Jixiang Qu",
                "labs": [
                    "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Laboratory, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Jinyinhu Laboratory, Huazhong University of Science and Technology, Wuhan, China",
                    "Jinyinhu Laboratory, Wuhan, China"
                ]
            },
            {
                "name": "Deqing Zou",
                "labs": [
                    "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Laboratory, Hubei Key Laboratory of Distributed System Security, Hubei Engineering Research Center on Big Data Security, School of Cyber Science and Engineering, Jinyinhu Laboratory, Huazhong University of Science and Technology, Wuhan, China",
                    "Jinyinhu Laboratory, Wuhan, China"
                ]
            },
            {
                "name": "Shouhuai Xu",
                "labs": [
                    "Department of Computer Science, Laboratory for Cybersecurity Dynamics, University of Colorado at Colorado Springs, Colorado Springs, CO, USA"
                ]
            },
            {
                "name": "Ziteng Xu",
                "labs": [
                    "Ant Technology Group Company Ltd., Hangzhou, China"
                ]
            },
            {
                "name": "Zhenwei Wang",
                "labs": [
                    "Ant Technology Group Company Ltd., Hangzhou, China"
                ]
            },
            {
                "name": "Hai Jin",
                "labs": [
                    "National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Laboratory, Cluster and Grid Computing Laboratory, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Detectors",
                "Malware",
                "Codes",
                "Training",
                "Security",
                "Data mining",
                "Large language models",
                "Big Data",
                "Syntactics"
            ],
            "Author Keywords": [
                "Malicious package detection",
                "NPM",
                "malicious features",
                "large language model"
            ]
        }
    },
    {
        "Title": "Edge-LLM Inference With Cost-Aware Layer Allocation and Adaptive Scheduling",
        "Link": "https://ieeexplore.ieee.org/document/11095716/",
        "Abstract": "This paper addresses two key challenges in distributed Large Language Model (LLM) inference at the edge: 1) cost-efficient and fair task allocation, and 2) dynamic scheduling under deadline constraints. We propose two mechanisms: the Fair Cost-Efficient Incentive Mechanism (FCIM) for task and layer assignment, and the Adaptive Dynamic Scheduling Algorithm (ADSA) for execution scheduling on individual devices. FCIM is an auction-based mechanism that selects cost-effective, memory-feasible devices while minimizing task latency, reward cost, and device usage. Its adaptive reward design ensures positive utility and fairness, even under shifting system priorities. ADSA enables preemption-aware, deadline-driven scheduling by dynamically reordering tasks based on arrival time and workload characteristics. Simulations demonstrate that FCIM reduces communication overhead by 54.7% and task completion time by 36.9% compared to static and performance-driven baselines, while ADSA reduces queueing delay by 39% under strict deadline constraints.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3592308",
            "Date of Publication": "24 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sama Habibi",
                "labs": [
                    "Faculty of Engineering and Natural Sciences, Sabancı University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Ozgur Ercetin",
                "labs": [
                    "Faculty of Engineering and Natural Sciences, Sabancı University, Istanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Resource management",
                "Dynamic scheduling",
                "Costs",
                "Processor scheduling",
                "Pipelines",
                "Scalability",
                "Performance evaluation",
                "Memory management",
                "Computational modeling",
                "Adaptive scheduling"
            ],
            "Author Keywords": [
                "Adaptive scheduling",
                "distributed AI",
                "edge computing",
                "fair incentive mechanism",
                "large language models",
                "resource allocation"
            ]
        }
    },
    {
        "Title": "An Adaptive Multi-Agent LLM-Based Clinical Decision Support System Integrating Biomedical RAG and Web Intelligence",
        "Link": "https://ieeexplore.ieee.org/document/11176078/",
        "Abstract": "Increasing data complexity in clinical decision-making processes hinders physicians’ ability to make rapid and accurate decisions. This study proposes an innovative solution to this problem by designing a multi-layered, adaptive Clinical Decision Support System (CDSS) comprising interacting large language model (LLM) agents. The proposed system performs semantic-level information retrieval using a BioBERT-based vector database, enhances information retrieval by accessing up-to-date medical resources via the web, and restructures outputs by activating an adaptive optimization loop in low-confidence situations. Through the structuring of clinical texts, cross-validation of symptom analyses with literature and internet sources, and collaborative data fusion among agents, the system integrates multi-source data and produces consistent decisions. In experiments conducted on the MedQA, PubMedQA, and MedBullets datasets, the system achieved accuracies of 94%, 88%, and 84%, respectively, representing substantial improvements over state-of-the-art methods and demonstrating the significance of the proposed architecture for clinical decision-making reliability. This framework is not merely an information retrieval engine; it is a clinical intelligence partner designed to learn, actively contribute to the decision process, and focus on reliability. In contrast to current CDSS protocols, which frequently depend on static modules or single-agent models, our architecture tackles some of the shortcomings in timeliness, multi-source evidence fusion, and confidence calibration. This originality enables the system to be a next-generation clinical intelligence partner by enabling an unprecedented level of transparency, customizability, and adaptability in real-world decision-making processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613340",
            "Date of Publication": "23 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Çağatay Umut Öğdü",
                "labs": [
                    "Department of Computer Engineering, Fırat University, Elâzığ, Türkiye"
                ]
            },
            {
                "name": "Kübra Arslanoğlu",
                "labs": [
                    "Department of Computer Engineering, Fırat University, Elâzığ, Türkiye"
                ]
            },
            {
                "name": "Mehmet Karaköse",
                "labs": [
                    "Department of Computer Engineering, Fırat University, Elâzığ, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Reliability",
                "Real-time systems",
                "Medical diagnostic imaging",
                "Large language models",
                "Data integration",
                "Protocols",
                "Heuristic algorithms",
                "Decision support systems",
                "Databases"
            ],
            "Author Keywords": [
                "Clinical decision support system",
                "large language models",
                "multi-agent system"
            ]
        }
    },
    {
        "Title": "Enhancing Sentiment-Driven Recommender Systems With LLM-Based Feature Engineering: A Case Study in Drug Review Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11083619/",
        "Abstract": "Sentiment analysis is vital for evaluating user feedback in drug reviews because understanding patient experiences leads to more personalized treatment recommendations by providing insights into the real-world effectiveness and tolerability of medications, which are often overlooked in clinical trials. This study evaluates the effectiveness of word-level and sentence-level embeddings for feature extraction in sentiment analysis. These embeddings are used in sequential models (Bi-LSTM, CNN) and non-sequential models (Random Forest, DNN, ExtraTreesClassifier). The Random Forest model with LLM2Vec achieves the best performance, with 0.93 accuracy, F1-scores of 0.95 (positive) and 0.88 (negative), and precision scores of 0.93 (positive) and 0.94 (negative). This approach detects subtle negative feedback often missed by standard models. To capture social consensus in patient feedback, we introduce Adaptive Confidence-Weighted Scoring. This method leverages social validation as an implicit confidence signal, enabling sentiment scores to reflect both individual experiences and community agreement. It enhances trust and interpretability while standardizing sentiment polarity on a\n[−5,+5]\nscale. Clinically validated drug-related information, scraped from trusted sources, is encoded using the Llama-3.2-3B-Instruct model to extract context-aware representations. Features derived from this external medical knowledge improve semantic understanding, ensure grounding and safety, and enhance robustness even when reviews are sparse or noisy. The final vectors are employed within a cosine similarity framework to recommend relevant drugs, aligning recommendations with user satisfaction. This work demonstrates how LLM-based feature engineering can advance clinically valid, patient-aligned healthcare recommender systems informed by real-world feedback.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3590326",
            "Date of Publication": "17 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Samuel Matia Kangoni",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Kinshasa, Kinshasa, Congo"
                ]
            },
            {
                "name": "Obed Tshimanga Tshipata",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Kinshasa, Kinshasa, Congo"
                ]
            },
            {
                "name": "Pierre Sedi Nzakuna",
                "labs": [
                    "Department of Industrial Engineering, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Vincenzo Paciello",
                "labs": [
                    "Department of Industrial Engineering, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Jean-Gilbert Mbula Mboma",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Kinshasa, Kinshasa, Congo"
                ]
            },
            {
                "name": "Jean-Robert Makulo",
                "labs": [
                    "Unit of Nephrology, Kinshasa University Hospital, Kinshasa, Congo"
                ]
            },
            {
                "name": "Kyandoghere Kyamakya",
                "labs": [
                    "Institute of smart systems technologies, University of Klagenfurt, Klagenfurt, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Drugs",
                "Sentiment analysis",
                "Recommender systems",
                "Feature extraction",
                "Analytical models",
                "Accuracy",
                "Measurement",
                "Training",
                "Standards"
            ],
            "Author Keywords": [
                "Cosine similarity ranking",
                "drug recommendation systems",
                "large language models",
                "real-world feedback in healthcare",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "A Multi-Criteria Comparison of Large Language Model Powered Assistants in Pre-Research Studies for the Academia",
        "Link": "https://ieeexplore.ieee.org/document/11072164/",
        "Abstract": "Large Language Models (LLMs), including Generative Pre-trained Transformers (GPT), a specific type of Large Language Model Powered Assistants (LLM-PA), have emerged as powerful tools in academic research and education. They offer capabilities ranging from language understanding to content generation, and serve as the foundation for LLM-PA-powered assistants, such as ChatGPT, DeepSeek, and Gemini, which facilitate interactive learning, research support, and intelligent tutoring. This study aims to guide researchers in choosing and ranking various LLM-PA alternatives in their preliminary research for academic studies. However, selecting the appropriate alternatives requires considering a large number of distinct criteria. Therefore, we conducted a multi-criteria comparison of different LLM-PAs employed in academic research. These assistants are evaluated based on criteria including performance metrics, user experience, ethical issues, and technical constraints. Examining the strengths and limitations of each tool across these dimensions, it is aimed to provide insights into their performance and suitability for academic applications. Throughout the solution procedure, we first define the criteria and sub-criteria affecting the preferences and sort them by the G1 method. Subsequently, we evaluate nine commonly used LLM-PA using the Simple Additive Weighting Method. According to the results, Gemini 2.0, Claude 3.7 Sonnet and ChatGPT-4o are the most preferred tools.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586502",
            "Date of Publication": "07 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Murat Akin",
                "labs": [
                    "TUSAŞ-Kazan Vocational School, Gazi University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Gül Didem Batur Sir",
                "labs": [
                    "Department of Industrial Engineering, Faculty of Engineering, Gazi University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Ayyüce Aydemir Karadağ",
                "labs": [
                    "Department of Industrial Engineering, Faculty of Engineering, Gazi University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Hakan Çerçioğlu",
                "labs": [
                    "Department of Industrial Engineering, Faculty of Engineering, Gazi University, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Writing",
                "Education",
                "Artificial intelligence",
                "Ethics",
                "Accuracy",
                "Publishing",
                "Decision making",
                "User experience",
                "Transformers"
            ],
            "Author Keywords": [
                "LLM-powered assistants",
                "academic studies",
                "multi-criteria decision-making",
                "simple additive weighting method"
            ]
        }
    },
    {
        "Title": "CAPRI: A Context-Aware Privacy Framework for Multi-Agent Generative AI Applications",
        "Link": "https://ieeexplore.ieee.org/document/10916629/",
        "Abstract": "While the swift advancement of cloud-based Large Language Models (LLMs) has significantly increased the efficiency and automation in business processes, it has also introduced considerable privacy concerns regarding Personally Identifiable Information (PII) and other protected data in multimodal forms, such as text, video, or images, being exported, potentially insecurely, outside the corporate environments. Although traditional anonymization-based techniques can alleviate these risks in offline applications, such as summarization or classification, incorporating it into online LLM workflows poses substantial challenges, particularly when these workflows encompass real-time transactions involving multiple stakeholders, as commonly observed in multi-agent generative AI applications. This study explores these challenges and proposes novel context-aware privacy frameworks and methods to address these issues. We employ a local privacy-focused gatekeeper LLM to contextually pseudonymize PII and assign unique identifiers as part of a new mapping process, thereby facilitating re-identification in real-time operations while safeguarding privacy when interacting with cloud-based LLMs. Our proposed methodologies and frameworks adeptly integrate privacy considerations into LLM and LLM Agent workflows, preserving both privacy and data utility while maintaining operational efficiency and utility comparable to non-anonymized generative AI processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3549312",
            "Date of Publication": "06 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jae H. Park",
                "labs": [
                    "Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Vijay K. Madisetti",
                "labs": [
                    "Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Synthetic data",
                "Privacy",
                "Identification of persons",
                "Generative AI",
                "Cognition",
                "Real-time systems",
                "Semantics",
                "Logic gates",
                "Large language models"
            ],
            "Author Keywords": [
                "Generative AI (Gen AI)",
                "large language model (LLM)",
                "pseudonymization"
            ]
        }
    },
    {
        "Title": "Legal Query RAG",
        "Link": "https://ieeexplore.ieee.org/document/10887211/",
        "Abstract": "Recently, legal practice has seen a significant rise in the adoption of Artificial Intelligence (AI) for various core tasks. However, these technologies remain in their early stages and face challenges such as understanding complex legal reasoning, managing biased data, ensuring transparency, and avoiding misleading responses, commonly referred to as hallucinations. To address these limitations, this paper introduces Legal Query RAG (LQ-RAG), a novel Retrieval-Augmented Generation framework with a recursive feedback mechanism specifically designed to overcome the critical shortcomings of standard RAG implementations in legal applications. The proposed framework incorporates four key components: a custom evaluation agent, a specialized response generation model, a prompt engineering agent, and a fine-tuned legal embedding LLM. Together, these components effectively minimize hallucinations, improve domain-specific accuracy, and deliver precise, high-quality responses for complex queries. Experimental results demonstrate that the fine-tuned embedding LLM achieves a 13% improvement in Hit Rate and a 15% improvement in Mean Reciprocal Rank (MRR). Comparisons with general LLMs reveal a 24% performance gain when using the Hybrid Fine-Tuned Generative LLM (HFM), the specialized response generation model integrated into the LQ-RAG framework. Furthermore, LQ-RAG achieves a 23% improvement in relevance score over naive configurations and a 14% improvement over RAG with Fine-Tuned LLMs (FTM). These findings underscore the potential of domain-specific fine-tuned LLMs, combined with advanced RAG modules and feedback mechanisms, to significantly enhance the reliability and performance of AI in legal practice. The reliance of this study on a proprietary model as the evaluation agent, combined with the lack of feedback from human experts, highlights the need for improvement. Future efforts should focus on developing a specialized legal evaluation agent and enhancing its performance by incorporating feedback from domain experts.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3542125",
            "Date of Publication": "14 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahman S. M. Wahidur",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "Sumin Kim",
                "labs": [
                    "Artificial Intelligence Graduate School, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "Haeung Choi",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "David S. Bhatti",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "Heung-No Lee",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Retrieval augmented generation",
                "Accuracy",
                "Tuning",
                "Semantics",
                "Hybrid power systems",
                "Adaptation models",
                "Training",
                "Reliability",
                "Mathematical models"
            ],
            "Author Keywords": [
                "Retrieval-augmented generation",
                "legal query",
                "LLM agent",
                "information retrieval"
            ]
        }
    },
    {
        "Title": "Leveraging Local LLMs for Secure In-System Task Automation With Prompt-Based Agent Classification",
        "Link": "https://ieeexplore.ieee.org/document/10766449/",
        "Abstract": "Recent progress in the field of intelligence has led to the creation of powerful large language models (LLMs). While these models show promise in improving personal computing experiences concerns surrounding data privacy and security have hindered their integration with sensitive personal information. In this study, a new framework is proposed to merge LLMs with personal file systems, enabling intelligent data interaction while maintaining strict privacy safeguards. The methodology organizes tasks based on LLM agents, which apply designated tags to the tasks before sending them to specific LLM modules. Every module is has its own function, including file search, document summarization, code interpretation, and general tasks, to make certain that all processing happens locally on the user’s device. Findings indicate high accuracy across agents: classification agent managed to get an accuracy rating of 86%, document summarization reached a BERT score of 0.9243. The key point of this framework is that it splits the LLM system into modules, which enables future development by integrating new task-specific modules as required. Findings suggest that integrating local LLMs can significantly improve interactions with file systems without compromising data privacy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3505298",
            "Date of Publication": "25 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Suthir Sriram",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            },
            {
                "name": "C. H. Karthikeya",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            },
            {
                "name": "K. P. Kishore Kumar",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            },
            {
                "name": "Nivethitha Vijayaraj",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            },
            {
                "name": "Thangavel Murugan",
                "labs": [
                    "College of Information and Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "File systems",
                "Data models",
                "Computational modeling",
                "Accuracy",
                "Data privacy",
                "Automation",
                "Tuning",
                "Large language models",
                "Vectors"
            ],
            "Author Keywords": [
                "File system",
                "few-shot prompting",
                "LangChain",
                "LLM",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "Anomaly Detection and Root Cause Analysis in Cloud-Native Environments Using Large Language Models and Bayesian Networks",
        "Link": "https://ieeexplore.ieee.org/document/10979844/",
        "Abstract": "Cloud computing technologies offer significant advantages in scalability and performance, enabling rapid deployment of applications. The adoption of microservices-oriented architectures has introduced an ecosystem characterized by an increased number of applications, frameworks, abstraction layers, orchestrators, and hypervisors, all operating within distributed systems. This complexity results in the generation of vast quantities of logs from diverse sources, making the analysis of these events an inherently challenging task, particularly in the absence of automation. To address this issue, Machine Learning techniques leveraging Large Language Models (LLMs) offer a promising approach for dynamically identifying patterns within these events. In this study, we propose a novel anomaly detection framework utilizing a microservices architecture deployed on Kubernetes and Istio, enhanced by an LLM model. The model was trained on various error scenarios, with Chaos Mesh employed as an error injection tool to simulate faults of different natures, and Locust used as a load generator to create workload stress conditions. After an anomaly is detected by the LLM model, we employ a dynamic Bayesian network to provide probabilistic inferences about the incident, proving the relationships between components and assessing the degree of impact among them. Additionally, a ChatBot powered by the same LLM model allows users to interact with the AI, ask questions about the detected incident, and gain deeper insights. The experimental results demonstrated the model’s effectiveness, reliably identifying all error events across various test scenarios. While it successfully avoided missing any anomalies, it did produce some false positives, which remain within acceptable limits.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565220",
            "Date of Publication": "29 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Diego Frazatto Pedroso",
                "labs": [
                    "ICMC-Institute of Mathematical and Computer Sciences, University of São Paulo (USP), São Carlos, Brazil"
                ]
            },
            {
                "name": "Luís Almeida",
                "labs": [
                    "Department of Computer Science, FCUP-Faculty of Sciences of the University of Porto, Porto, Portugal"
                ]
            },
            {
                "name": "Lucas Eduardo Gulka Pulcinelli",
                "labs": [
                    "ICMC-Institute of Mathematical and Computer Sciences, University of São Paulo (USP), São Carlos, Brazil"
                ]
            },
            {
                "name": "William Akihiro Alves Aisawa",
                "labs": [
                    "ICMC-Institute of Mathematical and Computer Sciences, University of São Paulo (USP), São Carlos, Brazil"
                ]
            },
            {
                "name": "Inês Dutra",
                "labs": [
                    "Department of Computer Science, FCUP-Faculty of Sciences of the University of Porto, Porto, Portugal"
                ]
            },
            {
                "name": "Sarita Mazzini Bruschi",
                "labs": [
                    "ICMC-Institute of Mathematical and Computer Sciences, University of São Paulo (USP), São Carlos, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Cloud computing",
                "Monitoring",
                "Microservice architectures",
                "Large language models",
                "Ecosystems",
                "Computer architecture",
                "Bayes methods",
                "Scalability",
                "Load modeling"
            ],
            "Author Keywords": [
                "Automated root cause analysis",
                "Bayesian networks",
                "LLM",
                "cloud computing"
            ]
        }
    },
    {
        "Title": "The Applicability of LLMs in Generating Textual Samples for Analysis of Imbalanced Datasets",
        "Link": "https://ieeexplore.ieee.org/document/10683735/",
        "Abstract": "In machine learning class imbalance is a pressing issue, where the model is biased towards the majority classes and underperforms in the minority classes. In textual data, the natural language processing (NLP) model bias significantly reduces overall accuracy, along with poor performance in minority classes. This paper investigates and compares the performance of transformer-based models, such as Multi-head Attention with the data levels and algorithmic levels approaches and BERT (Bidirectional Encoder Representations from Transformers) with LLM-based data augmentation. The research utilized the approaches, such as Random Over Sampler, Synthetic Minority Over-sampling Technique (SMOTE), SMOTEENN, data augmentation at word level, class weights, L2 regularization and leveraging GPT-3.5-Turbo’s for data augmentation to create additional data samples in imbalance dataset. The results from the experiment demonstrate that the LLM-based data augmentation with Multi-head Attention and BERT in the Myers-Briggs Type Indicator (MBTI) dataset (a highly skewed dataset) achieves the highest precision, recall and F1 score of 0.76 across terms. It indicates that the LLM-based data augmentation has significant improvements in dealing with class imbalance and improves the model’s accuracy in minority class types in the MBTI dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3463400",
            "Date of Publication": "18 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Saroj Gopali",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            },
            {
                "name": "Faranak Abri",
                "labs": [
                    "Department of Computer Science, San Jose State University, San Jose, CA, USA"
                ]
            },
            {
                "name": "Akbar Siami Namin",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            },
            {
                "name": "Keith S. Jones",
                "labs": [
                    "Department of Psychological Sciences, Texas Tech University, Lubbock, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Transformers",
                "Context modeling",
                "Data augmentation",
                "Machine learning",
                "Encoding",
                "Psychology",
                "Large language models",
                "Natural language processing",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Multi-head attention",
                "BERT",
                "LLM",
                "GPT 3.5-turbo",
                "imbalance dataset",
                "Myers-Briggs type indicators"
            ]
        }
    },
    {
        "Title": "Multimodal Emotion Recognition Using Feature Fusion: An LLM-Based Approach",
        "Link": "https://ieeexplore.ieee.org/document/10591796/",
        "Abstract": "Multimodal emotion recognition is a developing field that analyzes emotions through various channels, mainly audio, video, and text. However, existing state-of-the-art systems focus on two to three modalities at the most, utilize traditional techniques, fail to consider emotional interplay, lack the scope to add more modalities, and aren’t efficient in predicting emotions accurately. This research proposes a novel approach using rule-based systems to convert non-verbal cues to text, inspired by a limited prior attempt that lacked proper benchmarking. It achieves efficient multimodal emotion recognition by utilizing distilRoBERTa, a large language model fine-tuned with a combined textual representation of audio (such as loudness, spectral flux, MFCCs, pitch stability, and emphasis) and visual features (action units) extracted from videos. This approach is evaluated using the datasets RAVDESS and BAUM-1. It achieves high accuracy (93.18% in RAVDESS and 93.69% in BAUM-1) on both datasets, performing on par with the SOTA (state-of-the-art) systems, if not slightly better. Furthermore, the research highlights the potential for incorporating additional modalities by transforming them into text using rule-based systems and utilizing them to refine further pre-trained large language models, giving rise to a more comprehensive approach to emotion recognition.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3425953",
            "Date of Publication": "10 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Omkumar Chandraumakantham",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology- Chennai Campus, Chennai, India"
                ]
            },
            {
                "name": "N. Gowtham",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology- Chennai Campus, Chennai, India"
                ]
            },
            {
                "name": "Mohammed Zakariah",
                "labs": [
                    "Department of Computer Sciences and Engineering, College of Applied Science, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulaziz Almazyad",
                "labs": [
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Feature extraction",
                "Accuracy",
                "Visualization",
                "Videos",
                "Large language models",
                "Facial features",
                "Multisensory integration"
            ],
            "Author Keywords": [
                "Multimodal models",
                "emotion recognition",
                "large language models",
                "feature extraction with rule-based systems",
                "early fusion strategies"
            ]
        }
    },
    {
        "Title": "LLM-Based Text Prediction and Question Answer Models for Aphasia Speech",
        "Link": "https://ieeexplore.ieee.org/document/10636138/",
        "Abstract": "Aphasia, a brain injury-related linguistic problem, hinders communication. Current techniques generally struggle to handle aphasic speech’s intricacies. BERT, short for Bidirectional Encoder Representations from Transformers, is a pre-trained natural language model that utilizes contextual information from both preceding and succeeding words in a sentence to predict the target word. This study uses BERT models to predict and fill in sentences for people with aphasia, using the AphasiaBank dataset. The patients’ transcripts were thoroughly preprocessed, with nonverbal clues and redundant phrases removed. Because of the lack of control data, the accuracy of BERT in predicting masked tokens in aphasic speech was evaluated using a manual rating system with four raters. In addition, BERT was used for question-answering to increase context comprehension, underlining its ability to aid communication for those with aphasia. The preprocessing pipeline used advanced text-cleaning algorithms to ensure input data quality. The evaluation of BERT performance yielded satisfactory results with strong inter-rater reliability. The inter-rater correlation was remarkably strong, overall coefficients ranging from 0.61 to 0.74, suggesting a substantial level of agreement (Fleiss’ Kappa Score: 0.32). BERT’s predictions demonstrated a significant degree of contextual relevance and grammatical accuracy, as proven by ratings that were primarily above 3.0. The box plots also suggested a minimal number of outliers. The goal of this method is to improve the accuracy of speech prediction, which is beneficial for caregivers and speech therapists. BERT shows its nuanced capability in Aphasia sentence completion tests by exhibiting exceptional performance in terms of contextual appropriateness and grammatical correctness, as confirmed by manual evaluation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3443592",
            "Date of Publication": "14 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shamiha Binta Manir",
                "labs": [
                    "Department of EECE, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "K. M. Sajjadul Islam",
                "labs": [
                    "Department of CS, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Praveen Madiraju",
                "labs": [
                    "Department of CS, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Priya Deshpande",
                "labs": [
                    "Department of EECE, Marquette University, Milwaukee, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Aphasia",
                "Speech recognition",
                "Predictive models",
                "Databases",
                "Speech enhancement",
                "Task analysis",
                "Encoding",
                "Text processing",
                "Brain injuries"
            ],
            "Author Keywords": [
                "Aphasia",
                "BERT models",
                "natural language processing (NLP)",
                "speech prediction",
                "sentence completion",
                "AphasiaBank",
                "transformer models",
                "patient-spoken transcripts",
                "communication aids",
                "speech therapy",
                "text preprocessing"
            ]
        }
    },
    {
        "Title": "LLM Teacher-Student Framework for Text Classification With No Manually Annotated Data: A Case Study in IPTC News Topic Classification",
        "Link": "https://ieeexplore.ieee.org/document/10900365/",
        "Abstract": "With the ever-increasing number of news stories available online, classifying them by topic, regardless of the language they are written in, has become crucial for enhancing readers’ access to relevant content. To address this challenge, we propose a teacher-student framework based on large language models (LLMs) for developing multilingual news topic classification models of reasonable size with no need for manual data annotation. The framework employs a Generative Pretrained Transformer (GPT) model as the teacher model to develop a news topic training dataset through automatic annotation of 20,000 news articles in Slovenian, Croatian, Greek, and Catalan. Articles are classified into 17 main categories from the Media Topic schema, developed by the International Press Telecommunications Council (IPTC). The teacher model exhibits high zero-shot performance in all four languages. Its agreement with human annotators is comparable to that between the human annotators themselves. To mitigate the computational limitations associated with the requirement of processing millions of texts daily, smaller BERT-like student models are fine-tuned on the GPT-annotated dataset. These student models achieve high performance comparable to the teacher model. Furthermore, we explore the impact of the training data size on the performance of the student models and investigate their monolingual, multilingual, and zero-shot cross-lingual capabilities. The findings indicate that student models can achieve high performance with a relatively small number of training instances, and demonstrate strong zero-shot cross-lingual abilities. Finally, we publish the best-performing news topic classifier, enabling multilingual classification with the top-level categories of the IPTC Media Topic schema.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3544814",
            "Date of Publication": "24 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Taja Kuzman",
                "labs": [
                    "Department of Knowledge Technologies, Jožef Stefan Institute, Ljubljana, Slovenia",
                    "Jožef Stefan International Postgraduate School, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Nikola Ljubešić",
                "labs": [
                    "Department of Knowledge Technologies, Jožef Stefan Institute, Ljubljana, Slovenia",
                    "Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Annotations",
                "Media",
                "Manuals",
                "Multilingual",
                "Computational modeling",
                "Training",
                "Training data",
                "Transformers",
                "Text categorization"
            ],
            "Author Keywords": [
                "Multilingual text classification",
                "IPTC",
                "large language models",
                "LLMs",
                "news topic",
                "topic classification",
                "training data preparation",
                "data annotation"
            ]
        }
    },
    {
        "Title": "Yours Truly: A Credibility Framework for Effortless LLM-Powered Fact Checking",
        "Link": "https://ieeexplore.ieee.org/document/10807167/",
        "Abstract": "In an era where social media portrays subjective realities, discerning truth from propaganda has become increasingly challenging. The proposed system addresses this issue with an end-to-end credibility framework to make fact-checking effortless and intuitive. Recognizing the subjective nature of claims, the system provides a robust method to assess the veracity of social media claims. Twitter, a key platform for public opinion exchange, influences cultural beliefs, political affiliations, and crisis responses. This work offers a pragmatic solution to navigate manipulative claims, reducing the cognitive effort to distinguish fact from fabrication and breaking misinformation chains sooner. Yours Truly uses FactStore, an extensive real-time database of fact-checked claims from Indian and International fact-checking initiatives. This database powers the search function, enabling time-sensitive searches with increased coverage to retrieve relevant context. The system breaks down compound sentences into atomic claims, verifying each with iterative context retrieval. Each claim is further fact-checked with multiple articles using text and semantic search. These matched articles are reranked for relevance using a technique called query-based committee selector. The top-ranked results provide context to an instruction fine-tuned Large Language Model, which infers the truth value of input claims. This approach tackles claims’ ambiguity and complexity and returns an interpretable credibility report explaining the inferred truth value. Yours Truly achieves an impressive F1 Score of 94% The framework is easily extensible to verify contents from other social media platforms, as it only relies on text without metadata and effectively handles long-form texts by atomizing compound statements. Yours Truly outperforms contemporary fact-checking systems on multiple misinformation baselines. It generalizes well across various text forms and information domains, demonstrating a high level of automation.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3520187",
            "Date of Publication": "19 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vallidevi Krishnamurthy",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Varshini Balaji",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Surveys",
                "Real-time systems",
                "Databases",
                "Voting",
                "Pandemics",
                "COVID-19",
                "Vaccines",
                "Transformers"
            ],
            "Author Keywords": [
                "Fake news detection",
                "few-shot learning",
                "large language models",
                "retrieval augmented generation",
                "vector search"
            ]
        }
    },
    {
        "Title": "BdSentiLLM: A Novel LLM Approach to Sentiment Analysis of Product Reviews",
        "Link": "https://ieeexplore.ieee.org/document/10798428/",
        "Abstract": "Online communication has led to more people expressing themselves in their preferred languages, especially in e-commerce, where product reviews are crucial. Understanding customer sentiment through product reviews and comments can help businesses improve product quality and make informed decisions. However, the complexity of written language and the variety of languages used in reviews pose challenges for accurate sentiment analysis. In this study, we explored the linguistic landscape of Bangladeshi product reviews and developed BdSentiLLM, a robust model designed for automatic language classification and sentiment analysis in this context. We collected a dataset of 3,864 product reviews, revealing that 84% were written in English, followed by Bangla, Banglish (Romanized Bangla), and Bangla-English code-switched content. BdSentiLLM can categorize and prepare these language types for sentiment analysis with large language models. We evaluated the performance of four open-source LLMs, Llama-2, Flan-t5, Vicuna, and Falcon, using BdSentiLLM for sentiment analysis.BdSentiLLM with Llama-2 consistently outperformed the other models across most language categories with f1 score of 0.79 for Bangla, 0.70 for Banglish, 0.84 for Bangla_English, 0.90 for English, and 0.89 overall, while Flan-t5 excelled in English sentiment analysis. Compared to existing models, BdSentiLLM demonstrated superior versatility and effectiveness by handling mixed-language data across all categories making it a valuable tool for sentiment analysis in diverse linguistic contexts. Future work will focus on expanding the dataset to enhance BdSentiLLM’s robustness and exploring its applicability beyond e-commerce to broader multilingual sentiment analysis tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3516826",
            "Date of Publication": "13 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Atia Shahnaz Ipa",
                "labs": [
                    "Department of Mechatronics Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Priyo Nath Roy",
                "labs": [
                    "Department of Mechatronics Engineering, Khulna University of Engineering & Technology, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Mohammad Abu Tareq Rony",
                "labs": [
                    "Department of Statistics, Noakhali Science & Technology University, Noakhali, Bangladesh"
                ]
            },
            {
                "name": "Ali Raza",
                "labs": [
                    "Department of Software Engineering, University of Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Norma Latif Fitriyani",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Sejong University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Yeonghyeon Gu",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Sejong University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Muhammad Syafrudin",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Sejong University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Sentiment analysis",
                "Analytical models",
                "Accuracy",
                "Reviews",
                "Probabilistic logic",
                "Robustness",
                "Quality assessment",
                "Electronic commerce",
                "Context modeling"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "product",
                "Bangladeshi reviews",
                "large language model",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "AsymGroup: Asymmetric Grouping and Communication Optimization for 2D Tensor Parallelism in LLM Inference",
        "Link": "https://ieeexplore.ieee.org/document/11075777/",
        "Abstract": "Recent advances in Large Language Models (LLMs), such as GPT and LLaMA, have demonstrated remarkable capabilities across a wide array of natural language processing tasks. Despite these successes, efficient inference at scale remains challenging, particularly in heterogeneous computing environments characterized by variations in GPU counts, and computational capacities across nodes. Conventional tensor parallelism approaches typically assume homogeneous hardware, resulting in significant performance degradation under asymmetric conditions. To address this challenge, we propose AsymGroup, which is an asymmetric 2D tensor parallelism framework that dynamically constructs groups of uneven sizes based on node- and GPU-level metrics. AsymGroup proportionally allocates both computational and communication workloads according to individual device capabilities. In addition, we introduce a formal communication cost model to accurately quantify bottlenecks and a group optimization algorithm to systematically determine efficient group configurations. Experimental evaluations demonstrate that AsymGroup reduces inference latency by up to 26.3% and communication overhead by up to 33.4% compared to state-of-the-art frameworks, while also maintaining competitive performance under symmetric conditions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3587387",
            "Date of Publication": "10 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ki Tae Kim",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Seok-Ju Im",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Eui-Young Chung",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tensors",
                "Parallel processing",
                "Graphics processing units",
                "Computational modeling",
                "Costs",
                "Optimization",
                "Bandwidth",
                "Hardware",
                "Decoding",
                "Transformers"
            ],
            "Author Keywords": [
                "Large language models",
                "inference optimization",
                "tensor parallelism",
                "collective communication"
            ]
        }
    },
    {
        "Title": "TForMIX: A Method That Combines LLM and Multidimensional Modeling for Technological Foresight",
        "Link": "https://ieeexplore.ieee.org/document/11146655/",
        "Abstract": "Technical documents, such as scientific papers and patents, are widely used as a basis for Technological Foresight (TF) processes. Typically, these analyses require identifying elements (e.g., terms) in the textual contents of these documents, which are relevant to the scientific-technological domain under investigation. Information Extraction (IE) and Natural Language Processing (NLP) techniques are useful tools to automate the identification of these elements, which is essential in TF processes that usually involve the analysis of a corpus of hundreds (and sometimes thousands) of documents. An analytical view over this corpus, based on the occurrence of those relevant elements, helps prioritize document analysis and, consequently, accelerates the whole TF process. However, building a system that provides such analytical insight is expensive. Moreover, for each domain-specific TF process, a new system would have to be built. Thus, there is a need for viable solutions to analytically explore a corpus, according to the specific requirements of each domain. This work presents Technological Foresight with Multidimensional Information eXtraction (TForMIX), a novel method for building Decision Support Systems (DSSs) that applies Named Entity Recognition (NER) and Relation Extraction (RE) while allowing multidimensional analytical exploration of entities and relations together with bibliometric data from documents. TForMIX is a flexible method that can be applied to different domains, and speeds up building DSSs for each domain. Additionally, we evaluate the applicability of the produced DSSs in TF processes by conducting a practical experiment that demonstrates that applying the method to generate DSSs, supported by IE techniques, can significantly contribute to the conduction of TF analyses. The combination of the used theories, innovative methods, and proposed practical validation highlighted the high-quality nature of the analysis in this study while offering the potential for valuable insights and contributions to the TF process.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605116",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Giselle F. Rosa",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil",
                    "Agência de Gestão e Inovação Tecnológica (AGITEC), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Jones O. Avelino",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil",
                    "Centro de Análise de Sistemas Navais (CASNAV), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Maria Claudia Cavalcanti",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Julio Cesar Duarte",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Spread spectrum communication",
                "Information retrieval",
                "Decision support systems",
                "Data models",
                "Analytical models",
                "Patents",
                "Soft sensors",
                "Named entity recognition",
                "Buildings",
                "Transmission line measurements"
            ],
            "Author Keywords": [
                "Decision support systems",
                "information extraction",
                "multidimensional modeling",
                "technological foresighting",
                "technological forecasting"
            ]
        }
    },
    {
        "Title": "LLM-Based Generative AI in Medicine: Analysis of Current Research Trends With BERTopic",
        "Link": "https://ieeexplore.ieee.org/document/11151540/",
        "Abstract": "Recent advances in generative artificial intelligence (GenAI) have made large language models (LLMs) transformative tools in the healthcare industry. Powered by deep learning, these models show great potential in many medical applications such as clinical decision support systems, biomedical text mining and personalized patient care. However, while research on the use of LLMs in medicine is growing rapidly, there is a need to systematically analyze the key themes, emerging trends and challenges in this field. This study aims to identify dominant themes, track research trends and identify gaps in the literature by utilizing a large dataset of scientific publications in the medical field. A total of 3,941 academic publications related to the use of LLMs in medicine were retrieved from the Scopus database, covering the period from 2023 to 2024. Accordingly, the BERTopic method, an advanced topic modeling technique, is used to analyze and classify publications on LLMs applications in medicine. The findings show that LLMs are mostly concentrated in the fields of radiology, ophthalmology and mental health and that these models have the potential to support clinical processes. In particular, LLMs have been found to have a great impact on the analysis of medical imaging reports, are used for early diagnosis of ophthalmologic diseases, and are prominent in depression and suicide risk assessments in mental health. This study provides valuable insights for healthcare professionals, GenAI researchers, and policy makers, laying a solid foundation for future research and strategic applications for the use of LLMs in medicine. While emphasizing the transformative impact of LLMs in healthcare, it also highlights the necessity of responsible GenAI applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3606335",
            "Date of Publication": "04 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Murat Kilinc",
                "labs": [
                    "Department of Management Information Systems, Faculty of Economics and Administrative Sciences, Karadeniz Technical University, Trabzon, Türkiye"
                ]
            },
            {
                "name": "Fatih Gurcan",
                "labs": [
                    "Department of Management Information Systems, Faculty of Economics and Administrative Sciences, Karadeniz Technical University, Trabzon, Türkiye"
                ]
            },
            {
                "name": "Ahmet Soylu",
                "labs": [
                    "School of Economics, Innovation, and Technology, Kristiania University of Applied Sciences, Oslo, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Analytical models",
                "Market research",
                "Medical diagnostic imaging",
                "Text mining",
                "Decision support systems",
                "Systematic literature review",
                "Sentiment analysis",
                "Large language models",
                "Diseases"
            ],
            "Author Keywords": [
                "Large language models",
                "BERTopic",
                "topic modeling",
                "healthcare"
            ]
        }
    },
    {
        "Title": "Multimodal Social Relationship Recognition Based on LLM",
        "Link": "https://ieeexplore.ieee.org/document/11123169/",
        "Abstract": "In recent years, multimodal social relation recognition has become a critical task in the fields of computer vision and natural language processing. However, existing research still faces key gaps, particularly in effectively aligning image features with linguistic features to improve recognition accuracy. This paper proposes a social relation recognition method based on multimodal feature fusion and validates the crucial role of cross-modal alignment mechanisms in enhancing recognition accuracy. Our approach leverages large language models to meticulously extract event structures from textual descriptions, capturing key elements such as emotional states, scenarios, and relationships, while employing convolutional neural networks to extract deep features from images. Subsequently, we introduce a cross-modal alignment mechanism to semantically align textual event structures with visual features, ensuring high semantic consistency between the two modalities. Extensive experiments on multiple public datasets demonstrate that our method significantly outperforms existing unimodal and basic multimodal approaches, confirming its effectiveness and innovative contributions to social relation recognition.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3598186",
            "Date of Publication": "12 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Haopeng Wang",
                "labs": [
                    "School of Police Information, Shandong Police College, Jinan, China"
                ]
            },
            {
                "name": "Zhitian Zhang",
                "labs": [
                    "School of Information and Control Engineering, Qingdao University of Technology, Qingdao, China"
                ]
            },
            {
                "name": "Menglei Xia",
                "labs": [
                    "School of Information and Control Engineering, Qingdao University of Technology, Qingdao, China"
                ]
            },
            {
                "name": "Dejiao Huang",
                "labs": [
                    "School of Science, Qingdao University of Technology, Qingdao, China"
                ]
            },
            {
                "name": "Ruyi Chang",
                "labs": [
                    "School of Science, Qingdao University of Technology, Qingdao, China"
                ]
            },
            {
                "name": "Shuai Guo",
                "labs": [
                    "School of Police Information, Shandong Police College, Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Visualization",
                "Semantics",
                "Image recognition",
                "Accuracy",
                "Large language models",
                "Vectors",
                "Data mining",
                "Convolutional neural networks",
                "Face recognition"
            ],
            "Author Keywords": [
                "Large language models",
                "event structure extraction",
                "social relationship recognition",
                "feature fusion",
                "cross-modal alignment"
            ]
        }
    },
    {
        "Title": "TARAD: Task-Aware Robot Affordance-Centric Diffusion Policy Learned From LLM-Generated Demonstrations",
        "Link": "https://ieeexplore.ieee.org/document/11124589/",
        "Abstract": "In open-ended task settings, the ability of a robot to execute diverse tasks accurately by following language instructions is critical. Methods based on traditional imitation learning typically depend on extensive expert demonstrations and often struggle to generalize in the case of unseen scenarios or tasks. Recently, approaches leveraging large foundational models have demonstrated improved generalization by enhancing task comprehension in novel scenarios based on the intrinsic world knowledge embedded in these models. However, these methods rely on predefined motion primitives and lack a detailed understanding of the environment, which is essential for successful execution. Herein we introduce Task-Aware Robot Affordance-Centric Diffusion Policy (TARAD), a novel framework for robot manipulation. TARAD leverages large language models and vision-language models to perform high-level planning from natural language instructions and extract affordance information from the robot's observations. A heuristic motion planner is employed for low-level motion planning, enabling zero-shot trajectory synthesis and the fully automatic generation of a dataset with language labels and affordances. By incorporating affordances into the observation space, our approach integrates the intrinsic commonsense and reasoning capabilities of foundation models into imitation learning, enabling the training of an affordance-centric, multi-task three-dimensional (3D) diffusion policy. Empirical evaluations in both the RLBench simulated environments and real-world experiments with UR5e demonstrate that TARAD effectively combines the precise control of imitation learning with the strong generalization capabilities of foundation models, all without relying on expert demonstrations or predefined motion primitives.",
        "Details": {
            "DOI": "10.1109/LRA.2025.3598998",
            "Date of Publication": "14 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Robotics and Automation Letters"
        },
        "issn_info": {
            "Electronic ISSN": "2377-3766"
        },
        "authors_data": [
            {
                "name": "Site Hu",
                "labs": [
                    "Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            },
            {
                "name": "Takayuki Nagai",
                "labs": [
                    "Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            },
            {
                "name": "Takato Horii",
                "labs": [
                    "Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Affordances",
                "Robots",
                "Point cloud compression",
                "Training",
                "Foundation models",
                "Natural languages",
                "Data collection",
                "Grippers",
                "Trajectory",
                "Three-dimensional displays"
            ],
            "Author Keywords": [
                "AI-enabled robotics",
                "learning from demonstration",
                "manipulation planning"
            ]
        }
    },
    {
        "Title": "LLM-Assisted Ontology Restriction Verification With Clustering-Based Description Generation",
        "Link": "https://ieeexplore.ieee.org/document/10971367/",
        "Abstract": "An ontology is a scheme for structuring relationships between concepts in a domain, promoting data interoperability and system integration. However, poorly designed ontologies can lead to errors and performance issues. While systems engineering has standardized evaluation guidelines (e.g., ISO/IEC), ontology engineering lacks such standards, leading to various independent evaluation methods. One frequent issue among novice developers is the misuse of ontology restrictions, particularly ‘allValuesFrom’ and ‘someValuesFrom’, which can significantly impact the correctness and reliability of ontologies. However, existing studies have not adequately addressed effective methods for detecting such errors. To address this gap, we propose a context-aware verification framework utilizing large language models to detect and correct misuse in ontology restrictions. Unlike conventional methods, our framework integrates contextual descriptions derived from ontological axioms, enabling more accurate verification. Additionally, we introduce a clustering-based description generation method that systematically organizes contextual information, further enhancing verification accuracy. Experimental evaluation conducted on diverse ontology datasets suggests that contextual integration improves verification performance. Moreover, the clustering-based description generation improves restriction misuse detection and correction compared to traditional approaches. By automating ontology restriction verification, this study contributes significantly to enhancing the reliability of ontology evaluation and provides a foundation for developing more scalable and standardized verification techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3562560",
            "Date of Publication": "21 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seungyeon Kim",
                "labs": [
                    "Department of Computer Science, Yonsei University, Seoul, Republic of Korea",
                    "Department of Cyber Science, Republic of Korea Naval Academy, Changwon, Republic of Korea"
                ]
            },
            {
                "name": "Donghyun Kim",
                "labs": [
                    "Department of Computer Science, Yonsei University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Seokju Hwang",
                "labs": [
                    "Department of Computer Science, Yonsei University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Kyong-Ho Lee",
                "labs": [
                    "Department of Computer Science, Yonsei University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Kyunghwa Lee",
                "labs": [
                    "Ssangyong Information and Communications Corporation, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ontologies",
                "Accuracy",
                "Reliability",
                "ISO Standards",
                "IEC Standards",
                "Translation",
                "Software",
                "Semantics",
                "Scalability",
                "Quality assessment"
            ],
            "Author Keywords": [
                "Ontology evaluation",
                "ontology restriction verification",
                "text generation",
                "clustering"
            ]
        }
    },
    {
        "Title": "LegalBot-EC: An LLM-Based Chatbot for Legal Assistance in Ecuadorian Law",
        "Link": "https://ieeexplore.ieee.org/document/11037787/",
        "Abstract": "This work presents LegalBot-EC, a domain-specific legal chatbot designed to provide accurate responses grounded in Ecuadorian law. The system combines ChromaDB for contextual retrieval and LLaMA 3.1 as its generative model, ensuring legally relevant and contextually grounded answers. Its knowledge base consists of two key legal documents, the COIP and the 2008 Constitution of Ecuador, which serve as the foundation for response generation. The chatbot was evaluated through two key assessments: user satisfaction and accuracy measurement. A satisfaction study conducted with final-year university students specializing in law resulted in an average score of 88.72 out of 100, indicating strong approval in terms of correctness, relevance, and clarity. Additionally, an accuracy assessment based on 25 legal queries demonstrated robust performance, with 23 correct responses, 2 partially correct responses, and none classified as incorrect, yielding a weighted accuracy of 96%. Furthermore, qualitative tests confirm the chatbot’s ability to generate well-structured, legally sound responses, even when queried in English, demonstrating multilingual capabilities.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3580488",
            "Date of Publication": "18 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Francklin Rivas-Echeverría",
                "labs": [
                    "Escuela de Hábitat, Infraestructura y Creatividad, Pontificia Universidad Católica del Ecuador Sede Ibarra, Ibarra, Ecuador",
                    "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA",
                    "Kauel Inc., Menlo Park, Silicon Valley, CA, USA"
                ]
            },
            {
                "name": "Leo Thomas Ramos",
                "labs": [
                    "Kauel Inc., Menlo Park, Silicon Valley, CA, USA",
                    "Computer Vision Center, Universitat Autònoma de Barcelona, Barcelona, Spain"
                ]
            },
            {
                "name": "José Luis Ibarra",
                "labs": [
                    "Escuela de Hábitat, Infraestructura y Creatividad, Pontificia Universidad Católica del Ecuador Sede Ibarra, Ibarra, Ecuador"
                ]
            },
            {
                "name": "Sonia Zerpa-Bonillo",
                "labs": [
                    "Universidad de Otavalo, Otavalo, Ecuador"
                ]
            },
            {
                "name": "Stalin Arciniegas",
                "labs": [
                    "Escuela de Hábitat, Infraestructura y Creatividad, Pontificia Universidad Católica del Ecuador Sede Ibarra, Ibarra, Ecuador"
                ]
            },
            {
                "name": "Marilena Asprino-Salas",
                "labs": [
                    "Escuela de Ciencias Sociales y Humanidades, Pontificia Universidad Católica del Ecuador Sede Ibarra, Ibarra, Ecuador"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Chatbots",
                "Codes",
                "Accuracy",
                "Navigation",
                "Large language models",
                "Knowledge based systems",
                "Regulation",
                "IEEE Constitution",
                "Europe"
            ],
            "Author Keywords": [
                "Large language models",
                "chatbot",
                "natural language processing",
                "artificial intelligence",
                "legal informatics",
                "legal AI",
                "BERT",
                "LLaMA",
                "transformer"
            ]
        }
    },
    {
        "Title": "Common and Special Knowledge-Driven TSK Fuzzy System and Its Modeling and Application for Epileptic EEG Signals Recognition",
        "Link": "https://ieeexplore.ieee.org/document/8813088/",
        "Abstract": "Takagi-Sugeno-Kang (TSK) fuzzy systems are well known for their good balances between approximation accuracy and interpretability. Among a wide variety of existing TSK fuzzy systems, most of them are driven by special knowledge since the learned parameters of each fuzzy rule are totally different. However, common knowledge is equally important and useful in practice and hence a TSK fuzzy system embedded with common knowledge should be more intuitive and interpretable when tackling with real-world problems. In this paper, we propose a common and special knowledge-driven TSK fuzzy system (CSK-TSK-FS), in which the parameters corresponding to each feature in then-parts of fuzzy rules always keep invariant and these parameters are viewed as common knowledge. As for its modeling, except the gradient descent techniques and other existing training algorithms, we can obtain a trained CSK-TSK-FS from a trained GMM or a trained FLNN because the proposed fuzzy system CSK-TSK-FS is mathematically equivalent to a special GMM and a FLNN. CSK-TSK-FS has three characteristics: (1) with the classical centroid defuzzification strategy, the involved common knowledge can be separated from fuzzy rules such that the interpretability of CSK-TSK-FS can be enhanced; (2) it can be trained quickly by the proposed LLM-based training algorithm; (3) the equivalence relationships among CSK-TSK-FS, GMM and FLNN allow them to share some commonality in training such that the proposed LLM-based training algorithm provides a novel fast training tool for training GMM and FLNN. Experimental results on UCI, KEEL and epileptic EEG datasets demonstrate the promising classification of CSK-TSK-FS.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2937657",
            "Date of Publication": "26 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuanpeng Zhang",
                "labs": [
                    "Department of Health Technology and Informatics, The Hong Kong Polytechnic University, Hong Kong"
                ]
            },
            {
                "name": "Jiancheng Dong",
                "labs": [
                    "Medical Big Data Research Center, First Affiliated Hospital of Zhengzhou University, Zhengzhou, China"
                ]
            },
            {
                "name": "Junqing Zhu",
                "labs": [
                    "Case Center for Imaging Research, Case Western Reserve University, Cleveland, OH, USA"
                ]
            },
            {
                "name": "Chunying Wu",
                "labs": [
                    "Case Center for Imaging Research, Case Western Reserve University, Cleveland, OH, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fuzzy systems",
                "Training",
                "Electroencephalography",
                "Neural networks",
                "Classification algorithms",
                "Clinical diagnosis",
                "Expert systems"
            ],
            "Author Keywords": [
                "Common knowledge",
                "FLNN",
                "GMM",
                "LLM",
                "special knowledge",
                "TSK fuzzy systems"
            ]
        }
    },
    {
        "Title": "SVMFN-FSAR: Semantic-Guided Video Multimodal Fusion Network for Few-Shot Action Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10949813/",
        "Abstract": "Few-Shot Action Recognition (FSAR) has been a heat topic in various areas, such as computer vision and forest ecosystem security. FSAR aims to recognize previously unseen classes using limited labeled video examples. A principal challenge in the FSAR task is to obtain more action semantics related to the category from a few samples for classification. Recent studies attempt to compensate for visual information through action labels. However, concise action category names lead to less distinct semantic space and potential performance limitations. In this work, we propose a novel Semantic-guided Video Multimodal Fusion Network for FSAR (SVMFN-FSAR). We utilize the Large Language Model (LLM) to expand detailed textual knowledge of various action categories, enhancing the distinction of semantic space and alleviating the problem of insufficient samples in FSAR tasks to some extent. We perform the matching metric between the extracted distinctive semantic information and the visual information of unknown class samples to understand the overall semantics of the video for preliminary classification. In addition, we design a novel semantic-guided temporal interaction module based on Transformers, which can make the LLM-expanded knowledge and visual information complement each other, and improve the quality of feature representation in samples. Experimental results on three few-shot benchmarks, Kinetics, UCF101, and HMDB51, consistently demonstrate the effectiveness and interpretability of the proposed method.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020076",
            "Date of Publication": "04 April 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Ran Wei",
                "labs": [
                    "College of Information Science and Technology & Artificial Intelligence, Nanjing Forestry University, Nanjing, China",
                    "State Key Laboratory of Tree Genetics and Breeding, Nanjing Forestry University, Nanjing, China",
                    "Co-Innovation Center for Sustainable Forestry in Southern China, Nanjing Forestry University, Nanjing, China"
                ]
            },
            {
                "name": "Rui Yan",
                "labs": [
                    "Department of Computer Science and Technology, Nanjing University, Nanjing, China"
                ]
            },
            {
                "name": "Hongyu Qu",
                "labs": [
                    "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China"
                ]
            },
            {
                "name": "Xing Li",
                "labs": [
                    "College of Information Science and Technology & Artificial Intelligence, Nanjing Forestry University, Nanjing, China",
                    "State Key Laboratory of Tree Genetics and Breeding, Nanjing Forestry University, Nanjing, China",
                    "Co-Innovation Center for Sustainable Forestry in Southern China, Nanjing Forestry University, Nanjing, China"
                ]
            },
            {
                "name": "Qiaolin Ye",
                "labs": [
                    "College of Information Science and Technology & Artificial Intelligence, Nanjing Forestry University, Nanjing, China",
                    "State Key Laboratory of Tree Genetics and Breeding, Nanjing Forestry University, Nanjing, China",
                    "Co-Innovation Center for Sustainable Forestry in Southern China, Nanjing Forestry University, Nanjing, China"
                ]
            },
            {
                "name": "Liyong Fu",
                "labs": [
                    "College of Forestry, Hebei Agricultural University, Baoding, China",
                    "Institute of Forest Resource Information Techniques, Chinese Academy of Forestry, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Heating systems",
                "Visualization",
                "Fuses",
                "Large language models",
                "Semantics",
                "Transformers",
                "Kinetic theory",
                "Data mining",
                "Security"
            ],
            "Author Keywords": [
                "few-shot learning",
                "action recognition",
                "Large Language Model (LLM)",
                "Transformer",
                "video understanding"
            ]
        }
    },
    {
        "Title": "Enhancing the Precision and Interpretability of Retrieval-Augmented Generation (RAG) in Legal Technology: A Survey",
        "Link": "https://ieeexplore.ieee.org/document/10921633/",
        "Abstract": "Retrieval-Augmented Generation (RAG) is a promising solution that can enhance the capabilities of large language model (LLM) applications in critical domains, including legal technology, by retrieving knowledge from external databases. Implementing RAG pipelines requires careful attention to the techniques and methods implemented in the different stages of the RAG process. However, robust RAG can enhance LLM generation with faithfulness and few hallucinations in responses. In this paper, we discuss the application of RAG in the legal domain. First, we present an overview of the main RAG methods, stages, techniques, and applications in the legal domain. We then briefly discuss the different information retrieval models, processes, and applied methods in current legal RAG solutions. Then, we explain the different quantitative and qualitative evaluation metrics. We also describe several emerging datasets and benchmarks. We then discuss and assess the ethical and privacy considerations for legal RAG and summarize various challenges, and propose a challenge scale based on RAG failure points and control over external knowledge. Finally, we provide insights into promising future research to leverage RAG efficiently and effectively in the legal field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3550145",
            "Date of Publication": "11 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mahd Hindi",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Linda Mohammed",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Ommama Maaz",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Abdulmalik Alwarafy",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Retrieval augmented generation",
                "Pipelines",
                "Accuracy",
                "Knowledge graphs",
                "Surveys",
                "Generators",
                "Transformers",
                "Large language models",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Information retrieval",
                "large language model (LLM)",
                "legal technology",
                "prompt engineering",
                "retrieval-augmented generation (RAG)"
            ]
        }
    },
    {
        "Title": "Transforming Highway Safety With Autonomous Drones and AI: A Framework for Incident Detection and Emergency Response",
        "Link": "https://ieeexplore.ieee.org/document/10918802/",
        "Abstract": "Highway accidents pose serious challenges and safety risks, often resulting in severe injuries and fatalities due to delayed detection and response. Traditional accident management methods heavily rely on manual reporting, which can be sometime inefficient and error-prone resulting in valuable life loss. This paper proposes a novel framework that integrates autonomous aerial systems (drones) with advanced deep learning models to enhance real-time accident detection and response capabilities. The system not only dispatch the drones but also provide live accident footage, accident identification and aids in coordinating emergency response. In this study we implemented our system in Gazebo simulation environment, where an autonomous drone navigates to specified location based on the navigation commands generated by Large Language Model (LLM) by processing the emergency call/transcript. Additionally, we created a dedicated accident dataset to train YOLOv11 m model for precise accident detection. At accident location the drone provides live video feeds and our YOLO model detects the incident, these high-resolution captured images after detection are analyzed by Moondream2, a Vision language model (VLM), for generating detailed textual descriptions of the scene, which are further refined by GPT 4-Turbo, large language model (LLM) for producing concise incident reports and actionable suggestions. This end-to-end system combines autonomous navigation, incident detection and incident response, thus showcasing its potential by providing scalable and efficient solutions for incident response management. The initial implementation demonstrates promising results and accuracy, validated through Gazebo simulation. Future work will focus on implementing this framework to the hardware implementation for real-world deployment in highway incident system.",
        "Details": {
            "DOI": "10.1109/OJVT.2025.3549387",
            "Date of Publication": "11 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Vehicular Technology"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1330"
        },
        "authors_data": [
            {
                "name": "Muhammad Farhan",
                "labs": [
                    "Department of Electronics and Information Engineering, Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            },
            {
                "name": "Hassan Eesaar",
                "labs": [
                    "Department of Electronics and Information Engineering, Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            },
            {
                "name": "Afaq Ahmed",
                "labs": [
                    "Department of Electronics and Information Engineering, Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            },
            {
                "name": "Kil To Chong",
                "labs": [
                    "Department of Electronics and Information Engineering, Jeonbuk National University, Jeonju, Republic of Korea",
                    "Advances Electronics and Information Research Center, Jeonbuk National University, Jeonju, Republic of Korea",
                    "Juyoung Bio, Inc., Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            },
            {
                "name": "Hilal Tayara",
                "labs": [
                    "School of International Engineering and Science, Jeonbuk National University, Jeonju, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accidents",
                "Drones",
                "Road transportation",
                "YOLO",
                "Biological system modeling",
                "Deep learning",
                "Sensors",
                "Analytical models",
                "Navigation",
                "Sensor systems"
            ],
            "Author Keywords": [
                "Highway incident analysis",
                "YOLOv11",
                "visual language model (VLM)",
                "Moondream2",
                "gazebo simulator",
                "multi-modal deployment",
                "large language model (LLM)",
                "GPT-4 Turbo",
                "autonomous drone navigation"
            ]
        }
    },
    {
        "Title": "Beyond Binary Classification: A Fine-Grained Safety Dataset for Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10507773/",
        "Abstract": "Large Language Models (LLMs) excel in interactive chat scenarios due to their advanced conversational abilities. However, their training process invariably exposes them to a diverse range of harmful or toxic content, posing significant challenges in ensuring that LLM responses align with human ethical values. Consequently, the detection and quantification of adverse content remains a paramount issue in contemporary research. In this paper, we introduce the SAFE dataset, a novel resource designed to advance safety assessment research in LLMs. Our dataset extends beyond the binary categorization of content into “safe” and “unsafe”. Drawing upon human interpretations of safety, we further delineate unsafe content into six granular categories: Sensitivity, Harmfulness, Falsehood, Information Corruption, Unnaturalness, and Deviation from Instructions. This refined classification aims to enhance LLMs’ ability to discern unsafe data more accurately. In total, we have created a dataset comprising 52,340 instruction-response pairs, each annotated with safety meta-tags. Additionally, we have compiled expert comparative assessments for these indicators. We developed a multi-expert rating model trained on the SAFE dataset, designed to evaluate the responses of LLMs across various dimensions. This approach highlights the potential of our dataset in the realm of safety assessment for LLMs. The model’s capability to provide multi-faceted evaluations reflects an advanced understanding of the nuanced requirements in LLM response assessment. We believe this dataset represents a valuable resource for the community, contributing to the safe development and deployment of LLMs. Our findings and resources are poised to fuel future research endeavors in this domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3393245",
            "Date of Publication": "24 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jia Yu",
                "labs": [
                    "School of Engineering, Zhejiang University, Hangzhou, China",
                    "Westlake University, Hangzhou, China"
                ]
            },
            {
                "name": "Long Li",
                "labs": [
                    "School of Engineering, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Zhenzhong Lan",
                "labs": [
                    "School of Engineering, Zhejiang University, Hangzhou, China",
                    "Westlake University, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Safety",
                "Training",
                "Reliability",
                "Data models",
                "Context modeling",
                "Standards",
                "Sensitivity",
                "Large language models"
            ],
            "Author Keywords": [
                "Large language models",
                "LLM safety",
                "automatic safety score"
            ]
        }
    },
    {
        "Title": "An Adaptive Parallel Layer-Skipping Framework for Large Language Model Inference Speedup With Speculative Decoding",
        "Link": "https://ieeexplore.ieee.org/document/11018422/",
        "Abstract": "In recent years, the exponential growth in Large Language Model (LLM) parameter sizes has significantly increased computational complexity, with inference latency emerging as a prominent challenge. The primary bottleneck lies in the token-by-token prediction process during autoregressive decoding, resulting in substantial delays. Therefore, enhancing decoding efficiency while maintaining accuracy has become a critical research objective. This paper proposes an Adaptive Parallel Layer-Skipping Speculative Decoding (APLS) method, which leverages speculative decoding techniques by employing a Small-Scale Model (SSM) for preliminary inference and validating the predictions using the original LLM. This approach effectively balances the high precision of LLMs with the efficiency of SSMs. Notably, our SSM does not require additional training but is instead derived through a simplification of the original large-scale model. By incorporating parallelization and a layer-skipping structure, the inference process dynamically bypasses certain redundant transformation layers, significantly improving GPU utilization and inference speed without compromising performance. Furthermore, to address challenges such as window size limitations and memory fragmentation in long-text processing, this paper introduces progressive layer reduction and key-value cache deletion techniques to further optimize the performance of SSMs. Experimental results demonstrate that the proposed method achieves a 2.51 × improvement in efficiency during autoregressive decoding. As this approach eliminates the need for additional training of SSM, it offers a significant competitive advantage in high-cost model compression environments.",
        "Details": {
            "DOI": "10.23919/ICS.2025.3575371",
            "Date of Publication": "30 May 2025",
            "Publisher": "SJTU",
            "Published In": "Integrated Circuits and Systems"
        },
        "issn_info": {
            "Print ISSN": "2995-1968"
        },
        "authors_data": [
            {
                "name": "Zhe Wen",
                "labs": [
                    "School of Integrated Circuits, Sun Yat-sen University, Shenzhen, China"
                ]
            },
            {
                "name": "Liang Xu",
                "labs": [
                    "School of Integrated Circuits, Sun Yat-sen University, Shenzhen, China"
                ]
            },
            {
                "name": "Meiqi Wang",
                "labs": [
                    "School of Integrated Circuits, Sun Yat-sen University, Shenzhen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Computational modeling",
                "Integrated circuit modeling",
                "Optimization",
                "Memory management",
                "Graphics processing units",
                "Adaptation models",
                "Training",
                "Predictive models",
                "Accuracy"
            ],
            "Author Keywords": [
                "fuzzy inference",
                "inference decoding",
                "KV Cache optimization",
                "LLM optimization accelerates"
            ]
        }
    },
    {
        "Title": "ORANSight-2.0: Foundational LLMs for O-RAN",
        "Link": "https://ieeexplore.ieee.org/document/11096935/",
        "Abstract": "Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative to develop specialized foundational LLMs tailored for O-RAN. Built on 18 models spanning five open-source LLM frameworks—Mistral, Qwen, Llama, Phi, and Gemma—ORANSight-2.0 fine-tunes models ranging from 1B to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance in O-RAN-specific tasks. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG)-based instruction-tuning framework that employs two LLM agents—a Mistral-based Question Generator and a Qwen-based Answer Generator—to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack. Additionally, we leverage ORAN-Bench-13K, an existing benchmark for assessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate that ORANSight-2.0 models outperform general-purpose and closed-source models, such as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on srsRANBench, achieving superior performance while maintaining lower computational and energy costs. We also experiment with RAG-augmented variants of ORANSight-2.0 models and observe that RAG augmentation improves performance by an average of 6.35% across benchmarks, achieving the best overall cumulative score of 0.854, which is 12.37% better than the leading closed-source alternative. We thoroughly evaluate the energy characteristics of ORANSight-2.0, demonstrating its efficiency in training, inference, and inference with RAG augmentation, ensuring optimal performance while maintaining low computational and energy costs. Additionally, the best ORANSight-2.0 configuration is compared against the available telecom LLMs, where our proposed model outperformed them with an average improvement of 27.96%.\nShow Less",
        "Details": {
            "DOI": "10.1109/TMLCN.2025.3592658",
            "Date of Publication": "25 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Machine Learning in Communications and Networking"
        },
        "issn_info": {
            "Electronic ISSN": "2831-316X"
        },
        "authors_data": [
            {
                "name": "Pranshav Gajjar",
                "labs": [
                    "NextG Wireless Laboratory, North Carolina State University, Raleigh, NC, USA"
                ]
            },
            {
                "name": "Vijay K. Shah",
                "labs": [
                    "NextG Wireless Laboratory, North Carolina State University, Raleigh, NC, USA",
                    "WiSights Lab, Newark, DE, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Open RAN",
                "Computational modeling",
                "Adaptation models",
                "Telecommunications",
                "Benchmark testing",
                "Training",
                "Codes",
                "Biological system modeling",
                "Retrieval augmented generation",
                "Data models"
            ],
            "Author Keywords": [
                "O-RAN",
                "ORANSight",
                "5G",
                "LLM",
                "ORANBench",
                "srsRANBench",
                "QLoRA",
                "foundational models"
            ]
        }
    },
    {
        "Title": "A Knowledge Graph Enhanced Pre-Trained Large Language Model for Predicting MicroRNA-circRNA Interactions",
        "Link": "https://ieeexplore.ieee.org/document/11164415/",
        "Abstract": "The interactions between circular RNAs (circRNAs) and microRNAs are one of the key mechanisms determining the functions of non-coding RNAs (ncRNAs) in biological processes such as DNA methylation and RNA-induced silencing. Studying these relationships can deepen our understanding of the function of these RNAs' roles in developing cancer vaccines and designing treatments. Therefore, we propose a knowledge graph enhanced pre-trained Large Language Model (LLM) for predicting circRNA-microRNA interactions. Our approach employs graph contrastive learning to represent a knowledge graph consisting of circRNA and microRNA entities from multi-views. The features of these entities are derived by fine-tuning a sequential LLM by two types of ncRNAs separately. At the final, the embedding is fed into classifier for prediction. We employ an independent testing set to evaluate the model's performance and against our model with recently reported models on two datasets. Our model achieves approximately a 3% improvement in Area Under the Receiver Operating Characteristic Curve (AUROC), reaching 93.77% and 93.07%, respectively. The stability of our model is tested by performing 10-fold cross-validation on the remaining training set where our model performs the best stability. In ablation study, we comprehensively compare strategies for sequence processing and effectiveness of independent module. Finally, on a case study dataset derived from real-world scenarios, the model assign scores to all candidates and rank them accordingly. Among the top 10 highest-scoring results, 7 have been validated by wet-lab experiments, highlighting the model's strong generalization capability.",
        "Details": {
            "DOI": "10.26599/BDMA.2025.9020014",
            "Date of Publication": "15 September 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Jiren Zhou",
                "labs": [
                    "School of Computer Science, Northwestern Polytechnical University, Xi'an, China"
                ]
            },
            {
                "name": "Rui Niu",
                "labs": [
                    "School of Computer Science, Northwestern Polytechnical University, Xi'an, China"
                ]
            },
            {
                "name": "Boya Ji",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Zhuhong You",
                "labs": [
                    "School of Computer Science, Northwestern Polytechnical University, Xi'an, China"
                ]
            },
            {
                "name": "Xuequn Shang",
                "labs": [
                    "School of Computer Science, Northwestern Polytechnical University, Xi'an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "RNA",
                "Large language models",
                "Neural networks",
                "Knowledge graphs",
                "Contrastive learning",
                "Receivers",
                "Stability analysis",
                "Vaccines",
                "Testing"
            ],
            "Author Keywords": [
                "knowledge graph",
                "sequential Large Language Model (LLM)",
                "graph contrastive learning",
                "circRNA-microRNA interactions",
                "self-supervised neural network"
            ]
        }
    },
    {
        "Title": "Are Requirements Really All You Need? Using LLMs to Generate Configuration Code: A Case Study in Automotive Simulations",
        "Link": "https://ieeexplore.ieee.org/document/11122468/",
        "Abstract": "Large Language Models (LLMs) are taking many industries by storm. They possess impressive reasoning abilities and are capable of handling complex problems, as shown by their steadily improving scores on coding and mathematical benchmarks. However, questions remain about their ability to tackle domain-specific, real-world challenges, especially in highly technical fields like the automotive industry. How well can these models understand high-level, abstract instructions commonly found in automotive standards and documentation? Can they translate such specifications directly into functional code, or do they still require human guidance and post-processing? In this work, we investigate the practical capabilities of a state-of-the-art LLM in the context of autonomous driving functionalities. Specifically, we assess the model’s ability to interpret abstract textual requirements extracted from real automotive regulations and transform them into executable configuration code for CARLA, a widely used autonomous driving simulation environment. Our evaluation focuses on the accuracy, completeness, and reliability of the generated code, as well as the model’s ability to reason about domain-specific constraints. The results offer insight into both the potential and current limitations of the models in supporting LLM-based automotive development workflows.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3597748",
            "Date of Publication": "11 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Krzysztof Lebioda",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            },
            {
                "name": "Nenad Petrovic",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            },
            {
                "name": "Fengjunjie Pan",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            },
            {
                "name": "Vahid Zolfaghari",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            },
            {
                "name": "André Schamschurko",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            },
            {
                "name": "Alois Knoll",
                "labs": [
                    "Chair of Robotics, Artificial Intelligence and Embedded Systems, School of Computation, Information and Technology (CIT), Technical University of Munich (TUM), Munich, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Automotive engineering",
                "Generators",
                "Sensors",
                "Pipelines",
                "Translation",
                "Regulation",
                "Industries",
                "Telemetry",
                "Cognition"
            ],
            "Author Keywords": [
                "LLM",
                "requirements",
                "AEB",
                "automotive",
                "code generation"
            ]
        }
    },
    {
        "Title": "Enhanced Sign Language Translation Between American Sign Language and Indian Sign Language Using LLMs",
        "Link": "https://ieeexplore.ieee.org/document/11113285/",
        "Abstract": "This research introduces a foundational framework aimed at bridging the communication gap between American Sign Language (ASL) and Indian Sign Language (ISL) by translating alphabet-level gestures. The proposed system employs a hybrid deep learning model for ASL gesture recognition, integrating a random forest classifier (RFC) and a convolutional neural network (CNN) to enhance accuracy. Recognised gestures are converted into text, which is refined using a prompt-configured large language model (LLM) for contextual and grammatical accuracy. The corrected text is then synthesised into ISL gestures using RIFE-Net, a real-time intermediate flow estimation network, to generate smooth and natural gesture videos. The framework addresses key challenges such as gesture variability and linguistic differences between ASL and ISL. The hybrid model achieves a gesture recognition accuracy of 93.0%, measuring how accurately the system identifies ASL signs. Following recognition, the raw text output is refined using the Large Language Model (LLM), resulting in a text correction accuracy of 94.2%, which reflects improvements in grammatical correctness and contextual relevance. These metrics collectively demonstrate the system’s effectiveness in alphabet-level recognition and gesture synthesis, laying the groundwork for more advanced sentence-level translation. Initial experimental results demonstrate real-time processing capabilities, averaging one gesture per second, with video outputs at 60 FPS. This system not only facilitates seamless communication between ASL and ISL users but also lays the groundwork for scalability to other sign language pairs. The results highlight the potential to improve accessibility and inclusion of the global hard of hearing community, paving the way for future research in multi-modal sign language translation systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595943",
            "Date of Publication": "05 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Malay Kumar",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "S. Sarvajit Visagan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "Tanish Mahajan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "Anisha Natarajan",
                "labs": [
                    "School of Electronics Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "P. S. Sreeja",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sign language",
                "Translation",
                "Accuracy",
                "Convolutional neural networks",
                "Linguistics",
                "Real-time systems",
                "Videos",
                "Random forests",
                "Large language models",
                "Hands"
            ],
            "Author Keywords": [
                "American sign language (ASL)",
                "Indian sign language (ISL)",
                "sign language translation",
                "large language models (LLM)",
                "random forest classifier",
                "convolutional neural network",
                "natural language processing (NLP)",
                "RIFE-Net",
                "gesture recognition",
                "real-time translation"
            ]
        }
    },
    {
        "Title": "Prompt Driven Multimodal Large Language Models for Concrete Defect Identification",
        "Link": "https://ieeexplore.ieee.org/document/11146713/",
        "Abstract": "Detecting surface defects in concrete structures is essential for ensuring structural safety; however, traditional methods have limitations, including subjectivity and heavy data dependency. This study proposes using pretrained multimodal large and small language models (LLM/SLM), specifically GPT-4o and Gemini 2.5-Flash, for concrete defect detection without additional fine-tuning. Structured prompts (S-Prompt) were employed to direct the task instructions and to elicit structured JSON outputs. The models’ performances were evaluated in both zero-shot and few-shot scenarios, the latter using a compact exemplar board. Performance was benchmarked against a fine-tuned YOLOv8 model, employing standard detection metrics alongside newly introduced metrics: Class Presence Accuracy (CPA), Relaxed Localization Recall (RLR), and Unmatched Prediction Ratio (UPR). Experimental results demonstrated that even in a zero-shot setting, the LLM/SLM models meaningfully identified defect presence, type, and approximate location (at an IoU threshold of 0.1) (GPT-4o: F1@\n0.1=0.468\n, CPA-F\n1=0.667\n). The few-shot scenario improved certain metrics (F1@0.1, CPA-F1, RLR@0.1, etc.) with reduced UPR@0.1, but exhibited a significant trade-off in reduced inference speed. Although the proposed method showed lower performance than YOLOv8 in precise localization tasks (higher IoU thresholds), it demonstrated significant potential as a training-free pipeline suitable for initial screening purposes without the burden of extensive data labeling and retraining.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605263",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seokjae Heo",
                "labs": [
                    "School of Architecture, Dankook University, Yongin-si, Gyeonggi-do, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Labeling",
                "Defect detection",
                "Large language models",
                "Accuracy",
                "Training",
                "Measurement",
                "Concrete",
                "Tuning",
                "Manuals"
            ],
            "Author Keywords": [
                "Large language model (LLM)",
                "concrete defect detection",
                "structured prompts",
                "zero-shot learning",
                "few-shot learning",
                "object detection"
            ]
        }
    },
    {
        "Title": "Small Language Model Agent for the Operations of Continuously Updating ICT Systems",
        "Link": "https://ieeexplore.ieee.org/document/10900353/",
        "Abstract": "The management of ICT systems requires the implementation of appropriate operational procedures that are aligned with the specific system state and adhere to the latest updates and revisions of manuals and policies. The implementation of autonomous system operation has the potential to reduce the time and burden of human endeavors. Large Language Model (LLM) agents are expected to interact with ICT systems and operate them autonomously. However, existing LLM agents presume a sophisticated reasoning capability of API-based proprietary LLMs, which gives rise to concerns regarding operational costs and confidentiality. Therefore, we propose a novel framework for the Small Language Model (SLM) agent that is designed to adapt to a continuously updating environment. The proposed method addresses the limitation of the reasoning performance of the SLM agent using nested thoughts and prompt reconfiguration. In particular, we empirically identify the shortcut reasoning of the SLM agent and put forward an exemplar selection method to address this issue. We extensively evaluate the proposed method using both synthetic and real-world benchmarks and demonstrate that it significantly enhances the performance of the SLM agent with some computational overhead in comparison with the baselines.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3544637",
            "Date of Publication": "24 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nobukazu Fukuda",
                "labs": [
                    "NTT Access Network Service Systems Laboratories, NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Haruhisa Nozue",
                "labs": [
                    "NTT Access Network Service Systems Laboratories, NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Haruo Oishi",
                "labs": [
                    "NTT Access Network Service Systems Laboratories, NTT Corporation, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Cognition",
                "Manuals",
                "History",
                "Decision making",
                "Load modeling",
                "Information and communication technology",
                "Planning",
                "Natural language processing",
                "Large language models"
            ],
            "Author Keywords": [
                "Communication system operations and management",
                "AIOps",
                "LLM agent",
                "small language model"
            ]
        }
    },
    {
        "Title": "VoiceTalk: A No-Code Approach for Creating Voice-Controlled Smart Home Applications",
        "Link": "https://ieeexplore.ieee.org/document/11023638/",
        "Abstract": "This article introduces VoiceTalk, a no-code approach that develops voice-controlled smart home applications without requiring programming expertise. At its core, VoiceTalk utilizes IoTtalk, an IoT application development platform for managing a diverse range of IoT devices. IoTtalk employs a two-tier microservices architecture, enabling users to define and chain applications through an intuitive drag-and-drop line interface. Leveraging its microservice architecture, VoiceTalk integrates IoTtalk with Google Home, offering a no-code solution for voice-controlled applications. VoiceTalk leverages its understanding of smart appliances in the room/house to generate specific prompts. We have compared the translation accuracy of 7 Automatic Speech Recognition (ASR) systems. We make two contributions. First, the no-code VoiceTalk platform significantly simplifies the development of Google Home-like applications. Second, by integrating ASRs with a commercial LLM such as GPT, we dramatically reduce voice-to-text translation errors, for examples, from 5.13% to 0.54% for the Web Speech API and from 2.25% to zero for Whisper Medium. For small-sized open-source LLMs such as Llama 3.2 3B, the errors are reduced to 0.72% for the Web Speech API and to zero for Whisper Medium. Furthermore, Device LLM Agent of VoiceTalk can be easily extended to integrate IoTtalk with other voice platforms, such as AWS Alexa.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3576725",
            "Date of Publication": "04 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Yun-Wei Lin",
                "labs": [
                    "College of Artificial Intelligence, NYCU, Hsinchu, Taiwan"
                ]
            },
            {
                "name": "Yi-Bing Lin",
                "labs": [
                    "National Yang-Ming Chiao University, Hsinchu, Taiwan",
                    "China Medical University, Taichung, Taiwan",
                    "Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan",
                    "Research Center for Information Technology Innovation, Academia Sinica, Taipei, Taiwan"
                ]
            },
            {
                "name": "Yi-Feng Wu",
                "labs": [
                    "Institute of Artificial Intelligence Innovation, NYCU, Hsinchu, Taiwan"
                ]
            },
            {
                "name": "Pei-Hsuan Shen",
                "labs": [
                    "Institute of Computational Intelligence, NYCU, Hsinchu, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet",
                "Internet of Things",
                "Virtual assistants",
                "Microservice architectures",
                "Smart homes",
                "Transforms",
                "Home appliances",
                "Thermostats",
                "Programming",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Automatic speech recognition (ASR)",
                "large language model (LLM)",
                "internet of things (IoT)",
                "smart speaker"
            ]
        }
    },
    {
        "Title": "Product Helpfulness Detection With Novel Transformer Based BERT Embedding and Class Probability Features",
        "Link": "https://ieeexplore.ieee.org/document/10504273/",
        "Abstract": "Nowadays global market products are readily accessible worldwide, and a vast array of reviews across numerous platforms are posted daily in several categories, making it challenging for customers to stay informed about their product interests. To make informed decisions regarding product quality, users require access to reviews and ratings. Owners and managers must analyze customer ratings and the underlying emotional content of reviews to enhance the product’s quality, cost, customer service, and environmental impact. The primary aim of our proposed research is to accurately predict product helpfulness through customer reviews using the Large Language Model (LLM), thereby assisting customers in saving time and money. We employed a benchmark dataset, the Amazon Fine Food Reviews, to develop numerous advanced machine-learning techniques. We introduced a novel transformer approach BERF (BERT Random Forest) for feature engineering to enhance the value of user evaluations for Amazon’s gourmet food products. The BERF method utilizes BERT embeddings and class probability features derived from product helpfulness online reviews textual data. We have balanced the dataset using the Synthetic Minority Over-sampling TEchnique (SMOTE) approach. Our comprehensive study results demonstrated that the Light Gradient Boosting Machine (LGBM) strategy outperformed existing state-of-the-art approaches, achieving an accuracy of 98%. The performance of each method is confirmed using a k-fold method and further improved through hyperparameter optimization. Our innovative study employing a transformer model has significantly enhanced the utility of customer reviews, substantially reducing online product scams and preventing wasted time and money.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3390605",
            "Date of Publication": "17 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Areeba Ishtiaq",
                "labs": [
                    "Institute of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, Pakistan"
                ]
            },
            {
                "name": "Kashif Munir",
                "labs": [
                    "Institute of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, Pakistan"
                ]
            },
            {
                "name": "Ali Raza",
                "labs": [
                    "Department of Software Engineering, The University of Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Nagwan Abdel Samee",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mona M. Jamjoom",
                "labs": [
                    "Department of Computer Sciences, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Zahid Ullah",
                "labs": [
                    "Department of Information System, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Transformers",
                "Machine learning",
                "Feature extraction",
                "Adaptation models",
                "Social networking (online)",
                "Sentiment analysis",
                "Large language models",
                "Deep learning",
                "Text mining"
            ],
            "Author Keywords": [
                "Product helpfulness",
                "large language model (LLM)",
                "machine learning",
                "deep learning",
                "text mining",
                "BERT",
                "transformer"
            ]
        }
    },
    {
        "Title": "Large Language Models in Psychiatry: Current Applications, Limitations, and Future Scope",
        "Link": "https://ieeexplore.ieee.org/document/10778142/",
        "Abstract": "With the advancements in Artificial Intelligence (AI) technology, Large Language Models (LLMs) provide outstanding capabilities for natural language understanding and generation, enhancing various domains. In psychiatry, LLMs can empower healthcare by analyzing vast amounts of medical data to improve diagnostic accuracy, enhance therapeutic communication, and personalize patient care with their strength in understanding and generating human-like text. In clinical AI, developing and utilizing robust and interpretable models has been a longstanding challenge. This survey investigates the current psychiatric practice of LLMs, along with a series of corpus resources that could be used for training psychiatric LLMs. We discuss the limitations concerning LLM reproducibility, capabilities, usability, interpretability in clinical settings, and ethical considerations. Additionally, we propose potential future directions for research, clinical application, and education in psychiatric LLMs. Finally, we discuss the challenge of integrating LLMs into the evolving landscape of healthcare in real-world scenarios.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020046",
            "Date of Publication": "04 December 2024",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Zhe Liu",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Yihang Bao",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Shuai Zeng",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Ruiyi Qian",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Miaohan Deng",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "An Gu",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Jianye Li",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Weidi Wang",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Wenxiang Cai",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Wenhao Li",
                "labs": [
                    "School of Information Science and Technology, Institute of Computational Biology, Northeast Normal University, Changchun, China"
                ]
            },
            {
                "name": "Han Wang",
                "labs": [
                    "School of Information Science and Technology, Institute of Computational Biology, Northeast Normal University, Changchun, China"
                ]
            },
            {
                "name": "Dong Xu",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Guan Ning Lin",
                "labs": [
                    "Shanghai Mental Health Center, Shanghai Jiao Tong University, School of Medicine, Shanghai, China",
                    "School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Surveys",
                "Ethics",
                "Large language models",
                "Mental health",
                "Medical services",
                "Reproducibility of results",
                "Data models",
                "Psychiatry",
                "Usability"
            ],
            "Author Keywords": [
                "Artificial Intelligence (AI)",
                "Large Language Model (LLM)",
                "psychiatry",
                "medical application"
            ]
        }
    },
    {
        "Title": "Fine-Tuned Understanding: Enhancing Social Bot Detection With Transformer-Based Classification",
        "Link": "https://ieeexplore.ieee.org/document/10630818/",
        "Abstract": "In recent years, the proliferation of online communication platforms and social media has given rise to a new wave of challenges, including the rapid spread of malicious bots. These bots, often programmed to impersonate human users, can infiltrate online communities, disseminate misinformation, and engage in various activities detrimental to the integrity of digital discourse. It is becoming more and more difficult to discern a text produced by deep neural networks from that created by humans. Transformer-based Pre-trained Language Models (PLMs) have recently shown excellent results in challenges involving natural language understanding (NLU). The suggested method is to employ an approach to detect bots at the tweet level by utilizing content and fine-tuning PLMs, to reduce the current threat. Building on the recent developments of the BERT (Bidirectional Encoder Representations from Transformers) and GPT-3, the suggested model employs a text embedding approach. This method offers a high-quality representation that can enhance the efficacy of detection. In addition, a Feedforward Neural Network (FNN) was used on top of the PLMs for final classification. The model was experimentally evaluated using the Twitter bot dataset. The strategy was tested using test data that came from the same distribution as their training set. The methodology in this paper involves preprocessing Twitter data, generating contextual embeddings using PLMs, and designing a classification model that learns to differentiate between human users and bots. Experiments were carried out adopting advanced Language Models to construct an encoding of the tweet to create a potential input vector on top of BERT and their variants. By employing Transformer-based models, we achieve significant improvements in bot detection F1-score (93%) compared to traditional methods such as Word2Vec and Global Vectors for Word Representation (Glove). Accuracy improvements ranging from 3% to 24% compared to baselines were achieved. The capability of GPT-4, an advanced Large Language Model (LLM), in interpreting bot-generated content is examined in this research. Additionally, explainable artificial intelligence (XAI) was utilized alongside transformer-based models for detecting bots on social media, enhancing the transparency and reliability of these models.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3440657",
            "Date of Publication": "08 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amine Sallah",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Techniques, Moulay Ismail University of Meknes, Errachidia, Morocco"
                ]
            },
            {
                "name": "El Arbi Abdellaoui Alaoui",
                "labs": [
                    "Department of Sciences, Ecole Normale Supérieure, Moulay Ismail University of Meknes, Errachidia, Morocco"
                ]
            },
            {
                "name": "Said Agoujil",
                "labs": [
                    "École Nationale de Commerce et de Gestion, Moulay Ismail University of Meknes, El Hajeb, Morocco"
                ]
            },
            {
                "name": "Mudasir Ahmad Wani",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohamed Hammad",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Department of Information Technology, Faculty of Computers and Information, Menoufia University, Shibin El Kom, Egypt"
                ]
            },
            {
                "name": "Yassine Maleh",
                "labs": [
                    "Laboratory laSTI, ENSAK, Sultan Moulay Slimane University (USMS), Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Ahmed A. Abd El-Latif",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Center of Excellence in Quantum and Intelligent Computing, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Department of Mathematics and Computer Science, Faculty of Science, Menoufia University, Shebin El-Koom, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Transformers",
                "Social networking (online)",
                "Blogs",
                "Encoding",
                "Bidirectional control",
                "Task analysis",
                "Large language models"
            ],
            "Author Keywords": [
                "BERT",
                "online social networks",
                "NLP",
                "transfer learning",
                "bot classification",
                "transformers",
                "pre-trained language models",
                "explainability",
                "LLM-based prompting"
            ]
        }
    },
    {
        "Title": "Addressing Technical Challenges in Large Language Model-Driven Educational Software System",
        "Link": "https://ieeexplore.ieee.org/document/10845786/",
        "Abstract": "The integration of large language models (LLMs) into educational systems poses significant challenges across several key attributes, including integration, explainability, testability, and scalability. These challenges arise from the complexity of coordinating system components, difficulty interpreting LLM decision-making processes, and the need for reliable, consistent model outputs in varied educational scenarios. Additionally, ensuring scalability requires robust autoscaling mechanisms and suitable architecture design to handle fluctuating workloads. This paper tackles these challenges by proposing tactics to improve system integration, enhance explainability through metadata and an algorithm process, ensure response consistency via regression testing, and facilitate efficient autoscaling through an event-driven microservice architecture. The evaluation results highlight the effectiveness of these tactics, confirming both functional consistency and robust system performance under varying loads.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3531380",
            "Date of Publication": "20 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nacha Chondamrongkul",
                "labs": [
                    "Computer and Communication Engineering for Capacity Building Research Center, School of Applied Digital Technology, Mae Fah Luang University, Chiang Rai, Thailand"
                ]
            },
            {
                "name": "Georgi Hristov",
                "labs": [
                    "Centre of Excellence UNITe, University of Ruse, Ruse, Bulgaria"
                ]
            },
            {
                "name": "Punnarumol Temdee",
                "labs": [
                    "Computer and Communication Engineering for Capacity Building Research Center, School of Applied Digital Technology, Mae Fah Luang University, Chiang Rai, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Education",
                "Cognition",
                "Reliability",
                "Decision making",
                "Scalability",
                "Accuracy",
                "Testing",
                "Software systems",
                "Retrieval augmented generation"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "educational application",
                "generative AI",
                "large language model",
                "LLM"
            ]
        }
    },
    {
        "Title": "Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study",
        "Link": "https://ieeexplore.ieee.org/document/10879492/",
        "Abstract": "Despite various approaches being employed to detect software vulnerabilities, the number of reported software vulnerabilities shows an upward trend over the years. This suggests the problems are not caught before the code is released, which could be caused by many factors, like lack of awareness, limited efficacy of the existing vulnerability detection tools or the tools not being user-friendly. To help combat some issues with traditional vulnerability detection tools, we propose using large language models (LLMs) to assist in finding vulnerabilities in source code. LLMs have shown a remarkable ability to understand and generate code, underlining their potential in code-related tasks. The aim is to test multiple state-of-the-art LLMs and identify the best prompting strategies, allowing extraction of the best value from the LLMs. We leverage findings from prompting-focused research, benchmarking approaches like chain of thought, tree of thought and self-consistency for vulnerability detection use-cases. We provide an overview of the strengths and weaknesses of the LLM-based approach and compare the results to those of traditional static analysis tools. We find that LLMs can pinpoint more issues than traditional static analysis tools, outperforming traditional tools in terms of recall and F1 scores. However, LLMs are more prone to generate false positive classifications than traditional tools. The experiments are conducted using the Java programming language and the results should benefit software developers and security analysts responsible for ensuring that the code is free of vulnerabilities.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3541146",
            "Date of Publication": "11 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Karl Tamberg",
                "labs": [
                    "School of Information Technologies, Tallinn University of Technology, Tallinn, Estonia"
                ]
            },
            {
                "name": "Hayretdin Bahsi",
                "labs": [
                    "School of Information Technologies, Tallinn University of Technology, Tallinn, Estonia",
                    "School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, AZ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Static analysis",
                "Security",
                "Benchmark testing",
                "Software",
                "Java",
                "Costs",
                "Manuals",
                "Large language models",
                "Deep learning"
            ],
            "Author Keywords": [
                "Benchmarking",
                "large language models",
                "LLM",
                "prompting",
                "software vulnerabilities",
                "static code analyser"
            ]
        }
    },
    {
        "Title": "MemoryRepository for AI NPC",
        "Link": "https://ieeexplore.ieee.org/document/10508558/",
        "Abstract": "Since the release of ChatGPT, large language models (LLMs) have played a huge role in various industries. In the field of games, we have used LLMs to act as intelligent AI NPC, which makes NPCs more intelligent. However, there is still an obvious obstacle -the LLMs lacks long-term memory and human-like memory mechanism. This flawed memory mechanism prevents NPCs from Long-term interaction and humanized memory based on conversation records. Recognizing the necessity of long-term memory and humanized memory, we proposed MemoryRepository, a memory mechanism for LLMs specifically used in the AI NPC field.MemoryRepository enables the model to have short-term memory and long-term memory. Short-term memory is more detailed and full, while long-term memory are more concise and partial. MemoryRepository is inspired by human memory and forgetting mechanisms. This mechanism allows AI NPCs to forget and summarize past conversation records, thereby providing long-term interaction capabilities. More importantly, this process of forgetting and summarizing the details of short-term memory into general long-term memories makes NPCs more human-like. MemoryRepository is versatile and can adapt to closed source models such as ChatGPT and open source models such as ChatGLM. To Intuitively verify the effectiveness of MemoryRepository in the field of AI NPC, we created an example in which all NPCs are represented by LLMs adapted to MemoryRepository. The example shows that by embedding LLM in MemoryRepository and fine-tuning NPCs character dialogue data, AI NPC can conduct better long-term conversations and appear more human-like during the interaction process. To validate the effectiveness of MemoryRepository, one hundred pieces of NPCs dialogue data were created and then quantitatively analyzed through evaluation indicators. The analysis results show that NPCs equipped with MemoryRepository can summarize and forget past memories, which enables it to have the ability to hold long-term conversations and conduct more human-like conversations.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3393485",
            "Date of Publication": "25 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shijie Zheng",
                "labs": [
                    "School of Electronic Information and Electrical Engineering, Yangtze University, Jingzhou, China"
                ]
            },
            {
                "name": "Keith He",
                "labs": [
                    "OgCloud Ltd, Guangzhou, China"
                ]
            },
            {
                "name": "Le Yang",
                "labs": [
                    "School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Jie Xiong",
                "labs": [
                    "School of Electronic Information and Electrical Engineering, Yangtze University, Jingzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Games",
                "Memory management",
                "Oral communication",
                "Transforms",
                "Semantics",
                "Long short term memory",
                "Chatbots"
            ],
            "Author Keywords": [
                "AI NPC",
                "human-like",
                "long-term memory",
                "MemoryRepository",
                "LLM"
            ]
        }
    },
    {
        "Title": "Large Language Model for Medical Images: A Survey of Taxonomy, Systematic Review, and Future Trends",
        "Link": "https://ieeexplore.ieee.org/document/10856853/",
        "Abstract": "The advent of Large Language Models (LLMs) has sparked considerable interest in the medical image domain, as they can generalize to multiple tasks and offer outstanding performance. While LLMs achieve promising results, there is currently a lack of a comprehensive summary of medical images, making it challenging for researchers to understand the progress within this domain. To fill this gap, we make the first attempt to present a comprehensive survey for LLM on medical images. In addition, to better summarize the current progress comprehensively, we further introduce a novel x-stage tuning paradigm for summarization, including zero-stage tuning, one-stage tuning, and multi-stage tuning, offering a unified perspective on LLMs for medical images. Finally, we discuss challenges and future directions in this domain, aiming to spur more breakthroughs in the future. We hope this work can pave the way for the broad application of LLMs in medical images and provide a valuable resource for this domain.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020090",
            "Date of Publication": "28 January 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Peng Wang",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Wenpeng Lu",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security Affiliated with Ministry of Education, Qilu University of Technology (Shandong Academy of Sciences), Jinan, China"
                ]
            },
            {
                "name": "Chunlin Lu",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Ruoxi Zhou",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Min Li",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Libo Qin",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Large language models",
                "Prevention and mitigation",
                "Taxonomy",
                "Training data",
                "Multilingual",
                "Security",
                "Medical diagnostic imaging",
                "Tuning",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Large Language Model (LLM)",
                "x-stage tuning",
                "medical images"
            ]
        }
    },
    {
        "Title": "Large Language Model Enhanced Particle Swarm Optimization for Hyperparameter Tuning for Deep Learning Models",
        "Link": "https://ieeexplore.ieee.org/document/10976715/",
        "Abstract": "Determining the ideal architecture for deep learning models, such as the number of layers and neurons, is a difficult and resource-intensive process that frequently relies on human tuning or computationally costly optimization approaches. While Particle Swarm Optimization (PSO) and Large Language Models (LLMs) have been individually applied in optimization and deep learning, their combined use for enhancing convergence in numerical optimization tasks remains underexplored. Our work addresses this gap by integrating LLMs into PSO to reduce model evaluations and improve convergence for deep learning hyperparameter tuning. The proposed LLM-enhanced PSO method addresses the difficulties of efficiency and convergence by using LLMs (particularly ChatGPT-3.5 and Llama3) to improve PSO performance, allowing for faster achievement of target objectives. Our method speeds up search space exploration by substituting underperforming particle placements with best suggestions offered by LLMs. Comprehensive experiments across three scenarios—(1) optimizing the Rastrigin function, (2) using Long Short-Term Memory (LSTM) networks for time series regression, and (3) using Convolutional Neural Networks (CNNs) for material classification—show that the method significantly improves convergence rates and lowers computational costs. Depending on the application, computational complexity is lowered by 20% to 60% compared to traditional PSO methods. Llama3 achieved a 20% to 40% reduction in model calls for regression tasks, whereas ChatGPT-3.5 reduced model calls by 60% for both regression and classification tasks, all while preserving accuracy and error rates. This groundbreaking methodology offers a very efficient and effective solution for optimizing deep learning models, leading to substantial computational performance improvements across a wide range of applications.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3564493",
            "Date of Publication": "25 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Saad Hameed",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar"
                ]
            },
            {
                "name": "Basheer Qolomany",
                "labs": [
                    "Department of Medicine, College of Medicine, Howard University, Washington, D.C., USA"
                ]
            },
            {
                "name": "Samir Brahim Belhaouari",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar"
                ]
            },
            {
                "name": "Mohamed Abdallah",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar"
                ]
            },
            {
                "name": "Junaid Qadir",
                "labs": [
                    "Department of Computer Science and Engineering, Qatar University, Doha, Qatar"
                ]
            },
            {
                "name": "Ala Al-Fuqaha",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Tuning",
                "Neurons",
                "Deep learning",
                "Convergence",
                "Large language models",
                "Computational efficiency",
                "Accuracy",
                "Predictive models",
                "Particle swarm optimization"
            ],
            "Author Keywords": [
                "Deep learning optimization",
                "PSO",
                "LLM",
                "machine learning",
                "hyper-parameter optimization"
            ]
        }
    },
    {
        "Title": "SpaCCC: Large Language Model-Based Cell-Cell Communication Inference for Spatially Resolved Transcriptomic Data",
        "Link": "https://ieeexplore.ieee.org/document/10778152/",
        "Abstract": "Drawing parallels between linguistic constructs and cellular biology, Large Language Models (LLMs) have achieved success in diverse downstream applications for single-cell data analysis. However, to date, it still lacks methods to take advantage of LLMs to infer Ligand-Receptor (LR)-mediated cell-cell communications for spatially resolved transcriptomic data. Here, we propose SpaCCC to facilitate the inference of spatially resolved cell-cell communications, which relies on our fine-tuned single-cell LLM and functional gene interaction network to embed ligand and receptor genes into a unified latent space. The LR pairs with a significant closer distance in latent space are taken to be more likely to interact with each other. After that, the molecular diffusion and permutation test strategies are respectively employed to calculate the communication strength and filter out communications with low specificities. The benchmarked performance of SpaCCC is evaluated on real single-cell spatial transcriptomic datasets with superiority over other methods. SpaCCC also infers known LR pairs concealed by existing aggregative methods and then identifies communication patterns for specific cell types and their signaling pathways. Furthermore, SpaCCC provides various cell-cell communication visualization results at both single-cell and cell type resolution. In summary, SpaCCC provides a sophisticated and practical tool allowing researchers to decipher spatially resolved cell-cell communications and related communication patterns and signaling pathways based on spatial transcriptome data. SpaCCC is free and publicly available at https://github.com/jiboyalab/SpaCCC.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020056",
            "Date of Publication": "04 December 2024",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Boya Ji",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Xiaoqi Wang",
                "labs": [
                    "School of Computer Science, Northwestern Polytechnical University, Xi'an, China"
                ]
            },
            {
                "name": "Debin Qiao",
                "labs": [
                    "School of Computer and Artificial Intelligence and National Supercomputing Center in Zhengzhou, Zhengzhou University, Zhengzhou, China"
                ]
            },
            {
                "name": "Liwen Xu",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Shaoliang Peng",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Large language models",
                "Transcriptomics",
                "Data visualization",
                "Receivers",
                "Spatial databases",
                "Biology",
                "Reliability",
                "Spatial resolution",
                "Signal resolution"
            ],
            "Author Keywords": [
                "Large Language Models (LLM)",
                "spatial transcriptome data",
                "Cell-Cell Communications (CCCs)",
                "functional gene interaction networks",
                "unified latent space"
            ]
        }
    },
    {
        "Title": "The Impact of LoRA Adapters on LLMs for Clinical Text Classification Under Computational and Data Constraints",
        "Link": "https://ieeexplore.ieee.org/document/11048527/",
        "Abstract": "Fine-tuning Large Language Models (LLMs) for clinical Natural Language Processing (NLP) poses significant challenges due to domain gap, limited data, and stringent hardware constraints. In this study, we evaluate four adapter techniques—Adapter, Lightweight, TinyAttention, and Gated Residual Network (GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note classification under real-world, resource-constrained conditions. All experiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512 CUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to\n≤8\nsequences and maximum sequence length to 256 tokens. Our clinical corpus comprises only 580 000 tokens, several orders of magnitude smaller than standard LLM pre-training datasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio, AliBERT, DrBERT) and two lightweight Transformer models trained from scratch. Results show that 1) adapter structures provide no consistent gains when fine-tuning biomedical LLMs under these constraints, and 2) simpler Transformers, with minimal parameter counts and training times under six hours, outperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among adapters, GRN achieved the best metrics (accuracy, precision, recall, F1 = 0.88). These findings demonstrate that, in low-resource clinical settings with limited data and compute, lightweight Transformers trained from scratch offer a more practical and efficient solution than large LLMs, while GRN remains a viable adapter choice when minimal adaptation is needed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3582037",
            "Date of Publication": "24 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thanh-Dung Le",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, Montreal, QC, Canada",
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Ti Ti Nguyen",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Vu Nguyen Ha",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Symeon Chatzinotas",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Philippe Jouvet",
                "labs": [
                    "CHU Sainte-Justine Research Center, CHU Sainte-Justine Hospital, University of Montreal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Rita Noumeir",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, Montreal, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Text categorization",
                "Natural language processing",
                "Adaptation models",
                "Acute respiratory distress syndrome",
                "Graphics processing units",
                "Biological system modeling",
                "Accuracy",
                "Tuning",
                "Training"
            ],
            "Author Keywords": [
                "Low-rank adaptation (LoRA)",
                "adapters",
                "LLM",
                "clinical NLP",
                "cardiac failure",
                "text classification"
            ]
        }
    },
    {
        "Title": "Mathematical Model and Algorithm for Accurate Main Content Extraction From News Websites",
        "Link": "https://ieeexplore.ieee.org/document/10819347/",
        "Abstract": "Irrelevant elements like ads, menus, and footers in web pages hinder data extraction and reduce the performance of Retrieval-Augmented Generation (RAG) systems in Large Language Models (LLMs). This paper tackles the challenge of accurately identifying and extracting the main content from web pages to enhance the efficiency of these systems. We present a novel mathematical model and algorithm that leverages the Document Object Model (DOM) structure, effectively isolating relevant content with high accuracy. Our approach is language-neutral and performs well across diverse languages, including those with complex tokenization, such as Arabic. To validate the model, we created a dataset from 500 websites, allowing for comprehensive evaluation and benchmarking. The algorithm’s practical application demonstrates a reduction in token usage for LLM tasks, contributing to cost-effectiveness. This work introduces a robust, open-source tool for the academic and commercial communities, fostering further innovation in web content extraction and information retrieval.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3524656",
            "Date of Publication": "31 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hamza Salem",
                "labs": [
                    "Department of Computer Science and Engineering, Innopolis University, Innopolis, Russia"
                ]
            },
            {
                "name": "Hadi Salloum",
                "labs": [
                    "Department of Computer Science and Engineering, Innopolis University, Innopolis, Russia",
                    "Research Center for Artificial Intelligence, Innopolis University, Innopolis, Russia",
                    "QDeep, Innopolis, Russia"
                ]
            },
            {
                "name": "Manuel Mazzara",
                "labs": [
                    "Department of Computer Science and Engineering, Innopolis University, Innopolis, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Data mining",
                "Web pages",
                "Accuracy",
                "Hidden Markov models",
                "Mathematical models",
                "Layout",
                "Heuristic algorithms",
                "Convolutional neural networks",
                "Focusing"
            ],
            "Author Keywords": [
                "Information extraction",
                "document object model (DOM)",
                "retrieval-augmented generation (RAG)",
                "large language models (LLM)",
                "main content detection"
            ]
        }
    },
    {
        "Title": "Redefining OSINT Software Architecture With System-Centric Architecture Design: A Framework Shaped by QAW, ADD, and ATAM",
        "Link": "https://ieeexplore.ieee.org/document/10971222/",
        "Abstract": "This study develops a novel software architecture for Open Source Intelligence (OSINT). The primary architectural drivers of the OSINT architecture are identified using the Quality Attribute Workshop (QAW), and an end-to-end OSINT software architecture design is implemented in accordance with Attribute-Driven Design (ADD). The architecture is extensively analyzed with metric evaluations and the Architecture Tradeoff Analysis Method (ATAM), confirming critical quality attributes such as performance, reliability, functional suitability, and security. The design decisions taken within this architectural framework are detailed in the article through module view, component and connector view, and allocation view representations. The proposed architecture uses an on-premise Large Language Model (LLM) to explore the potential for deeper and more reliable information processing capabilities in OSINT analyses and presents a framework that enhances semantic depth and analytical capabilities. The architecture not only amplifies the semantic and analytical capabilities of OSINT systems but also sets a precedent for future architectural endeavors in intelligence systems design. This paper presents a framework that not only meets contemporary needs but also anticipates future demands in the rapidly evolving field of OSINT.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3562718",
            "Date of Publication": "21 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gökhan Yurtalan",
                "labs": [
                    "Department of Computer Engineering, Çankaya University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Serdar Arslan",
                "labs": [
                    "Department of Computer Engineering, Çankaya University, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer architecture",
                "Data mining",
                "Social networking (online)",
                "Security",
                "Software architecture",
                "Data collection",
                "Cyber threat intelligence",
                "Crawlers",
                "Text summarization",
                "Semantics"
            ],
            "Author Keywords": [
                "OSINT",
                "software architecture",
                "QAW",
                "ADD",
                "ATAM",
                "LLM"
            ]
        }
    },
    {
        "Title": "Convolutional Versus Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing",
        "Link": "https://ieeexplore.ieee.org/document/11072699/",
        "Abstract": "Software logs generated by sophisticated network emulators in the telecommunications industry, such as VIAVI TM500, are extremely complex, often comprising tens of thousands of text lines with minimal resemblance to natural language. Only specialised expert engineers can decipher such logs and troubleshoot defects in test runs. While AI offers a promising solution for automating defect triage, potentially leading to massive revenue savings for companies, state-of-the-art large language models (LLMs) suffer from significant drawbacks in this specialised domain. These include a constrained context window, limited applicability to text beyond natural language, and high inference costs. To address these limitations, we propose a compact convolutional neural network (CNN) architecture that offers a context window spanning up to 200,000 characters and achieves over 96% accuracy (F\n1>0.9\n) in classifying multifaceted software logs into various layers in the telecommunications protocol stack. Specifically, the proposed model is capable of identifying defects in test runs and triaging them to the relevant department, formerly a manual engineering process that required expert knowledge. We evaluate several LLMs; LLaMA2-7B, Mixtral_\n8×7\nB, Flan-T5, BERT and BigBird, and experimentally demonstrate their shortcomings in our specialized application. Despite being lightweight, our CNN achieves strong performance compared to LLM-based approaches in telecommunications log classification while minimizing the cost of production. Our defect triaging AI model is deployable on edge devices without dedicated hardware and is applicable across software logs in various industries.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3587029",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Achintha Ihalage",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K."
                ]
            },
            {
                "name": "Sayed Taheri",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K.",
                    "Department of Electronics and Electrical Engineering, Brunel University of London, London, U.K."
                ]
            },
            {
                "name": "Faris Muhammad",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K."
                ]
            },
            {
                "name": "Hamed Al-Raweshidy",
                "labs": [
                    "Department of Electronics and Electrical Engineering, Brunel University of London, London, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Computer architecture",
                "Convolutional neural networks",
                "Telecommunications",
                "Long short term memory",
                "Anomaly detection",
                "Large language models",
                "Cellular networks",
                "Support vector machines",
                "Analytical models"
            ],
            "Author Keywords": [
                "Cellular networks",
                "LLM",
                "log analysis",
                "machine learning",
                "NLP"
            ]
        }
    },
    {
        "Title": "Evolution of Malicious Social Bot Detection: From Individual Profiling to Group Analysis and Beyond",
        "Link": "https://ieeexplore.ieee.org/document/11184733/",
        "Abstract": "The rise of online social platforms has enhanced connectivity and access to information. Still, it has also enabled the proliferation of malicious social bots that threaten platform security and disrupt social order. In this paper, we introduce a unified framework for defining and classifying malicious social bots along three dimensions: behavior, interaction, and operation. We then present a comprehensive review of social bot detection methods, tracing their evolution from traditional machine learning techniques to deep learning architectures and graph neural networks, with particular emphasis on recent advances in group-level detection. We also explore the emerging paradigm of Large Language Model (LLM) based bot detection. This paper reviews the current state of research, identifies key challenges, and outlines future directions. It provides a cohesive foundation for building more robust detection frameworks to counter the evolving threats posed by malicious social bots.",
        "Details": {
            "DOI": "10.23919/JSC.2025.0017",
            "Date of Publication": "29 September 2025",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Yina Liu",
                "labs": [
                    "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China"
                ]
            },
            {
                "name": "Shuai Xu",
                "labs": [
                    "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China",
                    "Key Laboratory of Social Computing and Cognitive Intelligence, (Dalian University of Technology), Ministry of Education, Dalian, China"
                ]
            },
            {
                "name": "Yicong Li",
                "labs": [
                    "College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China"
                ]
            },
            {
                "name": "Shuo Yu",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Analytical models",
                "Technological innovation",
                "Social computing",
                "Reviews",
                "Social networking (online)",
                "Graph convolutional networks",
                "Large language models",
                "Security",
                "Next generation networking"
            ],
            "Author Keywords": [
                "malicious social bots",
                "bot detection",
                "social network",
                "Large Language Model (LLM) driven bots"
            ]
        }
    },
    {
        "Title": "Leveraging LLMs and Knowledge Graphs to Design Secure Automation Systems",
        "Link": "https://ieeexplore.ieee.org/document/10904297/",
        "Abstract": "The digital transformation of Industrial Control Systems (ICSs) within the Industry 4.0 paradigm is essential for industrial organizations to remain competitive, while cybersecurity is an enabler. However, security measures, often implemented late in the engineering process, lead to costly and complicated implementations. Thus, this article is concerned with the “security by design” principle in ICSs and facilitates compliance with ICS security standards, which can be legally mandated for some critical systems or adopted by asset owners to protect their assets. Current methods for compliance demand manual efforts from security experts, making the compliance process time-consuming and costly. To address this, we propose a framework for leveraging large language models (LLMs) combined with knowledge graphs to automate the interpretation of security requirements and system architecture as two main elements of the design phase. Our knowledge graph-augmented LLM framework converts system architectures into human natural language, enhancing the automation of various security analyses, especially those that need to handle textual requirements. The framework enables validating applicable security requirements provided by IEC 62443-3-3 (a widely-used ICS security standard) concerning system designs through a question-and-answer interface. To evaluate the framework, various questions with reference responses from human experts were prepared in the context of a use case, and the quality of the LLMs' responses was measured across various metrics. Moreover, we compared the framework with a baseline approach based on formal queries. The results show that the proposed framework effectively automates security tasks and offers a user-friendly interface accessible to nonexperts.",
        "Details": {
            "DOI": "10.1109/OJIES.2025.3545811",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Industrial Electronics Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1284"
        },
        "authors_data": [
            {
                "name": "Ali M. Hosseini",
                "labs": [
                    "Institute of Computer Engineering, TU Wien, Vienna, Austria"
                ]
            },
            {
                "name": "Wolfgang Kastner",
                "labs": [
                    "Institute of Computer Technology, TU Wien, Vienna, Austria"
                ]
            },
            {
                "name": "Thilo Sauter",
                "labs": [
                    "Institute of Computer Engineering, TU Wien, Vienna, Austria",
                    "Center for Distributed Systems and Sensor Networks, Donau-Universität Krems, Wiener Neustadt, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Ontologies",
                "Knowledge graphs",
                "Computer security",
                "IEC Standards",
                "Systems architecture",
                "Cyberattack",
                "Cognition",
                "Natural languages",
                "Large language models"
            ],
            "Author Keywords": [
                "Industrial control system (ICS)",
                "security by design",
                "knowledge graph",
                "large language model (LLM)",
                "ontology"
            ]
        }
    },
    {
        "Title": "Offline Detection of Violations in Chinese E-Commerce Live Streaming Content",
        "Link": "https://ieeexplore.ieee.org/document/11058940/",
        "Abstract": "With the rapid growth of the Chinese e-commerce live streaming industry, regulatory oversight of its content has become increasingly critical. This paper addresses the task of offline detection of content violations in recorded Chinese e-commerce live streaming videos. We introduce a new task, CLiveSVD, which categorizes content into three classes: compliance, suspected violation, and serious violation. To support research in this area, we constructed a high-quality dataset in collaboration with market supervision experts, comprising a training set, validation set, and two test sets. Given the semantic similarity between suspected and serious violations, we propose a two-stage classification framework that improves upon direct multi-class classification. Additionally, to address the challenges of data imbalance and the high cost of manual annotation, we leverage large language models (LLMs) to generate synthetic violation examples, enhancing both the diversity and volume of the training data. Experimental results show that our two-stage approach achieves superior performance, and that LLM-generated data further boosts the robustness and effectiveness of the violation detection system in offline settings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3584238",
            "Date of Publication": "30 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiaohan Liu",
                "labs": [
                    "China Academy of Electronics and Information Technology, Beijing, China",
                    "School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Chenyu Liu",
                "labs": [
                    "China Academy of Electronics and Information Technology, Beijing, China"
                ]
            },
            {
                "name": "Ran Bai",
                "labs": [
                    "China Academy of Electronics and Information Technology, Beijing, China"
                ]
            },
            {
                "name": "Liu Yuan",
                "labs": [
                    "China Academy of Electronics and Information Technology, Beijing, China"
                ]
            },
            {
                "name": "Yanquan Zhou",
                "labs": [
                    "School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Minjiang Huang",
                "labs": [
                    "Department of Computer Science, Yangzhou University, Yangzhou, Jiangsu, China"
                ]
            },
            {
                "name": "Jipeng Qiang",
                "labs": [
                    "Department of Computer Science, Yangzhou University, Yangzhou, Jiangsu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Videos",
                "Feature extraction",
                "Electronic commerce",
                "Regulation",
                "Reviews",
                "Deep learning",
                "Advertising",
                "Regulators",
                "Lips",
                "Industries"
            ],
            "Author Keywords": [
                "E-commerce live streaming",
                "violation detecting",
                "LLM"
            ]
        }
    },
    {
        "Title": "NAIA: A Multi-Technology Virtual Assistant for Boosting Academic Environments—A Case Study",
        "Link": "https://ieeexplore.ieee.org/document/11121858/",
        "Abstract": "Virtual assistants have become essential tools for improving productivity and efficiency in various domains. This paper presents NAIA (Nimble Artificial Intelligence Assistant), an advanced multi-role and multi-task virtual assistant enhanced with artificial intelligence, designed to serve a university community case study. The system integrates AI technologies including Large Language Models (LLM), Computer Vision, and voice processing to create an immersive and efficient interaction through animated digital avatars. NAIA features five specialized roles: researcher, receptionist, personal skills trainer, personal assistant, and university guide, each equipped with specific capabilities to support different aspects of academic life. The system’s Computer Vision capabilities enable it to comment on users’ physical appearance and environment, enriching the interaction. Through natural language processing and voice interaction, NAIA aims to improve productivity and efficiency within the university environment while providing personalized assistance through a ubiquitous platform accessible across multiple devices. NAIA is evaluated through a user experience survey involving 30 participants with different demographic characteristics, this is the most accepted way by the community to evaluate this type of solution. Participants give their feedback after using one role of NAIA after using it for 30 minutes. The experiment showed that 90% of the participants considered NAIA-assisted tasks of higher quality and, on average, NAIA has a score of 4.27 out of 5 on user satisfaction. Participants particularly appreciated the assistant’s visual recognition, natural conversation flow, and user interaction capabilities. Results demonstrate NAIA’s capabilities and effectiveness across the five roles.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3597565",
            "Date of Publication": "11 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Adrián Pabón Mendoza",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia"
                ]
            },
            {
                "name": "Kenneth J. Barrios Quiroga",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia"
                ]
            },
            {
                "name": "Samuel D. Solano Celis",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia"
                ]
            },
            {
                "name": "Christian M. Quintero",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Virtual assistants",
                "Artificial intelligence",
                "Productivity",
                "Avatars",
                "Retrieval augmented generation",
                "Computer vision",
                "Speech to text",
                "Multitasking",
                "Visualization",
                "User experience"
            ],
            "Author Keywords": [
                "Virtual assistant",
                "artificial intelligence",
                "large language model (LLM)",
                "computer vision",
                "text to speech (TTS)",
                "speech to text (STT)",
                "digital avatars",
                "human-AI interaction"
            ]
        }
    },
    {
        "Title": "Transforming Applied Behavior Analysis Therapy: An Internet of Things-Guided, Retrieval-Augmented Large Language Model Framework",
        "Link": "https://ieeexplore.ieee.org/document/11129621/",
        "Abstract": "We propose ABA-RAG, a retrieval-augmented generation (RAG) framework specifically tailored for applied behavior analysis (ABA) interventions, which integrates real-time emotional and behavioral data from Internet-of-Things (IoT) wearable devices. In ABA-RAG, we systematically retrieve semantically relevant prompts from a structured ABA task repository using embedding-based semantic search and dynamically construct context-aware prompts by incorporating IoT-derived predictions of learners’ emotional and behavioral states. To efficiently adapt large language model (LLM) to ABA contexts, we evaluate and compare several low-rank fine-tuning methods—including Low-Rank Adaptation (LoRA), Butterfly Orthogonal Fine-Tuning (BOFT), and LoRA with Gradient Approximation (LoRA-GA). Among these techniques, LoRA-GA demonstrates the best balance between computational efficiency and generation quality, making it particularly suitable for resource-constrained environments. Comprehensive experiments, validated through rigorous quantitative metrics and expert ABA practitioner evaluations, demonstrate that ABA-RAG significantly reduces manual workload while enhancing the precision, contextual relevance, and clinical utility of generated ABA tasks. Integrated into a practical web-based system, ABA-RAG provides ABA professionals with a scalable and real-time platform to generate individualized interventions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3600316",
            "Date of Publication": "19 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Haomin Qi",
                "labs": [
                    "Department of Information Engineering, The Chinese University of Hong Kong, New Territories, Hong Kong"
                ]
            },
            {
                "name": "Sin Chung-Ho",
                "labs": [
                    "Department of Information Engineering, The Chinese University of Hong Kong, New Territories, Hong Kong"
                ]
            },
            {
                "name": "Rosanna Yuen-Yan Chan",
                "labs": [
                    "Department of Information Engineering, The Chinese University of Hong Kong, New Territories, Hong Kong",
                    "Centre for Perceptual and Interactive Intelligence, The Chinese University of Hong Kong, New Territories, Hong Kong"
                ]
            },
            {
                "name": "Chun Man Victor Wong",
                "labs": [
                    "Department of Special Education and Counselling, The Education University of Hong Kong, Ting Kok, Hong Kong"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Real-time systems",
                "Medical treatment",
                "Retrieval augmented generation",
                "Internet of Things",
                "Education",
                "Biomedical monitoring",
                "Large language models",
                "Adaptation models",
                "Training",
                "Pipelines"
            ],
            "Author Keywords": [
                "Retrieval-augmented generation (RAG)",
                "large language model (LLM)",
                "applied behavior analysis (ABA)",
                "IoT-based emotional analysis",
                "efficient parameter fine-tuning (PEFT)",
                "autism spectrum disorders (ASD)",
                "special educational needs (SEN)"
            ]
        }
    },
    {
        "Title": "Research on the Construction and Application of Earthquake Emergency Information Knowledge Graph Based on Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11075653/",
        "Abstract": "To address the challenges of semantic parsing of multi-source heterogeneous information and the delayed emergency response decisions caused by insufficient relational reasoning capabilities in earthquake emergency management, this study proposes a domain knowledge extraction method for earthquakes based on a large language model combined with a three-level prompt engineering system (TPES-LLM) of “instruction fine-tuning - demand awareness - case matching. ”The method deploys a local large language model using LangChain +QWEN2.5-7B, integrates earthquake domain knowledge through LoRa fine-tuning based on earthquake experts’ classifications and industry standards, and injects seismic knowledge into the model. The multi-head attention mechanism weights are optimized based on the co-occurrence frequency of historical earthquake entities, and demand-aware knowledge identifies key textual features that significantly impact knowledge extraction. Training is performed on 36 known earthquake disaster events to learn the association patterns of entities, relationships, and events hidden within the earthquake case data for case matching. This method significantly enhances the accuracy of entity recognition and the efficiency of relation extraction for complex disaster-related texts. Additionally, a bidirectional graph attention network (Bi-GAT) is designed to enable bidirectional propagation and dynamic aggregation of node features. The path confidence constraint algorithm (PCCA) is used to achieve deep semantic associations of earthquake disaster elements. Based on the Neo4j graph database, an earthquake emergency knowledge graph is constructed. Experimental results from real earthquake events such as the 2022 Luding 6.8-magnitude earthquake, the 2024 Jishishan 6.2-magnitude earthquake, and the 2025 Dingri 6.8-magnitude earthquake show that the accuracy of intelligent Q&A retrieval for the earthquake emergency knowledge graph reaches 89.62%, 87.28%, and 90.23%, respectively. The earthquake emergency knowledge graph based on large language models constructed in this study provides intelligent decision support for earthquake emergencies, with significant application value.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586370",
            "Date of Publication": "10 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wentao Zhou",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Meng Huang",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Shuai Liu",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Qiao You",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Fanxin Meng",
                "labs": [
                    "Sichuan Disaster Reduction Center, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Earthquakes",
                "Disasters",
                "Semantics",
                "Emergency services",
                "Cognition",
                "Feature extraction",
                "Data mining",
                "Knowledge graphs",
                "Large language models",
                "Correlation"
            ],
            "Author Keywords": [
                "TPES-LLM",
                "NLP",
                "Bi-GAT",
                "PCCA",
                "Neo4j"
            ]
        }
    },
    {
        "Title": "Survey and Evaluation of Converging Architecture in LLMs Based on Footsteps of Operations",
        "Link": "https://ieeexplore.ieee.org/document/11072851/",
        "Abstract": "Large language models (LLMs), which have emerged from advances in natural language processing (NLP), enable chatbots, virtual assistants, and numerous domain-specific applications. These models, often comprising billions of parameters, leverage the Transformer architecture and Attention mechanisms to process context effectively and address long-term dependencies more efficiently than earlier approaches, such as recurrent neural networks (RNNs). Notably, since the introduction of Llama, the architectural development of LLMs has significantly converged, predominantly settling on a Transformer-based decoder-only architecture. The evolution of LLMs has been driven by advances in high-bandwidth memory, specialized accelerators, and optimized architectures, enabling models to scale to billions of parameters. However, it also introduces new challenges: meeting compute and memory efficiency requirements across diverse deployment targets, ranging from data center servers to resource-constrained edge devices. To address these challenges, we survey the evolution of LLMs at two complementary levels: architectural trends and their underlying operational mechanisms. Furthermore, we quantify how hyperparameter settings influence inference latency by profiling kernel-level execution on a modern GPU architecture. Our findings reveal that identical models can exhibit varying performance based on hyperparameter configurations and deployment contexts, emphasizing the need for scalable and efficient solutions. The insights distilled from this analysis guide the optimization of performance and efficiency within these converged LLM architectures, thereby extending their applicability across a broader range of environments.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3587005",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Seongho Kim",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jihyun Moon",
                "labs": [
                    "Department of Systems Semiconductor Engineering, Yonsei University, Seoul, South Korea",
                    "BK21 Graduate Program in Intelligent Semiconductor Technology, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Juntaek Oh",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Insu Choi",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Joon-Sung Yang",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea",
                    "Department of Systems Semiconductor Engineering, Yonsei University, Seoul, South Korea",
                    "BK21 Graduate Program in Intelligent Semiconductor Technology, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer architecture",
                "Computational modeling",
                "Transformers",
                "Training",
                "Neural networks",
                "Context modeling",
                "Artificial intelligence",
                "Encoding",
                "Surveys",
                "Optimization"
            ],
            "Author Keywords": [
                "Edge computing",
                "LLM",
                "NLP",
                "transformer architecture",
                "and server deployment"
            ]
        }
    },
    {
        "Title": "Quantization-Based Jailbreaking Vulnerability Analysis: A Study on Performance and Safety of the Llama3-8B-Instruct Model",
        "Link": "https://ieeexplore.ieee.org/document/11105403/",
        "Abstract": "This study systematically investigates how quantization, a key technique for the efficient deployment of large language models (LLMs), affects model safety. We specifically focus on jailbreaking vulnerabilities that emerge when models are subjected to quantization, particularly in multilingual and tense-shifted scenarios. Using Llama3-8B-Instruct as a representative model, we evaluate 23 quantization levels across two languages and three tenses. Our experimental results reveal a critical trade-off: lower-bit quantization degrades the model’s core reasoning abilities, which directly correlates with a higher Attack Success Rate (ASR). Within this context, for the model tested, 4-bit quantization appears as a practical “sweet spot,” maintaining near-baseline performance while significantly reducing computational costs. However, even at this level, substantial vulnerabilities persist—Korean prompts exhibit attack success rates 25.5 percentage points higher than English, and past-tense transformations increase vulnerability by 39.3 percentage points. These findings highlight that safety mechanisms are often compromised by quantization-induced performance degradation and are biased toward English, present-tense prompts. Although this study has clear limitations, it provides the first quantitative analysis of these combined vulnerabilities, underscoring the need for more comprehensive safety evaluations in quantized LLM deployment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3594287",
            "Date of Publication": "31 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jaesik Lee",
                "labs": [
                    "Korea Internet and Security Agency, Naju, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Safety",
                "Analytical models",
                "Multilingual",
                "Security",
                "Computational modeling",
                "Standards",
                "Benchmark testing",
                "Systematics",
                "Large language models"
            ],
            "Author Keywords": [
                "Attack success rate (ASR)",
                "jailbreak",
                "large language model (LLM)",
                "multilingual",
                "quantization",
                "safety",
                "tense transformation"
            ]
        }
    },
    {
        "Title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10433480/",
        "Abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3365742",
            "Date of Publication": "13 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohaimenul Azam Khan Raiaan",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Saddam Hossain Mukta",
                "labs": [
                    "LUT School of Engineering Sciences, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland"
                ]
            },
            {
                "name": "Kaniz Fatema",
                "labs": [
                    "Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia"
                ]
            },
            {
                "name": "Nur Mohammad Fahad",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sadman Sakib",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Most Marufatul Jannat Mim",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Jubaer Ahmad",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Mohammed Eunus Ali",
                "labs": [
                    "Department of CSE, Bangladesh University of Engineering and Technology (BUET), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sami Azam",
                "labs": [
                    "Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Artificial intelligence",
                "Transformers",
                "Training",
                "Taxonomy",
                "Task analysis",
                "Surveys",
                "Natural language processing",
                "Question answering (information retrieval)",
                "Information analysis",
                "Linguistics"
            ],
            "Author Keywords": [
                "Large language models (LLM)",
                "natural language processing (NLP)",
                "artificial intelligence",
                "transformer",
                "pre-trained models",
                "taxonomy",
                "application"
            ]
        }
    },
    {
        "Title": "Accelerating Innovation With Generative AI: AI-Augmented Digital Prototyping and Innovation Methods",
        "Link": "https://ieeexplore.ieee.org/document/10115412/",
        "Abstract": "Easy-to-use generative artificial intelligence (AI) is democratizing the use of AI in innovation management and may significantly change the way how we work and innovate. In this article, we show how large language models (LLMs), such as generative pretrained transformer (GPT), can augment the early phases of innovation, in particular, exploration, ideation, and digital prototyping. Drawing on six months of experimenting with LLMs in internal and client innovation projects, we share first-hand experiences and concrete examples of AI-assisted approaches. The article highlights a large variety of use cases for generative AI ranging from user journey mapping to idea generation and prototyping and foreshadows the promising role LLMs may play in future knowledge management systems. Moreover, we argue that generative AI may become a game changer in early prototyping as the delegation of tasks to an artificial agent can result in faster iterations and reduced costs. Our experiences also provide insights into how human innovation teams purposively and effectively interact with AIs and integrate them into their workflows.",
        "Details": {
            "DOI": "10.1109/EMR.2023.3272799",
            "Date of Publication": "04 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Engineering Management Review"
        },
        "issn_info": {
            "Print ISSN": "0360-8581",
            "Electronic ISSN": "1937-4178"
        },
        "authors_data": [
            {
                "name": "Volker Bilgram",
                "labs": [
                    "Nuremberg Institute of Technology, Nürnberg, Germany"
                ]
            },
            {
                "name": "Felix Laarmann",
                "labs": [
                    "HYVE, München, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Technological innovation",
                "Chatbots",
                "Codes",
                "Prototypes",
                "Task analysis",
                "Companies"
            ],
            "Author Keywords": [
                "AI-augmented innovation management",
                "artificial intelligence (AI)",
                "digital prototyping",
                "generative AI",
                "idea generation",
                "innovation",
                "large language model (LLM)",
                "need identification",
                "no-code prototyping",
                "UX/UI"
            ]
        }
    },
    {
        "Title": "A Comprehensive Survey of Convolutions in Deep Learning: Applications, Challenges, and Future Trends",
        "Link": "https://ieeexplore.ieee.org/document/10466766/",
        "Abstract": "In today’s digital age, Convolutional Neural Networks (CNNs), a subset of Deep Learning (DL), are widely used for various computer vision tasks such as image classification, object detection, and image segmentation. There are numerous types of CNNs designed to meet specific needs and requirements, including 1D, 2D, and 3D CNNs, as well as dilated, grouped, attention, depthwise convolutions, and NAS, among others. Each type of CNN has its unique structure and characteristics, making it suitable for specific tasks. It’s crucial to gain a thorough understanding and perform a comparative analysis of these different CNN types to understand their strengths and weaknesses. Furthermore, studying the performance, limitations, and practical applications of each type of CNN can aid in the development of new and improved architectures in the future. We also dive into the platforms and frameworks that researchers utilize for their research or development from various perspectives. Additionally, we explore the main research fields of CNN like 6D vision, generative models, and meta-learning. This survey paper provides a comprehensive examination and comparison of various CNN architectures, highlighting their architectural differences and emphasizing their respective advantages, disadvantages, applications, challenges, and future trends.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3376441",
            "Date of Publication": "18 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abolfazl Younesi",
                "labs": [
                    "Department of Computer Science and Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Mohsen Ansari",
                "labs": [
                    "Department of Computer Science and Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Mohammadamin Fazli",
                "labs": [
                    "Department of Computer Science and Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Alireza Ejlali",
                "labs": [
                    "Department of Computer Science and Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Muhammad Shafique",
                "labs": [
                    "eBrainLab, Division of Engineering, New York University (NYU) Abu Dhabi, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Jörg Henkel",
                "labs": [
                    "Department of Computer Science, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Convolutional neural networks",
                "Machine learning",
                "Computer vision",
                "Generative adversarial networks",
                "Classification algorithms",
                "Object detection",
                "Image segmentation",
                "Task analysis",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Deep learning",
                "DNN",
                "CNN",
                "machine learning",
                "vision transformers",
                "GAN",
                "attention",
                "computer vision",
                "LLM",
                "large language model",
                "transformer",
                "dilated convolution",
                "depthwise,NAS,NAT",
                "object detection",
                "6D vision",
                "vision language model"
            ]
        }
    },
    {
        "Title": "Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10504711/",
        "Abstract": "Sentiment analysis is essential for comprehending public opinion, particularly when considering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis as a document or sentence-level classification problem, lacking the ability to capture nuanced opinions about specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis (ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review. ABSA is relatively a recent field of sentiment analysis and the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set of datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models such as ATAE-LSTM, flan-t5-large-absa, DeBERTa, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced strengths and weaknesses of these models across different domains, with DeBERTa emerging as consistently high-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis (ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were used in the experiments including the restaurant, hotel, books, clothing, and laptop reviews. Notably, the analysis underscores the models’ domain sensitivity, shedding light on their varying efficacy for both ATSA and ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight potential areas for improvement in ABSA research and development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3386969",
            "Date of Publication": "17 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nimra Mughal",
                "labs": [
                    "Department of Computer Science, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Sukkur IBA University, Sukkur, Sindh, Pakistan"
                ]
            },
            {
                "name": "Ghulam Mujtaba",
                "labs": [
                    "Department of Computer Science, Center of Excellence for Robotics, Artificial Intelligence, and Block Chain, Sukkur IBA University, Sukkur, Sindh, Pakistan"
                ]
            },
            {
                "name": "Sarang Shaikh",
                "labs": [
                    "Department of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Gjøvik, Trondheim, Norway"
                ]
            },
            {
                "name": "Aveenash Kumar",
                "labs": [
                    "Learners.ai, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Sher Muhammad Daudpota",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Sindh, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Task analysis",
                "Reviews",
                "Computational modeling",
                "Transformers",
                "Biological system modeling",
                "Large language models"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis (ABSA)",
                "large language model (LLM)",
                "GPT",
                "PaLM",
                "BERT"
            ]
        }
    },
    {
        "Title": "ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas",
        "Link": "https://ieeexplore.ieee.org/document/10494570/",
        "Abstract": "Before interacting with real users, developers must be proficient in human–computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.",
        "Details": {
            "DOI": "10.1109/TLT.2024.3386095",
            "Date of Publication": "08 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Learning Technologies"
        },
        "issn_info": {
            "Electronic ISSN": "1939-1382"
        },
        "authors_data": [
            {
                "name": "Jose Barambones",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain"
                ]
            },
            {
                "name": "Cristian Moral",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain"
                ]
            },
            {
                "name": "Angélica de Antonio",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain"
                ]
            },
            {
                "name": "Ricardo Imbert",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain"
                ]
            },
            {
                "name": "Loïc Martínez-Normand",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain"
                ]
            },
            {
                "name": "Elena Villalba-Mora",
                "labs": [
                    "Madrid HCI Laboratory, Department of Computer Languages and Systems and Software Engineering, Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Madrid, Spain",
                    "CIBER de Bioingeniería, Biomateriales y Nanomedicina, Instituto de Salud Carlos III, Avda. Monforte de Lemos, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Interviews",
                "Training",
                "Chatbots",
                "Surveys",
                "Ethics",
                "Task analysis",
                "Recruitment"
            ],
            "Author Keywords": [
                "Chatbots",
                "computer science education",
                "human–computer interaction (HCI)",
                "large language model (LLM)",
                "training",
                "user-centered design"
            ]
        }
    },
    {
        "Title": "AI-Integrated Traffic Information System: A Synergistic Approach of Physics Informed Neural Network and GPT-4 for Traffic Estimation and Real-Time Assistance",
        "Link": "https://ieeexplore.ieee.org/document/10526250/",
        "Abstract": "Traffic management systems have primarily relied on live traffic sensors for real-time traffic guidance. However, this dependence often results in uneven service delivery due to the limited scope of sensor coverage or potential sensor failures. This research introduces a novel approach to overcome this limitation by synergistically integrating a Physics-Informed Neural Network-based Traffic State Estimator (PINN-TSE) with a powerful Natural Language Processing model, GPT-4. The purpose of this integration is to provide a seamless and personalized user experience, while ensuring accurate traffic density prediction even in areas with limited data availability. The innovative PINN-TSE model was developed and tested, demonstrating a promising level of precision with a Mean Absolute Error of less than four vehicles per mile in traffic density estimation. This performance underlines the model’s ability to provide dependable traffic information, even in regions where conventional traffic sensors may be sparsely distributed or data communication is likely to be interrupted. Furthermore, the incorporation of GPT-4 enhances user interactions by understanding and responding to inquiries in a manner akin to human conversation. This not only provides precise traffic updates but also interprets user intentions for a tailored experience. The results of this research showcase an AI-integrated traffic guidance system that outperforms traditional methods in terms of traffic estimation, personalization, and reliability. While the study primarily focuses on a single road segment, the methodology shows promising potential for expansion to network-level traffic guidance, offering even greater accuracy and usability. This paves the way for a smarter and more efficient approach to traffic management in the future.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3399094",
            "Date of Publication": "08 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tewodros Syum Gebre",
                "labs": [
                    "Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Leila Beni",
                "labs": [
                    "Geomatics Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Eden Tsehaye Wasehun",
                "labs": [
                    "Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Freda Elikem Dorbu",
                "labs": [
                    "Department of Computational Data Science and Engineering, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Biological neural networks",
                "Real-time systems",
                "Mathematical models",
                "Predictive models",
                "Information systems",
                "Sensor systems",
                "Traffic control",
                "Traffic congestion",
                "Intelligent transportation systems",
                "Mathematical models",
                "Information systems",
                "Artificial intelligence",
                "Natural language processing"
            ],
            "Author Keywords": [
                "AI-integrated traffic information system",
                "physics informed neural network (PINN)",
                "traffic state estimation (TSE)",
                "traffic data processing",
                "GPT-4",
                "prompt engineering",
                "natural language processing (NLP)",
                "large language models (LLM)",
                "foundation models"
            ]
        }
    },
    {
        "Title": "AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization",
        "Link": "https://ieeexplore.ieee.org/document/10804767/",
        "Abstract": "Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model’s strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3519423",
            "Date of Publication": "17 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nuruzzaman Faruqui",
                "labs": [
                    "Department of Software Engineering, Daffodil International University, Daffodil Smart City, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Priyabrata Thatoi",
                "labs": [
                    "Amazon, Chicago, IL, USA"
                ]
            },
            {
                "name": "Rohit Choudhary",
                "labs": [
                    "Amazon, Dallas, TX, USA"
                ]
            },
            {
                "name": "Ivana Roncevic",
                "labs": [
                    "Department of Linguistics and Translation, Applied Linguistics Research Laboratory, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Hamed Alqahtani",
                "labs": [
                    "Informatics and Computer Systems Department, Center of Artificial Intelligence, College of Computer Science, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Iqbal H. Sarker",
                "labs": [
                    "Centre for Securing Digital Futures, School of Science, Edith Cowan University, Perth, WA, Australia"
                ]
            },
            {
                "name": "Shapla Khanam",
                "labs": [
                    "Faculty of Computing and Digital Technology, HELP University, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Mathematical models",
                "Transformers",
                "Costs",
                "Vectors",
                "Business",
                "Unified modeling language",
                "Training",
                "Optimization",
                "Testing",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Transformer model",
                "large language model",
                "system development lifecycle",
                "transfer learning",
                "artificial intelligence",
                "business cost optimization",
                "project management automation",
                "system analyst",
                "LLM",
                "SDLC",
                "AI",
                "PMP"
            ]
        }
    },
    {
        "Title": "Political Bias in Large Language Models: A Comparative Analysis of ChatGPT-4, Perplexity, Google Gemini, and Claude",
        "Link": "https://ieeexplore.ieee.org/document/10817610/",
        "Abstract": "Artificial Intelligence large language models have rapidly gained widespread adoption, sparking discussions on their societal and political impact, especially for political bias and its far-reaching consequences on society and citizens. This study explores the political bias in large language models by conducting a comparative analysis across four popular AI models—ChatGPT-4, Perplexity, Google Gemini, and Claude. This research systematically evaluates their responses to politically charged prompts and questions from the Pew Research Center’s Political Typology Quiz, Political Compass Quiz, and ISideWith Quiz. The findings revealed that ChatGPT-4 and Claude exhibit a liberal bias, Perplexity is more conservative, while Google Gemini adopts more centrist stances based on their training data sets. The presence of such biases underscores the critical need for transparency in AI development and the incorporation of diverse training datasets, regular audits, and user education to mitigate any of these biases. The most significant question surrounding political bias in AI is its consequences, particularly its influence on public discourse, policy-making, and democratic processes. The results of this study advocate for ethical implications for the development of AI models and the need for transparency to build trust and integrity in AI models. Additionally, future research directions have been outlined to explore and address the complex AI bias issue.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3523764",
            "Date of Publication": "27 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tavishi Choudhary",
                "labs": [
                    "Greenwich High, Greenwich, CT, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Biological system modeling",
                "Training",
                "Data models",
                "Internet",
                "Generative AI",
                "Ethics",
                "Adaptation models",
                "Training data",
                "Decision making"
            ],
            "Author Keywords": [
                "Large language models (LLM)",
                "generative AI (GenAI)",
                "AI governance and policy",
                "ethical AI systems"
            ]
        }
    },
    {
        "Title": "VATMAN: Integrating Video-Audio-Text for Multimodal Abstractive SummarizatioN via Crossmodal Multi-Head Attention Fusion",
        "Link": "https://ieeexplore.ieee.org/document/10643448/",
        "Abstract": "The paper introduces VATMAN (Video-Audio-Text Multimodal Abstractive summarizatioN), a novel approach for generating hierarchical multimodal summaries utilizing Trimodal Hierarchical Multi-head Attention. Unlike existing generative pre-trained language models, VATMAN employs a hierarchical attention mechanism that hierarchically attends to visual, audio, and text modalities. However, in the existing literature, there is a lack of cross-modal attention at the block level. In light of this, we propose a block-level cross-modal attention mechanism, termed Blockwise Cross-modal Multi-head Attention (BCMA), to enhance the summarization performance. This attention mechanism enables the model to simultaneously capture context information from visual, audio, and text modalities, providing a more comprehensive understanding of the input data. In terms of performance, our VATMAN model outperforms the state-of-the-art trimodal model based on RNN in the How2 dataset. Specifically, it achieves a Rouge-1 improvement of 7.53% and Rouge-L improvement of 2.19%, demonstrating superior summarization quality. In addition, compared to uni-modal and di-modal baseline transformer models, VATMAN exhibits significant improvements in Rouge-L scores by 11.12% and 3.85%, respectively, highlighting its effectiveness in capturing hierarchical relationships across modalities. Furthermore, we evaluated our generated abstractive summaries using various metrics, including BLEU, METEOR, CIDEr, ContentF1, and BERTScore. Our proposed model consistently outperformed others across most metrics, demonstrating its effective performance in qualitative assessments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3447737",
            "Date of Publication": "22 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Doosan Baek",
                "labs": [
                    "School of Industrial Management Engineering, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jiho Kim",
                "labs": [
                    "School of Industrial Management Engineering, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Hongchul Lee",
                "labs": [
                    "School of Industrial Management Engineering, Korea University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Transformers",
                "Predictive models",
                "Recurrent neural networks",
                "Decoding",
                "Generative AI",
                "Natural language processing",
                "Large language models"
            ],
            "Author Keywords": [
                "Generative AI",
                "natural language generation (NLG)",
                "large language model (LLM)",
                "multimodal abstractive summarization",
                "How2",
                "hierarchical crossmodal multi-head attention"
            ]
        }
    },
    {
        "Title": "Generative AI for Analog Integrated Circuit Design: Methodologies and Applications",
        "Link": "https://ieeexplore.ieee.org/document/10937153/",
        "Abstract": "Electronic Design Automation (EDA) in analog Integrated Circuits (ICs) has been the focus of extensive research; however, unlike its digital counterpart, it has not achieved widespread adoption. In this systematic review, we discuss recent contributions in the last five years, highlighting methods that address data scarcity, topology exploration, process-voltage-temperature (PVT) variations, and layout parasitics. Our goal is to support researchers new to this domain by creating a comprehensive collection of references and practical application guidelines. We provide a methodological review of state-of-the-art machine learning (ML) approaches, including graph neural networks (GNNs), large language models (LLMs), and variational autoencoders (VAEs), which have been successfully applied to analog circuit sizing tasks. To the best of authors’ knowledge, this is the first review to comprehensively explore the application of generative AI models in analog IC circuit design. We conclude that future research could focus on few-shot learning with domain-adaptation training of generative AI methods to simplify the design tasks such as human-tool interaction or guided design space exploration.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3553743",
            "Date of Publication": "24 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Danial Noori Zadeh",
                "labs": [
                    "Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            },
            {
                "name": "Mohamed B. Elamien",
                "labs": [
                    "Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Integrated circuit modeling",
                "Automation",
                "Reviews",
                "Layout",
                "Topology",
                "Computational modeling",
                "Data models",
                "Generative AI",
                "Voltage",
                "Training"
            ],
            "Author Keywords": [
                "Analog integrated circuits (ICs)",
                "electronic design automation (EDA)",
                "layout-aware sizing",
                "machine learning (ML)",
                "large language models (LLM)",
                "graph neural networks (GNN)",
                "variational auto-encoders (VAE)",
                "artificial intelligence (AI)",
                "machine learning (ML)"
            ]
        }
    },
    {
        "Title": "Leveraging LLMs for Financial News Analysis and Macroeconomic Indicator Nowcasting",
        "Link": "https://ieeexplore.ieee.org/document/10738800/",
        "Abstract": "Approximating macroeconomic indicators is challenging due to the complex interaction of various factors, including global and national economic trends, political decisions, and unpredictable events like pandemics and natural disasters. These complexities, combined with the volatility of economies and the limitations of available data, make accurate modeling difficult. Sentiment analysis of economic news offers a novel approach to this challenge by providing instantaneous insights into public mood and market trends, capturing psychological and behavioral aspects that traditional models may miss. This method can enhance understanding of consumer confidence, investment trends, and stock market performance, for instance. In this study, we developed a dictionary and transformer-based sentiment model applied to over two decades of Hungarian economic news. To improve the model’s accuracy, we utilized large language models (LLMs) with active learning to efficiently augment the manually labeled sentiment dataset. We then compared the resulting sentiment-based time series with macroeconomic indicators such as GDP (Gross Domestic Product), PMI (Purchasing Managers’ Index), and unemployment rate. Our results show that integrating LLMs significantly enhances the accuracy of the sentiment models, and the sentiment-based indicators can serve as effective nowcasting tools for the inspected macroeconomic indicators.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3488363",
            "Date of Publication": "30 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lívia Réka Ónozó",
                "labs": [
                    "Digitalization Technology Department, Central Bank of Hungary, Budapest, Hungary",
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            },
            {
                "name": "Frigyes Viktor Arthur",
                "labs": [
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            },
            {
                "name": "Bálint Gyires-Tóth",
                "labs": [
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Macroeconomics",
                "Economics",
                "Transformers",
                "Analytical models",
                "Data models",
                "Sentiment analysis",
                "Predictive models",
                "Market research",
                "Encoding"
            ],
            "Author Keywords": [
                "GDP",
                "large language model (LLM)",
                "macroeconomic indicator",
                "natural language processing (NLP)",
                "PMI",
                "sentiment analysis",
                "unemployment rate"
            ]
        }
    },
    {
        "Title": "Large Language Models in Human-Robot Collaboration With Cognitive Validation Against Context-Induced Hallucinations",
        "Link": "https://ieeexplore.ieee.org/document/10980279/",
        "Abstract": "The recent leap in Large Language Models (LLMs) has paved the way for several research ideas. LLMs are employed not only for personal use but also in professional contexts to enhance human productivity at work. A significant area of research is human-robot collaboration (HRC), which focuses on developing methodologies for effective interaction between humans and AI-enabled machines. In this regard, exploitation of LLMs appears to be a practical approach. However, these models are susceptible to several limitations, including context-induced errors, the propagation of misleading information, and hallucinations. Such deficiencies impede the seamless application of LLMs in scenarios where a high degree of accuracy is essential. To address this issue, this study introduces a dual-agent system designed to validate the responses generated by LLMs. This novel system is integrated into a framework called “CogniVera”, which facilitates collaborative tasks involving a collaborative robot (cobot) through vocal interactions. This initiative represents a significant advancement in HRC, enabling robots to communicate vocally with human operators during assembly tasks. To evaluate the feasibility of this approach, a focused case study will be conducted, concentrating on the human-robot collaborative task of box assembly utilizing vocal communication. The outcomes of this study are anticipated to yield valuable insights into the efficacy of the proposed dual-agent system in enhancing the reliability and performance of LLMs in practical applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565918",
            "Date of Publication": "30 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nadun Ranasinghe",
                "labs": [
                    "FAST-Laboratory, Faculty of Engineering and Natural Sciences, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Wael M. Mohammed",
                "labs": [
                    "FAST-Laboratory, Faculty of Engineering and Natural Sciences, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Kostas Stefanidis",
                "labs": [
                    "Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Jose L. Martinez Lastra",
                "labs": [
                    "FAST-Laboratory, Faculty of Engineering and Natural Sciences, Tampere University, Tampere, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Collaborative robots",
                "Robots",
                "Human-robot interaction",
                "Natural languages",
                "Assembly",
                "Service robots",
                "Reliability",
                "Large language models",
                "Planning",
                "Fifth Industrial Revolution"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "human-robot interaction (HRI)",
                "large language models (LLM)",
                "conversational artificial intelligence",
                "human-robot collaboration (HRC)"
            ]
        }
    },
    {
        "Title": "Evaluation of Generative AI Models in Python Code Generation: A Comparative Study",
        "Link": "https://ieeexplore.ieee.org/document/10963975/",
        "Abstract": "This study evaluates leading generative AI models for Python code generation. Evaluation criteria include syntax accuracy, response time, completeness, reliability, and cost. The models tested comprise OpenAI’s GPT series (GPT-4 Turbo, GPT-4o, GPT-4o Mini, GPT-3.5 Turbo), Google’s Gemini (1.0 Pro, 1.5 Flash, 1.5 Pro), Meta’s LLaMA (3.0 8B, 3.1 8B), and Anthropic’s Claude models (3.5 Sonnet, 3 Opus, 3 Sonnet, 3 Haiku). Ten coding tasks of varying complexity were tested across three iterations per model to measure performance and consistency. Claude models, especially Claude 3.5 Sonnet, achieved the highest accuracy and reliability. They outperformed all other models in both simple and complex tasks. Gemini models showed limitations in handling complex code. Cost-effective options like Claude 3 Haiku and Gemini 1.5 Flash were budget-friendly and maintained good accuracy on simpler problems. Unlike earlier single-metric studies, this work introduces a multi-dimensional evaluation framework that considers accuracy, reliability, cost, and exception handling. Future work will explore other programming languages and include metrics such as code optimization and security robustness.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3560244",
            "Date of Publication": "11 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dominik Palla",
                "labs": [
                    "Faculty of Informatics and Management, University of Hradec Kralove, Hradec Kralove, Czech Republic"
                ]
            },
            {
                "name": "Antonin Slaby",
                "labs": [
                    "Faculty of Informatics and Management, University of Hradec Kralove, Hradec Kralove, Czech Republic"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Generative AI",
                "Costs",
                "Encoding",
                "Accuracy",
                "Python",
                "Artificial intelligence",
                "Internet",
                "Software development management",
                "Reliability"
            ],
            "Author Keywords": [
                "Automatization",
                "generative AI",
                "LLM",
                "python",
                "software development"
            ]
        }
    },
    {
        "Title": "ACRF: Aggregated Conditional Random Field for Out of Vocab (OOV) Token Representation for Hindi NER",
        "Link": "https://ieeexplore.ieee.org/document/10422739/",
        "Abstract": "Named entities are random, like emerging entities and complex entities. Most of the large language model’s tokenizers have fixed vocab; hence, they tokenize out-of-vocab (OOV) words into multiple sub-words during tokenization. During fine-tuning for any downstream task, these sub-words (tokens) make the named entity classification more complex since, for each sub-word, an extra entity type is assigned for utilizing the word embedding of the sub-word. This work attempts to reduce this complexity by aggregating token embeddings of each word. In this work, we have applied Aggregated-CRF (ACRF), where a conditional random field (CRF) is applied at the top of aggregated token embeddings for named entity prediction. Aggregation is done at embeddings of all tokens generated by a tokenizer corresponding to a word. The experiment was done with two Hindi datasets (HiNER and Hindi Multiconer2). This work showed that the ACRF is better than vanilla CRF (where token embeddings are not aggregated). Also, our result outperformed the existing best result at HiNER data, which was done by applying a cross-entropy classification layer. Further, An analysis of the impact of tokenization has been conducted, both generally and according to entity types for each word present in test data, and the results show that ACRF performed better for the words which tokenized in more than one sub-words (OOV) compared to vanilla CRF. In addition, this work conducts a comparative analysis between two transformer-based models, MuRIL-large and XLM-roberta-large and investigates how these models adopt aggregation strategy based on OOV.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3362645",
            "Date of Publication": "05 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sumit Singh",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, India"
                ]
            },
            {
                "name": "Uma Shanker Tiwary",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Transformers",
                "Conditional random fields",
                "Hidden Markov models",
                "Training",
                "Feature extraction",
                "Data models",
                "Natural language processing"
            ],
            "Author Keywords": [
                "CRF",
                "LLM",
                "NER",
                "NLP",
                "transformer"
            ]
        }
    },
    {
        "Title": "A Theoretical and Empirical Analysis of 2D and 3D Virtual Environments in Training for Child Interview Skills",
        "Link": "https://ieeexplore.ieee.org/document/10634162/",
        "Abstract": "This paper presents a detailed study of an AI-driven platform designed for the training of child welfare and law enforcement professionals in conducting investigative interviews with maltreated children. It achieves a subjective simulation of interview situation through the integration of fine-tuned GPT-3 models within the Unity framework. The study recruited participants from a range of backgrounds, including professionals experienced in conducting investigative interviews and individuals with academic qualifications in psychology, criminology, or related disciplines. To assess the effectiveness of this tool, a multi-method evaluation approach was utilized, incorporating both quantitative analyses and qualitative interviews. The quantitative methods included mixed-effects models, which provided insights into how effects such as the type of virtual environment (2D vs. 3D), scenario variations, virtual reality (VR) familiarity, and professional expertise influence the user experience. Additionally, structural equation modeling (SEM) provided deeper insights into the relationships between variables, offering a comprehensive understanding of how they collectively impact the user experience. The qualitative method included a detailed semi-structured interview that provided a deeper understanding of user experiences and perceptions. The findings indicate significant advantages of the 3D environment in enhancing Flow and Virtual Fidelity; however, the 2D environment was favored for Usability. Despite the 3D environment’s potential for greater immersion, the discomfort associated with VR head-mounted displays (HMDs) led some users to prefer the 2D setup. Familiarity with VR technology positively influenced user perception, indicating that prior exposure can mitigate some of the Avatar Interaction Comfort issues. Additionally, the Hand Movement Perception was better understood in scenarios with sensitive themes. As user experience increased, participants had a more positive view of the Age-Appropriate Response. Furthermore, the dialog system’s effectiveness, particularly Response Relevance and Detailed Responses, played a significant role in Empathy Elicitation, often outweighing Virtual Fidelity. However, Emotion in facial expressions and Responsiveness were two factors that negatively impacted the effectiveness of the tool, indicating areas that need improvement in the future.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3442297",
            "Date of Publication": "12 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pegah Salehi",
                "labs": [
                    "SimulaMet, Oslo, Norway",
                    "Department of Computer Science, UiT The Arctic University of Norway, Tromsø, Norway"
                ]
            },
            {
                "name": "Syed Zohaib Hassan",
                "labs": [
                    "SimulaMet, Oslo, Norway",
                    "Department of Computer Science, Faculty of Technology, Art, and Design, Oslo Metropolitan University (OsloMet), Oslo, Norway"
                ]
            },
            {
                "name": "Gunn Astrid Baugerud",
                "labs": [
                    "Department of Computer Science, Faculty of Technology, Art, and Design, Oslo Metropolitan University (OsloMet), Oslo, Norway"
                ]
            },
            {
                "name": "Martine Powell",
                "labs": [
                    "School of Criminology and Criminal Justice, Faculty of Arts Education and Law, Griffith University, Mount Gravatt, QLD, Australia"
                ]
            },
            {
                "name": "Miriam S. Johnson",
                "labs": [
                    "Department of Computer Science, Faculty of Technology, Art, and Design, Oslo Metropolitan University (OsloMet), Oslo, Norway"
                ]
            },
            {
                "name": "Dag Johansen",
                "labs": [
                    "Department of Computer Science, UiT The Arctic University of Norway, Tromsø, Norway"
                ]
            },
            {
                "name": "Saeed Shafiee Sabet",
                "labs": [
                    "SimulaMet, Oslo, Norway"
                ]
            },
            {
                "name": "Michael A. Riegler",
                "labs": [
                    "SimulaMet, Oslo, Norway",
                    "Department of Computer Science, Faculty of Technology, Art, and Design, Oslo Metropolitan University (OsloMet), Oslo, Norway"
                ]
            },
            {
                "name": "Pål Halvorsen",
                "labs": [
                    "SimulaMet, Oslo, Norway",
                    "Department of Computer Science, Faculty of Technology, Art, and Design, Oslo Metropolitan University (OsloMet), Oslo, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Avatars",
                "Three-dimensional displays",
                "Virtual environments",
                "User experience",
                "Pediatrics",
                "Large language models",
                "Quality of experience",
                "Usability",
                "Virtual environments",
                "Virtual reality"
            ],
            "Author Keywords": [
                "Immersion",
                "large language model (LLM)",
                "quality of experience (QoE)",
                "usability",
                "virtual environments (VEs)",
                "virtual reality (VR)"
            ]
        }
    },
    {
        "Title": "EconoFormer: A Novel Macroeconomic Policy Analysis and Implementation Planner Using Generative Transformer Model",
        "Link": "https://ieeexplore.ieee.org/document/10781335/",
        "Abstract": "Macroeconomic policy analysis and implementation planning are critical for economic growth, increasing employment rates, and ensuring price stability. It has become challenging to keep pace with today’s fast-evolving, technology-driven economy, as policy analysis is a time-consuming process. This paper proposes a Generative Transformer (GT)-based macroeconomic policy analysis and implementation planner model, EconoFormer, designed with 1 billion parameters and trained on 5358 pages of documents related to macroeconomic policies. It achieved a perplexity score of 12.3, which indicates high prediction confidence. The innovative prompt filtering mechanism incorporated with it blocks irrelevant prompts with 98.22% accuracy. The EconoFormer model is scalable and maintains a linear relationship with the processing time and the number of policy analyses while maintaining a stable accuracy, precision, recall, and F1-score. Moreover, the performance remains stable for wide ranges of macroeconomic policies from different sectors. Most importantly, the policy impact rating similarity test shows that it is as good as macroeconomics policy experts in policy analysis. The EconoFormer has the capability to process real-time data in prompts, establish non-linear relations among 44 different economic indicators, and develop effective and plans for policy implementation. The unique concept, robust capability, and outstanding performance make the EconoFormer a potential framework for rapid macroeconomic policy analysis and implementation plan development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3512594",
            "Date of Publication": "09 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Terry Zhao",
                "labs": [
                    "West Point Grey Academy, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "Nuruzzaman Faruqui",
                "labs": [
                    "Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Macroeconomics",
                "Economics",
                "Artificial intelligence",
                "Analytical models",
                "Data models",
                "Real-time systems",
                "Predictive models",
                "Transformers",
                "Stability analysis",
                "Robustness"
            ],
            "Author Keywords": [
                "Transformer model",
                "generative AI",
                "macroeconomic policy",
                "LLM",
                "economic indicators"
            ]
        }
    },
    {
        "Title": "ICCA-RAG: Intelligent Customs Clearance Assistant Using Retrieval-Augmented Generation (RAG)",
        "Link": "https://ieeexplore.ieee.org/document/10897992/",
        "Abstract": "Document processing and query generation tasks in customs declaration scenarios face key challenges such as the complexity of multimodal data, adaptability to dynamic regulations, and ambiguity in query semantics. This study proposes a Retrieval-Augmented Generation system (ICCA-RAG) that addresses the core issues of processing complex customs documents and dynamically generating queries through multimodal document parsing, sparse-dense hybrid storage, and context-driven large language model generation. In terms of multimodal document parsing, the system supports comprehensive parsing of PDFs, images, tables, and text, which are uniformly transformed into semantic vectors and keyword indices for hybrid storage. By combining the retrieval and generation modules, the ICCA-RAG system achieves significant improvements in contextual relevance and generation accuracy. Compared to traditional methods, the ICCA-RAG system demonstrates a 20.1% increase in answer correctness, a 15.3% increase in answer relevancy, and an 18.7% increase in the faithfulness of generated content, with outstanding performance in noisy query scenarios. The research findings validate the ICCA-RAG system’s advancement and applicability in handling complex document processing and professional domain question-answering tasks, while also providing a transferable technical framework for other fields, such as law and healthcare.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3544408",
            "Date of Publication": "21 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rong Hu",
                "labs": [
                    "Customs and Public Management College, Shanghai Customs University, Shanghai, China"
                ]
            },
            {
                "name": "Sen Liu",
                "labs": [
                    "Department of Electronic Information, Shanghai Dianji University, Shanghai, China"
                ]
            },
            {
                "name": "Panpan Qi",
                "labs": [
                    "Information Department, Xinglin College, Nantong University, Nantong, China"
                ]
            },
            {
                "name": "Jingyi Liu",
                "labs": [
                    "School of Information Engineering, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Fengyuan Li",
                "labs": [
                    "Xi’an Jiaotong University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Inspection",
                "Tariffs",
                "Complexity theory",
                "Large language models",
                "Codes",
                "Accuracy",
                "Companies",
                "Vectors",
                "Retrieval augmented generation"
            ],
            "Author Keywords": [
                "Customs declaration assistance",
                "dynamic regulation adaptation",
                "intelligent question-answering system",
                "large language model (LLM)",
                "multimodal document parsing",
                "retrieval-augmented generation (RAG)",
                "semantic retrieval"
            ]
        }
    },
    {
        "Title": "A Novel Approach to Password Strength Evaluation Using ChatGPT-Based Prompt Metrics",
        "Link": "https://ieeexplore.ieee.org/document/10759630/",
        "Abstract": "This study presents a password strength evaluation method using the GPT-4 model with prompt-based metrics. Unlike traditional algorithmic approaches, this method leverages GPT-4 to provide more flexible and adaptive password evaluations without the need for additional model training. The proposed evaluation metrics focus on Complexity, Memorability, and Personal Information (PI) Inclusion. To validate its effectiveness, comparisons were made with existing algorithmic metrics such as LUDS and zxcvbn, using 2,000 randomly sampled real-world passwords. The results revealed a strong correlation between LUDS and the Complexity score with a Pearson correlation of 0.7281, but a weaker correlation between zxcvbn and Memorability with a Pearson correlation of 0.4717. Additionally, the PI score evaluation demonstrated a significant gap between PI-included and non-PI-included passwords. A further comparison between English and Korean PI-based passwords showed that English PI inclusion yielded lower evaluation scores. These findings indicate that the GPT based prompt evaluation method has the potential to be used as an adaptable tool for assessing password security strength.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3503653",
            "Date of Publication": "20 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seok Jun Kim",
                "labs": [
                    "Department of IT Convergence, Gachon University, Seongnam-si, South Korea"
                ]
            },
            {
                "name": "Byung Mun Lee",
                "labs": [
                    "Department of Computer Engineering, Gachon University, Seongnam-si, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Passwords",
                "Measurement",
                "Security",
                "Deep learning",
                "Mathematical models",
                "Dictionaries",
                "Data models",
                "Data collection",
                "Correlation",
                "Chatbots"
            ],
            "Author Keywords": [
                "ChatGPT",
                "information security",
                "large language model (LLM)",
                "prompt evaluation",
                "password strength"
            ]
        }
    },
    {
        "Title": "Syntactic-Aware Text Classification Method Embedding the Weight Vectors of Feature Words",
        "Link": "https://ieeexplore.ieee.org/document/10904211/",
        "Abstract": "Text classification is the process of categorizing sentences into predefined classes on the basis of their meanings or functions. In this context, feature words play a crucial role in representing the core meaning and key information of sentences, reflecting the main content and deep semantics of scientific literature. Optimizing text classification models using feature words is an important task in the information mining of scientific literature. To address text classification considering feature words, this study constructs a set of feature words from a linguistic perspective and quantitatively expresses the weight differences of various feature words on the basis of syntactic structure features. By embedding the weight information, absolute position, relative position, and contextual information of feature words into pre-trained models, the universal text classification models considering feature word vector weights is established. The analysis of hyperparameter space relationships reveals that the hyperparameter settings are not simple linear relationships and that their interactions are often nonlinear and complex. Employing the Bayesian optimization algorithm facilitates the model in finding the optimal hyperparameters while reducing computational costs. Based on the public dataset RCMR 280K, the experimental results demonstrate that considering feature words enables the model to capture sentence structure and features in text classification task, improving the recognition accuracy of the model. Compared with base models (BERT, SciBERT, RoBERTa and ModernBERT) and their regularized models which consider feature words, the improved ModernBERT, which is based on weighted feature word vectors, achieves an average F1 of 95.8% in the recognition tasks of research objective, method, result and conclusion sentences, an improvement of 1.2%, 0.8%, 1.1%, and 0.9%, respectively. In addition, the results show that large language models (LLMs) exhibit robust performance in text classification tasks, with the fine-tuned GLM4-9B achieving superior performance by reaching an average F1 of 91.9%. This model can be applied to sentence recognition and classification tasks in various domains. By updating or replacing the feature word table, the model can be adapted to recognize and classify different types of sentences, providing a theoretical basis or model foundation for other downstream tasks. More details and model weights are public at https://huggingface.co/wmsr22/Classification/tree/main\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3545877",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Meng Wang",
                "labs": [
                    "National Science Library, Chinese Academy of Science, Beijing, China"
                ]
            },
            {
                "name": "Jisu Kim",
                "labs": [
                    "School of Applied Economics, Renmin University of China, Beijing, China"
                ]
            },
            {
                "name": "Yuting Yan",
                "labs": [
                    "Yunnan College of Finance and Economics, Kunming, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Text categorization",
                "Feature extraction",
                "Vectors",
                "Encoding",
                "Accuracy",
                "Context modeling",
                "Bidirectional control",
                "Computational modeling",
                "Biological system modeling"
            ],
            "Author Keywords": [
                "Text classification",
                "feature word weight",
                "pre-trained model",
                "LLM",
                "position embedding",
                "Bayesian optimization"
            ]
        }
    },
    {
        "Title": "TeleOracle: Fine-Tuned Retrieval-Augmented Generation With Long-Context Support for Networks",
        "Link": "https://ieeexplore.ieee.org/document/10935354/",
        "Abstract": "The telecommunications industry’s rapid evolution demands intelligent systems capable of managing complex networks and adapting to emerging technologies. While large language models (LLMs) show promise in addressing these challenges, their deployment in telecom environments faces significant constraints due to edge device limitations and inconsistent documentation. To bridge this gap, we present TeleOracle, a telecom-specialized retrieval-augmented generation (RAG) system built on the Phi-2 small language model (SLM). To improve context retrieval, TeleOracle employs a two-stage retriever that incorporates semantic chunking and hybrid key-word and semantic search. Additionally, we expand the context window during inference to enhance the model’s performance on open-ended queries. We also employ low-rank adaption for efficient fine-tuning. A thorough analysis of the model’s performance indicates that our RAG framework is effective in aligning Phi-2 to the telecom domain in a downstream question and answer (QnA) task, achieving a 30% improvement in accuracy over the base Phi-2 model, reaching an overall accuracy of 81.20%. Notably, we show that our model not only performs on par with the much larger LLMs but also achieves a higher faithfulness score, indicating higher adherence to the retrieved context.",
        "Details": {
            "DOI": "10.1109/JIOT.2025.3553161",
            "Date of Publication": "20 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Internet of Things Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2327-4662"
        },
        "authors_data": [
            {
                "name": "Nouf Alabbasi",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Omar Erak",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Omar Alhussein",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Ismail Lotfi",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Sami Muhaidat",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE",
                    "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Mérouane Debbah",
                "labs": [
                    "Department of Computer Science, KU 6G Research Center, Khalifa University, Abu Dhabi, UAE"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Telecommunications",
                "Retrieval augmented generation",
                "Context modeling",
                "Adaptation models",
                "Semantics",
                "3GPP",
                "Computational modeling",
                "Benchmark testing",
                "Automation",
                "Accuracy"
            ],
            "Author Keywords": [
                "6G networks",
                "AGI",
                "large language model (LLM)",
                "low-rank Adaptation (LoRA)",
                "retrieval-augmented generation (RAG)"
            ]
        }
    },
    {
        "Title": "Evaluating Large Language Models for Optimized Intent Translation and Contradiction Detection Using KNN in IBN",
        "Link": "https://ieeexplore.ieee.org/document/10855447/",
        "Abstract": "Intent-Based Networking (IBN) simplifies network management by enabling users to express high-level intents in natural language, but existing approaches often fail to ensure alignment with network policies, leading to misconfigurations. Moreover, many methods lack robust validation mechanisms, reducing their reliability in dynamic environments. This research addresses these gaps by evaluating advanced Large Language Models (LLMs) such as BERT-base uncased (BERT-bu), GPT2, LLaMA3, Claude2 and small deep learning model BiLSTM with attention for translating intents and detecting contradictions. Using a curated dataset of 10,000 intent pairs, the proposed hybrid framework integrates a K-Nearest Neighbors (KNN) classifier to validate translations and recalibrate erroneous outputs. Experimental results demonstrate up to 5% higher accuracy (88%) and F1 scores compared to existing methods, ensuring precise intent translation and reliable network orchestration. This approach significantly enhances scalability and policy compliance in automated network environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3534880",
            "Date of Publication": "27 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Asif",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            },
            {
                "name": "Talha Ahmed Khan",
                "labs": [
                    "Institute for Communication Systems, University of Surrey, Guildford, U.K."
                ]
            },
            {
                "name": "Wang-Cheol Song",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Translation",
                "Accuracy",
                "Nearest neighbor methods",
                "Reliability",
                "Bidirectional long short term memory",
                "Scalability",
                "Resource description framework",
                "Transformers",
                "Terminology",
                "Standardization"
            ],
            "Author Keywords": [
                "Intent-based networking",
                "K-Nearest Neighbors",
                "NLP",
                "LLM",
                "GPT",
                "LLaMa",
                "BERT"
            ]
        }
    },
    {
        "Title": "End-to-End Deployment of the Educational AI Hub for Personalized Learning and Engagement: A Case Study on Environmental Science Education",
        "Link": "https://ieeexplore.ieee.org/document/10938135/",
        "Abstract": "This study introduces an end-to-end framework for deploying conversational AI-enabled educational assistants, focusing on personalized support for students across diverse subject areas, including Business, Culture, Environmental Sciences, History, Politics, and Science, as outlined in our evaluation framework. The system leverages advanced conversational AI technologies to provide targeted, course-specific learning experiences by facilitating access to complex data and integrating seamlessly with Learning Management Systems (LMS) like Canvas. Key metrics—information retrieval accuracy, question-answering accuracy, and hallucination accuracy—were selected to rigorously evaluate the system’s ability to retrieve relevant contexts, generate accurate responses, and identify unanswerable questions. Additionally, the Educational AI Hub agents utilize innovative document parsing methods, such as the Nougat technique, to interpret content accurately, enabling adaptable academic support tailored to individual learning needs and extending to quantitative fields through code execution capabilities. This study also emphasizes the importance of accessibility, inclusivity, and user privacy. The results showcase the potential for enhanced engagement and improved understanding of environmental concepts and software tools, demonstrating the significant impact of conversational AI in educational settings, especially in disciplines involving complex data interactions. A case study, presented at the 12th International Congress on Environmental Modelling and Software, illustrates the Educational AI Hub’s effectiveness in enhancing student engagement and delivering personalized learning experiences in environmental sciences education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554222",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ramteja Sajja",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Iowa, Iowa City, IA, USA",
                    "IIHR—Hydroscience and Engineering, University of Iowa, Iowa City, IA, USA"
                ]
            },
            {
                "name": "Yusuf Sermet",
                "labs": [
                    "IIHR—Hydroscience and Engineering, University of Iowa, Iowa City, IA, USA"
                ]
            },
            {
                "name": "Ibrahim Demir",
                "labs": [
                    "Department of River-Coastal Science and Engineering, Tulane University, New Orleans, LA, USA",
                    "ByWater Institute, Tulane University, New Orleans, LA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Artificial intelligence",
                "Adaptive learning",
                "Virtual assistants",
                "Accuracy",
                "Electronic learning",
                "Water quality",
                "Learning management systems",
                "Large language models",
                "Decision making"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "document parsing techniques",
                "generative pre-training transformer (GPT)",
                "large language models (LLM)",
                "natural language processing (NLP)",
                "personalized learning"
            ]
        }
    },
    {
        "Title": "Leveraging Large Language Model for Enhanced Text-to-SQL Parsing",
        "Link": "https://ieeexplore.ieee.org/document/10878990/",
        "Abstract": "Text-to-SQL conversion, the process of generating SQL queries from natural language input, has gained significant attention due to its potential to simplify database interaction. Although benchmarks in this task have driven advancements in the field, the challenges posed by complex join logic and the rich diversity of natural language expressions remain significant obstacles. These complexities underscore the ongoing difficulty of accurately bridging the gap between natural language and structured query representations, particularly in cross-domain and real-world scenarios. Recent research, including intermediate representations, relation-aware transformers, and large language models such as T5 and LLaMA, has improved performance by addressing the semantic gap between natural language and SQL. In this work, we propose SLENet, a novel approach that uses state-of-the-art large language models (LLMs) to enhance semantic understanding and SQL generation. Our method integrates three core innovations: (1) the use of advanced LLMs for context-aware representations, (2) syntax-constrained SQL decoder to ensure grammatical correctness, and (3) search-based prompt optimization utilizing external knowledge sources like WikiSQL. These innovations collectively address schema comprehension and SQL generation complexities. Evaluations on the Spider benchmark demonstrate that SLENet significantly outperforms existing methods, achieving higher exact matching accuracy and effectively handling complex SQL components. Our contributions highlight the importance of combining LLMs with syntax constraints and external data for advancing cross-domain semantic parsing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3540072",
            "Date of Publication": "10 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zecheng Zhan",
                "labs": [
                    "Bytedance Inc, Beijing, China"
                ]
            },
            {
                "name": "E. Haihong",
                "labs": [
                    "School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Meina Song",
                "labs": [
                    "School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Structured Query Language",
                "Decoding",
                "Semantics",
                "Natural languages",
                "Databases",
                "Syntactics",
                "Benchmark testing",
                "Large language models",
                "Technological innovation",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Semantic parsing",
                "SQL generation",
                "deep learning",
                "LLM",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A Proposed Model for Distinguishing Between Human-Based and ChatGPT Content in Scientific Articles",
        "Link": "https://ieeexplore.ieee.org/document/10643547/",
        "Abstract": "This study introduces an innovative approach to address the growing challenge of detecting and distinguishing ChatGPT-generated content within scientific articles, particularly in the context of Learning Management Systems (LMS). Leveraging state-of-the-art large language models, including Robustly Optimized BERT Pretraining (RoBERTa), Text-to-Text Transfer Transformer (T5), and Generative Pre-trained Transformers (EleutherAI GPT-Neo-125M), our methodology focuses on the incorporation of the LMS concept into the research framework. To construct a comprehensive dataset representative of the diverse landscape of scientific abstracts, samples of the dataset are gathered from articles produced by human authors and those generated by ChatGPT within the LMS framework. The models (RoBERTa, T5, and EleutherAI GPT-Neo-125M) were subsequently trained on this unique dataset, showcasing their adaptability to the distinct characteristics of both human-generated and AI-generated content within the LMS context. The efficacy of our approach was rigorously evaluated using a range of metrics, resulting in an outstanding accuracy exceeding 99%. This achievement underscores the robustness of our methodology in successfully discerning content generated by ChatGPT within the LMS and that authored by human contributors, thereby advancing the field of content differentiation in scientific discourse.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3448315",
            "Date of Publication": "22 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Toka A. Mohamed",
                "labs": [
                    "Faculty of Computers and Artificial Intelligence, Fayoum University, Faiyum, Egypt",
                    "Faculty of Computers and Information Technology, National Egyptian E-learning University, Giza, Egypt"
                ]
            },
            {
                "name": "Mohamed H. Khafgy",
                "labs": [
                    "Faculty of Computers and Artificial Intelligence, Fayoum University, Faiyum, Egypt"
                ]
            },
            {
                "name": "Ahmed B. Elsedawy",
                "labs": [
                    "Educational Affairs Information System Department, AASTMT, Cairo, Egypt"
                ]
            },
            {
                "name": "Ahmed S. Ismail",
                "labs": [
                    "Faculty of Computers and Artificial Intelligence, Fayoum University, Faiyum, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Data models",
                "Accuracy",
                "Training",
                "Large language models",
                "Transformers",
                "Artificial intelligence",
                "Content management"
            ],
            "Author Keywords": [
                "GPT-3.5",
                "LLM",
                "ChatGPT",
                "T5",
                "RoBERTa",
                "EleutherAI GPT-Neo-125M",
                "AI content",
                "LMS"
            ]
        }
    },
    {
        "Title": "Distilling Wisdom: A Review on Optimizing Learning From Massive Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10942372/",
        "Abstract": "In the era of Large Language Models (LLMs), Knowledge Distillation (KD) enables the transfer of capabilities from proprietary LLMs to open-source models. This survey provides a detailed discussion of the basic principles, algorithms, and implementation methods of knowledge distillation. It explores KD’s impact on LLMs, emphasizing its utility in model compression, performance enhancement, and self-improvement. Through the analysis of practical examples such as DistilBERT, TinyBERT, and MobileBERT, the paper demonstrates how knowledge distillation can markedly enhance the efficiency and applicability of large language models in real-world scenarios. The discussion encompasses the varied applications of KD across multiple domains, including industrial systems, embedded systems, Natural Language Processing (NLP), multi-modal processing, and vertical domains, such as medicine, law, science, finance, and materials science. This survey outlines current KD methodologies and future research directions, highlighting its role in advancing AI technologies and fostering innovation across different sectors.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554586",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dingzong Zhang",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Devi Listiyani",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Priyanka Singh",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Manoranjan Mohanty",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Carnegie Mellon University in Qatar, Ar-Rayyan, Qatar"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Large language models",
                "Computational modeling",
                "Surveys",
                "Natural language processing",
                "Predictive models",
                "Artificial intelligence",
                "Technological innovation",
                "Encoding",
                "Context modeling"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "large language model (LLM)",
                "knowledge distillation (KD)",
                "optimization"
            ]
        }
    },
    {
        "Title": "Future of Connectivity: A Comprehensive Review of Innovations and Challenges in 7G Smart Networks",
        "Link": "https://ieeexplore.ieee.org/document/10963909/",
        "Abstract": "The evolution from 1G to 6G networks has transformed global communication, progressing from basic voice calls in 1G to the immersive, AI-enabled experiences of 6G. As emerging AI-driven applications like autonomous systems, the Internet of Everything (IoE), and immersive technologies demand unprecedented capabilities, 7G networks are set to redefine connectivity by overcoming the limitations of earlier generations. This paper comprehensively reviews the innovations and challenges in 7G networks, focusing on integrating advanced AI and machine learning paradigms such as meta-learning, incremental learning, distributed intelligence, and reinforcement learning to enhance adaptability, resource allocation, and edge performance. The review also examines the role of Large Language Models (LLMs) in enabling real-time actionable intelligence and optimizing edge devices within 7G. The paper highlights the use of technologies, including blockchain for decentralized security, quantum computing for robust encryption, terahertz communication for ultra-fast data transfer, zero-energy solutions for sustainability, and generative AI for intelligent network optimization and automation. By addressing these challenges and exploring cutting-edge strategies, this paper envisions 7G networks as the foundation for a secure, intelligent, and sustainable digital future, equipped to combat emerging cyber warfare threats, enhance resilience against technological disruptions, and support innovations across smart cities, autonomous systems, healthcare, and industrial IoT.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2025.3560035",
            "Date of Publication": "11 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Vinay Chamola",
                "labs": [
                    "Department of Electrical and Electronics Engineering, BITS Pilani, Pilani, India"
                ]
            },
            {
                "name": "Mritunjay Shall Peelam",
                "labs": [
                    "Department of Electrical and Electronics Engineering, BITS Pilani, Pilani, India"
                ]
            },
            {
                "name": "Mohsen Guizani",
                "labs": [
                    "Machine Learning Department, Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Dusit Niyato",
                "labs": [
                    "College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "6G mobile communication",
                "Artificial intelligence",
                "Terahertz communications",
                "5G mobile communication",
                "Real-time systems",
                "Technological innovation",
                "Quantum computing",
                "Security",
                "Quantum entanglement",
                "Wireless communication"
            ],
            "Author Keywords": [
                "7G networks",
                "intelligent networking",
                "machine learning",
                "AI",
                "LLM",
                "wireless",
                "terahertz communication",
                "meta-learning",
                "self-sustaining",
                "security",
                "XAI",
                "explainable AI",
                "distributed intelligence",
                "edge performance",
                "real-time actionable intelligence",
                "generative AI"
            ]
        }
    },
    {
        "Title": "Evaluating Coding Proficiency of Large Language Models: An Investigation Through Machine Learning Problems",
        "Link": "https://ieeexplore.ieee.org/document/10937484/",
        "Abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, but their effectiveness in coding workflows, particularly in machine learning (ML), requires deeper evaluation. This paper investigates the coding proficiency of LLMs such as GPT and Gemini by benchmarking their performance on three ML problems: Titanic, MNIST, and Steel Defect. These problems were chosen to encompass a range of challenges, including handling missing data, feature engineering, deep learning architectures, and multi-label classification. Using systematic prompts, we evaluated the LLMs’ abilities in data preprocessing, hyperparameter tuning, and classifier generation, comparing their outputs with those of human developers and AutoML frameworks. Experimental results indicate that the human developer outperformed untuned LLMs in data preprocessing, maintaining a 3–5% accuracy advantage across datasets. However, GPT’s hyperparameter tuning improved model performance by up to 6.3% in Titanic and 3.33% in Steel Defect, surpassing human-tuned models in some cases. In contrast, Gemini exhibited only marginal tuning improvements (0.19–1.78%) and failed to compensate for preprocessing inefficiencies. These findings show that while LLMs can assist with ML coding tasks, they exhibit varying levels of efficiency depending on task complexity and preprocessing requirements. GPT demonstrated superior hyperparameter tuning capabilities, whereas both LLMs struggled with intuitive data preprocessing, particularly in feature selection and transformation. This study provides practical insights into the strengths and limitations of LLMs in ML workflows, offering guidance for their effective integration into real-world applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3553870",
            "Date of Publication": "24 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eunbi Ko",
                "labs": [
                    "Department of Computer Engineering, Dankook University, Yongin, Republic of Korea"
                ]
            },
            {
                "name": "Pilsung Kang",
                "labs": [
                    "Department of Software Science, Dankook University, Yongin, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Codes",
                "Machine learning",
                "Benchmark testing",
                "Tuning",
                "Software development management",
                "Automated machine learning",
                "Steel",
                "Chatbots",
                "Accuracy"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "machine learning",
                "code generation",
                "large language model (LLM)",
                "generative pre-trained transformer (GPT)"
            ]
        }
    },
    {
        "Title": "Educational Technology in the University: A Comprehensive Look at the Role of a Professor and Artificial Intelligence",
        "Link": "https://ieeexplore.ieee.org/document/10643130/",
        "Abstract": "This study aims to delineate the roles of professors at universities and explore the educational applications of Artificial Intelligence (AI). With rapid advancements in AI technology, there is an increasing effort to integrate AI and Educational Technology (EdTech) into educational practices, resulting in AI EdTech. Higher education institutions, particularly universities, are focused on leveraging AI EdTech to augment traditional teaching roles. Traditional educational methods often face limitations in providing personalized learning experiences, whereas AI EdTech offers promising solutions to enhance these methods and provide immersive learning opportunities for students. Currently, various universities independently pursue the implementation of AI EdTech. However, for AI EdTech to be successfully established and widely adopted in higher education, key factors such as maintenance costs and the potential for continuous development should be considered. Therefore, the standardization and development of AI EdTech systems that can be universally applied across universities are essential. In this regard, this study defines the core roles of professors and proposes developmental levels for AI professors to complement these roles. It also outlines the necessary Key Performance Indicators (KPIs) for each level of AI professor development. These initiatives are expected to play a crucial role in the future standardization and research development of AI EdTech systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3447067",
            "Date of Publication": "21 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cheolkyu Shin",
                "labs": [
                    "Research Institute for Data Science and Artificial Intelligence, Hallym University, Chuncheon-si, South Korea"
                ]
            },
            {
                "name": "Dong Gi Seo",
                "labs": [
                    "Research Institute for Data Science and Artificial Intelligence, Hallym University, Chuncheon-si, South Korea"
                ]
            },
            {
                "name": "Seoyeon Jin",
                "labs": [
                    "Research Institute for Data Science and Artificial Intelligence, Hallym University, Chuncheon-si, South Korea"
                ]
            },
            {
                "name": "Soo Hwa Lee",
                "labs": [
                    "Research Institute for Data Science and Artificial Intelligence, Hallym University, Chuncheon-si, South Korea"
                ]
            },
            {
                "name": "Hyun Je Park",
                "labs": [
                    "Research Institute for Data Science and Artificial Intelligence, Hallym University, Chuncheon-si, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Educational technology",
                "Solid modeling",
                "Tutorials",
                "Large language models",
                "Human in the loop",
                "Education"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "educational technology (EdTech)",
                "intelligent tutoring system (ITS)",
                "large language model (LLM)",
                "human-in-the-loop (HITL)",
                "technological pedagogical and content knowledge (TPACK)",
                "key performance indicator (KPI)",
                "universal design for learning (UDL)"
            ]
        }
    },
    {
        "Title": "Next-Gen UAV-Satellite Communications: AI Innovations and Future Prospects",
        "Link": "https://ieeexplore.ieee.org/document/11072807/",
        "Abstract": "The convergence of sixth-generation (6G) networks with unmanned aerial vehicles (UAVs) and satellites is poised to introduce substantial improvements to the landscape of wireless communication, paving the way for a unified and uninterrupted space-air-ground-sea network that ensures comprehensive global connectivity. At the heart of this transformative paradigm lies artificial intelligence (AI), which drives innovation across diverse sectors by enhancing decision-making autonomy, enabling real-time data processing, and optimizing network performance and coverage. This survey paper explores AI-enabled UAV-satellite communications for 6G applications, focusing on its challenges, potential, and future. This new system combines the strengths of 6G networks, UAVs (advanced drones), and satellites. It opens up new possibilities in precision agriculture, disaster management, enhanced telecommunication services, and remote sensing. Despite its promise, this field faces complex challenges. These include spectrum management, security risks, regulatory barriers, and integrating AI operations seamlessly. This paper comprehensively analyzes these challenges, offering innovative solutions and outlining future research directions to unlock the complete capabilities of 6G-enabled UAV-satellite communications. Furthermore, it includes a case study demonstrating the effectiveness of multi-armed bandit (MAB) algorithms in optimizing resource allocation and decision-making processes for UAV-low Earth orbit (LEO) satellite communication scenarios, showcasing significant improvements in network performance. This work lays the foundation for a new generation of ultra-connected, data-driven applications that will redefine global connectivity and technological advancement by addressing these critical aspects.",
        "Details": {
            "DOI": "10.1109/OJVT.2025.3587028",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Vehicular Technology"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1330"
        },
        "authors_data": [
            {
                "name": "Sherief Hashima",
                "labs": [
                    "Computational Learning Theory Team, RIKEN-Advanced Intelligence Project (AIP), Fukuoka, Japan",
                    "Engineering Dept, Nuclear Research Center (NRC), Egyptian Atomic Energy Authority, Cairo, Egypt"
                ]
            },
            {
                "name": "Ahmad Gendia",
                "labs": [
                    "Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan",
                    "Electrical Engineering Department, Faculty of Engineering, Al-Azhar University, Cairo, Egypt"
                ]
            },
            {
                "name": "Kohei Hatano",
                "labs": [
                    "Computational Learning Theory Team, RIKEN-Advanced Intelligence Project (AIP), Fukuoka, Japan",
                    "Department of Informatics, Kyushu University, Fukuoka, Japan"
                ]
            },
            {
                "name": "Osamu Muta",
                "labs": [
                    "Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Japan"
                ]
            },
            {
                "name": "Mostafa S. Nada",
                "labs": [
                    "Egypt Japan University of Science and Technology, Alexandria, Egypt"
                ]
            },
            {
                "name": "Ehab Mahmoud Mohamed",
                "labs": [
                    "Department of Electrical Engineering, College of Engineering in Wadi Addawasir, Prince Sattam Bin Abdulaziz University, Wadi Addawasir, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "6G mobile communication",
                "Autonomous aerial vehicles",
                "Satellites",
                "Artificial intelligence",
                "Satellite communications",
                "Real-time systems",
                "Low latency communication",
                "Low earth orbit satellites",
                "Earth",
                "Technological innovation"
            ],
            "Author Keywords": [
                "Sixth-generation (6G)",
                "artificial intelligence (AI)",
                "unmanned aerial vehicles (UAVs)",
                "satellite communications",
                "multi-armed bandit (MAB)",
                "generative adversarial network (GAN)",
                "large language model (LLM)"
            ]
        }
    },
    {
        "Title": "DeepDiveAI: Identifying AI-Related Documents in Large Scale Literature Dataset",
        "Link": "https://ieeexplore.ieee.org/document/11060647/",
        "Abstract": "In this paper, we propose and implement a systematic pipeline for the automatic classification of AI-related documents extracted from large-scale literature databases. This process results in the creation of an AI-related literature dataset named DeepDiveAI. The dataset construction pipeline integrates expert knowledge with the capabilities of advanced models, structured into two primary stages. In the first stage, expert-curated classification datasets are used to train a Long Short-Term Memory (LSTM) model, which performs coarse-grained classification of AI-related records from large-scale datasets. In the second stage, a large language model, specifically Qwen2.5 Plus, is employed to annotate a random 10% of the initially coarse set of classified AI-related records. These annotated records are subsequently used to train a Bidirectional Encoder Representations from Transformers (BERT) based binary classifier, further refining the coarse set to produce the final DeepDiveAI dataset. Evaluation results indicate that the proposed pipeline achieves both accuracy and efficiency in identifying AI-related literature from large-scale datasets.",
        "Details": {
            "DOI": "10.23919/JSC.2025.0007",
            "Date of Publication": "30 June 2025",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Xingzhou Liang",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China",
                    "School of International and Public Affairs, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Xiaochen Zhou",
                "labs": [
                    "University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Hui Zou",
                "labs": [
                    "School of Cultural Heritage and Information Management, Shanghai University, Shanghai, China"
                ]
            },
            {
                "name": "Yi Lu",
                "labs": [
                    "Department of Informatics, King's College London, London, UK"
                ]
            },
            {
                "name": "Jingjing Qu",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Databases",
                "Large language models",
                "Pipelines",
                "Text categorization",
                "Bidirectional control",
                "Transformers",
                "Market research",
                "Tag clouds",
                "Encoding",
                "Long short term memory"
            ],
            "Author Keywords": [
                "AI-related document",
                "text classification",
                "Long Short-Term Memory (LSTM)",
                "Bidirectional Encoder Representations from Transformers (BERT)",
                "Large Language Model (LLM)"
            ]
        }
    },
    {
        "Title": "Fake News Classification Methodology With Enhanced BERT",
        "Link": "https://ieeexplore.ieee.org/document/10742347/",
        "Abstract": "News serves as a vital source of information for staying updated on various aspects of life worldwide. However, massive volume of information available on social media platforms makes it challenging to extract meaningful insights. Additionally, dispersion of false information has grown broader, often serving specific agendas. In this work, we present a novel fake news classification methodology based on an enhanced BERT deep learning model which is trained on self-developed PolitiTweet datasets along with benchmarked Buzzfeed dataset. The PolitiTweet dataset is augmented to solve class imbalance problem and improve data diversity to capture regional language nuances, cultural references that help in more accurate detection of fake news. For this purpose, We enhance BERTbase model by adding 3 additional layers namely Linear Layer, Dropout Layer, Activation Layer and fine tuned the model to train enhanced BERT classifier. The fine tuned BERT model trained on augmented dataset is capable of capturing patterns and nuances within the data, giving better classification results. Subsequently, the enhanced BERT model is evaluated against BERTbase model for further elaboration on the generalisibility and effective performance of the fine tuned model for real-world cases. The enhanced BERT model achieved an accuracy of 85% on Buzzfeed and 98% on PolitiTweet. In comparison the baseline BERT models achieved an average accuracy of 81% and 88%, respectively. The proposed Enhanced BERT model uses a mix of pre-training strategies with fine-tuning techniques to achieve better performance. The developed research data is available online at: https://www.kaggle.com/datasets/ameerhamza123/pak-tweets.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3491376",
            "Date of Publication": "04 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ammar Oad",
                "labs": [
                    "Faculty of Information Engineering, Shaoyang University, Shaoyang, China"
                ]
            },
            {
                "name": "Muhammad Hamza Farooq",
                "labs": [
                    "National Center of Artificial Intelligence, KICS, University of Engineering and Technology Lahore (UET Lahore), Lahore, Pakistan"
                ]
            },
            {
                "name": "Amna Zafar",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Beenish Ayesha Akram",
                "labs": [
                    "Department of Computer Engineering, University of Engineering and Technology, Lahore, Pakistan"
                ]
            },
            {
                "name": "Ruogu Zhou",
                "labs": [
                    "Hunan Vocational College of Commerce, Changsha, China"
                ]
            },
            {
                "name": "Feng Dong",
                "labs": [
                    "Faculty of Information Engineering, Shaoyang University, Shaoyang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Accuracy",
                "Social networking (online)",
                "Support vector machines",
                "Long short term memory",
                "Encoding",
                "Bidirectional control",
                "Cultural differences",
                "Classification algorithms",
                "Transformers"
            ],
            "Author Keywords": [
                "Bidirectional encoder representations from transformers (BERT)",
                "natural language processing",
                "transformers",
                "fake news classification",
                "gradient boosting classifier",
                "machine learning (ML)",
                "deep learning (DL)",
                "large language model (LLM)"
            ]
        }
    },
    {
        "Title": "Understanding ChatGPT: Impact Analysis and Path Forward for Teaching Computer Science and Engineering",
        "Link": "https://ieeexplore.ieee.org/document/10833612/",
        "Abstract": "Large Language Models (LLMs) like ChatGPT have become the most popular regenerative AI applications, used for obtaining responses for queries in different domains. The responses of ChatGPT are already becoming mainstream and are challenging conventional methods of learning. This article focuses on the application of ChatGPT for academic instructional purposes in the field of computer engineering and related majors. The capability of ChatGPT for instructional purposes is evaluated based on the responses to different questions about these engineering streams. This article explores different opportunities (with use cases), that ChatGPT can provide in augmenting the learning experience. It also provides scenarios of limitations and modifying the evaluation process to prevent the use of ChatGPT, which may lead to an inaccurate dissemination of accepted facts. In this paper, common classroom problems and their respective responses from ChatGPT in the domains of Computer Science, Cyber Security, Data Science, and Electrical Engineering are analyzed to determine the categories of queries for which ChatGPT offers reliable responses and those for which it may be factually incorrect. A student survey is performed to demonstrate that students must be made aware that ChatGPT may not be suitable for certain types of queries and means of upgrading the evaluation process.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3524102",
            "Date of Publication": "08 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "P. Banerjee",
                "labs": [
                    "Lane Department of Computer Science and Electrical Engineering, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA"
                ]
            },
            {
                "name": "Anurag K. Srivastava",
                "labs": [
                    "Lane Department of Computer Science and Electrical Engineering, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA"
                ]
            },
            {
                "name": "Donald A. Adjeroh",
                "labs": [
                    "Lane Department of Computer Science and Electrical Engineering, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA"
                ]
            },
            {
                "name": "Ramana Reddy",
                "labs": [
                    "Lane Department of Computer Science and Electrical Engineering, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA"
                ]
            },
            {
                "name": "Nima Karimian",
                "labs": [
                    "Lane Department of Computer Science and Electrical Engineering, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Artificial intelligence",
                "Measurement",
                "Education",
                "Computer science",
                "Writing",
                "Object recognition",
                "Electrical engineering",
                "Translation",
                "Robot sensing systems"
            ],
            "Author Keywords": [
                "ChatGPT",
                "education",
                "LLM",
                "computer science and engineering",
                "electrical engineering"
            ]
        }
    },
    {
        "Title": "Zero-Shot Classification of Art With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10851281/",
        "Abstract": "Art has become an important new investment vehicle. Thus, interest is growing in art price prediction as a tool for assessing the returns and risks of art investments. Both traditional statistical methods and machine learning methods have been used to predict art prices. However, both methods incur substantial human costs for data preprocessing for the construction of prediction models, necessitating a reduction in the workload. In this study, we propose the zero-shot classification method to perform automatic annotation in data processing for art price prediction by leveraging large language models (LLMs). The proposed method can perform annotation without new training data. Thus, it minimizes human costs. Our experiments demonstrated that the 4-bit quantized Llama-3 70B model, which can run on a local server, achieved the most accurate (over 0.9) automatic annotation of different art forms using LLMs, performing slightly better than the GPT-4o model from OpenAI. These results are practical for data preprocessing and comparable with the results of previous machine learning methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3532995",
            "Date of Publication": "23 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tatsuya Tojima",
                "labs": [
                    "Degree Programs in Systems and Information Engineering, University of Tsukuba, Tsukuba, Ibaraki, Japan"
                ]
            },
            {
                "name": "Mitsuo Yoshida",
                "labs": [
                    "Institute of Business Sciences, University of Tsukuba, Bunkyo, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Art",
                "Large language models",
                "Investment",
                "Photography",
                "Painting",
                "Graphics processing units",
                "Servers",
                "Load modeling",
                "Data preprocessing",
                "Data models"
            ],
            "Author Keywords": [
                "Art",
                "auction price",
                "ChatGPT",
                "classification",
                "data preprocessing",
                "Gemma",
                "large language model",
                "Llama",
                "LLM",
                "machine learning",
                "zero-shot learning"
            ]
        }
    },
    {
        "Title": "Toward Fairer and More Accurate Real-Time Pedestrian Attribute Recognition for Enhanced Women’s Safety: A Domain-Adversarial Multi-Head Model With Agent-Based Reporting",
        "Link": "https://ieeexplore.ieee.org/document/11097321/",
        "Abstract": "Effective surveillance systems play a vital role in improving public security, most important among which are applications related to women’s security, where the capacity to correctly carry out Pedestrian Attribute Recognition (PAR) is of utmost importance. Current PAR models are susceptible to being thrown off by dataset bias, mainly gender bias due to training set imbalance, resulting in suboptimal generalization and incorrect prediction across groups. This paper solves the challenges above by creating a Domain-Adversarial Training for Multi-Head Pedestrian Attribute Recognition (DAMH-PAR) model. DAMH-PAR uses a domain-adversarial training method combined with a multi-head structure to provide specialized training to various sets of attributes. The model learns invariant domain features upon training independent “expert” heads per dataset, which are chosen during inference to produce detailed pedestrian descriptions. The usefulness of the model is established by its capacity to predict pedestrian attributes accurately from security feeds even under heavy lighting. Such details, combined with violence detection and proximity modules, forms critical contextual information for automated safety systems. Testing DAMH-PAR model on PETA and PA-100K datasets reveals significant performance improvement compared to existing top-performing benchmarks. The DAMH-PAR model achieves 90.50% Mean Accuracy on PETA and 94.31% accuracy on PA-100K, which is more than the previously established standards. The performance highlights the potential of the suggested methodology to develop more effective and unbiased PAR models for meaningful development in security and safety surveillance tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3592975",
            "Date of Publication": "28 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. Balaji",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            },
            {
                "name": "G. Anitha",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Pedestrians",
                "Surveillance",
                "Training",
                "Security",
                "Feature extraction",
                "Safety",
                "Real-time systems",
                "Computational modeling",
                "Accuracy",
                "Deep learning"
            ],
            "Author Keywords": [
                "Domain discriminator",
                "domain-adversarial training (DAT)",
                "gradient reversal layer (GRL)",
                "inception-ResNet-v2",
                "LLM",
                "multi-head architecture",
                "pedestrian attribute recognition (PAR)",
                "YOLO"
            ]
        }
    },
    {
        "Title": "Applying the FAIR Principles to Open Educational Resources: A Semantic Similarity Approach to Improve Resource Discovery",
        "Link": "https://ieeexplore.ieee.org/document/11106503/",
        "Abstract": "Open educational resources (OER) are teaching, learning, or research resources freely available for use and reuse. Despite their potential, OER uptake in existing education systems remains low, primarily due to challenges in locating suitable resources. This study addresses this challenge by proposing and implementing a workflow applying the FAIR (Findable, Accessible, Interoperable, and Reusable) principles to OER. We demonstrated this framework within the Earth System Sciences as an application domain. We constructed a knowledge graph of approximately 500 FAIR OER, each annotated with structured metadata using the Schema.org vocabulary and made accessible through a SPARQL endpoint. To bridge the gap between making resources queryable and enabling their practical reuse, we employed a transformer-based language model (Sentence-BERT). The model was fine-tuned using few-shot learning on a domain-specific dataset of course-description pairs. This specialized model was then used to map the OER collection against over 200 university courses across five academic programs at a German university, based on semantic similarity between OER descriptions and university course descriptions. Expert evaluation of the model’s recommendations demonstrated 74% accuracy in identifying reusable OER for university courses. Notably, even with limited training data, fine-tuning the Sentence-BERT model significantly improved performance, resulting in a 16% reduction in mean squared error compared to the base model. This study provides both a generalizable methodology and a practical demonstration of how FAIR principles can streamline OER discovery, potentially accelerating OER uptake in higher education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3594963",
            "Date of Publication": "01 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Farzaneh Sadeghi",
                "labs": [
                    "Department of Sustainability and Planning, Aalborg University, Copenhagen, Denmark",
                    "Department of Geodesy, Bochum University of Applied Sciences, Bochum, Germany"
                ]
            },
            {
                "name": "Auriol Degbelo",
                "labs": [
                    "Chair of Geoinformatics, TUD Dresden University of Technology, Dresden, Germany"
                ]
            },
            {
                "name": "Carsten Kessler",
                "labs": [
                    "Department of Sustainability and Planning, Aalborg University, Copenhagen, Denmark",
                    "Department of Geodesy, Bochum University of Applied Sciences, Bochum, Germany"
                ]
            },
            {
                "name": "Reza Zolnouri",
                "labs": [
                    "Chair of Mathematics of Information Processing, RWTH Aachen University, Aachen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Metadata",
                "Guidelines",
                "Standards",
                "Software",
                "Semantics",
                "Open Educational Resources",
                "Training",
                "Collaboration",
                "Technological innovation",
                "Protocols"
            ],
            "Author Keywords": [
                "FAIR principles",
                "higher education",
                "knowledge graph",
                "LLM",
                "metadata",
                "open educational resources",
                "reusability"
            ]
        }
    },
    {
        "Title": "UE-NER-2025: A GPT-Based Approach to Multi-Lingual Named Entity Recognition on Urdu and English",
        "Link": "https://ieeexplore.ieee.org/document/11036786/",
        "Abstract": "Named Entity Recognition (NER) is a fundamental task that identifies and classifies entities into predefined categories from unstructured text. As textual data continues to grow and span diverse linguistic communities, NER is rarely studied as a multilingual task, particularly for low-resource languages. While many researchers have focused on name identification in various high-resource languages, only a few research efforts have addressed NER for the Urdu script. This is primarily due to a lack of resources and annotated datasets. Furthermore, previous research has mostly concentrated on monolingual techniques, leaving significant gaps in addressing multilingual challenges, especially for the Urdu language. To fill this gap, this study makes four key contributions. First, we created a unique multilingual dataset (UE-NER-2025) sourced from Twitter, which contains 182,411 tokens and 8 uniquely annotated entity types. Second, we applied two novel techniques that are relatively new to the UE-NER-2025 dataset: 1) a joint multilingual approach and 2) a joint translation-based approach. Third, we conducted 30 different experiments using 5-fold cross-validation, combining traditional supervised learning with token-based feature extraction, deep learning with pre-trained word embeddings such as FastText and GloVe, and advanced transfer learning models using contextual embeddings, to evaluate their effectiveness in enhancing NER performance for both English and Urdu, particularly addressing the challenges of low-resource and morphologically rich languages. Finally, we performed statistical analysis on our top-performing models to determine whether the differences in performance were statistically significant or occurred by chance. Based on the analysis of the results, our transformer-based language model (XLM-RoBERTa-base) achieved strong performance compared to traditional supervised learning models. We observed a performance improvement of 3.99% in the English translation-based approach, 3.72% in the multilingual approach, and 2.32% in the Urdu translation-based approach over traditional supervised learning (RF in Urdu = 0.927, in English = 0.9258, and multilingual = 0.9272).\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3579289",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Ahmad",
                "labs": [
                    "Centro de Investigación en Computación, Instituto Politécnico Nacional (CIC-IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Humaira Farid",
                "labs": [
                    "Independent Researcher, Sunnyvale, CA, USA"
                ]
            },
            {
                "name": "Iqra Ameer",
                "labs": [
                    "Division of Science and Engineering, The Pennsylvania State University, Abington, PA, USA"
                ]
            },
            {
                "name": "Fida Ullah",
                "labs": [
                    "Centro de Investigación en Computación, Instituto Politécnico Nacional (CIC-IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Muhammad Muzamil",
                "labs": [
                    "Department of Software Engineering and Computer Science, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Muhammad Jalal",
                "labs": [
                    "Department of Software Engineering and Computer Science, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Ameer Hamza",
                "labs": [
                    "Department of Software Engineering and Computer Science, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Ildar Batyrshin",
                "labs": [
                    "Centro de Investigación en Computación, Instituto Politécnico Nacional (CIC-IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Grigori Sidorov",
                "labs": [
                    "Centro de Investigación en Computación, Instituto Politécnico Nacional (CIC-IPN), Mexico City, Mexico"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multilingual",
                "Social networking (online)",
                "Translation",
                "Deep learning",
                "Complexity theory",
                "Transformers",
                "Analytical models",
                "Supervised learning",
                "Named entity recognition",
                "Blogs"
            ],
            "Author Keywords": [
                "Social media analysis",
                "named entity recognition",
                "LLM",
                "GPT",
                "deep learning",
                "machine learning",
                "SVM",
                "twitter",
                "Urdu text mining"
            ]
        }
    },
    {
        "Title": "Action-State Testing—A Model for Test Design Automation",
        "Link": "https://ieeexplore.ieee.org/document/10973230/",
        "Abstract": "Model-based testing (MBT) is essential in software testing, offering automation, comprehensive coverage, and defect prevention. It uses abstract models to automatically design and generate test cases, representing the expected system behaviour, including states, transitions, inputs, and outputs. This paper explores the action-state testing modelling technique, originally introduced by the authors in Forgács and Kovács (2000). In this approach, a model step comprises an action (input), one or more responses (outputs), and an optional state. The steps can be arranged sequentially, or they may be forked and joined. Sequential steps appear within the same test case. Forked steps are distributed across different test cases. The joined steps also belong to separate test cases. In addition, the graphical model can be constructed using a text editor. This paper builds upon the concept by establishing its theoretical foundation. We demonstrate how the action-state model eliminates the need for guard conditions and coding, maintains a concise and manageable structure, and seamlessly incorporates outputs, ultimately enhancing testing efficiency. Additionally, we provide guidelines for adding new states and empirically validate the benefits of action-state testing over alternative techniques, achieving a 100% defect detection percentage (DDP). This paper marks the first instalment of the author’s Test Design Trilogy, dedicated to refining and unifying various test design techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3563337",
            "Date of Publication": "22 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "István Forgács",
                "labs": [
                    "4Test-Plus Ltd., Budapest, Hungary"
                ]
            },
            {
                "name": "Attila Kovács",
                "labs": [
                    "Department of Computer Algebra, Eötvöd Loránd University, Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Testing",
                "Unified modeling language",
                "Automation",
                "Computational modeling",
                "Codes",
                "Guidelines",
                "Electronic mail",
                "Defect detection",
                "Software testing",
                "Prevention and mitigation"
            ],
            "Author Keywords": [
                "Action-state testing",
                "EFSM",
                "FSM",
                "guard condition",
                "LLM",
                "modeling",
                "stateful and stateless models",
                "test automation",
                "test design",
                "test generation",
                "test selection criteria"
            ]
        }
    },
    {
        "Title": "Toward Reliable Knowledge Graphs in Virtual Product Development: Data Strategies and Reproducibility Assessment",
        "Link": "https://ieeexplore.ieee.org/document/11162540/",
        "Abstract": "The integration of knowledge graphs into industrial product development workflows offers a promising solution for managing complex and heterogeneous data to enhance development efficiency. However, concrete strategies for their deployment, particularly with respect to data quality, integration, and framework implementation, remain underexplored. This study addresses this gap by investigating the data-related requirements and strategies essential for constructing robust and reproducible knowledge graphs within the context of virtual product development. Building on a proposed framework within the context of the BMW Group, we identify critical factors including the use of ontologies, standardized data formats, the implementation of unique and versioned entity identifiers, as well as data quality and integration strategies. To validate the reproducibility and correctness of the framework, we conduct a comparative analysis using two independent example datasets. Both knowledge graphs were constructed under identical conditions and evaluated in terms of completeness and accuracy. Our results confirm that the framework reliably generates high-quality knowledge graphs across varying domains with minimal manual intervention.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3609662",
            "Date of Publication": "12 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Carolin Lehmacher",
                "labs": [
                    "Department of Mechanical Engineering, Technische Universität Dresden, Dresden, Germany",
                    "Research and Development Center, Bayerische Motoren Werke AG, Munich, Germany"
                ]
            },
            {
                "name": "Kristin Paetzold-Byhain",
                "labs": [
                    "Department of Mechanical Engineering, Technische Universität Dresden, Dresden, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge graphs",
                "Product development",
                "Ontologies",
                "Data integrity",
                "Solid modeling",
                "Design automation",
                "Soft sensors",
                "Information retrieval",
                "Data models",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Computer-aided design",
                "foundational requirements",
                "knowledge graphs",
                "labeled property graph",
                "LLM",
                "ontology",
                "virtual product development"
            ]
        }
    },
    {
        "Title": "ReACT_OCRS: An AI-Driven Anonymous Online Reporting System Using Synergized Reasoning and Acting in Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11007115/",
        "Abstract": "Victims and witnesses of cybercrime often hesitate to report incidents due to concerns over privacy, complexity, and fear of retaliation. Traditional reporting mechanisms require manual data entry, creating accessibility barriers and delaying response times. To address these challenges, this paper introduces ReACT_OCRS, an AI-driven voice-based cybercrime reporting system that allows victims and witnesses to anonymously submit complaints through audio recordings. Leveraging speech recognition transformers, a recent language model, and encryption, the system processes real-time multilingual voice inputs, extracts meaningful content, and classifies reports with high precision using a hybrid voting mechanism. Experimental evaluations on synthetically generated and human-validated datasets confirm the system’s ability to accurately transcribe, classify, and securely process audio complaints while preserving user anonymity. This work improves cybercrime reporting by making it more accessible, efficient, and secure, fostering greater participation from victims and witnesses.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571526",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amir Aboubakr Shaker Mahmoud",
                "labs": [
                    "School of Digital Forensics and Cyber Security, National Forensic Sciences University, Gandhinagar, India"
                ]
            },
            {
                "name": "Wesam Shishah",
                "labs": [
                    "College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nilay R. Mistry",
                "labs": [
                    "School of Digital Forensics and Cyber Security, National Forensic Sciences University, Gandhinagar, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer crime",
                "Law enforcement",
                "Law",
                "Manuals",
                "Encryption",
                "Multilingual",
                "Cognition",
                "Translation",
                "Transformers",
                "Reviews"
            ],
            "Author Keywords": [
                "Cybercrime",
                "encryption",
                "LLM",
                "ML",
                "NLP",
                "ReACT",
                "reporting system",
                "transformers"
            ]
        }
    },
    {
        "Title": "Detecting Creative States From Emotional Cues: Insights From Speech With Focus on Text Modality",
        "Link": "https://ieeexplore.ieee.org/document/10977009/",
        "Abstract": "Creativity and emotion are fundamental aspects of human expression, interaction, and innovation, shaping various facets of modern society. This paper explores the intersection of technology, human creativity and emotional expression by proposing a novel approach to detecting creative states through the analysis of emotional cues derived from speech. To validate the findings, a linguistic prompt creativity test was conducted, incorporating both human evaluations and AI-driven assistance as the co-collaborative approach, using the Torrance Test of Creative Thinking (TTCT) as the evaluation criteria. The study analysed 50 creative speech samples from 25 participants, each exposed to happy and sad video stimuli to evoke distinct emotional responses. The results reveal a correlation between emotional states and creativity. A paired t-test revealed a difference in creativity scores between the happy and sad conditions (t(24) = 2.46, p = 0.021), with higher creativity observed in the happy condition. In 80% of the participants, higher creativity levels were observed when they experienced positive emotions and happiness, highlighting the significant influence of emotional context on creative expression and creative states and also aligning with the psychological research on exploring the effects of emotions on creativity.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3564499",
            "Date of Publication": "25 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sepideh Kalateh",
                "labs": [
                    "Centre of Technology and Systems (CTS-UNINOVA), NOVA University of Lisbon, Caparica, Portugal",
                    "Associated Laboratory on Intelligent Systems (LASI), NOVA University of Lisbon, Caparica, Portugal"
                ]
            },
            {
                "name": "Sanaz Nikghadam-Hojjati",
                "labs": [
                    "Centre of Technology and Systems (CTS-UNINOVA), NOVA University of Lisbon, Caparica, Portugal",
                    "Associated Laboratory on Intelligent Systems (LASI), NOVA University of Lisbon, Caparica, Portugal"
                ]
            },
            {
                "name": "José Barata",
                "labs": [
                    "Centre of Technology and Systems (CTS-UNINOVA), NOVA University of Lisbon, Caparica, Portugal",
                    "Associated Laboratory on Intelligent Systems (LASI), NOVA University of Lisbon, Caparica, Portugal"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Creativity",
                "Linguistics",
                "Emotion recognition",
                "Artificial intelligence",
                "Technological innovation",
                "Wheels",
                "Shape",
                "Problem-solving",
                "Cultural differences",
                "Cognitive processes"
            ],
            "Author Keywords": [
                "Computational creativity",
                "affective computing",
                "emotion detection",
                "sentiment analysis",
                "linguistic computation",
                "LLM",
                "NLTK",
                "Emroberta"
            ]
        }
    },
    {
        "Title": "SLAM: Sales Lead AMplification Through GenAI and ML for e-Learning Platforms",
        "Link": "https://ieeexplore.ieee.org/document/10770225/",
        "Abstract": "In the competitive landscape of contemporary business, predictive analytics, particularly in sales lead prediction, has become instrumental for enhancing sales effectiveness and maximizing revenue generation. This study investigates sales lead prediction utilizing machine learning techniques. In the domain of sales, the accurate prediction of leads is deemed essential for optimizing resource allocation and maximizing conversion rates. This study investigates sales lead prediction utilizing machine learning techniques, with a particular focus on the ensemble method of stacking algorithms. The research objective is to improve the predictive accuracy of sales lead identification through the utilization of advanced machine learning methodologies. Through rigorous experimentation and analysis, singular models were first explored, followed by the integration into a stacking ensemble model, achieving an accuracy rate of 94%. Extensive pre-processing techniques have been applied to ensure data quality and feature relevance, facilitating robust model training. The experimental results demonstrate the efficacy of both singular models and the proposed ensemble approach in accurately predicting sales leads. The implications of these findings extend to various sectors reliant on efficient lead management, including marketing, sales, and customer relationship management. By leveraging advanced machine learning techniques such as stacking ensembles, organizations can enhance their lead identification processes, leading to improved conversion rates and overall business performance. This research contributes to the growing body of knowledge in predictive analytics and offers valuable insights for practitioners seeking to optimize their sales strategies through the integration of machine learning technologies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3507878",
            "Date of Publication": "27 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ganesan Ramachandran",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Tanmay Narang",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Vallidevi Krishnamurthy",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Predictive models",
                "Machine learning",
                "Lead",
                "Business",
                "Industries",
                "Data models",
                "Analytical models",
                "Stacking",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "Large language models (LLM)",
                "random forest",
                "tokenizer",
                "classification",
                "one hot encoding",
                "synthetic generation",
                "generative pretrained transformers (GPT)",
                "normalisation",
                "natural language processor (NLP)",
                "sentiment intensity analyser",
                "stacking",
                "voting"
            ]
        }
    },
    {
        "Title": "Privacy-Aware Detection for Large Language Models Using a Hybrid BiLSTM-HMM Approach",
        "Link": "https://ieeexplore.ieee.org/document/11077118/",
        "Abstract": "Large Language Models (LLMs) have transformed natural language processing, enabling applications such as conversational agents and machine translation. However, their deployment introduces significant privacy concerns, including the memorization and unintended disclosure of sensitive data. Existing privacy-preserving techniques—such as Differential Privacy and federated learning—struggle to balance data protection, model utility, and computational efficiency. To address these limitations, we propose a lightweight privacy-disclosure detection system that combines Bidirectional Long Short-Term Memory (BiLSTM) networks with Hidden Markov Models (HMM) using a novel modeling pipeline. Our approach employs the Predefined and Sensitive Labeling (PSL) technique, a generative labeling approach that extracts meaningful patterns from data. These patterns are then used to train a BiLSTM model capable of proactively identifying sensitive information in real-time user interactions with LLMs. As BiLSTMs do not provide the probability of private data, we design a HMM that estimates the probability of occurrence for this private data. Utilizing the Forward algorithm, our system quantifies privacy risks, enabling users to revise inputs prior to submission and thereby enhancing data privacy. Trained on synthetic data using PSL technique, the model achieves approximately 99.94% precision, recall, and F1-score, and successfully detects previously unseen sensitive information in synthetic datasets with\n≈99.98\n% accuracy across 55,000 sentences. Additionally, the generated model trained on patterns derived from synthetic data, achieved\n≈99.99\n% accuracy when evaluated on a real-world dataset across varying sentence structures, demonstrating strong generalizability in detecting sensitive information regardless of the data source. Importantly, the model provides real-time predictions with an average execution time of 35.46 milliseconds, satisfying the speed requirements for practical deployment. It also trains 45.5 times faster than a state-of-the-art framework, offering high computational efficiency without compromising accuracy.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3587988",
            "Date of Publication": "10 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maryam Abbasalizadeh",
                "labs": [
                    "Miner School of Computer and Information Sciences, University of Massachusetts Lowell, Lowell, MA, USA"
                ]
            },
            {
                "name": "Sashank Narain",
                "labs": [
                    "Miner School of Computer and Information Sciences, University of Massachusetts Lowell, Lowell, MA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Hidden Markov models",
                "Real-time systems",
                "Data privacy",
                "Data models",
                "Accuracy",
                "Training",
                "Synthetic data",
                "Differential privacy",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Privacy preserving",
                "BiLSTM",
                "HMM",
                "forward algorithm",
                "synthetic data",
                "sensitive information",
                "LLM"
            ]
        }
    },
    {
        "Title": "LegalMind: Agentic AI-Driven Process Optimization and Cost Reduction in Legal Services Using DeepSeek",
        "Link": "https://ieeexplore.ieee.org/document/11072348/",
        "Abstract": "The legal industry struggles with inefficiencies, high costs, and manual-intensive workflows. Traditional AI lacks adaptability in optimizing legal operations. To address this, we propose LegalMind, an agentic AI-driven framework leveraging DeepSeek R1 for intelligent legal process automation and cost reduction. LegalMind integrates a structured legal dataset and fine-tunes DeepSeek R1 to enhance decision-making and workflow efficiency. Experimental results show a 42.6% cost reduction and a 60.8% improvement in document processing speed over baseline AI models. Scalability tests confirm the system’s ability to handle 100,000 queries efficiently. Real-world case studies validate LegalMind’s effectiveness in law firms, corporate legal departments, and government agencies, demonstrating significant reductions in case preparation time and operational costs. These findings highlight the transformative potential of agentic AI in legal automation, optimizing workflows and improving decision support.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586781",
            "Date of Publication": "07 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nidadavolu Venkat Durga Sai Siva Vara Prasad Raju",
                "labs": [
                    "Department of Software Engineering, Birla Institute of Technology and Science (BITS) at Pilani, Pilani, Rajasthan, India"
                ]
            },
            {
                "name": "Nuruzzaman Faruqui",
                "labs": [
                    "Department of Software Engineering, Daffodil International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Nikhil Patel",
                "labs": [
                    "Department of Business Administration, University of Dubuque, Dubuque, IA, USA"
                ]
            },
            {
                "name": "Olivia-Roxana Alecsoiu",
                "labs": [
                    "Faculty of Educational Sciences, Law and Public Administration, Constantin Brâncuşi University of Târgu-Jiu, Târgu Jiu, Romania"
                ]
            },
            {
                "name": "Priyabrata Thatoi",
                "labs": [
                    "Amazon, Chicago, IL, USA"
                ]
            },
            {
                "name": "Salem A. Alyami",
                "labs": [
                    "Department of Mathematics and Statistics, Faculty of Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "AKM Azad",
                "labs": [
                    "Department of Mathematics and Statistics, Faculty of Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Artificial intelligence",
                "Costs",
                "Optimization",
                "Automation",
                "Cognition",
                "Systematic literature review",
                "STEM",
                "Mathematical models",
                "Complexity theory"
            ],
            "Author Keywords": [
                "DeepSeek",
                "agentic AI",
                "legal process automation",
                "cost optimization in legal services",
                "deep learning in law",
                "scalable AI for LegalTech",
                "intelligent legal decision support",
                "LLM",
                "transformer model"
            ]
        }
    },
    {
        "Title": "Prompting Large Language Models with Knowledge-Injection for Knowledge-Based Visual Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/10654678/",
        "Abstract": "Previous works employ the Large Language Model (LLM) like GPT-3 for knowledge-based Visual Question Answering (VQA). We argue that the inferential capacity of LLM can be enhanced through knowledge injection. Although methods that utilize knowledge graphs to enhance LLM have been explored in various tasks, they may have some limitations, such as the possibility of not being able to retrieve the required knowledge. In this paper, we introduce a novel framework for knowledge-based VQA titled “Prompting Large Language Models with Knowledge-Injection” (PLLMKI). We use vanilla VQA model to inspire the LLM and further enhance the LLM with knowledge injection. Unlike earlier approaches, we adopt the LLM for knowledge enhancement instead of relying on knowledge graphs. Furthermore, we leverage open LLMs, incurring no additional costs. In comparison to existing baselines, our approach exhibits the accuracy improvement of over 1.3 and 1.7 on two knowledge-based VQA datasets, namely OK-VQA and A-OKVQA, respectively.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020026",
            "Date of Publication": "28 August 2024",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Zhongjian Hu",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network, Information Integration (Southeast University), Ministry of Education of the People's Republic of China, Nanjing, China"
                ]
            },
            {
                "name": "Peng Yang",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network, Information Integration (Southeast University), Ministry of Education of the People's Republic of China, Nanjing, China"
                ]
            },
            {
                "name": "Fengyuan Liu",
                "labs": [
                    "Southeast University - Monash University Joint Graduate School (Suzhou), Southeast University, Suzhou, China"
                ]
            },
            {
                "name": "Yuan Meng",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network, Information Integration (Southeast University), Ministry of Education of the People's Republic of China, Nanjing, China"
                ]
            },
            {
                "name": "Xingyu Liu",
                "labs": [
                    "Southeast University - Monash University Joint Graduate School (Suzhou), Southeast University, Suzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Costs",
                "Large language models",
                "Knowledge based systems",
                "Knowledge graphs",
                "Predictive models",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "visual question answering",
                "knowledge-based visual question answering",
                "large language model",
                "knowledge injection"
            ]
        }
    },
    {
        "Title": "Large Language Model Guided Reinforcement Learning Based Six-Degree-of-Freedom Flight Control",
        "Link": "https://ieeexplore.ieee.org/document/10551749/",
        "Abstract": "As artificial intelligence (AI) technology advances rapidly, its increasing involvement in military defense fosters intelligent air combat domain development. The Intelligent Flight Controller (IFC) is a crucial technology and foundation for intelligent air combat decision-making systems. Controlling 6 Degree-of-freedom (DOF) aircraft in close-to-real-world environments requires an adaptable and dynamic decision-making controller. Most IFC researches focus on simplistic flight trajectory design and validation, while air combat requires aircraft that can perform complex tactical maneuvers. Deep reinforcement learning (DRL) provides a suitable technical paradigm. However, DRL suffers from sparse rewards, insufficient supervisory signals, low sampling efficiency, and slow convergence. In contrast, Large Language Model (LLM) possesses abundant knowledge about the real world, contextual understanding, and reasoning capabilities. By leveraging this, LLM can serve as prior knowledge for DRL, thereby reducing DRL training time. This paper proposes an LLM-guided deep reinforcement learning framework for IFC, which utilizes LLM-guided deep reinforcement learning to achieve intelligent flight control under limited computational resources. LLM provides direct guidance during training based on local knowledge, which improves the quality of data generated in agent-environment interaction within DRL, expedites training, and offers timely feedback to agents, thereby partially mitigating sparse reward issues. Additionally, we present an effective reward function to comprehensively balance the aircraft coupling control to ensure stable, flexible control. Finally, simulations and experiments show that the proposed techniques have good performance, robustness, and adaptability across various flight tasks, laying a foundation for future research in the intelligent air combat decision-making domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3411015",
            "Date of Publication": "07 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanqiao Han",
                "labs": [
                    "School of Aeronautics and Astronautics, Sichuan University, Chengdu, China"
                ]
            },
            {
                "name": "Menglong Yang",
                "labs": [
                    "School of Aeronautics and Astronautics, Sichuan University, Chengdu, China"
                ]
            },
            {
                "name": "Yang Ren",
                "labs": [
                    "School of Aeronautics and Astronautics, Sichuan University, Chengdu, China"
                ]
            },
            {
                "name": "Weizheng Li",
                "labs": [
                    "School of Aeronautics and Astronautics, Sichuan University, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Aerospace control",
                "Aircraft",
                "Atmospheric modeling",
                "Training",
                "Deep reinforcement learning",
                "Adaptation models",
                "Decision making",
                "Intelligent control"
            ],
            "Author Keywords": [
                "Intelligent flight control",
                "large language model",
                "deep reinforcement learning",
                "6 DOF aircraft"
            ]
        }
    },
    {
        "Title": "Impact of Large Language Models on Scholarly Publication Titles and Abstracts: A Comparative Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10613027/",
        "Abstract": "Artificial Intelligence (AI) tools become essential across industries, distinguishing AI-generated from human-authored text is increasingly challenging. This study assesses the coherence of AI-generated titles and corresponding abstracts in anticipation of rising AI-assisted document production. Our main goal is to examine the correlation between original and AI-generated titles, emphasizing semantic depth and similarity measures, particularly in the context of Large Language Models (LLMs). We argue that LLMs have transformed research focus, dissemination, and citation patterns across five selected knowledge areas: Business Administration and Management (BAM), Computer Science and Information Technology (CS), Engineering and Material Science (EMS), Medicine and Healthcare (MH), and Psychology and Behavioral Sciences (PBS). We collected 15 000 titles and abstracts, narrowing the selection to 2000 through a rigorous multi-stage screening process adhering to our study's criteria. Result shows that there is insufficient evidence to suggest that LLM outperforms human authors in article title generation or articles from the LLM era demonstrates a marked difference in semantic richness and readability compared to those from the pre-LLM. Instead, it asserts that LLM is a valuable tool and can assist researchers in generating titles. With LLM's assistance, the researcher ensures that the content is reflective of the finalized abstract and core research themes, potentially increasing the impact and accessibility and readability of the academic work.",
        "Details": {
            "DOI": "10.23919/JSC.2024.0011",
            "Date of Publication": "June 2024",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Phoey Lee Teh",
                "labs": [
                    "Department of Cyber and Computing, Wrexham University, Wrexham, UK"
                ]
            },
            {
                "name": "Chukwudi Festus Uwasomba",
                "labs": [
                    "School of Computing and Computing, STEM Faculty, The Open University, Milton Keynes, UK"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge engineering",
                "Industries",
                "Social computing",
                "Materials science and technology",
                "Large language models",
                "Semantics",
                "Psychology"
            ],
            "Author Keywords": [
                "semantic alignment",
                "cosine similarity",
                "patterns",
                "large language models",
                "technology impact"
            ]
        }
    },
    {
        "Title": "From LLMs to Randomness: Analyzing Program Input Efficacy With Resource and Language Metrics",
        "Link": "https://ieeexplore.ieee.org/document/11006641/",
        "Abstract": "Security-focused program testing typically focuses on crash detection and code coverage while overlooking additional system behaviors that can impact program confidentiality and availability. To address this gap, we propose a statistical framework that combines embedding-based anomaly detection, resource usage metrics, and resource-state distance measures to systematically profile software behaviors beyond traditional coverage-based methods. Leveraging over 5 million labeled samples from 50 Python programs, we evaluate how these independent scoring terms distinguish among different sources of input, including Large Language Model (LLM)-generated inputs, and demonstrate how standard statistical tests (e.g., Kolmogorov—Smirnov and Kendall’s\nτ\n) confirm their effectiveness. Our findings show that LLM-generated samples can trigger diverse behaviors but are often less effective at exploring resource usage dynamics (CPU, memory) compared with conventional fuzzing. However, combining LLM outputs with existing techniques broadens behavior coverage and reveals commonalities between commercial LLM outputs. We provide open-source tools for this evaluation framework, demonstrating the potential to refine software testing by integrating behavior metrics into security-testing workflows.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571205",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gavin Black",
                "labs": [
                    "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA",
                    "Cyber Accelerator, Office of Technology, Leidos, Reston, VA, USA"
                ]
            },
            {
                "name": "Eric Yocam",
                "labs": [
                    "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
                ]
            },
            {
                "name": "Varghese Mathew Vaidyan",
                "labs": [
                    "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
                ]
            },
            {
                "name": "Gurcan Comert",
                "labs": [
                    "Department of Computer Science, College of Engineering, North Carolina Agricultural and Technical State University, Greensboro, NC, USA",
                    "Engineering and Computer Science Department, Benedict College, Columbia, SC, USA"
                ]
            },
            {
                "name": "Yong Wang",
                "labs": [
                    "Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Software",
                "Fuzzing",
                "Testing",
                "Memory management",
                "Computer crashes",
                "Codes",
                "Anomaly detection",
                "Python",
                "Statistical analysis"
            ],
            "Author Keywords": [
                "Software profiling",
                "program behavior analysis",
                "fuzzing techniques",
                "resource usage metrics",
                "large language models",
                "anomaly detection"
            ]
        }
    },
    {
        "Title": "Large Language Models for UAVs: Current State and Pathways to the Future",
        "Link": "https://ieeexplore.ieee.org/document/10643253/",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as a transformative technology across diverse sectors, offering adaptable solutions to complex challenges in both military and civilian domains. Their expanding capabilities present a platform for further advancement by integrating cutting-edge computational tools like Artificial Intelligence (AI) and Machine Learning (ML) algorithms. These advancements have significantly impacted various facets of human life, fostering an era of unparalleled efficiency and convenience. Large Language Models (LLMs), a key component of AI, exhibit remarkable learning and adaptation capabilities within deployed environments, demonstrating an evolving form of intelligence with the potential to approach human-level proficiency. This work explores the significant potential of integrating UAVs and LLMs to propel the development of autonomous systems. We comprehensively review LLM architectures, evaluating their suitability for UAV integration. Additionally, we summarize the state-of-the-art LLM-based UAV architectures and identify novel opportunities for LLM embedding within UAV frameworks. Notably, we focus on leveraging LLMs to refine data analysis and decision-making processes, specifically for enhanced spectral sensing and sharing in UAV applications. Furthermore, we investigate how LLM integration expands the scope of existing UAV applications, enabling autonomous data processing, improved decision-making, and faster response times in emergency scenarios like disaster response and network restoration. Finally, we highlight crucial areas for future research that are critical for facilitating the effective integration of LLMs and UAVs.",
        "Details": {
            "DOI": "10.1109/OJVT.2024.3446799",
            "Date of Publication": "21 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Vehicular Technology"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1330"
        },
        "authors_data": [
            {
                "name": "Shumaila Javaid",
                "labs": [
                    "Department of Control Science, Engineering, College of Electronics, Information Engineering, Tongji University, Shanghai, China",
                    "National Key Laboratory of Autonomous Intelligent Unmanned Systems, Tongji University, Shanghai, China",
                    "Frontiers Science Center for Intelligent Autonomous Systems, Ministry of Education, Shanghai, China"
                ]
            },
            {
                "name": "Hamza Fahim",
                "labs": [
                    "Department of Control Science, Engineering, College of Electronics, Information Engineering, Tongji University, Shanghai, China",
                    "National Key Laboratory of Autonomous Intelligent Unmanned Systems, Tongji University, Shanghai, China",
                    "Frontiers Science Center for Intelligent Autonomous Systems, Ministry of Education, Shanghai, China"
                ]
            },
            {
                "name": "Bin He",
                "labs": [
                    "Department of Control Science, Engineering, College of Electronics, Information Engineering, Tongji University, Shanghai, China",
                    "National Key Laboratory of Autonomous Intelligent Unmanned Systems, Tongji University, Shanghai, China",
                    "Frontiers Science Center for Intelligent Autonomous Systems, Ministry of Education, Shanghai, China"
                ]
            },
            {
                "name": "Nasir Saeed",
                "labs": [
                    "Department of Electrical, Communication Engineering, United Arab Emirates University (UAEU), Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Artificial intelligence",
                "Sensors",
                "Decision making",
                "Real-time systems",
                "Wireless networks",
                "Training",
                "Large language models",
                "Spectral analysis"
            ],
            "Author Keywords": [
                "UAVs",
                "large language models",
                "spectral sensing",
                "autonomous systems",
                "decision-making"
            ]
        }
    },
    {
        "Title": "MedBench: A Comprehensive, Standardized, and Reliable Benchmarking System for Evaluating Chinese Medical Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10778138/",
        "Abstract": "Ensuring the general efficacy and benefit for human beings from medical Large Language Models (LLM) before real-world deployment is crucial. However, a widely accepted and accessible evaluation process for medical LLM, especially in the Chinese context, remains to be established. In this work, we introduce “MedBench”, a comprehensive, standardized, and reliable benchmarking system for Chinese medical LLM. First, MedBench assembles the currently largest evaluation dataset (300 901 questions) to cover 43 clinical specialties, and performs multi-faceted evaluation on medical LLM. Second, MedBench provides a standardized and fully automatic cloud-based evaluation infrastructure, with physical separations between question and ground truth. Third, MedBench implements dynamic evaluation mechanisms to prevent shortcut learning and answer memorization. Applying MedBench to popular general and medical LLMs, we observe unbiased, reproducible evaluation results largely aligning with medical professionals' perspectives. This study establishes a significant foundation for preparing the practical applications of Chinese medical LLMs. MedBench is publicly accessible at https://medbench.opencompass.org.cn.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020044",
            "Date of Publication": "04 December 2024",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Mianxin Liu",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            },
            {
                "name": "Weiguo Hu",
                "labs": [
                    "Ruijin Hospital Affiliated to Shanghai Jiao Tong University, School of Medicine, Shanghai, China"
                ]
            },
            {
                "name": "Jinru Ding",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            },
            {
                "name": "Jie Xu",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            },
            {
                "name": "Xiaoyang Li",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            },
            {
                "name": "Lifeng Zhu",
                "labs": [
                    "Ruijin Hospital Affiliated to Shanghai Jiao Tong University, School of Medicine, Shanghai, China"
                ]
            },
            {
                "name": "Zhian Bai",
                "labs": [
                    "Ruijin Hospital Affiliated to Shanghai Jiao Tong University, School of Medicine, Shanghai, China"
                ]
            },
            {
                "name": "Xiaoming Shi",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            },
            {
                "name": "Benyou Wang",
                "labs": [
                    "The Chinese University of Hong Kong, Shenzhen, China"
                ]
            },
            {
                "name": "Haitao Song",
                "labs": [
                    "Shanghai Artificial Intelligence Research Institute, Shanghai",
                    "Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Pengfei Liu",
                "labs": [
                    "School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Xiaofan Zhang",
                "labs": [
                    "Qing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Shanshan Wang",
                "labs": [
                    "Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China"
                ]
            },
            {
                "name": "Kang Li",
                "labs": [
                    "West China Hospital, Sichuan University, Chengdu, China"
                ]
            },
            {
                "name": "Haofen Wang",
                "labs": [
                    "School of Design and Innovation, Tongji University, Shanghai, China"
                ]
            },
            {
                "name": "Tong Ruan",
                "labs": [
                    "Department of Computer Science and Technology, East China University of Science and Technology, Shanghai, China"
                ]
            },
            {
                "name": "Xuanjing Huang",
                "labs": [
                    "School of Computer Science, Fudan University, Shanghai, China"
                ]
            },
            {
                "name": "Xin Sun",
                "labs": [
                    "Xinhua Hospital Affiliated to Shanghai Jiaotong University School of Medicine, Shanghai, China"
                ]
            },
            {
                "name": "Shaoting Zhang",
                "labs": [
                    "Shanghai Artificial Intelligence Laboratory, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Industries",
                "Large language models",
                "Pipelines",
                "Medical services",
                "Benchmark testing",
                "Big Data",
                "Reliability",
                "Data mining"
            ],
            "Author Keywords": [
                "Medical Large Language Model (MLLM)",
                "benchmark",
                "platform",
                "open-source"
            ]
        }
    },
    {
        "Title": "DeCoAgent: Large Language Model Empowered Decentralized Autonomous Collaboration Agents Based on Smart Contracts",
        "Link": "https://ieeexplore.ieee.org/document/10720018/",
        "Abstract": "Large Language Models (LLMs) empowered agents are effective across various tasks and demonstrate outstanding performance, which can be further enhanced through collaboration with multiple LLM agents. The current approaches for collaboration with multiple LLM agents are static approaches, which adopt a fixed set of agents to interact with each other. However, these approaches suffer from a significant limitation: multi-agent collaboration depends on the assumption that all participants know each other in a local closed environment, can find each other and direct communication, and will act with integrity. To address these challenges, this paper proposes DeCoAgent, a novel framework for decentralized autonomous collaboration between LLMs empowered agents based on smart contracts. This framework enables decentralized autonomous collaboration between LLM agents, allowing them to register themselves, discover the capabilities of other agents, and assign tasks on the platform. LLMs can convert natural language descriptions from human and LLM agent users into smart contract calls, enabling agents to interact with humans, the blockchain, and other agents to achieve automation. This paper implements the platform based on OpenAI and Ethereum, demonstrating the practical feasibility of this approach. The proposed framework has broader applications, including supply chain management, manufacturing, crowdsourcing, and complementing other existing multi-agent collaborations. This framework is open source on GitHub. Please visit the repository at https://github.com/AnanKing/DeCoAgent.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3481641",
            "Date of Publication": "16 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anan Jin",
                "labs": [
                    "Software Research Institute, Technological University of the Shannon: Midlands Midwest, Athlone, Ireland"
                ]
            },
            {
                "name": "Yuhang Ye",
                "labs": [
                    "Department of Computer and Software Engineering, Technological University of the Shannon: Midlands Midwest, Athlone, Ireland"
                ]
            },
            {
                "name": "Brian Lee",
                "labs": [
                    "Software Research Institute, Technological University of the Shannon: Midlands Midwest, Athlone, Ireland"
                ]
            },
            {
                "name": "Yuansong Qiao",
                "labs": [
                    "Software Research Institute, Technological University of the Shannon: Midlands Midwest, Athlone, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Collaboration",
                "Smart contracts",
                "Blockchains",
                "Natural languages",
                "Large language models",
                "Probability",
                "Decision making",
                "Training",
                "System analysis and design",
                "Supply chain management"
            ],
            "Author Keywords": [
                "Large language models",
                "agent collaboration",
                "smart contract",
                "blockchain",
                "decentralized autonomous"
            ]
        }
    },
    {
        "Title": "Learning Electromagnetic Metamaterial Physics With ChatGPT",
        "Link": "https://ieeexplore.ieee.org/document/10930934/",
        "Abstract": "Large language models (LLMs) such as ChatGPT, Gemini, LlaMa, and Claude are trained on massive quantities of text parsed from the internet and have shown a remarkable ability to respond to complex prompts in a manner often indistinguishable from humans. For all-dielectric metamaterials consisting of unit cells with four elliptical resonators, we present a LLM fine-tuned on up to 40,000 data that can predict the absorptivity spectrum given a text prompt that only specifies the metasurface geometry. Results are compared to conventional machine learning approaches including feed-forward neural networks, random forest, linear regression, and K-nearest neighbor (KNN). Remarkably, the fine-tuned LLM (FT-LLM) achieves a comparable performance across large dataset sizes with a deep neural network. We also explore inverse problems by asking the LLM to predict the geometry necessary to achieve a desired spectrum. LLMs possess several advantages over humans that may give them benefits for research, including the ability to process enormous amounts of data, find hidden patterns in data, and operate in higher-dimensional spaces. This suggests they may be able to leverage their general knowledge of the world to learn faster from training data than traditional models, making them valuable tools for research and analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3552418",
            "Date of Publication": "18 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Darui Lu",
                "labs": [
                    "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA"
                ]
            },
            {
                "name": "Yang Deng",
                "labs": [
                    "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA"
                ]
            },
            {
                "name": "Jordan M. Malof",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Willie J. Padilla",
                "labs": [
                    "Department of Electrical and Computer Engineering, Duke University, Durham, NC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Geometry",
                "Metasurfaces",
                "Chatbots",
                "Vectors",
                "Training",
                "Encoding",
                "Data models",
                "Predictive models",
                "Physics",
                "Electromagnetic metamaterials"
            ],
            "Author Keywords": [
                "Metamaterial",
                "large language model",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A Write-Buffer Scheme to Protect Cache Memories Against Multiple-Bit Errors",
        "Link": "https://ieeexplore.ieee.org/document/9857910/",
        "Abstract": "Protecting cache memories against radiation-induced soft errors is critical in designing highly reliable processors. Dirty lines in write-back data caches are more critical, since the dirty lines have no backups in lower-level memory (LLM). This paper provides a write-buffer scheme for backing up dirty lines to protect cache memories based on the replication mechanism combined with interleaving parity check against multiple-bit errors. The write-buffer contains two same replication caches to replicate the dirty data from the original cache, and the two replication caches take turns to write the replicated data back to LLM during the free time when there is no access in LLM. In this way, the dirty data in original cache is backed up to LLM that can be used for error recovery, and meanwhile, spaces of the replication caches are released to replicate new dirty data; moreover, the writebacks of the replicated data can be performed in the background without extra clocks. Simulation results show that the proposed write-buffer scheme can provide a full protection for caches without degrading system performance, while it can improve the system performance by an average of 1.4% due to the background writebacks, and compared with state-of-the-art replication-based technique, it can increase the replication capability by 11.6% and save 6.2% energy consumption in case of the optimal configuration. It is superior to the existing techniques in terms of protection capability and system performance overhead.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3198989",
            "Date of Publication": "16 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jie Li",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Liyi Xiao",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Linzhe Li",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Hongchen Li",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "He Liu",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Chenxu Wang",
                "labs": [
                    "Microelectronic Center, Harbin Institute of Technology, Harbin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Arrays",
                "Program processors",
                "Error correction codes",
                "System performance",
                "Parity check codes",
                "Delays",
                "Cache memory"
            ],
            "Author Keywords": [
                "Soft error",
                "reliability",
                "parity check",
                "write-buffer",
                "cache"
            ]
        }
    },
    {
        "Title": "Lateral Phishing With Large Language Models: A Large Organization Comparative Study",
        "Link": "https://ieeexplore.ieee.org/document/10943116/",
        "Abstract": "The emergence of Large Language Models (LLMs) has heightened the threat of phishing emails by enabling the generation of highly targeted, personalized, and automated attacks. Traditionally, many phishing emails have been characterized by typos, errors, and poor language. These errors can be mitigated by LLMs, potentially lowering the barrier for attackers. Despite this, there is a lack of large-scale studies comparing the effectiveness of LLM-generated lateral phishing emails to those crafted by humans. Current literature does not adequately address the comparative effectiveness of LLM and human-generated lateral phishing emails in a real-world, large-scale organizational setting, especially considering the potential for LLMs to generate more convincing and error-free phishing content. To address this gap, we conducted a pioneering study within a large university, targeting its workforce of approximately 9,000 individuals including faculty, staff, administrators, and student workers. Our results indicate that LLM-generated lateral phishing emails are as effective as those written by communications professionals, emphasizing the critical threat posed by LLMs in leading phishing campaigns. We break down the results of the overall phishing experiment, comparing vulnerability between departments and job roles. Furthermore, to gather qualitative data, we administered a detailed questionnaire, revealing insights into the reasons and motivations behind vulnerable employee’s actions. This study contributes to the understanding of cyber security threats in educational institutions and provides a comprehensive comparison of LLM and human-generated phishing emails’ effectiveness, considering the potential for LLMs to generate more convincing content. The findings highlight the need for enhanced user education and system defenses to mitigate the growing threat of AI-powered phishing attacks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3555500",
            "Date of Publication": "27 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mazal Bethany",
                "labs": [
                    "Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA",
                    "Secure AI and Autonomy Laboratory, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Athanasios Galiopoulos",
                "labs": [
                    "Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Emet Bethany",
                "labs": [
                    "Secure AI and Autonomy Laboratory, San Antonio, TX, USA",
                    "Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Mohammad Bahrami Karkevandi",
                "labs": [
                    "Secure AI and Autonomy Laboratory, San Antonio, TX, USA",
                    "Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Nicole Beebe",
                "labs": [
                    "Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Nishant Vishwamitra",
                "labs": [
                    "Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Peyman Najafirad",
                "labs": [
                    "Department of Information Systems and Cyber Security, The University of Texas at San Antonio, San Antonio, TX, USA",
                    "Secure AI and Autonomy Laboratory, San Antonio, TX, USA",
                    "Department of Computer Science, The University of Texas at San Antonio, San Antonio, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Electronic mail",
                "Organizations",
                "Large language models",
                "Computer crime",
                "Training",
                "Social networking (online)",
                "Prevention and mitigation",
                "Market research",
                "Internet"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "cybersecurity",
                "disinformation",
                "generative AI",
                "large language models",
                "phishing",
                "text generation"
            ]
        }
    },
    {
        "Title": "A Review of Large Language Models for Energy Systems: Applications, Challenges, and Future Prospects",
        "Link": "https://ieeexplore.ieee.org/document/11168242/",
        "Abstract": "Rapid developments in large language models (LLMs) have created new opportunities for their use in the energy sector, from forecasting renewable energy to power system operation and energy market analysis. These models help improve decision-making, anomaly detection, and optimization procedures in intricate energy systems by using vast amounts of structured and unstructured data. This study provides a comprehensive review of the LLM origins, evaluation, and fine-tuning techniques as well as their integration into energy systems, including their application in fault detection and diagnosis, energy forecasting, document automation, energy management, defect detection, and power system operation. Their performance in terms of explainability, generalization ability, and scalability for energy-related applications is critically examined in this paper. The report also emphasizes significant challenges to the adoption of LLMs, such as the need for computing power, the lack of data, and ethical issues like bias and false information. Power-efficient models, hybrid artificial intelligence (AI) platforms, and domain-specific fine-tuning are some of the solutions discussed. Future areas of interest include multi-modality to obtain maximal forecasting and operational intelligence, real-time adaptability, and explainable. This paper summarizes current developments and provides information on LLM-driven innovation in energy systems while maintaining transparency and dependability. Compared with prior LLM–energy surveys that either remain general-purpose or focus on a single subdomain, this review fills three concrete gaps: (i) a cross-domain synthesis of energy-specific LLM applications spanning power systems, buildings, and forecasting; (ii) a methods-oriented consolidation of evaluation and parameter-efficient fine-tuning practices tailored to energy tasks; and (iii) a deployment-centric analysis of real-time and edge constraints (energy, latency, hardware) with a practical reporting checklist for operational adoption.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3610994",
            "Date of Publication": "17 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hamid Mirshekali",
                "labs": [
                    "SDU Center for Energy Informatics, Faculty of Engineering, Mærsk Mc-Kinney Moeller Institute, University of Southern Denmark (SDU), Odense, Denmark"
                ]
            },
            {
                "name": "Mohammad Reza Shadi",
                "labs": [
                    "SDU Center for Energy Informatics, Faculty of Engineering, Mærsk Mc-Kinney Moeller Institute, University of Southern Denmark (SDU), Odense, Denmark"
                ]
            },
            {
                "name": "Fatemehsadat Ghanadi Ladani",
                "labs": [
                    "Department of Electrical and Computer Engineering, Isfahan University of Technology, Isfahan, Iran"
                ]
            },
            {
                "name": "Hamid Reza Shaker",
                "labs": [
                    "SDU Center for Energy Informatics, Faculty of Engineering, Mærsk Mc-Kinney Moeller Institute, University of Southern Denmark (SDU), Odense, Denmark"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Forecasting",
                "Predictive models",
                "Reviews",
                "Artificial intelligence",
                "Load modeling",
                "Buildings",
                "Power systems",
                "Scalability",
                "Renewable energy sources",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Large language models",
                "energy systems",
                "fault detection and diagnosis",
                "explainable artificial intelligence",
                "energy forecasting"
            ]
        }
    },
    {
        "Title": "MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning",
        "Link": "https://ieeexplore.ieee.org/document/10577164/",
        "Abstract": "In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3420709",
            "Date of Publication": "28 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ching Nam Hang",
                "labs": [
                    "Yam Pak Charitable Foundation School of Computing and Information Sciences, Saint Francis University, Hong Kong, China"
                ]
            },
            {
                "name": "Chee Wei Tan",
                "labs": [
                    "College of Computing and Data Science, Nanyang Technological University, Jurong West, Singapore"
                ]
            },
            {
                "name": "Pei-Duo Yu",
                "labs": [
                    "Department of Applied Mathematics, Chung Yuan Christian University, Taoyuan, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Knowledge engineering",
                "Testing",
                "Knowledge based systems",
                "Task analysis",
                "Semantics",
                "Problem-solving",
                "Large language models",
                "Information retrieval",
                "Data augmentation"
            ],
            "Author Keywords": [
                "Large language models",
                "multiple-choice questions",
                "personalized learning",
                "prompt engineering",
                "retrieval-augmented generation"
            ]
        }
    },
    {
        "Title": "LLM4CP: Adapting Large Language Models for Channel Prediction",
        "Link": "https://ieeexplore.ieee.org/document/10582829/",
        "Abstract": "Channel prediction is an effective approach for reducing the feedback or estimation overhead in massive multi-input multi-output (m-MIMO) systems. However, existing channel prediction methods lack precision due to model mismatch errors or network generalization issues. Large language models (LLMs) have demonstrated powerful modeling and generalization abilities, and have been successfully applied to cross-modal tasks, including the time series analysis. Leveraging the expressive power of LLMs, we propose a pre-trained LLM-empowered channel prediction (LLM4CP) method to predict the future downlink channel state information (CSI) sequence based on the historical uplink CSI sequence. We fine-tune the network while freezing most of the parameters of the pre-trained LLM for better cross-modality knowledge transfer. To bridge the gap between the channel data and the feature space of the LLM, preprocessor, embedding, and output modules are specifically tailored by taking into account unique channel characteristics. Simulations validate that the proposed method achieves state-of-the-art (SOTA) prediction performance on full-sample, few-shot, and generalization tests with low training and inference costs.",
        "Details": {
            "DOI": "10.23919/JCIN.2024.10582829",
            "Date of Publication": "June 2024",
            "Publisher": "PTP",
            "Published In": "Journal of Communications and Information Networks"
        },
        "issn_info": {
            "Print ISSN": "2096-1081",
            "Electronic ISSN": "2509-3312"
        },
        "authors_data": [
            {
                "name": "Boxun Liu",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing 100871, China"
                ]
            },
            {
                "name": "Xuanyu Liu",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing 100871, China"
                ]
            },
            {
                "name": "Shijian Gao",
                "labs": [
                    "Internet of Things Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou 511400, China"
                ]
            },
            {
                "name": "Xiang Cheng",
                "labs": [
                    "State Key Laboratory of Advanced Optical Communication Systems and Networks, School of Electronics, Peking University, Beijing 100871, China"
                ]
            },
            {
                "name": "Liuqing Yang",
                "labs": [
                    "Internet of Things Thrust and Intelligent Transportation Thrust, The Hong Kong University of Science and Technology (Guangzhou), Guangzhou 511400, China; Department of Electronic and Computer Engineering and Department of Civil and Environmental Engineering, The Hong Kong University of Science and Technology, Hong Kong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Downlink",
                "Channel estimation",
                "Task analysis",
                "Predictive models",
                "Time-frequency analysis",
                "Uplink",
                "Vectors"
            ],
            "Author Keywords": [
                "channel prediction",
                "massive multi-input multi-output (m-MIMO)",
                "large language models (LLMs)",
                "fine-tuning",
                "time-series"
            ]
        }
    },
    {
        "Title": "TelecomGPT: A Framework to Build Telecom-Specific Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11097898/",
        "Abstract": "The emergent field of Large Language Models (LLMs) has significant potential to revolutionize how future telecom networks are designed and operated. However, mainstream Large Language Models (LLMs) lack the specialized knowledge required to understand and operate within the highly technical telecom domain. In this paper, we introduce TelecomGPT, the first telecom-specific LLM, built through a systematic adaptation pipeline designed to enhance general-purpose LLMs for telecom applications. To achieve this, we curate comprehensive telecom-specific datasets, including pre-training datasets, instruction datasets, and preference datasets. These datasets are leveraged for continual pre-training, instruction tuning, and alignment tuning, respectively. Additionally, due to the lack of widely accepted evaluation benchmarks that are tailored for the telecom domain, we proposed three novel LLM-Telecom evaluation benchmarks, namely, Telecom Math Modeling, Telecom Open QnA, and Telecom Code Tasks. These new benchmarks provide a holistic evaluation of the capabilities of LLMs in telecom math modeling, open-ended question answering, code generation, infilling, summarization and analysis. Using the curated datasets, our fine-tuned LLM, TelecomGPT, significantly outperforms general-purpose state of the art (SOTA) LLMs, including GPT-4, Llama-3 and Mistral, particularly in Telecom Math Modeling benchmarks. Additionally, it achieves comparable performance across various evaluation benchmarks, such as TeleQnA, 3GPP technical document classification, telecom code summarization, generation, and infilling. This work establishes a new foundation for integrating LLMs into telecom systems, paving the way for AI-powered advancements in network operations.",
        "Details": {
            "DOI": "10.1109/TMLCN.2025.3593184",
            "Date of Publication": "28 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Machine Learning in Communications and Networking"
        },
        "issn_info": {
            "Electronic ISSN": "2831-316X"
        },
        "authors_data": [
            {
                "name": "Hang Zou",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Qiyang Zhao",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Yu Tian",
                "labs": [
                    "Department of Computer and Information Engineering, KU 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Lina Bariah",
                "labs": [
                    "Department of Computer and Information Engineering, KU 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Faouzi Bader",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Thierry Lestable",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Merouane Debbah",
                "labs": [
                    "Department of Computer and Information Engineering, KU 6G Research Center, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Telecommunications",
                "Training",
                "Tuning",
                "Codes",
                "Benchmark testing",
                "Adaptation models",
                "Standards",
                "Retrieval augmented generation",
                "Finance",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Generative AI",
                "large language models",
                "3GPP",
                "telecom foundation models"
            ]
        }
    },
    {
        "Title": "Effect of Explainable Artificial Intelligence on Trust of Mental Health Professionals in an AI-Based System for Suicide Prevention",
        "Link": "https://ieeexplore.ieee.org/document/10945851/",
        "Abstract": "Artificial Intelligence (AI)-based systems have been proposed to aid Mental Health Professionals (MHPs) in various tasks, including the prevention of suicide by identifying Suicidal Ideation (SI). However, these systems may lack transparency and thereby create mistrust among MHPs. Explainable Artificial Intelligence (XAI) methods can elucidate how features influence system predictions, aiding MHPs in understanding them. This exploratory study aims to investigate how MHPs’ trust is influenced by AI explanations (educational intervention and XAI methods) and other factors (professional background, knowledge of AI and computing, and reported system misclassification). We conducted an experiment using Boamente, an AI-powered clinical decision support system designed to assist MHPs in suicide prevention. Boamente identifies SI in Brazilian Portuguese texts typed on smartphones by leveraging a Large Language Model (LLM) for analysis. The results demonstrate that professional background, knowledge of AI and computing, and educational intervention had no statistically significant effect on trust. In contrast, trust was affected by factors such as LLM prediction explanations, the quality of explanations, and reported misclassification. Therefore, providing prediction explanations to understand the inner workings of AI models led MHPs to be more critical in relation to predictions, while there was an overtrust on MHPs when no explanations were provided. Furthermore, disagreement with LLM classifications and perceptions of system vulnerabilities also affected trust.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3556245",
            "Date of Publication": "31 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Adonias Caetano de Oliveira",
                "labs": [
                    "Programa de Pós-Graduação em Biotecnologia (PPGBiotec), Universidade Federal do Delta do Parnaíba, Parnaíba, Brazil",
                    "Instituto Federal do Ceará, Tianguá, Brazil"
                ]
            },
            {
                "name": "João Pedro Cavalcanti Azevedo",
                "labs": [
                    "Programa de Pós-graduação em Ciência da Computação (PPGCC), Universidade Federal do Maranhão, São Luís, Brazil"
                ]
            },
            {
                "name": "Lívia Ruback",
                "labs": [
                    "Faculdade de Tecnologia (FT), Universidade Estadual de Campinas, Campinas, Brazil"
                ]
            },
            {
                "name": "Rayele Moreira",
                "labs": [
                    "Programa de Pós-Graduação em Biotecnologia (PPGBiotec), Universidade Federal do Delta do Parnaíba, Parnaíba, Brazil"
                ]
            },
            {
                "name": "Silmar Silva Teixeira",
                "labs": [
                    "Programa de Pós-Graduação em Biotecnologia (PPGBiotec), Universidade Federal do Delta do Parnaíba, Parnaíba, Brazil"
                ]
            },
            {
                "name": "Ariel Soares Teles",
                "labs": [
                    "Programa de Pós-Graduação em Biotecnologia (PPGBiotec), Universidade Federal do Delta do Parnaíba, Parnaíba, Brazil",
                    "Programa de Pós-graduação em Ciência da Computação (PPGCC), Universidade Federal do Maranhão, São Luís, Brazil",
                    "Instituto Federal do Maranhão, Araioses, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Mental health",
                "Glass box",
                "Prevention and mitigation",
                "Medical services",
                "Explainable AI",
                "Smart phones",
                "Monitoring",
                "Closed box",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Explainable artificial intelligence",
                "trust",
                "medical AI",
                "mental health",
                "suicide",
                "digital phenotyping"
            ]
        }
    },
    {
        "Title": "AIvaluate: A Multi-Agent Framework for Automated Answer Script Evaluation Using Large Language Models and Semantic Vector Indexing",
        "Link": "https://ieeexplore.ieee.org/document/11155081/",
        "Abstract": "In conventional educational environments, it is labor-intensive, subjective, and susceptible to human error to hand-mark descriptive answers. This article introduces AIvaluate, a modular, rubric-guided multi-agent system for theory-based student answer script marking automation. The system combines Optical Character Recognition (OCR) using Azure Document Intelligence with a Cleaning Agent powered by a Large Language Model (LLM) hosted on Azure AI Foundry that cleans the text obtained without losing semantic information and ensures anonymization. Answers are parsed using RegEx to de-sentence question identifiers and mapped into corresponding correct answers and faculty-defined marking schemes in a MongoDB database. The system supports structured input prompts, where rubrics are dynamically injected into the evaluation context for consistency and flexibility across subjects. An Evaluation Agent, also driven by the LLM, matches the sanitized student answer to the correct answer and provides both a score and one-line feedback. To supplement this generative scoring, a semantic similarity-based scoring is employed via FAISS and the all-MiniLM-L6-v2 transformer model; however, this vector-based pipeline is used purely for research benchmarking and does not contribute to the final marks. Experimental outcomes indicate strong correlation between AI-computed scores and human faculty ratings, particularly in the LLM-based pipeline. This system is designed particularly for technical and theory-based academic tests, and not for literary or creative questions where language usage is the prevailing criterion. The suggested approach reduces evaluation time by approximately 70–80% compared to manual correction, without compromising fairness and transparency.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3608158",
            "Date of Publication": "10 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "P. Suryakumar",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "A. Malini",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "S. K. Subasini",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "G. Priyanka",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "V. Sandhiya",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical character recognition",
                "Semantics",
                "Pipelines",
                "Large language models",
                "Cleaning",
                "Vectors",
                "Information integrity",
                "Information filtering",
                "Data privacy",
                "Transformers"
            ],
            "Author Keywords": [
                "Subjective answer evaluation",
                "rubric-guided large language models",
                "educational assessment automation",
                "multi-agent systems",
                "fairness in AI-based grading"
            ]
        }
    },
    {
        "Title": "A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems",
        "Link": "https://ieeexplore.ieee.org/document/11143218/",
        "Abstract": "Increased reliance on automation and connectivity exposes transportation cyber-physical systems (CPS) to many cyber vulnerabilities. Existing threat modeling frameworks are often narrow in scope, labor-intensive, and require substantial cybersecurity expertise. To this end, we introduce the Transportation Cybersecurity and Resiliency Threat Modeling Framework (TraCR-TMF), a large language model (LLM)-based threat modeling framework for transportation CPS that requires limited cybersecurity expert intervention. TraCR-TMF identifies threats, potential attack techniques (i.e., methods to exploit vulnerabilities), and relevant countermeasures (e.g., attack detection and mitigation strategies) for transportation CPS. Three LLM-based approaches support these identifications: (i) a retrieval-augmented generation approach requiring no cybersecurity expert intervention, (ii) an in-context learning approach with low intervention from cybersecurity experts, and (iii) a supervised fine-tuning approach with moderate cybersecurity expert intervention. TraCR-TMF offers LLM-based attack path identification for critical assets based on vulnerabilities across different transportation CPS entities. Additionally, it incorporates the Common Vulnerability Scoring System (CVSS) scores of previously exploited vulnerabilities to prioritize threat mitigations. The framework was evaluated through two use cases. First, the framework identified relevant attack techniques for various transportation CPS applications, about 73% of which were validated by cybersecurity experts as correct. Second, the framework was used to identify attack paths for a target asset in a real-world cyberattack incident. TraCR-TMF successfully predicted exploitations, like lateral movement of adversaries, data exfiltration, and data encryption for ransomware, as reported in the incident. These findings demonstrate TraCR-TMF’s efficacy in transportation CPS threat modeling while reducing the need for extensive involvement of cybersecurity experts. To facilitate real-world adoption, all our codes are shared via an open-source repository.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3603580",
            "Date of Publication": "29 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M Sabbir Salek",
                "labs": [
                    "Glenn Department of Civil Engineering, Clemson University, Clemson, SC, USA"
                ]
            },
            {
                "name": "Mashrur Chowdhury",
                "labs": [
                    "Glenn Department of Civil Engineering, Clemson University, Clemson, SC, USA"
                ]
            },
            {
                "name": "Muhaimin Bin Munir",
                "labs": [
                    "Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA"
                ]
            },
            {
                "name": "Yuchen Cai",
                "labs": [
                    "Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA"
                ]
            },
            {
                "name": "Mohammad Imtiaz Hasan",
                "labs": [
                    "Glenn Department of Civil Engineering, Clemson University, Clemson, SC, USA"
                ]
            },
            {
                "name": "Jean-Michel Tine",
                "labs": [
                    "Glenn Department of Civil Engineering, Clemson University, Clemson, SC, USA"
                ]
            },
            {
                "name": "Latifur Khan",
                "labs": [
                    "Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA"
                ]
            },
            {
                "name": "Mizanur Rahman",
                "labs": [
                    "Department of Civil, Construction, and Environmental Engineering, The University of Alabama, Tuscaloosa, AL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Threat modeling",
                "Transportation",
                "Computer security",
                "Prevention and mitigation",
                "Mathematical models",
                "Resilience",
                "Data models",
                "Cyberattack",
                "Analytical models",
                "Large language models"
            ],
            "Author Keywords": [
                "Threat modeling",
                "cybersecurity",
                "large language model",
                "intelligent transportation systems",
                "transportation cyber-physical systems"
            ]
        }
    },
    {
        "Title": "A Systematic Literature Review on Large Language Models Applications in Computer Programming Teaching Evaluation Process",
        "Link": "https://ieeexplore.ieee.org/document/11058691/",
        "Abstract": "Tools based on the use of Large Language Models (LLMs) have improved the computer programming teaching process, automated feedback processes, facilitated program repair, and enabled personalized learning experiences. This research examines which and how LLM-based opportunities are applied in the computer programming teaching assessment process and how LLMs are applied to improve evaluation accuracy, their impact on student learning outcomes, and the challenges in scaling these technologies. Key opportunities arise from prompt engineering, which optimizes precision and LLM-generated feedback relevance, and feedback propagation techniques, which offer scalable solutions for large-scale programming courses. LLMs are also applied effectively in debugging assistance to detect and repair syntactic and semantic errors in student code. This review identifies several research directions, including prompt engineering refinement, improved feedback system scalability, and deeper exploration of the long-term educational impacts of LLM. The study concludes that LLMs are effective in enhancing the assessment process, but a balanced approach combining human oversight with automated feedback is crucial to fostering critical thinking and ensuring long-term learning success in programming education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3584060",
            "Date of Publication": "30 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Andre Fabiano Pereira",
                "labs": [
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Pernambuco, Brazil"
                ]
            },
            {
                "name": "Rafael Ferreira Mello",
                "labs": [
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Pernambuco, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Programming profession",
                "Maintenance engineering",
                "Debugging",
                "Databases",
                "Codes",
                "Scalability",
                "Real-time systems",
                "Large language models",
                "Accuracy"
            ],
            "Author Keywords": [
                "Programming education",
                "assessment processes",
                "large language models",
                "adaptive learning"
            ]
        }
    },
    {
        "Title": "Adaptive Spelling in Immersive Reality: The Impact of Gamified VR and LLMs on Young Learners’ English Color Word Acquisition",
        "Link": "https://ieeexplore.ieee.org/document/11087543/",
        "Abstract": "Spelling is a crucial language skill, yet traditional instruction often relies on rote memorization rather than meaningful learning. Despite various approaches to spelling instruction, the potential of virtual reality (VR) along with the integration of gamification and LLMs, remains underexplored. This study explores a VR-based, gamified approach using LLM-driven adaptive learning to improve spelling acquisition of English color words among young learners. The study employed a quasi-experimental, pre-test-post-test design with a control group. The participants were 50 male students aged 10, divided into an experimental group (N=25) that used the LLM-enhanced VR game and a control group (N=25) that received traditional instruction. The VR intervention consisted of a three-stage game built on the whole-word approach, featuring gamified elements and adaptive feedback from an LLM. Data were collected via spelling tests (pre-test, immediate post-test, and delayed post-test), user experience surveys, and semi-structured interviews. Results showed that the VR-based approach, significantly improved spelling performance and engagement. Specifically, the experimental group demonstrated substantially higher scores in both immediate vocabulary uptake and long-term retention after one week compared to the control group. Furthermore, qualitative and survey data indicated the VR experience was perceived as significantly more interesting, effective, and motivating. These findings highlight the potential of immersive, gamified learning environments to enhance spelling education, offering an effective alternative to conventional methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3591114",
            "Date of Publication": "21 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jalal Safari Bazargani",
                "labs": [
                    "Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea"
                ]
            },
            {
                "name": "Abolghasem Sadeghi-Niaraki",
                "labs": [
                    "Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea"
                ]
            },
            {
                "name": "Xinyu Shi",
                "labs": [
                    "Department of Korean Linguistics, The Academy of Korean Studies, Seongnam-si, Gyeonggi-do, South Korea"
                ]
            },
            {
                "name": "Soo-Mi Choi",
                "labs": [
                    "Department of Computer Science and Engineering and Convergence Engineering for Intelligent Drone, XR Research Center, Sejong University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vocabulary",
                "Games",
                "Education",
                "Focusing",
                "Color",
                "Visualization",
                "Surveys",
                "Production",
                "Interviews",
                "Information and communication technology"
            ],
            "Author Keywords": [
                "Virtual reality",
                "gamification",
                "VR learning environment",
                "spelling",
                "vocabulary acquisition"
            ]
        }
    },
    {
        "Title": "Will GPT-4 Run DOOM?",
        "Link": "https://ieeexplore.ieee.org/document/10752360/",
        "Abstract": "We show that GPT-4’s reasoning and planning capabilities extend to the 1993 first-person shooter Doom. This large language model (LLM) is able to run and play the game with only a few instructions, plus a textual description–generated by the model itself from screenshots–about the state of the game being observed. We find that GPT-4 can play the game to a passable degree: it is able to manipulate doors, combat enemies, and perform pathing. More complex prompting strategies involving multiple model calls provide better results. While further work is required to enable the LLM to play the game as well as its classical, reinforcement learning-based counterparts, we note that GPT-4 required no training, leaning instead on its own reasoning and observational capabilities. We hope our work pushes the boundaries on intelligent, LLM-based agents in video games. We conclude by discussing the ethical implications of our work.",
        "Details": {
            "DOI": "10.1109/TG.2024.3497601",
            "Date of Publication": "13 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Games"
        },
        "issn_info": {
            "Print ISSN": "2475-1502",
            "Electronic ISSN": "2475-1510"
        },
        "authors_data": [
            {
                "name": "Adrian de Wynter",
                "labs": [
                    "University of York, York, U.K.",
                    "Microsoft, Redmond, WA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Video games",
                "Codes",
                "Weapons",
                "Games",
                "Benchmark testing",
                "Cognition",
                "Regulation",
                "Planning",
                "Reliability"
            ],
            "Author Keywords": [
                "Doom",
                "first-person shooter (FPS)",
                "GPT-4",
                "planning",
                "reasoning"
            ]
        }
    },
    {
        "Title": "Identifying Learning Leaders in Online Social Networks Based on Community of Practice Theoretical Framework and Information Entropy",
        "Link": "https://ieeexplore.ieee.org/document/10639392/",
        "Abstract": "The dynamic shifts in educational settings have led scholars to explore online social networks (OSNs) as emergent environment for learning communities. Recognized for their effectiveness in fostering lifelong learning, these online groups surpass traditional educational methods in scope and impact. However, they require meticulous management to maintain efficacy and facilitate knowledge sharing. Addressing this need, the current study introduces the objective of identifying and defining learning leaders to aid in the management of these learning communities. To achieve this, two innovative metrics have been developed, rooted in the theoretical framework of Community of Practice (CoP) and the principles of information entropy: the Learning Leader Metric (LLM) and the Weighted Learning Leader Metric (WLLM). The LLM evaluates three key areas: Learning Engagement, Expertise, and Domain Relevance, forming a comprehensive tripartite framework. In contrast, the WLLM enhances this evaluation by applying information entropy to assign varying weights to these dimensions, thus refining the assessment process while preserving computational efficiency. These metrics operate in an unsupervised manner, addressing the challenge of the absence of annotated data which is a common hurdle in supervised learning scenarios, particularly in information retrieval tasks. Tested against five established expert finding models, the empirical results of this study confirm that both LLM and WLLM demonstrate superior effectiveness in accurately identifying highly relevant experts compared to other models considered in the analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3446454",
            "Date of Publication": "19 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hend Aldahmash",
                "labs": [
                    "College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia",
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulrahman Alothaim",
                "labs": [
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulrahman Mirza",
                "labs": [
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Knowledge engineering",
                "Information entropy",
                "Blogs",
                "Object recognition",
                "Electronic learning"
            ],
            "Author Keywords": [
                "Expert finding",
                "learning leaders",
                "Twitter",
                "community of practice",
                "learning",
                "social media"
            ]
        }
    },
    {
        "Title": "ISAC-Driven Software Development With Large Language Models: A Foundation for Enhanced Public Life Support",
        "Link": "https://ieeexplore.ieee.org/document/10921710/",
        "Abstract": "The rapid evolution of integrated sensing and communication (ISAC) technologies has created an unprecedented data overflow, making traditional analysis methods obsolete. The emergence of large language models (LLMs) such as ChatGPT has revolutionized various fields, including software engineering, by enabling the development of novel communication-aware software applications. This study explores the synergy between ISAC and LLMs in software development, using the Internet of Vehicle-Monitoring Software as a case study. The experimental data shows that without LLM, the average packet loss rate increases from 0.2% to 1.2%. It can be seen that the potential of ISAC-LLM integration is to release new opportunities for data-driven innovation by combining communication awareness technology with large-scale software development. By integrating communication awareness technology with large-scale software development, the potential of ISAC-LLM convergence is demonstrated in unlocking new opportunities for data-driven innovation. The research lays the foundation for further exploring the capabilities of LLMs in software development and harnessing their potential for transformative impact.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3550156",
            "Date of Publication": "11 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yaqiong Huang",
                "labs": [
                    "Jiangxi Tourism and Commerce Vocational College, Nanchang, China"
                ]
            },
            {
                "name": "Xin Jin",
                "labs": [
                    "Jiangxi Tourism and Commerce Vocational College, Nanchang, China"
                ]
            },
            {
                "name": "Li Zhang",
                "labs": [
                    "Jiangxi Tourism and Commerce Vocational College, Nanchang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software development management",
                "Software",
                "Artificial intelligence",
                "Radar",
                "Integrated sensing and communication",
                "Internet of Vehicles",
                "Computer applications",
                "Databases",
                "Business",
                "Software systems"
            ],
            "Author Keywords": [
                "ISAC",
                "vehicle networking",
                "software development",
                "AI"
            ]
        }
    },
    {
        "Title": "Adaptive Federated Learning With Local Large Language Models for Modeling Photonic and Chemical Systems",
        "Link": "https://ieeexplore.ieee.org/document/11153460/",
        "Abstract": "We present AFL–L, an LLM-augmented federated learning (FL) framework for modeling photonic devices and chemical reactions under strict data-privacy constraints. Each client enriches its local data with a domain-specific prompt to a frozen large language model (LLM), then performs proximal-regularized updates that are aggregated on the server under the Gaussian mechanism with client-level\nℓ\n2\nclipping. Each update is clipped to a fixed radius C, yielding per-round sensitivity\nS\nr\n=2C/m\nfor m participating clients, and noise scaled by\nσ\nensures rigorous\n(ε,δ)\n-DP. We provide theoretical guarantees, proving an\nO(\nT\n−1/2\n)\nworst-client descent rate for non-convex objectives and a linear rate under\nγ\n-strong convexity, consistent with the empirical decay of gradient norms. On two real-world benchmarks, AFL–L improves low-percentile client accuracy by\n4−7\npoints and reduces communication volume by\n1.8×\ncompared to FedProx. Grounding prompts in cognitive semantics enables the LLM to bridge symbolic descriptors (reaction schemas, device layouts) and sub-symbolic representations, showing that meaning-aware conditioning—not mere token frequency—drives the observed gains. Finally, we sketch an extension toward a federation of heterogeneous expert models, where secure aggregation can combine updates from specialized LLMs or surrogate genetic-algorithm experts without compromising convergence or privacy guarantees.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3606855",
            "Date of Publication": "08 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Koffka Khan",
                "labs": [
                    "Department of Computing and Information Technology, The University of the West Indies, St. Augustine Campus, St. Augustine, Trinidad and Tobago"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Photonics",
                "Federated learning",
                "Training",
                "Chemistry",
                "Adaptation models",
                "Servers",
                "Privacy",
                "Large language models",
                "Convergence"
            ],
            "Author Keywords": [
                "Federated learning",
                "large language models",
                "differential privacy",
                "photonic and chemical modeling",
                "cognitive semantics"
            ]
        }
    },
    {
        "Title": "Leveraging Large Language Models for Enhanced Back-Translation: Techniques and Applications",
        "Link": "https://ieeexplore.ieee.org/document/10947762/",
        "Abstract": "Cross-cultural studies are prevalent in academia, yet challenges arise in conducting objective research due to linguistic and cultural disparities. Rigorous international comparative research requires appropriate questionnaires that can be used in all countries, and translation becomes an extremely important process. Brislin’s back-translation method is widely recognized, but it usually requires many skilled bilingual translators and is both time-consuming and expensive. This study aims to overcome these limitations by using Large Language Model (LLM) AI technology. We utilized the Application Programming Interfaces (APIs) of well-known commercial LLM models such as ChatGPT3.5, ChatGPT4o, Google-Gemini, and Anthropic-Claude 3. The entire program was built using the Python programming language, and the user interface was built using the Streamlit library. This pilot study’s results confirm the feasibility of LLM-assisted back-translation, particularly for complex topics like carbon footprint reduction planning. This represents a significant advance over traditional back-translation methods, offering substantial time and cost savings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3557014",
            "Date of Publication": "02 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ji-Bum Chung",
                "labs": [
                    "Department of Civil, Urban, Earth, and Environmental Engineering, Ulsan National Institute of Science and Technology, Ulsan, Republic of Korea"
                ]
            },
            {
                "name": "Taehyun Kim",
                "labs": [
                    "Division for Environmental Planning, Korea Environment Institute (KEI), Sejong, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Translation",
                "Instruments",
                "Machine translation",
                "Cultural differences",
                "Surveys",
                "Large language models",
                "Vectors",
                "User interfaces",
                "Python",
                "Prevention and mitigation"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "machine translation",
                "cross-cultural communication"
            ]
        }
    },
    {
        "Title": "LLMs on a Budget: System-Level Approaches to Power-Efficient and Scalable Fine-Tuning",
        "Link": "https://ieeexplore.ieee.org/document/11037824/",
        "Abstract": "Large Language Models (LLMs) have shown remarkable capabilities in various applications, including robotics, telecommunications, and scientific discovery. While much attention has been given to LLM inference and training phases, fine-tuning has received less focus despite its increasing cost, especially from a systems perspective. Fine-tuning is especially important for customizing compact models for edge applications, such as personal assistants running on local devices and models personalized with user-specific data, which in turn requires a deeper examination of fine-tuning performance and efficiency on single-GPU systems. Fine-tuning large models involves intensive matrix operations from backpropagation and gradient updates, which require extensive power and memory usage. In order to explore the range of performance optimization opportunities available to improve the LLM fine-tuning runtime, we understand the impact of techniques like activation checkpointing, low-rank adaptation, and operation fusion on LLM fine-tuning runtime optimization. In addition, we explore the effects of resource utilization through GPU peak power capping. Our experiments, conducted on NVIDIA RTX 4090 GPU using Meta’s LLaMA-3.1, Google’s Gemma, and Microsoft’s Phi-3, reveal that enabling all optimizations reduces memory usage by over 40% compared to FP32 baselines. Moreover, power capping to 300 W results in an average throughput drop of only 5.55% while reducing power consumption by 33%. Post-fine-tuning accuracy improvements on the Sycophancy Evaluation Benchmark range from 2% to 5%, depending on model architecture, validating that our optimization techniques preserve model quality while reducing resource requirements. Furthermore, we discuss several insights and potential future research directions from a systems perspective.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3580498",
            "Date of Publication": "17 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Kailash Gogineni",
                "labs": [
                    "George Washington University, Washington, DC, USA"
                ]
            },
            {
                "name": "Ali Suvizi",
                "labs": [
                    "George Washington University, Washington, DC, USA"
                ]
            },
            {
                "name": "Guru Venkataramani",
                "labs": [
                    "George Washington University, Washington, DC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Computational modeling",
                "Optimization",
                "Graphics processing units",
                "Memory management",
                "Costs",
                "Data models",
                "Internet",
                "Tuning",
                "Training"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "large language models",
                "fine-tuning",
                "power efficiency"
            ]
        }
    },
    {
        "Title": "Semi-Automatic BVI Human-Centered Image Conversational Descriptions: Leveraging LLMs and Expert Refinements for Inclusive Visual Accessibility",
        "Link": "https://ieeexplore.ieee.org/document/11146787/",
        "Abstract": "Ensuring that blind and visually impaired (BVI) individuals can fully participate in today’s image-rich digital world remains a significant challenge. Current visual assistants often rely on annotations from sighted contributors, which may fail to capture BVI individuals’ preferences and expectations. Addressing this challenge, we explore how to develop optimal, conversational image descriptions that resonate with BVI individuals, and how to effectively scale their creation. We propose a semi-automatic approach that couples large language models (LLMs) with iterative, BVI-driven refinements. Starting with initial LLM-generated image descriptions, a small set of BVI experts refine them to better meet BVI individuals’ needs. These enhanced examples guide subsequent LLM outputs, which are then evaluated by BVI end-users to confirm improved quality and satisfaction. We contribute to constructing large-scale, BVI-centered training data, thereby advancing inclusive and conversational visual accessibility. Throughout our studies, the results show a significant improvement in BVI end-users’ satisfaction with image conversational descriptions when edited by BVI experts. Additionally, the results indicate promising improvements when the LLM re-generates descriptions using those edits as few-shot examples. Moreover, we got valuable insights from BVI participants’ focused mainly on optimizing clarity, relevance, and interaction patterns for image descriptions and conversational exchanges between AI and BVI individuals.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605490",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mazen Salous",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Daniel Lange",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Timo von Reeken",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Maria K. Wolters",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Wilko Heuten",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Susanne Boll",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            },
            {
                "name": "Larbi Abdenebaoui",
                "labs": [
                    "OFFIS Institute for Information Technology, Oldenburg, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Oral communication",
                "Videos",
                "Large language models",
                "Iterative methods",
                "Guidelines",
                "Training",
                "Standards",
                "Annotations",
                "Training data"
            ],
            "Author Keywords": [
                "Accessibility",
                "digital image description",
                "human–AI image conversation"
            ]
        }
    },
    {
        "Title": "Enhancing LLMs for Sequential Recommendation With Reversed User History and User Embeddings",
        "Link": "https://ieeexplore.ieee.org/document/11050368/",
        "Abstract": "Inspired by the successful applications of Large Language Models (LLMs) in various fields, LLMs for sequential recommendation have also become an active research area. Recent studies have focused on leveraging the powerful capabilities of LLMs to enhance their alignment with sequential recommendation. While LLMs excel in sequence modeling and have inspired adaptations for sequential recommendation tasks, their potential to fully exploit sequential nature remains underexplored. In this paper, we propose two key strategies: Reversed User History Generation (RUHG) and Recency-based User Embedding. The first method, RUHG, forces LLM to generate the next item and then regenerate the user history in reverse order. Due to the autoregressive nature of LLM, this method allows for better understanding of the next item and user history. Our second method, Recency-based User Embedding, captures the dynamics of user preference by emphasizing recent interactions. This user embedding provides a global view of user history to LLM, rather than utilizing only individual items. Moreover, we leverage Curriculum Learning (CL) for effectively training, and provide insights into defining easy and hard tasks for LLMs within CL. Our methods effectively bridge the modality gap between LLMs and sequential recommendation while maximizing the capabilities of LLMs through our scheme. Extensive experiments demonstrate the effectiveness of proposed methods and show performance improvements across three benchmark datasets. Our code is available at https://github.com/Yeo-Jun-Choi/llmfor",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583094",
            "Date of Publication": "25 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yeo Jun Choi",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Woo-Seong Yun",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Yoon-Sik Cho",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "History",
                "Adaptation models",
                "Large language models",
                "Computational modeling",
                "Complexity theory",
                "Cognition",
                "User preference",
                "Training",
                "Stars",
                "Predictive models"
            ],
            "Author Keywords": [
                "Sequential recommendation",
                "large language models",
                "reversed user history generation",
                "recency-based user embedding",
                "curriculum learning"
            ]
        }
    },
    {
        "Title": "DAWN: Designing Distributed Agents in a Worldwide Network",
        "Link": "https://ieeexplore.ieee.org/document/11078243/",
        "Abstract": "The rapid evolution of Large Language Models (LLMs) has transformed them from basic conversational tools into sophisticated entities capable of complex reasoning and decision-making. These advancements have led to the development of specialized LLM-based agents designed for diverse tasks such as coding and web browsing. As these agents become more capable, the need for a robust framework that facilitates global agentic communication and collaboration for building sophisticated software solutions has become increasingly important. Distributed Agents in a Worldwide Network (DAWN) addresses this need by providing an architectural framework that allows globally distributed agents of any provenance to be registered, discovered, and organized for building AI-based applications and solutions. In DAWN, a Principal Agent Service composes and oversees the execution of agentic applications. It delegates tasks to one or more Gateway Agent Services that provide for the discovery, registration, and connection of the most suitable agents to fit each application’s needs. DAWN offers three operational modes: No-LLM mode for deterministic and classical software development, Copilot for decision-making augmented using AI, and LLM Agent for autonomous operations. Last but not least, DAWN ensures the safety and security of agent collaborations globally through a dedicated safety, security, and compliance layer, protecting the network against attackers and adhering to stringent security and compliance standards. These features make DAWN a robust framework for designing, developing, and deploying agent-based applications across business and consumer applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3588425",
            "Date of Publication": "11 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zahra Aminiranjbar",
                "labs": [
                    "Cisco Systems, Inc., San Jose, CA, USA"
                ]
            },
            {
                "name": "Jianan Tang",
                "labs": [
                    "Cisco Systems, Inc., San Jose, CA, USA"
                ]
            },
            {
                "name": "Qiudan Wang",
                "labs": [
                    "Cisco Systems, Inc., San Jose, CA, USA"
                ]
            },
            {
                "name": "Shubha Pant",
                "labs": [
                    "Cisco Systems, Inc., San Jose, CA, USA"
                ]
            },
            {
                "name": "Mahesh Viswanathan",
                "labs": [
                    "Cisco Systems, Inc., San Jose, CA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Logic gates",
                "Security",
                "Safety",
                "Collaboration",
                "Multi-agent systems",
                "Software development management",
                "Computer architecture",
                "Cognition",
                "Software tools",
                "Large language models"
            ],
            "Author Keywords": [
                "Large language model",
                "AI agents",
                "agentic software development",
                "multi-agent systems",
                "agentic frameworks"
            ]
        }
    },
    {
        "Title": "Deep Learning-Driven Labor Education and Skill Assessment: A Big Data Approach for Optimizing Workforce Development and Industrial Relations",
        "Link": "https://ieeexplore.ieee.org/document/11052269/",
        "Abstract": "The automation of resume screening is a critical component of modern recruitment processes, particularly in large organizations. Automated systems for resume screening typically involve various NLP tasks to streamline candidate evaluation. This paper investigates the application of LLM models in automating labor education and skill assessment, focusing on optimizing workforce development through advanced language models. We propose a comprehensive framework for automating resume screening and grading, utilizing SOTA LLM models to enhance recruitment processes. The proposed system integrates information extraction and summarization tasks, leveraging LLMs for decision-making throughout the hiring process. Our experiments, conducted on a publicly available resume dataset, demonstrate significant improvements in efficiency and accuracy. The LLaMA2-13B model, achieves a ROUGE-1 score of 37.31, ROUGE-2 of 15.04, ROUGE-L of 36.99, and BLEU score of 13.82, significantly outperforming the baseline models such as FLAN-T5 and GPT-NeoX. These results highlight the potential of LLM-based systems in automating labor-related assessments, with the fine-tuned LLaMA2-13B model delivering up to 27% better performance than zero-shot models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583324",
            "Date of Publication": "26 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dan Peng",
                "labs": [
                    "School of Marxism, China University of Mining and Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Resumes",
                "Decision making",
                "Recruitment",
                "Hidden Markov models",
                "Pipelines",
                "Accuracy",
                "Manuals",
                "Large language models",
                "Data models",
                "Unsupervised learning"
            ],
            "Author Keywords": [
                "Skill assessment",
                "hiring optimization",
                "large language models",
                "knowledge graph",
                "NLP"
            ]
        }
    },
    {
        "Title": "An Interactive Framework for Personalized Navigation Based on Metacosmic Cultural Tourism and Large Model Fine-Tuning",
        "Link": "https://ieeexplore.ieee.org/document/10979851/",
        "Abstract": "With the wide application of large language models (LLMs) and the rapid growth of metaverse tourism demand, the digital tour and personalized interaction of historical sites have become the key to improving users’ digital travel experience. Creating an environment where users can access rich cultural information and enjoy personalized, immersive experiences is a crucial issue in the field of digital cultural travel. To this end, we propose a tourism information multimodal generation personalized question-answering interactive framework TIGMI (Tourism Information Generation and Multimodal Interaction) based on LLM fine-tuning, which aims to provide a richer and more in-depth experience for virtual tours of historical monuments. Taking Qutan Temple as an example, the framework combines LLM, retrieval augmented generation (RAG), and auto-prompting engineering techniques to retrieve accurate information related to the historical monument from external knowledge bases and seamlessly integrates it into the generated content. This integration mechanism ensures the accuracy and relevance of the generated answers. Through TIGMI’s LLM-driven command interaction mechanism in the 3D digital scene of Qutan Temple, users are able to interact with the building and scene environment in a personalized and real-time manner, successfully integrating historical and cultural information with modern digital technology. This integration significantly enhances the naturalness of interaction and personalizes the user experience, thereby improving user immersion and information acquisition efficiency. Evaluation results show that TIGMI excels in question-answering and multimodal interactions, significantly enhancing the depth and breadth of services provided by the personalized virtual tour. We conclude by addressing the limitations of TIGMI and briefly discuss how future research will focus on further improving the accuracy and user satisfaction of the generated content to adapt to the dynamically changing tourism environment.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565359",
            "Date of Publication": "29 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hang Guo",
                "labs": [
                    "School of Computer Technology and Application, Qinghai University, Xining, China"
                ]
            },
            {
                "name": "Zhiqiang Liu",
                "labs": [
                    "School of Computer Technology and Application, Qinghai University, Xining, China",
                    "Qinghai Provincial Laboratory for Intelligent Computing and Application, Qinghai University, Xining, China"
                ]
            },
            {
                "name": "Chuanqian Tang",
                "labs": [
                    "School of Computer Technology and Application, Qinghai University, Xining, China",
                    "Qinghai Provincial Laboratory for Intelligent Computing and Application, Qinghai University, Xining, China"
                ]
            },
            {
                "name": "Xiaodan Zhang",
                "labs": [
                    "School of Computer Technology and Application, Qinghai University, Xining, China",
                    "Qinghai Provincial Laboratory for Intelligent Computing and Application, Qinghai University, Xining, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cultural differences",
                "Adaptation models",
                "Computational modeling",
                "Three-dimensional displays",
                "Large language models",
                "Navigation",
                "Metaverse",
                "Accuracy",
                "Retrieval augmented generation",
                "Planning"
            ],
            "Author Keywords": [
                "Large language model",
                "fine-tuning",
                "multimodal interaction",
                "metacosmic cultural tourism",
                "digital cultural heritage",
                "digital guide"
            ]
        }
    },
    {
        "Title": "Exploiting Intel Advanced Matrix Extensions (AMX) for Large Language Model Inference",
        "Link": "https://ieeexplore.ieee.org/document/10538369/",
        "Abstract": "The ever-increasing number of parameters in Large Language Models (LLMs) demands many expensive GPUs for both inference and training. This is because even such a high-end GPU such as NVIDIA A100 can store only a subset of parameters due to its limited memory capacity. To reduce the number of required GPUs, especially for inference, we may exploit the large memory capacity of (host) CPU to store not only all the model parameters but also intermediate outputs which also require a substantial memory capacity. However, this necessitates frequent data transfers between CPU and GPU over the slow PCIe interface, creating a bottleneck that hinders the accomplishment of both low latency and high throughput in inference. To address such a challenge, we first propose CPU-GPU cooperative computing that exploits the Advanced Matrix Extensions (AMX) capability of the latest Intel CPU, codenamed Sapphire Rapids (SPR). Second, we propose an adaptive model partitioning policy that determines the layers of a given LLM to be run on CPU and GPU, respectively, based on their memory capacity requirement and arithmetic intensity. As CPU executes the layers with large memory capacity but low arithmetic intensity, the amount of data transferred through the PCIe interface is significantly reduced, thereby improving the LLM inference performance. Our evaluation demonstrates that CPU-GPU cooperative computing, based on this policy, delivers 12.1× lower latency and 5.4× higher throughput than GPU-only computing for OPT-30B inference when both CPU-GPU and GPU-only computing store the model in CPU memory.",
        "Details": {
            "DOI": "10.1109/LCA.2024.3397747",
            "Date of Publication": "24 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Computer Architecture Letters"
        },
        "issn_info": {
            "Print ISSN": "1556-6056",
            "Electronic ISSN": "1556-6064"
        },
        "authors_data": [
            {
                "name": "Hyungyo Kim",
                "labs": [
                    "University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Gaohan Ye",
                "labs": [
                    "University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Nachuan Wang",
                "labs": [
                    "University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Amir Yazdanbakhsh",
                "labs": [
                    "Google Deepmind, Mountain View, CA, USA"
                ]
            },
            {
                "name": "Nam Sung Kim",
                "labs": [
                    "University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Graphics processing units",
                "Throughput",
                "Data transfer",
                "Arithmetic",
                "Memory management",
                "Data models"
            ],
            "Author Keywords": [
                "Large language models",
                "advance matrix extensions",
                "cooperative heterogeneous computing"
            ]
        }
    },
    {
        "Title": "Finetuning Large Language Models for Vulnerability Detection",
        "Link": "https://ieeexplore.ieee.org/document/10908394/",
        "Abstract": "This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in Java source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder’s training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, handling class imbalance, and improving performance on difficult vulnerability detection datasets. This demonstrates the potential for transfer learning by finetuning large pretrained language models for specialized source code analysis tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3546700",
            "Date of Publication": "28 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aleksei Shestov",
                "labs": [
                    "Sber AI Lab, Moscow, Russia"
                ]
            },
            {
                "name": "Rodion Levichev",
                "labs": [
                    "SaluteDevices, Moscow, Russia"
                ]
            },
            {
                "name": "Ravil Mussabayev",
                "labs": [
                    "Sber AI Lab, Moscow, Russia",
                    "AI Research Lab, Satbayev University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Evgeny Maslov",
                "labs": [
                    "Software Development Tools Cloud Technology Laboratory, Huawei Russian Research Institute, Moscow, Russia"
                ]
            },
            {
                "name": "Pavel Zadorozhny",
                "labs": [
                    "SaluteDevices, Moscow, Russia"
                ]
            },
            {
                "name": "Anton Cheshkov",
                "labs": [
                    "Software Development Tools Cloud Technology Laboratory, Huawei Russian Research Institute, Moscow, Russia"
                ]
            },
            {
                "name": "Rustam Mussabayev",
                "labs": [
                    "AI Research Lab, Satbayev University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Alymzhan Toleu",
                "labs": [
                    "AI Research Lab, Satbayev University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Gulmira Tolegen",
                "labs": [
                    "AI Research Lab, Satbayev University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Alexander Krassovitskiy",
                "labs": [
                    "AI Research Lab, Satbayev University, Almaty, Kazakhstan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Codes",
                "Standards",
                "Large language models",
                "Predictive models",
                "Limiting",
                "Java",
                "Entropy",
                "Adaptation models",
                "Reviews"
            ],
            "Author Keywords": [
                "Large language models",
                "vulnerability detection",
                "cybersecurity",
                "finetuning",
                "StarCoder",
                "WizardCoder",
                "PEFT",
                "LoRA"
            ]
        }
    },
    {
        "Title": "Detection of Turkish Fake News From Tweets With BERT Models",
        "Link": "https://ieeexplore.ieee.org/document/10399808/",
        "Abstract": "As the number of people using social networks increases, more people are using social media platforms to meet their news needs. Users think that it is easier to follow the agenda by accessing news, especially on Twitter, rather than newspaper news pages. However, fake news is increasingly appearing on social media, and it is not always possible for people to obtain correct news from partial news pages or short Twitter posts. Understanding whether the news shared on Twitter is true or not is an important problem. Detecting fake tweets is of great importance in Turkish as well as in any language. In this study, fake news obtained from verification platforms on Twitter and real news obtained from the Twitter accounts of mainstream newspapers were labeled and, preprocessed using the Zemberek natural language processing tool developed for the Turkish language, and a dataset named TR_FaRe_News was created. Then, the TR_FaRe_News dataset was explored using ensemble methods and BoW, TF-IDF, and Word2Vec vectorization methods for fake news detection. Then a pre-trained BERT deep learning model was fine-tuned, and variations of the model extended with Bi-LSTM and Convolutional Neural Network (CNN) layers with the frozen and unfrozen parameters methods were explored. The performance evaluation was conducted using seven comparable datasets, namely BuzzFeedNews, GossipCop, ISOT, LIAR, Twitter15, and Twitter16, including an LLM-generated fake news dataset. Analyzing Turkish tweets and using fake news datasets generated by LLM is considered an important contribution. Accuracy values between 90 and 94% were obtained with the BERT and BERTurk + CNN models with 94% accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3354165",
            "Date of Publication": "15 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gülsüm Kayabaşi Koru",
                "labs": [
                    "Computer Forensics Department, Gazi University, Ankara, Turkey"
                ]
            },
            {
                "name": "Çelebı Uluyol",
                "labs": [
                    "Computer Forensics Department, Gazi University, Ankara, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Blogs",
                "Deep learning",
                "Ensemble learning",
                "Convolutional neural networks",
                "Machine learning algorithms"
            ],
            "Author Keywords": [
                "Fake news",
                "generated news",
                "ensemble learning",
                "deep learning",
                "BERT"
            ]
        }
    },
    {
        "Title": "Leveraging Large Language Models for Integrated Satellite-Aerial-Terrestrial Networks: Recent Advances and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/10813004/",
        "Abstract": "Integrated satellite, aerial, and terrestrial networks (ISATNs) represent a sophisticated convergence of diverse communication technologies to ensure seamless connectivity across different altitudes and platforms. This paper explores the transformative potential of integrating Large Language Models (LLMs) into ISATNs, leveraging advanced Artificial Intelligence (AI) and Machine Learning (ML) capabilities to enhance these networks. We outline the current architecture of ISATNs and highlight the significant role LLMs can play in optimizing data flow, signal processing, and network management to advance 5G/6G communication technologies through advanced predictive algorithms and real-time decision-making. A comprehensive analysis of ISATN components is conducted, assessing how LLMs can effectively address traditional data transmission and processing bottlenecks. The paper delves into the network management challenges within ISATNs, emphasizing the necessity for sophisticated resource allocation strategies, traffic routing, and security management to ensure seamless connectivity and optimal performance under varying conditions. Furthermore, we examine the technical challenges and limitations associated with integrating LLMs into ISATNs, such as data integration for LLM processing, scalability issues, latency in decision-making processes, and the design of robust, fault-tolerant systems. The study also identifies critical future research directions for fully harnessing LLM capabilities in ISATNs, which is important for enhancing network reliability, optimizing performance, and achieving a truly interconnected and intelligent global network system.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2024.3522103",
            "Date of Publication": "25 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Shumaila Javaid",
                "labs": [
                    "Department of Control Science and Engineering, College of Electronics and Information Engineering, Tongji University, Shanghai, China",
                    "National Key Laboratory of Autonomous Intelligent Unmanned Systems, Tongji University, Shanghai, China",
                    "Frontiers Science Center for Intelligent Autonomous Systems, Tongji University, Shanghai, China"
                ]
            },
            {
                "name": "Ruhul Amin Khalil",
                "labs": [
                    "Engineering Requirement Unit, College of Engineering, United Arab Emirates University, Al-Ain, UAE"
                ]
            },
            {
                "name": "Nasir Saeed",
                "labs": [
                    "Department of Electrical and Communication Engineering, College of Engineering, United Arab Emirates University, Al-Ain, UAE"
                ]
            },
            {
                "name": "Bin He",
                "labs": [
                    "Department of Control Science and Engineering, College of Electronics and Information Engineering, Tongji University, Shanghai, China",
                    "National Key Laboratory of Autonomous Intelligent Unmanned Systems, Tongji University, Shanghai, China",
                    "Frontiers Science Center for Intelligent Autonomous Systems, Tongji University, Shanghai, China"
                ]
            },
            {
                "name": "Mohamed-Slim Alouini",
                "labs": [
                    "Computer, Electrical and Mathematical Science and Engineering Division, King Abdullah University of Science And Technology, Thuwal, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Satellites",
                "Satellite broadcasting",
                "Resource management",
                "Reliability",
                "Computational modeling",
                "Complexity theory",
                "Bandwidth",
                "Scalability",
                "STEM"
            ],
            "Author Keywords": [
                "Integrated satellite-aerial-terrestrial networks",
                "large language models",
                "5G/6G communication",
                "resource allocation",
                "intelligent networks"
            ]
        }
    },
    {
        "Title": "Navigating the Pitfalls: Analyzing the Behavior of LLMs as a Coding Assistant for Computer Science Students—A Systematic Review of the Literature",
        "Link": "https://ieeexplore.ieee.org/document/10636140/",
        "Abstract": "In recent years, large language models (LLMs) have been employed significantly in different domains of computing education. Nevertheless, these models have been focused on essential adherence to their integration as coding assistants in computing education. However, attention has been switched to thoroughly examining and analyzing LLM behavior, particularly in computing education for programming tasks such as code generation, code explanation, and programming error message explanation. Therefore, it becomes imperative to understand their behavior to examine potential pitfalls. This article addresses this gap systematically and details how different LLM-based coding chatbots, such as ChatGPT, Codex, Copilot, and others, react to various coding inputs within computing education. To achieve this objective, we collected and analyzed articles from 2021 to 2024, and 72 studies were thoroughly examined. These objectives include investigating the existing limitations and challenges associated with utilizing these systems for coding tasks, assessing their responses to prompts containing coding syntax, examining the impact of their output on student learning, and evaluating their performance as debugging tools. The findings of this review highlight that it is premature to incorporate these systems into computing education due to their limitations that may limit their effectiveness as comprehensive coding assistants for computer science students. These limitations include issues with handling prompts containing code snippets, potential negative impacts on student learning, limited debugging capabilities, and other ineffectiveness. The finding also reports multiple research directions that can be considered in future research related to LLMs in computing education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3443621",
            "Date of Publication": "14 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Farman Ali Pirzado",
                "labs": [
                    "School of Engineering and Sciences Monterrey, Tecnológico de Monterrey, Nuevo León, Monterrey, Mexico"
                ]
            },
            {
                "name": "Awais Ahmed",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China—UESTC, Sichuan, China"
                ]
            },
            {
                "name": "Román Alejandro Mendoza-Urdiales",
                "labs": [
                    "School of Engineering and Sciences Monterrey, Tecnológico de Monterrey, Nuevo León, Monterrey, Mexico"
                ]
            },
            {
                "name": "Hugo Terashima-Marin",
                "labs": [
                    "School of Engineering and Sciences Monterrey, Tecnológico de Monterrey, Nuevo León, Monterrey, Mexico"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Encoding",
                "Chatbots",
                "Programming profession",
                "Task analysis",
                "Surveys",
                "Large language models",
                "Computer science education",
                "Error analysis"
            ],
            "Author Keywords": [
                "Large language models",
                "computing education",
                "code generation",
                "code explanation",
                "programming error messages explanation"
            ]
        }
    },
    {
        "Title": "Predicting Tumor Type and Residual Status of Suprasellar Lesions Using Indian Discharge Summaries",
        "Link": "https://ieeexplore.ieee.org/document/10680514/",
        "Abstract": "A suprasellar lesion is an unusual mass in the suprasellar region in the brain. Some common suprasellar lesions include Pituitary Adenoma, Craniopharyngioma and Meningioma. Patients may present with significant visual and other symptoms like headache, and hormonal imbalances. The proposed study utilizes 553 discharge summaries of suprasellar patients admitted during 2013–2019 at NIMHANS hospitals, Bangalore. Classification of discharge summary was conducted using 11 different word embedding techniques, including word2vec, FastText, Glove, and transformer-based embeddings. Tumor type is predicted using advanced ML classifiers like AdaBoost, Random Forest, and XGBoost. The highest F-score of 0.91 was reported for XGBoost when implemented along with SMOTE based data balancing and PCA based feature reduction. To enhance the classification performance of the best performing model, ClinicalBioBERT, a pre-trained BERT model that demonstrated superior results, was finetuned with domain-specific clinical data and resulted in an improvement of the F-score to 0.93. Classification of presence/absence of residual tumor post surgery is also carried out using transformer models and achieved a macro F1-score of maximum 1, after handling the class imbalance using SMOTE. Different combinations of experiments with PCA and SMOTE were carried out in both classification problems. Two Large Language Models: FlanT5 and Bloom, are also investigated in this work for both classification problems Initially, the LLM is employed with a zero-shot classification pipeline, resulting in poor performance. Consequently, fine-tuning of the LLM models are attempted using the discharge summary text, resulting in performance improvements.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3460976",
            "Date of Publication": "16 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Priyanka C. Nair",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India"
                ]
            },
            {
                "name": "Deepa Gupta",
                "labs": [
                    "Department of Computer Science and Engineering, Amrita School of Computing, Amrita Vishwa Vidyapeetham, Bengaluru, India"
                ]
            },
            {
                "name": "Bhagavatula Indira Devi",
                "labs": [
                    "Department of Neurosurgery, National Institute of Mental Health and Neurosciences, Bengaluru, India"
                ]
            },
            {
                "name": "Vani Kanjirangat",
                "labs": [
                    "Istituto Dalle Molle di Studi sull’Intelligenza Artificiale USI/SUPSI, Lugano, Switzerland"
                ]
            },
            {
                "name": "P. Deepak",
                "labs": [
                    "School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Lesions",
                "Transformers",
                "Encoding",
                "Biological system modeling",
                "Bidirectional control",
                "Adaptation models",
                "Visualization",
                "Brain cancer",
                "Tumors",
                "Large language models",
                "Zero-shot learning"
            ],
            "Author Keywords": [
                "Brain tumor",
                "suprasellar lesions",
                "discharge summaries",
                "residual tumor",
                "fine-tuning",
                "large language model",
                "zero-shot classification",
                "word embedding",
                "BioBERT",
                "Flan-T5",
                "bloom"
            ]
        }
    },
    {
        "Title": "Large Language Model-Informed ECG Dual Attention Network for Heart Failure Risk Prediction",
        "Link": "https://ieeexplore.ieee.org/document/10858425/",
        "Abstract": "Heart failure (HF) poses a significant public health challenge, with a rising global mortality rate. Early detection and prevention of HF could significantly reduce its impact. We introduce a novel methodology for predicting HF risk using 12-lead electrocardiograms (ECGs). We present a novel, lightweight dual attention ECG network designed to capture complex ECG features essential for early HF risk prediction, despite the notable imbalance between low and high-risk groups. This network incorporates a cross-lead attention module and 12 lead-specific temporal attention modules, focusing on cross-lead interactions and each lead's local dynamics. To further alleviate model overfitting, we leverage a large language model (LLM) with a public ECG-Report dataset for pretraining on an ECG-Report alignment task. The network is then fine-tuned for HF risk prediction using two specific cohorts from the U.K. Biobank study, focusing on patients with hypertension (UKB-HYP) and those who have had a myocardial infarction (UKB-MI). The results reveal that LLM-informed pre-training substantially enhances HF risk prediction in these cohorts. The dual attention design not only improves interpretability but also predictive accuracy, outperforming existing competitive methods with C-index scores of 0.6349 for UKB-HYP and 0.5805 for UKB-MI. This demonstrates our method's potential in advancing HF risk assessment with clinical complex ECG data.",
        "Details": {
            "DOI": "10.1109/TBDATA.2025.3536922",
            "Date of Publication": "30 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Big Data"
        },
        "issn_info": {
            "Electronic ISSN": "2332-7790"
        },
        "authors_data": [
            {
                "name": "Chen Chen",
                "labs": [
                    "Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford, U.K.",
                    "Imperial College London, London, U.K.",
                    "University of Sheffield, Sheffield, U.K."
                ]
            },
            {
                "name": "Lei Li",
                "labs": [
                    "Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford, U.K.",
                    "University of Southampton, Southampton, U.K."
                ]
            },
            {
                "name": "Marcel Beetz",
                "labs": [
                    "Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford, U.K."
                ]
            },
            {
                "name": "Abhirup Banerjee",
                "labs": [
                    "Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford, U.K."
                ]
            },
            {
                "name": "Ramneek Gupta",
                "labs": [
                    "Novo Nordisk Research Centre Oxford (NNRCO), Oxford, U.K."
                ]
            },
            {
                "name": "Vicente Grau",
                "labs": [
                    "Department of Engineering Science, Institute of Biomedical Engineering, University of Oxford, Oxford, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electrocardiography",
                "Predictive models",
                "Feature extraction",
                "Lead",
                "Biological system modeling",
                "Data models",
                "Training",
                "Representation learning",
                "Large language models",
                "Hafnium"
            ],
            "Author Keywords": [
                "Large language model",
                "multi-modal learning",
                "heart failure",
                "risk prediction",
                "interpretable artificial intelligence",
                "electrocardiogram"
            ]
        }
    },
    {
        "Title": "Fighting Against the Repetitive Training and Sample Dependency Problem in Few-Shot Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10463035/",
        "Abstract": "Few-shot named entity recognition (NER) systems recognize entities using a few labeled training examples. The general pipeline consists of a span detector to identify entity spans in text and an entity-type classifier to assign types to entities. Current span detectors rely on extensive manual labeling to guide training. Almost every span detector requires initial training on basic span features followed by adaptation to task-specific features. This process leads to repetitive training of the basic span features among span detectors. Additionally, metric-based entity-type classifiers, such as prototypical networks, typically employ a specific metric that gauges the distance between the query sample and entity-type referents, ultimately assigning the most probable entity type to the query sample. However, these classifiers encounter the sample dependency problem, primarily stemming from the limited samples available for each entity-type referent. To address these challenges, we proposed an improved few-shot NER pipeline. First, we introduce a steppingstone span detector that is pre-trained on open-domain Wikipedia data. It can be used to initialize the pipeline span detector to reduce the repetitive training of basic features. Second, we leverage a large language model (LLM) to set reliable entity-type referents, eliminating reliance on few-shot samples of each type. Our model exhibits superior performance with fewer training steps and human-labeled data compared with baselines, as demonstrated through extensive experiments on various datasets. Particularly in fine-grained few-shot NER settings, our model outperforms strong baselines, including ChatGPT. We will publicly release the code, datasets, LLM outputs, and model checkpoints.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3374727",
            "Date of Publication": "07 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chang Tian",
                "labs": [
                    "Department of Computer Science, LIIR, KU Leuven, Leuven, Belgium"
                ]
            },
            {
                "name": "Wenpeng Yin",
                "labs": [
                    "AI4Research Laboratory, The Pennsylvania State University, State College, PA, USA"
                ]
            },
            {
                "name": "Dan Li",
                "labs": [
                    "Elsevier, Amsterdam, The Netherlands"
                ]
            },
            {
                "name": "Marie-Francine Moens",
                "labs": [
                    "Department of Computer Science, LIIR, KU Leuven, Leuven, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Detectors",
                "Training",
                "Internet",
                "Encyclopedias",
                "Online services",
                "Task analysis",
                "Adaptation models",
                "Artificial intelligence",
                "Data mining",
                "Feature extraction",
                "Few-shot learning",
                "Natural language processing",
                "Text analysis"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "data mining",
                "feature extraction",
                "few-shot learning",
                "named entity recognition",
                "natural language processing",
                "text analysis"
            ]
        }
    },
    {
        "Title": "ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration",
        "Link": "https://ieeexplore.ieee.org/document/10410848/",
        "Abstract": "Natural language processing (NLP) models find extensive applications but face vulnerabilities against adversarial inputs. Traditional defenses lean heavily on supervised detection techniques, which makes them vulnerable to issues arising from training data quality, inherent biases, noise, or adversarial inputs. This study observed common compromises in sentence fluency during aggression. On this basis, the Zero Sample Defender (ZDDR) is introduced for adversarial sample detection and recovery without relying on prior knowledge. ZDDR combines the log probability calculated by the model and the syntactic normative score of a large language model (LLM) to detect adversarial examples. Furthermore, using strategic prompts, ZDDR guides LLM in rephrasing adversarial content, maintaining clarity, structure, and meaning, thereby restoring the sentence from the attack. Benchmarking reveals a 9% improvement in area under receiver operating characteristic curve (AUROC) for adversarial detection over existing techniques. Post-restoration, model classification efficacy surges by 45% compared to the offensive inputs, setting new performance standards against other restoration techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3356568",
            "Date of Publication": "22 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Musheng Chen",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            },
            {
                "name": "Guowei He",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            },
            {
                "name": "Junhua Wu",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Robustness",
                "Computational modeling",
                "Perturbation methods",
                "Semantics",
                "Natural language processing",
                "Data models",
                "Adversarial machine learning",
                "Detection algorithms"
            ],
            "Author Keywords": [
                "Adversarial defense",
                "large language model",
                "natural language processing",
                "model security",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "Semantic Importance-Aware Communications With Semantic Correction Using Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10843783/",
        "Abstract": "Semantic communications, a promising approach for agent-human and agent-agent interactions, typically operate at a feature level, lacking true semantic understanding. This paper explores understanding-level semantic communications (ULSC), transforming visual data into human-intelligible semantic content. We employ an image caption neural network (ICNN) to derive semantic representations from visual data, expressed as natural language descriptions. These are further refined using a pre-trained large language model (LLM) for importance quantification and semantic error correction. The subsequent semantic importance-aware communications (SIAC) aim to minimize semantic loss while respecting transmission delay constraints, exemplified through adaptive modulation and coding strategies. At the receiving end, LLM-based semantic error correction is utilized. If visual data recreation is desired, a pre-trained generative artificial intelligence (AI) model can regenerate it using the corrected descriptions. We assess semantic similarities between transmitted and recovered content, demonstrating ULSC’s superior ability to convey semantic understanding compared to feature-level semantic communications (FLSC). ULSC’s conversion of visual data to natural language facilitates various cognitive tasks, leveraging human knowledge bases. Additionally, this method enhances privacy, as neither original data nor features are directly transmitted.",
        "Details": {
            "DOI": "10.1109/TMLCN.2025.3530875",
            "Date of Publication": "16 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Machine Learning in Communications and Networking"
        },
        "issn_info": {
            "Electronic ISSN": "2831-316X"
        },
        "authors_data": [
            {
                "name": "Shuaishuai Guo",
                "labs": [
                    "School of Control Science and Engineering, Shandong University, Jinan, Shandong, China"
                ]
            },
            {
                "name": "Yanhu Wang",
                "labs": [
                    "School of Control Science and Engineering, Shandong University, Jinan, Shandong, China"
                ]
            },
            {
                "name": "Jia Ye",
                "labs": [
                    "School of Electrical Engineering, Chongqing University, Chongqing, China"
                ]
            },
            {
                "name": "Anbang Zhang",
                "labs": [
                    "School of Control Science and Engineering, Shandong University, Jinan, Shandong, China"
                ]
            },
            {
                "name": "Peng Zhang",
                "labs": [
                    "School of Physics and Electronic Information, Weifang University, Weifang, China"
                ]
            },
            {
                "name": "Kun Xu",
                "labs": [
                    "Shandong Inspur Intelligent Building Technology Company Ltd., Jinan, Shandong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Visualization",
                "Natural languages",
                "Error correction",
                "Receivers",
                "Generative AI",
                "Semantic communication",
                "Channel coding",
                "Vectors",
                "Transmitters"
            ],
            "Author Keywords": [
                "Semantic communications",
                "semantic error correction",
                "large language models",
                "generative artificial intelligence"
            ]
        }
    },
    {
        "Title": "Exploring the Potential of Offline LLMs in Data Science: A Study on Code Generation for Data Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10947006/",
        "Abstract": "Large Language Models (LLMs) have recently attracted considerable attention from the scientific community, due to their advanced capabilities and potential to serve as vital tools across various industries and academic fields. An important implementation domain for LLMs is Data Science, in which they could enhance the efficiency of Data Analysis and Profiling tasks. With the utilization of LLMs in Data Analytics tools, end-users could directly issue data analysis queries in natural language, bypassing the need for specialized user interfaces. However, due to the sensitive nature of certain data in some organizations, it is unwise to consider using established, cloud-based LLMs. This article explores the feasibility and effectiveness of a standalone, offline LLM in generating code for performing data analytics, given a set of natural language queries. A methodology tailored to a code-specific LLM is presented, evaluating its performance in generating Python Spark code and successfully producing the desired result. The model is assessed on its efficiency and ability to handle natural language queries of varying complexity, exploring the potential for wider adoption of offline LLMs in future data analysis frameworks and software solutions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3556973",
            "Date of Publication": "01 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anastasios Nikolakopoulos",
                "labs": [
                    "School of Electrical and Computer Engineering, Institute of Communication and Computer Systems, National Technical University of Athens, Zografou, Greece"
                ]
            },
            {
                "name": "Antonios Litke",
                "labs": [
                    "School of Electrical and Computer Engineering, Institute of Communication and Computer Systems, National Technical University of Athens, Zografou, Greece"
                ]
            },
            {
                "name": "Alexandros Psychas",
                "labs": [
                    "School of Electrical and Computer Engineering, Institute of Communication and Computer Systems, National Technical University of Athens, Zografou, Greece"
                ]
            },
            {
                "name": "Eleni Veroni",
                "labs": [
                    "Research and Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg"
                ]
            },
            {
                "name": "Theodora Varvarigou",
                "labs": [
                    "School of Electrical and Computer Engineering, Institute of Communication and Computer Systems, National Technical University of Athens, Zografou, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Large language models",
                "Natural languages",
                "Data models",
                "Data science",
                "Software",
                "Benchmark testing",
                "Analytical models",
                "Training",
                "Technological innovation"
            ],
            "Author Keywords": [
                "Code generation",
                "data analysis",
                "data profiling",
                "data science",
                "large language models"
            ]
        }
    },
    {
        "Title": "A Bibliometric Exposition and Review on Leveraging LLMs for Programming Education",
        "Link": "https://ieeexplore.ieee.org/document/10938596/",
        "Abstract": "The world is experiencing an AI revolution, with large language models (LLMs) transforming various industries, including education. Academics are striving to harness the potential of LLMs while also contending with their risks. This paper presents the first bibliometric analysis focused on LLM research in programming education, identifying leading countries, authors, and institutions while analyzing key terms and popular keywords in this field. Additionally, it highlights influential studies on topics such as introductory programming, computer science, computing, programming education, and prompt engineering, discussing key insights from these works. Findings indicate that LLMs could play a significant role in programming education and may be integrated into computer science curricula. However, careful consideration is needed to ensure their benefits outweigh their risks across various use cases. This study specifically examines ChatGPT as a representative LLM, exploring its benefits and limitations as both a learning aid for students and a support tool for professionals. It also evaluates the quality of ChatGPT-generated code and its effectiveness in simplifying programming concepts for beginners. Furthermore, the ethical implications of increasing reliance on LLMs for programming tasks, including concerns about dependency, plagiarism, and potential effects on critical thinking, are addressed. By contributing to the ongoing discourse on integrating AI tools like ChatGPT in programming education, this research emphasizes the importance of responsible and ethical usage to maximize benefits for students, educators, and the broader educational community.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554627",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Joanah Pwanedo Amos",
                "labs": [
                    "Information and Communication Engineering Department, Elizade University, Ilara-Mokin, Nigeria"
                ]
            },
            {
                "name": "Oluwatosin Ahmed Amodu",
                "labs": [
                    "Information and Communication Engineering Department, Elizade University, Ilara-Mokin, Nigeria",
                    "Department of Communication Technology and Network, Universiti Putra Malaysia (UPM), Serdang, Selangor, Malaysia"
                ]
            },
            {
                "name": "Raja Azlina Raja Mahmood",
                "labs": [
                    "Department of Communication Technology and Network, Universiti Putra Malaysia (UPM), Serdang, Selangor, Malaysia"
                ]
            },
            {
                "name": "Akanbi Bolakale Abdulqudus",
                "labs": [
                    "Department of Mathematics and Computer Science, Elizade University, Ilara-Mokin, Nigeria"
                ]
            },
            {
                "name": "Anies Faziehan Zakaria",
                "labs": [
                    "Department of Engineering Education, Faculty of Engineering and Built Environment, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Abimbola Rhoda Iyanda",
                "labs": [
                    "Computer Science and Engineering Department, Obafemi Awolowo University, Ile-Ife, Nigeria"
                ]
            },
            {
                "name": "Umar Ali Bukar",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Artificial Intelligence, Taraba State University, Jalingo, Nigeria",
                    "Centre for Intelligent Cloud Computing (CICC), Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Zurina Mohd Hanapi",
                "labs": [
                    "Department of Communication Technology and Network, Universiti Putra Malaysia (UPM), Serdang, Selangor, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Programming profession",
                "Education",
                "Bibliometrics",
                "Market research",
                "Large language models",
                "Codes",
                "Ethics",
                "Requirements engineering",
                "Mathematics"
            ],
            "Author Keywords": [
                "ChatGPT",
                "code generation",
                "ethical concerns",
                "large language models (LLMs)",
                "introductory programming",
                "programming education",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "SumLLaMA: Efficient Contrastive Representations and Fine-Tuned Adapters for Bug Report Summarization",
        "Link": "https://ieeexplore.ieee.org/document/10521511/",
        "Abstract": "In software maintenance, concise summaries of bug reports are crucial, significantly enhancing developer efficiency and ultimately improving software quality and user experience. Large language models (LLMs) have become the standard method for bug report summarization due to their powerful representation capabilities. However, LLM-based approaches face two primary challenges: accurately modeling the contextual relationships between various components within a bug report and the risk of overfitting when fine-tuning LLMs on datasets of limited size. To address these challenges, we propose a novel approach, SumLLaMA, which leverages contrastive learning pre-training and parameter-efficient fine-tuning. Contrastive learning pre-training is employed to construct contextual relations between components in a single bug report, enabling SumLLaMA to learn sequence-level representations. For parameter-efficient fine-tuning, we fine-tune a smaller adapter instead of the entire LLM, reducing the number of parameters trained to about 1/1500 of the original model, effectively mitigating the risk of overfitting. To evaluate the effectiveness of SumLLaMA, we compare it against five baseline models, including a state-of-the-art model, on a publicly available dataset. The experimental results show that SumLLaMA outperforms all baselines by up to 26.66, 17.10, and 24.01 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, respectively, achieving a state-of-the-art result for automated bug report summarization.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3397326",
            "Date of Publication": "06 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bangmeng Xiang",
                "labs": [
                    "Zhejiang College of Security Technology, Wenzhou, Zhejiang, China"
                ]
            },
            {
                "name": "Yunna Shao",
                "labs": [
                    "Zhejiang College of Security Technology, Wenzhou, Zhejiang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Task analysis",
                "Training",
                "Codes",
                "Semantics",
                "Self-supervised learning",
                "Vectors",
                "Software maintenance"
            ],
            "Author Keywords": [
                "Bug report summarization",
                "efficient fine-tuning",
                "software maintenance",
                "contrastive representation"
            ]
        }
    },
    {
        "Title": "Can GPT-4 Aid in Detecting Ambiguities, Inconsistencies, and Incompleteness in Requirements Analysis? A Comprehensive Case Study",
        "Link": "https://ieeexplore.ieee.org/document/10684184/",
        "Abstract": "Effective software projects hinge on robust requirements, yet flawed requirements often lead to costly delays and revisions. While tools have been developed to identify defects in Software Requirements Specifications (SRS), the advent of Large Language Models (LLMs) like GPT-4 presents new opportunities for enhancing requirements quality. However, the potential of LLMs in this realm remains largely unexplored, particularly in the context of large-scale industrial documents. To bridge this gap, we investigate the efficacy of zero-shot GPT-4 in various requirements analysis tasks using an industrial software specification document. Our study evaluates LLM performance in detecting defects, such as ambiguities, inconsistencies, and incompleteness, while also analyzing GPT-4’s ability to identify issues across version iterations and support technical experts in requirements analysis. Qualitatively, we identify key limitations of LLMs in defect detection, notably their inability to cross-reference throughout the document and their constrained understanding of specialized contexts. Quantitatively, we find that while LLMs excel in identifying incomplete requirements (precision 0.61), their performance is less impressive in detecting inconsistencies (precision 0.43) and ambiguities (precision 0.39). Although GPT-4 demonstrates promise in automating early defect detection across versions and providing accurate technical answers, our results underscore that they cannot entirely replace human analysts due to their lack of nuanced domain knowledge in a zero-shot setting. Nevertheless, avenues like few-shot learning and complex prompt design offer the potential to enhance LLM precision in defect detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3464242",
            "Date of Publication": "19 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Taslim Mahbub",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Dana Dghaym",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Aadhith Shankarnarayanan",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Taufiq Syed",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Salsabeel Shapsough",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Imran Zualkernan",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Stakeholders",
                "Large language models",
                "Accuracy",
                "Requirements engineering",
                "Defect detection",
                "Software development management",
                "Software engineering"
            ],
            "Author Keywords": [
                "Ambiguity",
                "completeness",
                "GPT",
                "inconsistency",
                "large language models (LLMs)",
                "requirements engineering",
                "software engineering",
                "software requirements specifications (SRS)"
            ]
        }
    },
    {
        "Title": "Memory Robot Design: A New Perspective From Human Brain Model and Large Language Model",
        "Link": "https://ieeexplore.ieee.org/document/10872903/",
        "Abstract": "With the spread of generative AI, the study proposed a memory-based cognitive robot architecture by using a Large Language Model (LLM), inspired by the working memory of the human brain model. A card-pairing task is designed to perform visual working memory with 60 participants with the measurement of electroencephalography (EEG). The proposed human brain model is a muti-featured EEG model, represented by the concept of brain energy, connectivity, and complexity. Band power ratios show that the anti-correlation of alpha and gamma waveforms can be observed in the occipital lobe. Brain connectivity is represented through magnitude squared coherence and phase locking value, and brain complexity is calculated by the Katz fractal dimension. Three pathways—attention, short-term memory, and distraction resistance are revealed. The changes in Katz fractal dimension are discovered in the frontal and occipital lobes. A novel memory architecture of robot cognition designed from human brain model includes three types of memory—short-term memory, working memory, and long-term memory, which is driven by GPT-4o. Two memory tests, a recalling test, and a working memory test, are conducted to validate the memory ability of the robot. The precision / recall / F1-score of working memory performance is 1.0 / 0.35 / 0.519, and the average accuracy of recalling test is 0.7. It is demonstrated that the different types of human memory functions can be implemented in the cognitive robot architecture driven by LLM. The research not only provides insight into the working memory of the human brain model but also realizes the robot architecture with the application of generative AI.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3538889",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jia-Hsun Lo",
                "labs": [
                    "Department of Mechanical Engineering, National Taiwan University, Taipei City, Taiwan"
                ]
            },
            {
                "name": "Han-Pang Huang",
                "labs": [
                    "Department of Mechanical Engineering, National Taiwan University, Taipei City, Taiwan"
                ]
            },
            {
                "name": "Yen-Ching Chen",
                "labs": [
                    "Epidemiology and Preventive Medicine, Taipei City, Taiwan"
                ]
            },
            {
                "name": "Jen-Hau Chen",
                "labs": [
                    "Department of Geriatrics and Gerontology, National Taiwan University Hospital, Taipei City, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electroencephalography",
                "Robots",
                "Memory management",
                "Cognitive robotics",
                "Fast Fourier transforms",
                "Brain modeling",
                "Visualization",
                "Memory architecture",
                "Mathematical models",
                "Large language models"
            ],
            "Author Keywords": [
                "Electroencephalography",
                "generative AI",
                "human brain model",
                "large language model"
            ]
        }
    },
    {
        "Title": "Voltage Control for Distribution Networks Based on Large Language Model-Assisted Deep Reinforcement Learning",
        "Link": "https://ieeexplore.ieee.org/document/10979848/",
        "Abstract": "With the continuous integration of large-scale distributed energy resources into distribution networks, numerous challenges arise regarding security, stability, and economic performance, particularly voltage violations and increased network losses. Furthermore, existing deep reinforcement learning (DRL) methods often rely on extensive real-world operational data for agent training. Yet, the lack of diversity in the collected data can significantly limit the generalization ability of agents under varying operating conditions. This paper proposes a regional voltage optimization control strategy for distribution networks to address these issues based on DRL supported by large language model (LLM). By integrating LLM technologies with DRL, the approach leverages prompt engineering to guide large-language models in generating customized datasets for DRL agent training, enabling data augmentation. This reduces the dependence on real-world data while improving the generalizability of agents. The proposed control strategy was validated on modified IEEE 33-bus and 123-bus distribution systems. The experimental results effectively mitigate voltage violations and reduce network losses while exhibiting strong robustness and generalization under various operating conditions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565280",
            "Date of Publication": "29 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Limei Yan",
                "labs": [
                    "School of Electrical Information Engineering, Northeast Petroleum University, Daqing, China"
                ]
            },
            {
                "name": "Chongyang Cheng",
                "labs": [
                    "School of Electrical Information Engineering, Northeast Petroleum University, Daqing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Distribution networks",
                "Voltage control",
                "Optimization",
                "Training",
                "Training data",
                "Renewable energy sources",
                "Prompt engineering",
                "Data models",
                "Biological system modeling",
                "Knowledge engineering"
            ],
            "Author Keywords": [
                "Deep reinforcement learning",
                "large language model",
                "voltage control",
                "multi-agent",
                "data augmentation",
                "data-driven"
            ]
        }
    },
    {
        "Title": "Generating Plausible and Context-Appropriate Comments on Social Media Posts: A Large Language Model-Based Approach",
        "Link": "https://ieeexplore.ieee.org/document/10740171/",
        "Abstract": "Research has examined diverse aspects of user commenting behaviors on online platforms, identifying critical engagement factors and influencing marketing strategies. However, a gap remains in predicting the specific comments and replies elicited by individual posts, which has become increasingly relevant as platforms aim to foster positive user interactions. This study applies a large language model (LLM) to bridge this gap, examining the effectiveness of three distinct prompt types in generating realistic comments and replies on social media posts. After fine-tuning LLMs with different prompts and 1,052,288 pairs of posts and comments, LLMs can effectively integrate textual and numerical post features to anticipate user interactions, with significant influence from the nature of the community on the response patterns. These findings underscore the potential of LLMs in enhancing social media analytics and suggest avenues for creating more engaging and responsive online communities. This study discusses the implications of this research for content strategy and highlights critical directions for future inquiry, emphasizing the integration of LLM capabilities with a detailed analysis of the user-generated content.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3488903",
            "Date of Publication": "31 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Taehyun Ha",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Sejong University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Semantics",
                "Predictive models",
                "Numerical models",
                "Measurement",
                "Large language models",
                "Decoding",
                "Data models",
                "Training",
                "Reviews",
                "User centered design",
                "User experience"
            ],
            "Author Keywords": [
                "Comment generation",
                "large language model",
                "post features",
                "social media",
                "user interaction"
            ]
        }
    },
    {
        "Title": "Intent-Based Multi-Cloud Storage Management Powered by a Fine-Tuned Large Language Model",
        "Link": "https://ieeexplore.ieee.org/document/10975014/",
        "Abstract": "Storage resources are essential in heterogeneous multi-cloud environments. In response to the growing demand for efficient storage resource management (SRM) in these environments, this paper proposes an intent-based storage management (IBSM) system powered by a fine-tuned large language model (LLM). To overcome the limitations of existing methods, the IBSM system focuses on enhancing the controllability, completeness, and reliability of SRM in multi-cloud environments. Specifically, the IBSM system employs a dual-phase joint intent classification algorithm, which leverages a fine-tuned LLM to accurately identify user intents across diverse knowledge backgrounds. Additionally, the system constructs a collaborative intent decomposition method, which guarantees the integrity of intents. Furthermore, the system integrates an automated intent deployment mechanism that supports error recovery through checkpoints. Experimental results show that the system achieves a whole end-to-end (E2E) lifecycle for managing user intents. The E2E time is reduced by at least half compared to the manual approach, with an average of 50.14% dedicated to interactive tasks. Performance metrics for intent classification, including accuracy, precision, and recall, all exceed 90%. Moreover, the recovery time is reduced by an average of 30.6%. Therefore, the system provides a valuable solution for the autonomous management of multi-cloud resources.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3563200",
            "Date of Publication": "23 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jingya Zheng",
                "labs": [
                    "Shandong Future Network Research Institute, Jinan, China"
                ]
            },
            {
                "name": "Gaofeng Tao",
                "labs": [
                    "Shandong Future Network Research Institute, Jinan, China",
                    "Purple Mountain Laboratories, Nanjing, China"
                ]
            },
            {
                "name": "Shuxin Qin",
                "labs": [
                    "Purple Mountain Laboratories, Nanjing, China"
                ]
            },
            {
                "name": "Dan Wang",
                "labs": [
                    "Purple Mountain Laboratories, Nanjing, China"
                ]
            },
            {
                "name": "Zhongjun Ma",
                "labs": [
                    "Shandong Future Network Research Institute, Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Translation",
                "Chatbots",
                "Long short term memory",
                "Prompt engineering",
                "Manuals",
                "Large language models",
                "Intent recognition",
                "Storage management",
                "Resource management",
                "Few shot learning"
            ],
            "Author Keywords": [
                "Autonomous management",
                "cloud computing",
                "cloud-network integration",
                "intent-based networking",
                "large language model",
                "multi-cloud"
            ]
        }
    },
    {
        "Title": "Enhancing Patient Acceptance of Robotic Ultrasound through Conversational Virtual Agent and Immersive Visualizations",
        "Link": "https://ieeexplore.ieee.org/document/10916942/",
        "Abstract": "Robotic ultrasound systems have the potential to improve medical diagnostics, but patient acceptance remains a key challenge. To address this, we propose a novel system that combines an AI-based virtual agent, powered by a large language model (LLM), with three mixed reality visualizations aimed at enhancing patient comfort and trust. The LLM enables the virtual assistant to engage in natural, conversational dialogue with patients, answering questions in any format and offering real-time reassurance, creating a more intelligent and reliable interaction. The virtual assistant is animated as controlling the ultrasound probe, giving the impression that the robot is guided by the assistant. The first visualization employs augmented reality (AR), allowing patients to see the real world and the robot with the virtual avatar superimposed. The second visualization is an augmented virtuality (AV) environment, where the real-world body part being scanned is visible, while a 3D Gaussian Splatting reconstruction of the room, excluding the robot, forms the virtual environment. The third is a fully immersive virtual reality (VR) experience, featuring the same 3D reconstruction but entirely virtual, where the patient sees a virtual representation of their body being scanned in a robot-free environment. In this case, the virtual ultrasound probe, mirrors the movement of the probe controlled by the robot, creating a synchronized experience as it touches and moves over the patient's virtual body. We conducted a comprehensive agent-guided robotic ultrasound study with all participants, comparing these visualizations against a standard robotic ultrasound procedure. Results showed significant improvements in patient trust, acceptance, and comfort. Based on these findings, we offer insights into designing future mixed reality visualizations and virtual agents to further enhance patient comfort and acceptance in autonomous medical procedures.",
        "Details": {
            "DOI": "10.1109/TVCG.2025.3549181",
            "Date of Publication": "07 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Visualization and Computer Graphics"
        },
        "issn_info": {
            "Print ISSN": "1077-2626",
            "Electronic ISSN": "1941-0506"
        },
        "authors_data": [
            {
                "name": "Tianyu Song",
                "labs": [
                    "Technical University of Munich, Germany"
                ]
            },
            {
                "name": "Felix Pabst",
                "labs": [
                    "Technical University of Munich, Germany"
                ]
            },
            {
                "name": "Ulrich Eck",
                "labs": [
                    "Technical University of Munich, Germany"
                ]
            },
            {
                "name": "Nassir Navab",
                "labs": [
                    "Technical University of Munich, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Ultrasonic imaging",
                "Visualization",
                "Mixed reality",
                "Medical services",
                "Virtual assistants",
                "Real-time systems",
                "Virtual environments",
                "Three-dimensional displays",
                "Probes"
            ],
            "Author Keywords": [
                "Mixed Reality",
                "Virtual Agent",
                "Robotic Ultrasound",
                "Trust and Acceptance"
            ]
        }
    },
    {
        "Title": "Measuring and Improving the Efficiency of Python Code Generated by LLMs Using CoT Prompting and Fine-Tuning",
        "Link": "https://ieeexplore.ieee.org/document/11069268/",
        "Abstract": "The burgeoning sophistication of Artificial Intelligence (AI) has catalyzed the rapid proliferation of Large Language Models (LLMs) within software development. These models are increasingly employed to automate the generation of functionally correct code, address complex computational problems, and facilitate the debugging of existing software systems. However, LLM-generated code often faces challenges due to inherent inefficiencies, including redundant logical structures, factually inconsistent content (hallucinations), and programming errors. To address this issue, our research rigorously evaluated the computational efficiency of Python code generated by three prominent LLMs: GPT-4o-Mini, GPT-3.5-Turbo, and GPT-4-Turbo. The evaluation metrics encompass execution time, memory utilization, and peak memory consumption, while maintaining the functional correctness of the generated code. Leveraging the EffiBench benchmark datasets within the Google Vertex AI Workbench environment, across a spectrum of machine configurations, the study implemented a consistent seed parameter to ensure experimental reproducibility. Furthermore, we investigated the impact of two distinct optimization strategies: Chain-of-Thought (CoT) prompting and model fine-tuning. Our findings reveal a significant enhancement in efficiency metrics for GPT-4o-Mini and GPT-3.5-Turbo when employing CoT prompting; however, this trend was not observed for GPT-4-Turbo. Based on its promising performance with CoT prompting, we selected the GPT-4o-Mini model for subsequent fine-tuning, aiming to further enhance both its computational efficiency and accuracy. However, contrary to our expectations, fine-tuning the GPT-4o-Mini model led to a discernible degradation in both its accuracy and computational efficiency. In conclusion, this study provides empirical evidence suggesting that the deployment of high-CPU machine configurations, in synergy with the utilization of the GPT-4o-Mini model and CoT prompting techniques, yields demonstrably more efficient and accurate LLM-generated Python code, particularly within computationally intensive application scenarios.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3585742",
            "Date of Publication": "03 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ramya Jonnala",
                "labs": [
                    "Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Jeong Yang",
                "labs": [
                    "Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Young Lee",
                "labs": [
                    "Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Gongbo Liang",
                "labs": [
                    "Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA"
                ]
            },
            {
                "name": "Zechun Cao",
                "labs": [
                    "Department of Computational, Engineering, and Mathematical Sciences, Texas A&M University-San Antonio, San Antonio, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Memory management",
                "Cloud computing",
                "Measurement",
                "Python",
                "Computational modeling",
                "Benchmark testing",
                "Computational efficiency",
                "Training",
                "Time measurement"
            ],
            "Author Keywords": [
                "LLMs",
                "vertex AI",
                "CoT",
                "fine-tuning",
                "Python",
                "code generation",
                "code efficiency",
                "code correctness",
                "execution time",
                "memory usage"
            ]
        }
    },
    {
        "Title": "Efficacy of Autonomous Vehicle’s Adaptive Decision-Making Based on Large Language Models Across Multiple Driving Scenarios",
        "Link": "https://ieeexplore.ieee.org/document/11039763/",
        "Abstract": "Understanding how large language models (LLMs) generalize across diverse traffic scenarios is critical for advancing autonomous driving systems. While previous studies have validated LLMs’ potential in specific driving tasks, evaluations of their scenario adaptability remain limited. This research adopts the Dilu framework as a case study, with the objective of investigating the generalisation performance of LLMs in five typical scenarios: basic highway sections, highway merge area, intersection, racetrack, and roundabout, with varying traffic parameters. Through extensive experiments with 17 configurations in scenarios metioned above, we employ success rate (SR) and success steps (SS) as metrics to quantify LLMs’ generalization capabilities in different driving scenarios. The results reveal significant scenario-dependent performance variations: the LLM achieves a peak SR of 99% at 30 m/s in low-speed merges but declines to 69% at 60 m/s. In intersection scenarios, the LLM outperforms traditional reinforcement learning methods (DQN, PPO) by about three times (61% SR vs. 24% SR). Furthermore, expanding memory entries from 2-shot to 5-shot enhances median SS by 114% in roundabouts and 69% in intersections, highlighting the role of experience accumulation in dynamic environments. These findings provide empirical evidence for LLMs’ scenario-aware generalization capabilities and offer actionable insights for optimizing their deployment in real-world autonomous driving systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3580641",
            "Date of Publication": "18 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guanzhi Xiong",
                "labs": [
                    "School of Transportation Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Siyang Liu",
                "labs": [
                    "School of Transportation Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Yihong Yan",
                "labs": [
                    "School of Transportation Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Qile Li",
                "labs": [
                    "School of Transportation Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Hangze Li",
                "labs": [
                    "School of Transportation Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous vehicles",
                "Decision making",
                "Cognition",
                "Reinforcement learning",
                "Planning",
                "Few shot learning",
                "Large language models",
                "Adaptation models",
                "Prompt engineering",
                "Adaptive systems"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "autonomous driving",
                "knowledge-driven framework",
                "multiple driving scenarios"
            ]
        }
    },
    {
        "Title": "Capturing the Process of Students' AI Interactions When Creating and Learning Complex Network Structures",
        "Link": "https://ieeexplore.ieee.org/document/10994563/",
        "Abstract": "Despite the growing use of large language models (LLMs) in educational contexts, there is no evidence on how these can be operationalized by students to generate custom datasets suitable for teaching and learning. Moreover, in the context of network science, little is known about whether LLMs can replicate real-life network properties. This study addresses these gaps by evaluating the use of generative artificial intelligence (AI), specifically LLMs, to create synthetic network datasets for educational use. The analyzed data include students’ AI-generated network datasets, their interactions with the LLMs, and their perceptions and evaluations of the task's value. The results indicate that the LLM-generated networks had properties closer to real-life networks, such as higher transitivity, network density, and smaller mean distances compared to randomly generated networks. Thus, our findings show that students can use LLMs to produce synthetic networks with realistic structures while tailoring to the individual preferences of each student. The analysis of students’ interactions (prompts) with the LLMs revealed a predominant use of direct instructions and output specifications, with less emphasis on providing contextual details or iterative refinement of the LLM's responses, which highlights the need for AI literacy training to optimize students’ use of generative AI. Students’ perceptions of the use of AI were overall positive; they found using LLMs time saving and beneficial, although opinions on output relevance and quality varied, especially for assignments requiring replication of specific networks.",
        "Details": {
            "DOI": "10.1109/TLT.2025.3568599",
            "Date of Publication": "09 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Learning Technologies"
        },
        "issn_info": {
            "Electronic ISSN": "1939-1382"
        },
        "authors_data": [
            {
                "name": "Sonsoles López-Pernas",
                "labs": [
                    "University of Eastern Finland, Joensuu, Finland"
                ]
            },
            {
                "name": "Kamila Misiejuk",
                "labs": [
                    "FernUniversität, Hagen, Germany"
                ]
            },
            {
                "name": "Rogers Kaliisa",
                "labs": [
                    "University of Oslo, Oslo, Norway"
                ]
            },
            {
                "name": "Mohammed Saqr",
                "labs": [
                    "University of Eastern Finland, Joensuu, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Synthetic data",
                "Generative AI",
                "Artificial intelligence",
                "Data collection",
                "Training",
                "Social networking (online)",
                "Large language models",
                "Training data",
                "Privacy",
                "Network analyzers"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI) in education",
                "generative AI",
                "large language models (LLMs)",
                "learning analytics",
                "sequence analysis",
                "social network analysis",
                "synthetic data generation",
                "transition network analysis"
            ]
        }
    },
    {
        "Title": "Large Language Model-Based Functional Scenario Generation for Automated Vehicle Safety Evaluation Using Vehicle and Pedestrian Traffic Accident Data",
        "Link": "https://ieeexplore.ieee.org/document/11175382/",
        "Abstract": "Despite advancements in automated driving technology, traffic accidents remain a significant safety concern in urban areas because of complex traffic environments and current technical limitations of automated vehicles (AV). Structured, quantitative scenario-based evaluations are essential for assessing AV safety. This study aims to generate functional scenarios by accurately inferring vehicle and pedestrian behavior information from unstructured traffic accident descriptions. The dataset comprises 137,432 traffic accident cases collected by the Korean National Police Agency. A total of 1,774 training samples were extracted using term frequency–inverse document frequency keyword analysis. We then evaluated the prediction performance of three large language models (LLM): Claude 3, GPT-4o, and GPT-4o with fine-tuning, using 500 randomly selected traffic accident records that lacked keyword-extractable behavior information. GPT-4o with fine-tuning achieved the highest accuracy of 81.1%. Using this model, 26 functional scenarios were generated. The risk levels for each scenario were evaluated by integrating the equivalent property damage only index with risk predictions from logistic regression and XGBoost models. A weighted average of the normalized results was used to rank the scenarios. Scenarios such as “turning left / crossing,” “straight / crossing,” and “turning right / crossing” were consistently identified as high-risk. This study demonstrates the effectiveness of LLM-based contextual inference in converting real-world traffic accident data into functional scenarios, and contributes to the advancement of AV safety evaluation frameworks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3612989",
            "Date of Publication": "22 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jihun Kang",
                "labs": [
                    "Department of Data, Network, and AI, Ajou University, Suwon-si, South Korea"
                ]
            },
            {
                "name": "Woori Ko",
                "labs": [
                    "Department of Transportation System Engineering, Ajou University, Suwon-si, South Korea"
                ]
            },
            {
                "name": "Youngtaek Lee",
                "labs": [
                    "Department of Data, Network, and AI, Ajou University, Suwon-si, South Korea"
                ]
            },
            {
                "name": "Kyeongjin Lee",
                "labs": [
                    "Department of Data, Network, and AI, Ajou University, Suwon-si, South Korea"
                ]
            },
            {
                "name": "Ilsoo Yun",
                "labs": [
                    "Department of Data, Network, and AI, Ajou University, Suwon-si, South Korea",
                    "Department of Transportation System Engineering, Ajou University, Suwon-si, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accidents",
                "Safety",
                "Pedestrians",
                "Roads",
                "Scenario generation",
                "Injuries",
                "Legged locomotion",
                "Indexes",
                "Turning",
                "Predictive models"
            ],
            "Author Keywords": [
                "Automated vehicle",
                "fine-tuning",
                "functional scenario",
                "large language model",
                "traffic accident description"
            ]
        }
    },
    {
        "Title": "A GPT-Based Code Review System With Accurate Feedback for Programming Education",
        "Link": "https://ieeexplore.ieee.org/document/11039773/",
        "Abstract": "The increasing demand for programming education and growing class sizes require immediate and personalized feedback. However, integrating Large Language Models (LLMs) like ChatGPT in introductory programming courses raises concerns about AI-assisted cheating. In large-scale settings, faulty code submissions may lead LLMs to overanalyze, causing unnecessary token consumption. This paper proposes a GPT-4o-based code review system that provides accurate feedback while reducing token usage and preventing AI-assisted cheating. Unlike general-purpose LLM tools for professionals, the system is pedagogically designed for primary and secondary students by focusing on review necessity and learner-friendly feedback. The system features a Code Review Module (CRM) that reduces token usage via a Review Necessity Chain (RNC), and Code Correctness Check Module (CCM) combining test case validation with LLM-based assessment. To prevent AI-assisted cheating, the system provides automated feedback on submitted code without prompting and revealing correct answers, which are accessed only through the “Ask Code Tutor” button. In usability test, the system detected up to 42.86% more errors than a conventional online judge. BERTScore analysis showed that over 80% of the system-generated reviews were semantically aligned with human feedback. A performance comparison with state-of-the-art systems demonstrated a blocking success rate of 86%, with a comparable review omission rate. These results indicate that the system provides more accurate feedback than conventional automated code reviews, while achieving token efficiency and supporting self-directed learning through educational feedback. Thus, it can serve as a practical solution for scalable programming education in primary and secondary classes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3581139",
            "Date of Publication": "18 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dong-Kyu Lee",
                "labs": [
                    "Department of Computer Science, Hanyang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Inwhee Joe",
                "labs": [
                    "Department of Computer Science, Hanyang University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Reviews",
                "Education",
                "Programming profession",
                "Chatbots",
                "Proposals",
                "Automation",
                "Accuracy",
                "Usability",
                "Training"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "GPT-4o",
                "programming education",
                "learner-friendly code reviews",
                "LangChain"
            ]
        }
    },
    {
        "Title": "Large Language Models in Transportation: A Comprehensive Bibliometric Analysis of Emerging Trends, Challenges, and Future Research",
        "Link": "https://ieeexplore.ieee.org/document/11080381/",
        "Abstract": "This paper presents a comprehensive review and bibliometric analysis of Large Language Models (LLMs) in transportation, exploring emerging trends, challenges and future research. Understanding their evolution and impact in transportation research is essential. The study used Scopus as the primary data source, applying Bibliometrix, VOSviewer, and Python for performance analysis and science mapping. This study analyzes 161 peer-reviewed articles and reveals a 25.74% annual growth in scholarly output. IEEE Transactions on Intelligent Transportation Systems and IEEE Transactions on Intelligent Vehicles emerge as the most influential journals by publication volume and impact on LLM research. The findings highlight global disparities in research contributions, with China and the United States dominating by publication volume, followed by Germany and Canada, while developing regions exhibit lower scientific productivity. In addition, the study provides qualitative insights by reviewing recent LLM applications in transportation, examining their key contributions, methodological approaches, inherent limitations, and domain-specific challenges. Key research themes focus on autonomous mobility, traffic optimization, and sustainable transportation networks. Despite significant progress, several challenges remain, including decision-making uncertainties, computational scalability, and high energy consumption. Overcoming these challenges requires greater transparency through causal learning, enhanced reasoning via hybrid AI models, and inclusive frameworks that address algorithmic bias and ensure equitable adoption.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3589319",
            "Date of Publication": "15 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mahbub Hassan",
                "labs": [
                    "Faculty of Civil Engineering and Technology, Universiti Malaysia Perlis (UniMAP), Arau, Malaysia"
                ]
            },
            {
                "name": "Md. Emtiaz Kabir",
                "labs": [
                    "Department of Civil Engineering, Atish Dipankar University of Science and Technology (ADUST), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Muzammil Jusoh",
                "labs": [
                    "Centre of Excellence for Advanced Computing (AdvComp), Faculty of Electronic Engineering Technology, UniMAP, Arau, Malaysia",
                    "Centre for Research Impact and Outcome, Chitkara University Institute of Engineering and Technology, Chitkara University, Rajpura, Punjab, India"
                ]
            },
            {
                "name": "Hong Ki An",
                "labs": [
                    "Faculty of Civil Engineering and Technology, Universiti Malaysia Perlis (UniMAP), Arau, Malaysia"
                ]
            },
            {
                "name": "Michael Negnevitsky",
                "labs": [
                    "School of Engineering, University of Tasmania, Hobart, Australia"
                ]
            },
            {
                "name": "Chengjiang Li",
                "labs": [
                    "School of Management, Guizhou University, Guiyang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transportation",
                "Computational modeling",
                "Bibliometrics",
                "Market research",
                "Transformers",
                "Safety",
                "Real-time systems",
                "Context modeling",
                "Reviews",
                "Optimization"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "bibliometric analysis",
                "intelligent transportation systems",
                "large language models",
                "smart mobility",
                "transportation"
            ]
        }
    },
    {
        "Title": "An Adapted Few-Shot Prompting Technique Using ChatGPT to Advance Low-Resource Languages Understanding",
        "Link": "https://ieeexplore.ieee.org/document/11016028/",
        "Abstract": "The lack of annotated data in low-resource languages presents a significant challenge in natural language processing, particularly for language understanding tasks such as intent detection and slot filling. To address this, we propose a novel approach that first employs an effective cross-lingual transfer model to generate labeled data for the target language, overcoming the scarcity of labeled data in low-resource settings. The main contribution of our work lies in the second step, where we introduce an adapted few-shot prompting technique to guide ChatGPT as a large language model (LLM). In this step, a subset of the machine-generated examples is selected based on the domain of the input, ensuring that the LLM is provided with more tailored and domain-specific examples. This two-step process leads to enhanced performance in handling low-resource languages. We conduct extensive experiments on Spanish, Thai, and Persian using the Facebook-multilingual and Persian-ATIS datasets. Experimental results demonstrate that our method outperforms existing techniques for non-Latin languages, such as Thai and Persian, and matches state-of-the-art performance for Latin-based languages, such as Spanish. The repository for this study is publicly available at https://github.com/saedeht/language-understanding-chatgpt",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574115",
            "Date of Publication": "27 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Saedeh Tahery",
                "labs": [
                    "Faculty of Computer Engineering, K. N. Toosi University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Saeed Farzi",
                "labs": [
                    "Faculty of Computer Engineering, K. N. Toosi University of Technology, Tehran, Iran",
                    "Fondazione Bruno Kessler, Trento, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multilingual",
                "Adaptation models",
                "Chatbots",
                "Data models",
                "Training",
                "Natural language processing",
                "Large language models",
                "Buildings",
                "Translation",
                "Transfer learning"
            ],
            "Author Keywords": [
                "ChatGPT",
                "few-shot prompting",
                "language understanding tasks",
                "large language models",
                "low-resource languages"
            ]
        }
    },
    {
        "Title": "M2D-CLAP: Exploring General-Purpose Audio-Language Representations Beyond CLAP",
        "Link": "https://ieeexplore.ieee.org/document/11168481/",
        "Abstract": "Contrastive language-audio pre-training (CLAP), which learns audio-language representations by aligning audio and text in a common feature space, has become popular for solving audio tasks. However, CLAP’s audio features lack generalizability, whereas self-supervised learning (SSL) models offer general-purpose features that perform well across diverse audio tasks. We aim to develop a broadly applicable audio representation and hypothesize that a model that learns both general audio and CLAP features should achieve our goal, which we call a general-purpose audio-language representation. To implement our hypothesis, we propose M2D-CLAP, the first approach to jointly learn effective general audio and CLAP features. It extends an SSL masked modeling duo (M2D) by incorporating CLAP and utilizes LLM-based sentence embeddings. The training process consists of multiple stages. In the first stage, generalizable audio features are pre-trained via a multitask objective combining M2D and CLAP, with CLAP leveraging LLM-based semantic embeddings to distill semantic knowledge into them. In the following stages, CLAP features are pre-trained and refined with guidance from the learned audio features. Experiments demonstrated that M2D-CLAP learns high-performing general audio features (e.g., AudioSet mAP of 49.0, SOTA results in music tasks) and CLAP features, thereby enabling a general-purpose audio-language representation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611348",
            "Date of Publication": "17 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Daisuke Niizumi",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            },
            {
                "name": "Daiki Takeuchi",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            },
            {
                "name": "Masahiro Yasuda",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            },
            {
                "name": "Binh Thien Nguyen",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            },
            {
                "name": "Yasunori Ohishi",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            },
            {
                "name": "Noboru Harada",
                "labs": [
                    "Communication Science Laboratories, NTT, Inc., Atsugi, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Semantics",
                "Training",
                "Encoding",
                "Supervised learning",
                "Representation learning",
                "Transformers",
                "Transfer learning",
                "Spectrogram",
                "Predictive models"
            ],
            "Author Keywords": [
                "Audio representation learning",
                "general-purpose audio-language representation",
                "masked modeling duo",
                "CLAP"
            ]
        }
    },
    {
        "Title": "In-Context Learning in Large Language Models (LLMs): Mechanisms, Capabilities, and Implications for Advanced Knowledge Representation and Reasoning",
        "Link": "https://ieeexplore.ieee.org/document/11018434/",
        "Abstract": "The rapid growth of Large Language Models (LLMs) and their in-context learning (ICL) capabilities has significantly transformed paradigms in artificial intelligence (AI) and natural language processing. Notable models, such as OpenAI’s GPT series, have demonstrated previously unprecedented advancements in verbal comprehension and adaptability, dynamically responding to new tasks offered via contextual prompts. This study provides a detailed survey of recent advances in theoretical research on LLMs and ICL. The search was conducted across several scholarly databases including Google Scholar, arXiv, IEEE Xplore, ACM Digital Library, and SpringerLink, covering publications from January 2019 to March 2024. We investigate how LLMs encode and use knowledge via ICL, the evolving reasoning skills that result from this process, and the considerable impact of prompt design on LLM reasoning performance, particularly in symbolic reasoning tasks. Furthermore, we investigate the theoretical frameworks that explain or challenge LLM behaviors in ICL contexts and address the significance of these findings for the development of complex knowledge representation and reasoning systems. Using a systematic methodology consistent with accepted research criteria, this review synthesizes significant observations, highlights existing gaps and obstacles, and discusses implications for future research and practice. Our goal is to connect theoretical ideas with actual advances in Artificial Intelligence, ultimately contributing to the continuing discussion about the capabilities and applications of LLMs in knowledge representation and reasoning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3575303",
            "Date of Publication": "30 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Azza Mohamed",
                "labs": [
                    "Faculty of Engineering and Computing, Liwa University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Mohamed El Rashid",
                "labs": [
                    "Imam Malik College, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Khaled Shaalan",
                "labs": [
                    "Faculty of Engineering and IT, The British University in Dubai, Dubai, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Artificial intelligence",
                "Knowledge representation",
                "Systematic literature review",
                "Gaze tracking",
                "Solid modeling",
                "Benchmark testing",
                "Training",
                "Context modeling",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "in-context learning",
                "large language models (LLMs)",
                "knowledge representation reasoning",
                "advanced AI models",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Automating IoT Data Privacy Compliance by Integrating Knowledge Graphs With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11072168/",
        "Abstract": "Regulatory compliance is mandatory for Internet of Things (IoT) manufacturers, particularly under stringent frameworks such as the General Data Protection Regulation (GDPR), which governs the handling of personal data. We introduce a novel framework for automating IoT compliance verification by integrating a Large Language Model (LLM) with a domain-specific Knowledge Graph (KG). The framework achieves two primary objectives: 1) leveraging the LLM to interpret natural-language compliance queries, and 2) employing a KG populated with synthetic GDPR scenarios to provide structured, up-to-date regulatory guidance, modeling obligations, permissions, and prohibitions for both deontic (normative) and non-deontic (factual) queries, thus mitigating biases and hallucinations inherent in language models. Evaluated on 50 representative GDPR compliance queries, our approach achieves high semantic alignment (mean BERTScore F1 of 0.89), with expert reviewers rating approximately 84% of generated compliance advice as fully or mostly correct. This work offers IoT manufacturers a scalable, automated solution for data privacy compliance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586278",
            "Date of Publication": "07 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kelvin U. Echenim",
                "labs": [
                    "Department of Information Systems, University of Maryland, Baltimore County, MD, USA"
                ]
            },
            {
                "name": "Karuna P. Joshi",
                "labs": [
                    "Department of Information Systems, University of Maryland, Baltimore County, MD, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Law",
                "Cognition",
                "Data privacy",
                "Large language models",
                "Knowledge graphs",
                "Accuracy",
                "Regulation",
                "General Data Protection Regulation",
                "Privacy"
            ],
            "Author Keywords": [
                "Data privacy compliance",
                "IoT",
                "knowledge graphs",
                "large language models",
                "regulatory compliance automation",
                "semantic interoperability",
                "wearables"
            ]
        }
    },
    {
        "Title": "ADAM-1: An AI Reasoning and Bioinformatics Model for Alzheimer’s Disease Detection and Microbiome-Clinical Data Integration",
        "Link": "https://ieeexplore.ieee.org/document/11129017/",
        "Abstract": "Alzheimer’s Disease Analysis Model Generation 1 (ADAM-1) is a multi-agent reasoning large language model (LLM) framework designed to integrate and analyze multimodal data, including microbiome profiles, clinical datasets, and external knowledge bases, to enhance the understanding and classification of Alzheimer’s disease (AD). By leveraging the agentic system with LLM, ADAM-1 produces insights from diverse data sources and contextualizes the findings with literature-driven evidence. A comparative evaluation with XGBoost revealed a significantly improved mean F1 score and significantly reduced variance for ADAM-1, highlighting its robustness and consistency, particularly when utilizing human biological data. Although currently tailored for binary classification tasks with two data modalities, future iterations will aim to incorporate additional data types, such as neuroimaging and peripheral biomarkers, and expand them to predict disease progression, thereby broadening ADAM-1’s scalability and applicability in AD research and diagnostic applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599857",
            "Date of Publication": "18 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ziyuan Huang",
                "labs": [
                    "Department of Microbiology, UMass Chan Medical School, Worcester, MA, USA",
                    "Department of Emergency Medicine, UMass Chan Medical School, Worcester, MA, USA",
                    "Program in Microbiome Dynamics, UMass Chan Medical School, Worcester, MA, USA"
                ]
            },
            {
                "name": "Vishaldeep Kaur Sekhon",
                "labs": [
                    "Department of Geriatric Medicine and Gerontology, Johns Hopkins University, Baltimore, MD, USA"
                ]
            },
            {
                "name": "Roozbeh Sadeghian",
                "labs": [
                    "School of Analytics and Computational Sciences, Program in Data Sciences, Harrisburg University of Science and Technology, Harrisburg, PA, USA"
                ]
            },
            {
                "name": "Maria L. Vaida",
                "labs": [
                    "School of Analytics and Computational Sciences, Program in Data Sciences, Harrisburg University of Science and Technology, Harrisburg, PA, USA"
                ]
            },
            {
                "name": "Cynthia Jo",
                "labs": [
                    "Department of Emergency Medicine, UMass Chan Medical School, Worcester, MA, USA"
                ]
            },
            {
                "name": "Beth A. McCormick",
                "labs": [
                    "Department of Microbiology, UMass Chan Medical School, Worcester, MA, USA",
                    "Program in Microbiome Dynamics, UMass Chan Medical School, Worcester, MA, USA"
                ]
            },
            {
                "name": "Doyle V. Ward",
                "labs": [
                    "Department of Microbiology, UMass Chan Medical School, Worcester, MA, USA",
                    "Program in Microbiome Dynamics, UMass Chan Medical School, Worcester, MA, USA"
                ]
            },
            {
                "name": "Vanni Bucci",
                "labs": [
                    "Department of Microbiology, UMass Chan Medical School, Worcester, MA, USA",
                    "Program in Microbiome Dynamics, UMass Chan Medical School, Worcester, MA, USA"
                ]
            },
            {
                "name": "John P. Haran",
                "labs": [
                    "Department of Microbiology, UMass Chan Medical School, Worcester, MA, USA",
                    "Department of Emergency Medicine, UMass Chan Medical School, Worcester, MA, USA",
                    "Program in Microbiome Dynamics, UMass Chan Medical School, Worcester, MA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Microorganisms",
                "Diseases",
                "Alzheimer's disease",
                "Cognition",
                "Medical diagnostic imaging",
                "Artificial intelligence",
                "Medical services",
                "Bioinformatics",
                "Engines",
                "Semantic search"
            ],
            "Author Keywords": [
                "Alzheimer’s disease",
                "artificial intelligence",
                "multi-agent systems",
                "knowledge based systems"
            ]
        }
    },
    {
        "Title": "Addressing Activation Outliers in LLMs: A Systematic Review of Post-Training Quantization Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10994764/",
        "Abstract": "Large Language Models (LLMs) have transformed natural language processing, yet their deployment remains challenging due to substantial computational, memory, and energy demands. Post-training quantization has emerged as a key strategy for enabling efficient inference, particularly in resource-constrained settings. This systematic review focuses on weight-activation quantization, with a unique emphasis on the emergent outlier phenomenon in LLM activations. This work evaluates recent techniques that mitigate activation outliers and improve quantization efficiency, distinguishing itself from prior reviews. Using the PRISMA methodology, we examine 52 recent studies to uncover key trends and evaluate the effectiveness of different approaches. By synthesizing insights from these works, this review presents a diverse set of techniques and their implications for activation quantization, laying the groundwork for future research and practical advancements in LLM deployment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3568702",
            "Date of Publication": "09 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Patrik Czakó",
                "labs": [
                    "Doctoral School of Applied Informatics and Applied Mathematics, Óbuda University, Budapest, Hungary"
                ]
            },
            {
                "name": "Gábor Kertész",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Laboratory of Parallel and Distributed Systems, Institute for Computer Science and Control (SZTAKI), Hungarian Research Network (HUN-REN), Budapest, Hungary"
                ]
            },
            {
                "name": "Sándor Szénási",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Faculty of Economics and Informatics, J. Selye University, Komárno, Slovakia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Computational modeling",
                "Throughput",
                "Arithmetic",
                "Decoding",
                "Adaptation models",
                "Transformers",
                "Systematics",
                "Systematic literature review",
                "Large language models"
            ],
            "Author Keywords": [
                "Activation outliers",
                "efficient inference",
                "large language models (LLMs)",
                "model compression",
                "quantization"
            ]
        }
    },
    {
        "Title": "PEARL: An Adaptive and Explainable Hardware Trojan Detection Using Open Source and Enterprise Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11091291/",
        "Abstract": "The Integrated Circuit (IC) supply chain risk allows attackers to implant hardware Trojans (HT) in various stages of chip production. To counter this, different machine learning (ML) and deep learning (DL)-based methods have been developed to detect HTs. However, these methods require massive amounts of high-quality labeled data for effective training, extended training times for accurate HT detection, limited generalization to novel or unseen HTs, and insufficient capability to explain the detected HTs. Recent studies have started exploring the potential of Large language models (LLMs) for hardware security tasks. However, there are no current studies that explore, study, and compare the applicability of open-source vs. enterprise LLMs for efficient HT detection and explanation of the detected HT. To close the gap, we propose an innovative HT detection and explanation method by leveraging the knowledge of a pre-trained LLM, namely enterprise application programming interface (API)-enabled a Generative Pre-trained Transformer (GPT)-3.5 Turbo, Google Gemini 1.5 Pro and open-source LLMs: Meta AI Llama-3.1 and DeepSeek AI DeepSeek-V2 models, which have already been trained on massive and diverse datasets and is capable of providing the reasoning of the detected HT. Specifically, we apply In-Context Learning (ICL)-based mechanisms: zero-shot, one-shot, and few-shot learning strategies (e.g., register transfer level (RTL) files (Verilog) of the circuit) to adopt this model for HT detection and explanation tasks. We validate our proposed approach on diverse circuit design benchmarks from Trust-Hub and ISCAS (85 and 89). Our experimental results show that the proposed few-shot learning-based enterprise-API-enabled GPT-3.5 Turbo and open-source DeepSeek-V2 LLM models detect unknown HTs with an accuracy of 97% and 91% and drastically reduce the training time compared to state-of-the-art techniques. Furthermore, after detecting the HT, they provide human-centric reasoning/explanation, reinforcing transparency and trust in the IC supply chain through its understanding.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3592030",
            "Date of Publication": "23 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ripan Kumar Kundu",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Khurram Khalil",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Eric Garcia",
                "labs": [
                    "Columbia College, Columbia, MO, USA"
                ]
            },
            {
                "name": "Ethan Grassia",
                "labs": [
                    "Department of Computer Science, Loyola University, Chicago, IL, USA"
                ]
            },
            {
                "name": "Prasad Calyam",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            },
            {
                "name": "Khaza Anuarul Hoque",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Missouri, Columbia, MO, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trojan horses",
                "Training",
                "Computational modeling",
                "Integrated circuit modeling",
                "Accuracy",
                "Data models",
                "Cognition",
                "Benchmark testing",
                "Register transfer level",
                "Predictive models"
            ],
            "Author Keywords": [
                "Hardware trojan",
                "deep learning",
                "large language model",
                "in-context learning",
                "explainable AI"
            ]
        }
    },
    {
        "Title": "MAD-CTI: Cyber Threat Intelligence Analysis of the Dark Web Using a Multi-Agent Framework",
        "Link": "https://ieeexplore.ieee.org/document/10908603/",
        "Abstract": "The dark web is a host to illicit activities where hacker forums, blogs, and articles provide significant insights into Cyber Threat Intelligence (CTI) that are frequently unavailable on the surface web. The increasing incidence of security breaches underscores the necessity for advanced CTI solutions to defend against emerging threats. This paper introduces MAD-CTI, a novel multi-agent framework based on Large Language Models (LLM) designed to extract insights from dark web sources. It independently scrapes, analyzes, and classifies content related to vulnerabilities, malware, and hacking, by leveraging a multi-agent architecture to improve efficiency, scalability, and consistency. By utilizing state-of-the-art LLM models and agents, we demonstrate how organizations can adopt this methodology to enhance the accuracy and efficiency of CTI.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3547172",
            "Date of Publication": "03 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sayuj Shah",
                "labs": [
                    "College of Computing, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Vijay K. Madisetti",
                "labs": [
                    "School of Cybersecurity and Privacy, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Dark Web",
                "Cyber threat intelligence",
                "Malware",
                "Translation",
                "Oral communication",
                "Computer hacking",
                "Blogs",
                "Accuracy",
                "Large language models",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Cybersecurity defense",
                "cyber threat intelligence",
                "dark web",
                "hack",
                "large language models (LLMs)",
                "malware",
                "multi-agent systems (MAS)",
                "predictive intelligence",
                "vulnerability"
            ]
        }
    },
    {
        "Title": "TypeFly: Low-Latency Drone Planning With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10970379/",
        "Abstract": "Recent advancements in robot planning using large language models (LLMs) have demonstrated significant potential, primarily due to LLMs’ capabilities to understand natural language commands and generate executable plans in various languages. However, in time-sensitive and interactive applications involving mobile robots, particularly drones, the sequential token generation process inherent to LLMs introduces substantial latency, i.e. response time, during the control plan generation. In this paper, we present a system called TypeFly that tackles this latency problem using a combination of a novel programming language called MiniSpec and its runtime to reduce both the response time and generation time for the robot plan. That is, instead of asking an LLM to write a program (robotic plan) in the popular but verbose Python, TypeFly gets it to do it in MiniSpec specially designed for token efficiency and stream interpreting. Using a set of challenging drone tasks, we show that design choices made by TypeFly can reduce the average response time to 74% compared to existing works and provide a more consistent user experience, enabling responsive and intelligent LLM-based drone control.",
        "Details": {
            "DOI": "10.1109/TMC.2025.3561282",
            "Date of Publication": "18 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Mobile Computing"
        },
        "issn_info": {
            "Print ISSN": "1536-1233",
            "Electronic ISSN": "1558-0660"
        },
        "authors_data": [
            {
                "name": "Guojun Chen",
                "labs": [
                    "Yale University, New Haven, CT, USA"
                ]
            },
            {
                "name": "Xiaojing Yu",
                "labs": [
                    "Yale University, New Haven, CT, USA"
                ]
            },
            {
                "name": "Neiwen Ling",
                "labs": [
                    "Yale University, New Haven, CT, USA"
                ]
            },
            {
                "name": "Lin Zhong",
                "labs": [
                    "Yale University, New Haven, CT, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Drones",
                "Robots",
                "Planning",
                "Time factors",
                "Python",
                "Probes",
                "Syntactics",
                "Runtime",
                "Technological innovation",
                "Servers"
            ],
            "Author Keywords": [
                "Large language models",
                "drones",
                "command and control systems"
            ]
        }
    },
    {
        "Title": "Leveraging Non-Parametric Reasoning With Large Language Models for Enhanced Knowledge Graph Completion",
        "Link": "https://ieeexplore.ieee.org/document/10766600/",
        "Abstract": "The completeness of knowledge graphs is critical to their effectiveness across various applications. However, existing knowledge graph completion methods face challenges such as difficulty in adapting to new entity information, parameter explosion, and limited generalization capability. To address these issues, this paper proposes a knowledge graph completion framework that integrates large language models with case-based reasoning (CBR-LLM). By combining non-parametric reasoning with the semantic understanding capabilities of large language models, the framework not only improves completion accuracy but also significantly enhances generalization under various data-missing scenarios. Experimental results demonstrate that CBR-LLM excels in handling complex reasoning tasks and large-scale data-missing scenarios, providing an efficient and scalable solution for knowledge graph completion.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3505433",
            "Date of Publication": "25 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ying Zhang",
                "labs": [
                    "Academy of Military Sciences (AMS), Institute of Systems Engineering, Beijing, China"
                ]
            },
            {
                "name": "Yangpeng Shen",
                "labs": [
                    "CITIC Bank, Beijing, China"
                ]
            },
            {
                "name": "Gang Xiao",
                "labs": [
                    "Academy of Military Sciences (AMS), Institute of Systems Engineering, Beijing, China"
                ]
            },
            {
                "name": "Jinghui Peng",
                "labs": [
                    "School of Artificial Intelligence, Anhui Polytechnic University, Wuhu, Anhui, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge graphs",
                "Cognition",
                "Accuracy",
                "Computational modeling",
                "Data models",
                "Semantics",
                "Large language models",
                "Training",
                "User experience",
                "Tail"
            ],
            "Author Keywords": [
                "Case-based reasoning",
                "large language model",
                "information entropy",
                "knowledge graph completion"
            ]
        }
    },
    {
        "Title": "A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model",
        "Link": "https://ieeexplore.ieee.org/document/10452390/",
        "Abstract": "In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2285",
            "Date of Publication": "November 2023",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Daeseung Park",
                "labs": [
                    "Department of Computer Science, Namseoul University, Cheonan, Republic of Korea"
                ]
            },
            {
                "name": "Gi-taek An",
                "labs": [
                    "Korea Food Research Institute, Wanju-gun, Republic of Korea"
                ]
            },
            {
                "name": "Chayapol Kamyod",
                "labs": [
                    "Computer and Communication Engineering for Capacity Building Research Center, School of Information Technology, Mae Fah Luang University, Chiang Rai, Thailand"
                ]
            },
            {
                "name": "Cheong Ghil Kim",
                "labs": [
                    "Department of Computer Science, Namseoul University, Cheonan, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generative AI",
                "Transforms",
                "Chatbots",
                "Internet"
            ],
            "Author Keywords": [
                "AI",
                "large language model",
                "generative AI",
                "few-shot learning",
                "prompt engineering",
                "AI Chatbot"
            ]
        }
    },
    {
        "Title": "Beam Prediction Based on Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10892257/",
        "Abstract": "In this letter, we use large language models (LLMs) to develop a high-performing and robust beam prediction method. We formulate the millimeter wave (mmWave) beam prediction problem as a time series forecasting task, where the historical observations are aggregated through cross-variable attention and then transformed into text-based representations using a trainable tokenizer. By leveraging the prompt-as-prefix (PaP) technique for contextual enrichment, our method harnesses the power of LLMs to predict future optimal beams. Simulation results demonstrate that our LLM-based approach outperforms traditional learning-based models in prediction accuracy as well as robustness, highlighting the significant potential of LLMs in enhancing wireless communication systems.",
        "Details": {
            "DOI": "10.1109/LWC.2025.3543567",
            "Date of Publication": "19 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Wireless Communications Letters"
        },
        "issn_info": {
            "Print ISSN": "2162-2337",
            "Electronic ISSN": "2162-2345"
        },
        "authors_data": [
            {
                "name": "Yucheng Sheng",
                "labs": [
                    "National Mobile Communications Research Laboratory, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Kai Huang",
                "labs": [
                    "National Mobile Communications Research Laboratory, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Le Liang",
                "labs": [
                    "National Mobile Communications Research Laboratory, Southeast University, Nanjing, China",
                    "Purple Mountain Laboratories, Nanjing, China"
                ]
            },
            {
                "name": "Peng Liu",
                "labs": [
                    "Huawei Technologies Company Ltd., Shenzhen, China"
                ]
            },
            {
                "name": "Shi Jin",
                "labs": [
                    "National Mobile Communications Research Laboratory, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Geoffrey Ye Li",
                "labs": [
                    "Department of Electrical and Electronic Engineering, ITP Lab, Imperial College London, London, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Wireless communication",
                "Time series analysis",
                "Predictive models",
                "Millimeter wave communication",
                "Market research",
                "Antennas",
                "Training",
                "Vocabulary",
                "Robustness",
                "Prototypes"
            ],
            "Author Keywords": [
                "Beam prediction",
                "large language model",
                "time series forecasting",
                "cross attention"
            ]
        }
    },
    {
        "Title": "Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10121440/",
        "Abstract": "The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with prior studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3274199",
            "Date of Publication": "08 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Paula Maddigan",
                "labs": [
                    "School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand"
                ]
            },
            {
                "name": "Teo Susnjak",
                "labs": [
                    "School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Task analysis",
                "Data models",
                "Codes",
                "Chatbots",
                "Transformers",
                "Market research",
                "Natural language processing",
                "Text recognition"
            ],
            "Author Keywords": [
                "ChatGPT",
                "codex",
                "end-to-end visualisations from natural language",
                "GPT-3",
                "large language models",
                "natural language interfaces",
                "text-to-visualisation"
            ]
        }
    },
    {
        "Title": "A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?",
        "Link": "https://ieeexplore.ieee.org/document/10380590/",
        "Abstract": "Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3349952",
            "Date of Publication": "04 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "John Fields",
                "labs": [
                    "Business Analytics, Concordia University Wisconsin-Ann Arbor, Mequon, WI, USA",
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Kevin Chovanec",
                "labs": [
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Praveen Madiraju",
                "labs": [
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Transformers",
                "Surveys",
                "Task analysis",
                "Taxonomy",
                "Data models",
                "Chatbots"
            ],
            "Author Keywords": [
                "NLP",
                "text classification",
                "transformers",
                "survey"
            ]
        }
    },
    {
        "Title": "Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course",
        "Link": "https://ieeexplore.ieee.org/document/10478015/",
        "Abstract": "Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students’ learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT’s generated code to the exercises’ implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3380909",
            "Date of Publication": "22 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Philipp Haindl",
                "labs": [
                    "Department of Computer Science and Security, St. Pölten University of Applied Sciences, St. Pölten, Austria"
                ]
            },
            {
                "name": "Gerald Weinberger",
                "labs": [
                    "Department of Computer Science and Security, St. Pölten University of Applied Sciences, St. Pölten, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Codes",
                "Programming profession",
                "Task analysis",
                "Education",
                "Artificial intelligence",
                "Surveys"
            ],
            "Author Keywords": [
                "Programming education",
                "ChatGPT",
                "generative AI",
                "large language models"
            ]
        }
    },
    {
        "Title": "Generation of Asset Administration Shell With Large Language Model Agents: Toward Semantic Interoperability in Digital Twins in the Context of Industry 4.0",
        "Link": "https://ieeexplore.ieee.org/document/10559483/",
        "Abstract": "This research introduces a novel approach for achieving semantic interoperability in digital twins and assisting the creation of Asset Administration Shell (AAS) as digital twin model within the context of Industry 4.0. The foundational idea of our research is that the communication based on semantics and the generation of meaningful textual data are directly linked, and we posit that these processes are equivalent if the exchanged information can be serialized in text form. Based on this, we construct a “semantic node” data structure in our research to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process the “semantic node” and generate standardized digital twin models (AAS instance models in the context of Industry 4.0) from raw textual data collected from datasheets describing technical assets. Our evaluation demonstrates an effective generation rate of 62-79%, indicating a substantial proportion of the information from the source text can be translated error-free to the target digital twin instance model with the generative capability of large language models. This result has a direct application in the context of Industry 4.0, and the designed system is implemented as a data model generation tool for reducing the manual effort in creating AAS model by automatically translating unstructured textual data into a standardized AAS model. The generated AAS model can be integrated into AAS-compliant digital twin software for seamless information exchange and communication. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts and translating data. Our findings emphasize LLMs’ capability to automate AAS instance creation and contribute to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are presented on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3415470",
            "Date of Publication": "17 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuchen Xia",
                "labs": [
                    "Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, Germany"
                ]
            },
            {
                "name": "Zhewen Xiao",
                "labs": [
                    "Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, Germany"
                ]
            },
            {
                "name": "Nasser Jazdi",
                "labs": [
                    "Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, Germany"
                ]
            },
            {
                "name": "Michael Weyrich",
                "labs": [
                    "Institute of Industrial Automation and Software Engineering, University of Stuttgart, Stuttgart, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Data models",
                "Digital twins",
                "Context modeling",
                "Interoperability",
                "Unified modeling language",
                "Fourth Industrial Revolution",
                "Large language models",
                "Information retrieval",
                "Augmented reality"
            ],
            "Author Keywords": [
                "Asset administration shell",
                "large language model",
                "semantic interoperability",
                "digital twin",
                "industry 4.0",
                "generative AI",
                "retrieval-augmented generation"
            ]
        }
    },
    {
        "Title": "PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3",
        "Link": "https://ieeexplore.ieee.org/document/10287342/",
        "Abstract": "The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI’s Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3325727",
            "Date of Publication": "18 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Danial Khosh Kholgh",
                "labs": [
                    "Center for Ubiquitous Computing, University of Oulu, Oulu, Finland"
                ]
            },
            {
                "name": "Panos Kostakos",
                "labs": [
                    "Center for Ubiquitous Computing, University of Oulu, Oulu, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generators",
                "Telecommunication traffic",
                "Computer security",
                "Transformers",
                "Task analysis",
                "Protocols",
                "Machine learning",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "cybersecurity",
                "generative pre-trained transformer",
                "GPT-3",
                "machine learning",
                "NLP",
                "transformer",
                "LLMs"
            ]
        }
    },
    {
        "Title": "How Good Is ChatGPT at Face Biometrics? A First Look Into Recognition, Soft Biometrics, and Explainability",
        "Link": "https://ieeexplore.ieee.org/document/10445251/",
        "Abstract": "Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning). The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of automatic decisions in human scenarios. Experiments are carried out in order to evaluate the performance and robustness of ChatGPT, using popular public benchmarks and comparing the results with state-of-the-art methods in the field. The results achieved in this study show the potential of LLMs such as ChatGPT for face biometrics, especially to enhance explainability. For reproducibility reasons, we release all the code in GitHub.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3370437",
            "Date of Publication": "26 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ivan Deandres-Tame",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Ruben Tolosana",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Ruben Vera-Rodriguez",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Aythami Morales",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Julian Fierrez",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Javier Ortega-Garcia",
                "labs": [
                    "Biometrics and Data Pattern Analytics Laboratory—BiDA Laboratory, Universidad Autónoma de Madrid, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Face recognition",
                "Task analysis",
                "Image color analysis",
                "Facial features",
                "Estimation",
                "Biological system modeling",
                "Large language models",
                "Biometrics (access control)",
                "Explainable AI"
            ],
            "Author Keywords": [
                "Large language models",
                "ChatGPT",
                "face recognition",
                "soft biometrics",
                "explainability"
            ]
        }
    },
    {
        "Title": "Navigating the Web of Disinformation and Misinformation: Large Language Models as Double-Edged Swords",
        "Link": "https://ieeexplore.ieee.org/document/10540581/",
        "Abstract": "This paper explores the dual role of Large Language Models (LLMs) in the context of online misinformation and disinformation. In today’s digital landscape, where the internet and social media facilitate the rapid dissemination of information, discerning between accurate content and falsified information presents a formidable challenge. Misinformation, often arising unintentionally, and disinformation, crafted deliberately, are at the forefront of this challenge. LLMs such as OpenAI’s GPT-4, equipped with advanced language generation abilities, present a double-edged sword in this scenario. While they hold promise in combating misinformation by fact-checking and detecting LLM-generated text, their ability to generate realistic, contextually relevant text also poses risks for creating and propagating misinformation. Further, LLMs are plagued with many problems such as biases, knowledge cutoffs, and hallucinations, which may further perpetuate misinformation and disinformation. The paper outlines historical developments in misinformation detection and how it affects social media consumption, especially among youth, and introduces LLMs and their applications in various domains. It then critically analyzes the potential of LLMs to generate and counter misinformation and disinformation in sensitive topics such as healthcare, COVID-19, and political agendas. Further, it discusses mitigation strategies, ethical considerations, and regulatory measures, summarizing previous methods and proposing future research direction toward leveraging the benefits of LLMs while minimizing misuse risks. The paper concludes by acknowledging LLMs as powerful tools with significant implications in both spreading and combating misinformation in the digital age.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3406644",
            "Date of Publication": "29 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Siddhant Bikram Shah",
                "labs": [
                    "Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India"
                ]
            },
            {
                "name": "Surendrabikram Thapa",
                "labs": [
                    "Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "Ashish Acharya",
                "labs": [
                    "Herald College Kathmandu, Naxal, Nepal"
                ]
            },
            {
                "name": "Kritesh Rauniyar",
                "labs": [
                    "Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India"
                ]
            },
            {
                "name": "Sweta Poudel",
                "labs": [
                    "Kathmandu Engineering College, Tribhuvan University, Kathmandu, Nepal"
                ]
            },
            {
                "name": "Sandesh Jain",
                "labs": [
                    "Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "Anum Masood",
                "labs": [
                    "Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, Trondheim, Norway"
                ]
            },
            {
                "name": "Usman Naseem",
                "labs": [
                    "School of Computing, Macquarie University, Sydney, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Information integrity",
                "Social networking (online)",
                "Navigation",
                "Market research",
                "Feature extraction",
                "Neural networks",
                "Large language models",
                "Social sciences"
            ],
            "Author Keywords": [
                "Large language models",
                "disinformation",
                "computational social sciences",
                "ChatGPT",
                "hallucinations in LLMs"
            ]
        }
    },
    {
        "Title": "DeepTextMark: A Deep Learning-Driven Text Watermarking Approach for Identifying Large Language Model Generated Text",
        "Link": "https://ieeexplore.ieee.org/document/10471537/",
        "Abstract": "The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of text generators. With the potential for misuse escalating, the importance of discerning whether texts are human-authored or generated by LLMs has become paramount. Several preceding studies have ventured to address this challenge by employing binary classifiers to differentiate between human-written and LLM-generated text. Nevertheless, the reliability of these classifiers has been subject to question. Given that consequential decisions may hinge on the outcome of such classification, it is imperative that text source detection is of high caliber. In light of this, the present paper introduces DeepTextMark, a deep learning-driven text watermarking methodology devised for text source identification. By leveraging Word2Vec and Sentence Encoding for watermark insertion, alongside a transformer-based classifier for watermark detection, DeepTextMark epitomizes a blend of blindness, robustness, imperceptibility, and reliability. As elaborated within the paper, these attributes are crucial for universal text source detection, with a particular emphasis in this paper on text produced by LLMs. DeepTextMark offers a viable “add-on” solution to prevailing text generation frameworks, requiring no direct access or alterations to the underlying text generation mechanism. Experimental evaluations underscore the high imperceptibility, elevated detection accuracy, augmented robustness, reliability, and swift execution of DeepTextMark.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3376693",
            "Date of Publication": "13 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Travis Munyer",
                "labs": [
                    "Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA"
                ]
            },
            {
                "name": "Abdullah All Tanvir",
                "labs": [
                    "Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA"
                ]
            },
            {
                "name": "Arjon Das",
                "labs": [
                    "Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA"
                ]
            },
            {
                "name": "Xin Zhong",
                "labs": [
                    "Department of Computer Science, University of Nebraska Omaha, Omaha, NE, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Watermarking",
                "Blindness",
                "Transformers",
                "Semantics",
                "Robustness",
                "Proposals",
                "Large language models",
                "Deep learning",
                "Text processing",
                "Detection algorithms"
            ],
            "Author Keywords": [
                "Text source detection",
                "large language model text detection",
                "text watermarking",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10720163/",
        "Abstract": "Large Language Models (LLMs) represent a class of deep learning models adept at understanding natural language and generating coherent responses to various prompts or queries. These models far exceed the complexity of conventional neural networks, often encompassing dozens of neural network layers and containing billions to trillions of parameters. They are typically trained on vast datasets, utilizing architectures based on transformer blocks. Present-day LLMs are multi-functional, capable of performing a range of tasks from text generation and language translation to question answering, as well as code generation and analysis. An advanced subset of these models, known as Multimodal Large Language Models (MLLMs), extends LLM capabilities to process and interpret multiple data modalities, including images, audio, and video. This enhancement empowers MLLMs with capabilities like video editing, image comprehension, and captioning for visual content. This survey provides a comprehensive overview of the recent advancements in LLMs. We begin by tracing the evolution of LLMs and subsequently delve into the advent and nuances of MLLMs. We analyze emerging state-of-the-art MLLMs, exploring their technical features, strengths, and limitations. Additionally, we present a comparative analysis of these models and discuss their challenges, potential limitations, and prospects for future development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482107",
            "Date of Publication": "16 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Minghao Shao",
                "labs": [
                    "New York University Tandon School of Engineering, New York University, New York, NY, USA"
                ]
            },
            {
                "name": "Abdul Basit",
                "labs": [
                    "Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Ramesh Karri",
                "labs": [
                    "New York University Tandon School of Engineering, New York University, New York, NY, USA"
                ]
            },
            {
                "name": "Muhammad Shafique",
                "labs": [
                    "Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Transformers",
                "Benchmark testing",
                "Encoding",
                "Large language models",
                "Adaptation models",
                "Market research",
                "Decoding",
                "Training",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "Transformer architecture",
                "generative models",
                "survey",
                "multimodal learning",
                "deep learning",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Exploring LLMs Applications in Law: A Literature Review on Current Legal NLP Approaches",
        "Link": "https://ieeexplore.ieee.org/document/10850911/",
        "Abstract": "Artificial Intelligence (AI) is reshaping the legal landscape, with software tools now impacting various aspects of legal work. The intersection of Natural Language Processing (NLP) and law holds potential to transform how legal professionals, including lawyers and judges, operate, resolve disputes, and retrieve case information to formulate their decisions. To identify the current state of the applications of Transformers (also known as Large Language Models or LLMs) in the legal domain, we analysed the existing literature from 2017 to 2023 through a database search and snowballing method. From 61 selected publications, we identified key application categories such as legal document analysis, case prediction, and contract review, along with their main characteristics. We observed a discernible upsurge in the volume of scholarly publications, a diversification of tasks undertaken (e.g., legal research, contract analysis, and regulatory compliance), and an increased range of languages considered. There has been a notable enhancement in the methodological sophistication employed by researchers in practical applications. The performance of models grounded in the Generative Pre-trained Transformer (GPT) architecture has consistently improved across various legal domains, including contract review, legal document summarization, and case outcome prediction. This paper makes several significant contributions to the field. Firstly, it identifies emerging trends in the application of LLMs within the legal domain, highlighting the growing interest and investment in this area. Secondly, it pinpoints methodological gaps in current research, suggesting areas where further development and refinement are needed. Lastly, it discusses the broader implications of these advancements for real-world legal tasks, offering insights into how LLM-based AI can enhance legal practice while addressing the associated challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3533217",
            "Date of Publication": "23 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marco Siino",
                "labs": [
                    "Department of Electrical, Electronics and Informatics Engineering, University of Catania, Catania, Italy",
                    "Department of Engineering, University of Palermo, Palermo, Italy",
                    "Palermo Research Unit, National Inter-University Consortium for Telecommunications (CNIT), Palermo, Italy"
                ]
            },
            {
                "name": "Mariana Falco",
                "labs": [
                    "Department of Engineering, University of Palermo, Palermo, Italy"
                ]
            },
            {
                "name": "Daniele Croce",
                "labs": [
                    "Department of Engineering, University of Palermo, Palermo, Italy",
                    "Palermo Research Unit, National Inter-University Consortium for Telecommunications (CNIT), Palermo, Italy"
                ]
            },
            {
                "name": "Paolo Rosso",
                "labs": [
                    "PRHLT Research Center, Universitat Politècnica de València, Valencia, Spain",
                    "ValgrAI–Valencian Graduate School and Research Network of Artificial Intelligence, Valencia, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Artificial intelligence",
                "Transformers",
                "Systematic literature review",
                "Contracts",
                "Attention mechanisms",
                "Databases",
                "Reliability",
                "Question answering (information retrieval)",
                "Quality assessment"
            ],
            "Author Keywords": [
                "Natural language processing",
                "law",
                "AI for law",
                "legal NLP",
                "legal tech",
                "GPT",
                "transformers",
                "literature review"
            ]
        }
    },
    {
        "Title": "On the Intersection of Explainable and Reliable AI for Physical Fatigue Prediction",
        "Link": "https://ieeexplore.ieee.org/document/9831436/",
        "Abstract": "In the era of Industry 4.0, the use of Artificial Intelligence (AI) is widespread in occupational settings. Since dealing with human safety, explainability and trustworthiness of AI are even more important than achieving high accuracy. eXplainable AI (XAI) is investigated in this paper to detect physical fatigue during manual material handling task simulation. Besides comparing global rule-based XAI models (LLM and DT) to black-box models (NN, SVM, XGBoost) in terms of performance, we also compare global models with local ones (LIME over XGBoost). Surprisingly, global and local approaches achieve similar conclusions, in terms of feature importance. Moreover, an expansion from local rules to global rules is designed for Anchors, by posing an appropriate optimization method (Anchors coverage is enlarged from an original low value, 11%, up to 43%). As far as trustworthiness is concerned, rule sensitivity analysis drives the identification of optimized regions in the feature space, where physical fatigue is predicted with zero statistical error. The discovery of such “non-fatigue regions” helps certifying the organizational and clinical decision making.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3191907",
            "Date of Publication": "18 July 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sara Narteni",
                "labs": [
                    "Consiglio Nazionale delle Ricerche (CNR), IEIIT Institute, Genoa, Italy",
                    "DAUIN Department, Politecnico di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Vanessa Orani",
                "labs": [
                    "Aitek S.p.A., Genoa, Italy"
                ]
            },
            {
                "name": "Enrico Cambiaso",
                "labs": [
                    "Consiglio Nazionale delle Ricerche (CNR), IEIIT Institute, Genoa, Italy"
                ]
            },
            {
                "name": "Matteo Rucco",
                "labs": [
                    "Biocentis Ltd., Milan, Italy"
                ]
            },
            {
                "name": "Maurizio Mongelli",
                "labs": [
                    "Consiglio Nazionale delle Ricerche (CNR), IEIIT Institute, Genoa, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fatigue",
                "Artificial intelligence",
                "Safety",
                "Robots",
                "Support vector machines",
                "Reliability",
                "Service robots"
            ],
            "Author Keywords": [
                "Physical fatigue detection",
                "industry 4.0",
                "explainable AI",
                "logic learning machine",
                "LIME",
                "anchors",
                "reliable AI"
            ]
        }
    },
    {
        "Title": "ChatPhishDetector: Detecting Phishing Sites Using Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10723311/",
        "Abstract": "Large Language Models (LLMs), such as ChatGPT, are significantly impacting various fields. While LLMs have been extensively studied for code generation and text synthesis, their application in detecting malicious web content, particularly phishing sites, remains largely unexplored. To counter the increasing cyber-attacks that leverage LLMs for creating more sophisticated and convincing phishing content, it is crucial to automate detection by harnessing LLMs’ advanced capabilities. This paper introduces ChatPhishDetector, a novel system that employs LLMs to identify phishing sites. Our approach involves using a web crawler to collect website information, generating prompts for LLMs based on the gathered data, and extracting detection results from LLM responses. This system enables accurate detection of multilingual phishing sites by identifying impersonated brands and social engineering techniques within the entire website context, without requiring machine learning model training. We evaluated our system’s performance using our own dataset and compared it with baseline systems and several LLMs. Experiments using GPT-4V showed exceptional results, achieving 98.7% precision and 99.6% recall, surpassing the detection performance of other LLMs and existing systems. These findings highlight the potential of LLMs for protecting users from online fraudulent activities and provide crucial insights for strengthening defenses against phishing attacks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3483905",
            "Date of Publication": "21 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Takashi Koide",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Hiroki Nakano",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            },
            {
                "name": "Daiki Chiba",
                "labs": [
                    "NTT Security Holdings Corporation & NTT Corporation, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Uniform resource locators",
                "Large language models",
                "Crawlers",
                "Codes",
                "Web pages",
                "Security",
                "Accuracy",
                "Visualization",
                "Cognition"
            ],
            "Author Keywords": [
                "Large language models",
                "phishing sites",
                "social engineering"
            ]
        }
    },
    {
        "Title": "LegalReasoner: A Multi-Stage Framework for Legal Judgment Prediction via Large Language Models and Knowledge Integration",
        "Link": "https://ieeexplore.ieee.org/document/10750819/",
        "Abstract": "Legal judgment prediction (LJP) presents a formidable challenge in artificial intelligence, demanding intricate comprehension of legal texts, nuanced interpretation of statutes, and complex reasoning over multifaceted case elements. While recent advancements in natural language processing have shown promise, existing approaches often struggle to capture the sophisticated interplay between facts, legal principles, and precedents that characterize legal decision-making. This paper introduces LegalReasoner, a novel multi-stage framework that leverages large language models (LLMs) and integrates domain-specific knowledge for enhanced legal judgment prediction. Our approach encompasses four key stages: 1) legal knowledge infusion, where we pre-train an LLM on a vast corpus of legal literature using contrastive learning techniques; 2) case-law retrieval, employing a graph neural network to identify relevant precedents and statutes; 3) multi-hop reasoning, utilizing a transformer-based architecture with a hierarchical attention mechanism to navigate complex legal arguments; and 4) judgment synthesis, where we employ a generative adversarial network to produce coherent and legally sound judgments. We evaluate LegalReasoner on two diverse datasets: the European Court of Human Rights (ECHR) cases and the Chinese AI and Law Challenge (CAIL2018). Our framework demonstrates substantial improvements over state-of-the-art baselines, achieving an average accuracy increase of 7.8% across all datasets. Furthermore, we conduct extensive ablation studies and interpretability analyses to elucidate the contributions of each component and provide insights into the model’s decision-making process. Our work not only advances the field of automated legal reasoning but also offers a transparent and explainable system that could serve as a valuable tool for legal professionals. By bridging the gap between AI and legal expertise, LegalReasoner paves the way for more efficient, consistent, and fair legal decision-making processes.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3496666",
            "Date of Publication": "12 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xuran Wang",
                "labs": [
                    "Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA, USA"
                ]
            },
            {
                "name": "Xinguang Zhang",
                "labs": [
                    "Erik Jonsson School of Engineering and Computer Science, The University of Texas at Dallas, Richardson, TX, USA"
                ]
            },
            {
                "name": "Vanessa Hoo",
                "labs": [
                    "School of Mathematics, School of Economics, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Zhouhang Shao",
                "labs": [
                    "Department of Computer Science and Engineering, The University of California, San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Xuguang Zhang",
                "labs": [
                    "School of Business, Computing and Social Sciences, University of Gloucestershire, Cheltenham, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Cognition",
                "Artificial intelligence",
                "Predictive models",
                "Natural language processing",
                "Decision making",
                "Large language models",
                "Transformers",
                "Contrastive learning",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Legal judgment prediction",
                "large language models",
                "knowledge integration",
                "multi-hop reasoning"
            ]
        }
    },
    {
        "Title": "Repeatability of Fine-Tuning Large Language Models Illustrated Using QLoRA",
        "Link": "https://ieeexplore.ieee.org/document/10700744/",
        "Abstract": "Large language models (LLMs) have shown progress and promise in diverse applications ranging from the medical field to chat bots. Developing LLMs requires a large corpus of data and significant computation resources to achieve efficient learning. Foundation models (in particular LLMs) serve as the basis for fine-tuning on a new corpus of data. Since the original foundation models contain a very large number of parameters, fine-tuning them can be quite challenging. Development of the low-rank adaption technique (LoRA) for fine-tuning, and the quantized version of LoRA, also known as QLoRA, allows for fine-tuning of LLMs on a new smaller corpus of data. This paper focuses on the repeatability of fine-tuning four LLMs using QLoRA. We have fine-tuned them for seven trials each under the same hardware and software settings. We also validated our study for the repeatability (stability) issue by fine-tuning LLMs on two public datasets. For each trial, each LLM was fine-tuned on a subset of the dataset and tested on a holdout test set. Fine-tuning and inference were done on a single GPU. Our study shows that fine-tuning of LLMs with the QLoRA method is not repeatable (not stable), such that different fine-tuned runs result in different performance on the holdout test set.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3470850",
            "Date of Publication": "30 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Saeed S. Alahmari",
                "labs": [
                    "Department of Computer Science, Najran University, Najran, Saudi Arabia"
                ]
            },
            {
                "name": "Lawrence O. Hall",
                "labs": [
                    "Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA"
                ]
            },
            {
                "name": "Peter R. Mouton",
                "labs": [
                    "Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",
                    "SRC Biosciences, Tampa, FL, USA"
                ]
            },
            {
                "name": "Dmitry B. Goldgof",
                "labs": [
                    "Department of Computer Science, Najran University, Najran, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hardware",
                "Training",
                "Adaptation models",
                "Large language models",
                "Reproducibility of results",
                "Graphics processing units",
                "Deep learning",
                "Data models",
                "Transformers",
                "LoRa"
            ],
            "Author Keywords": [
                "QLoRA",
                "LoRA",
                "LLMs",
                "deep learning",
                "repeatability",
                "foundation models",
                "fine-tuning"
            ]
        }
    },
    {
        "Title": "IDAS: Intelligent Driving Assistance System Using RAG",
        "Link": "https://ieeexplore.ieee.org/document/10643289/",
        "Abstract": "In the fast-growing automotive technology sector, it has become increasingly clear that there is a need for cars with smarter and more interactive systems. This article presents the Intelligent Driving Assistance System (IDAS), an artificial intelligence system that enables the driver to use voice commands to access various features of a car. The primary component of IDAS is a Large Language Model (LLM), which, through retrieval augmented generation (RAG), can efficiently read and understand the car manual for immediate context-based aid. In addition, this system incorporates speech recognition and speech synthesis capabilities, it can understand commands given in multiple languages, improving user experiences among diverse driver communities. Our results show a minimum response time of one second for the pipeline using GPT-4o-mini and Mistral Nemo.",
        "Details": {
            "DOI": "10.1109/OJVT.2024.3447449",
            "Date of Publication": "21 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Vehicular Technology"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1330"
        },
        "authors_data": [
            {
                "name": "Luis-Bernardo Hernandez-Salinas",
                "labs": [
                    "Instituto Politecnico Nacional, CICATA, Querétaro, Mexico"
                ]
            },
            {
                "name": "Juan Terven",
                "labs": [
                    "Instituto Politecnico Nacional, CICATA, Querétaro, Mexico"
                ]
            },
            {
                "name": "E. A. Chavez-Urbiola",
                "labs": [
                    "Instituto Politecnico Nacional, CICATA, Querétaro, Mexico"
                ]
            },
            {
                "name": "Diana-Margarita Córdova-Esparza",
                "labs": [
                    "Facultad de Informatica, Universidad Autónoma de Queretaro, Queretaro, Mexico"
                ]
            },
            {
                "name": "Julio-Alejandro Romero-González",
                "labs": [
                    "Facultad de Informatica, Universidad Autónoma de Queretaro, Queretaro, Mexico"
                ]
            },
            {
                "name": "Amadeo Arguelles",
                "labs": [
                    "Instituto Politecnico Nacional, Centro de Investigacion en Computacion, Mexico City, Mexico"
                ]
            },
            {
                "name": "Ilse Cervantes",
                "labs": [
                    "Instituto Politecnico Nacional, CICATA, Querétaro, Mexico"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vehicles",
                "Automobiles",
                "Manuals",
                "Artificial intelligence",
                "Safety",
                "Real-time systems",
                "Human computer interaction",
                "Intelligent agents",
                "Large language models",
                "Smart transportation"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "human-computer interaction",
                "intelligent agents",
                "large language models",
                "retrieval augmented generation (RAG)"
            ]
        }
    },
    {
        "Title": "LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics",
        "Link": "https://ieeexplore.ieee.org/document/10752628/",
        "Abstract": "Large language models (LLMs), such as GPT-4 have demonstrated their ability to understand natural language and generate complex code snippets. This article introduces a novel LLM evolutionary algorithm (LLaMEA) framework, leveraging GPT models for the automated generation and refinement of algorithms. Given a set of criteria and a task definition (the search space), LLaMEA iteratively generates, mutates, and selects algorithms based on performance metrics and feedback from runtime evaluations. This framework offers a unique approach to generating optimized algorithms without requiring extensive prior expertise. We show how this framework can be used to generate novel closed box metaheuristic optimization algorithms for box-constrained, continuous optimization problems automatically. LLaMEA generates multiple algorithms that outperform state-of-the-art optimization algorithms (covariance matrix adaptation evolution strategy and differential evolution) on the 5-D closed box optimization benchmark (BBOB). The algorithms also show competitive performance on the 10- and 20-D instances of the test functions, although they have not seen such instances during the automated generation process. The results demonstrate the feasibility of the framework and identify future directions for automated generation and optimization of algorithms via LLMs.",
        "Details": {
            "DOI": "10.1109/TEVC.2024.3497793",
            "Date of Publication": "13 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Evolutionary Computation"
        },
        "issn_info": {
            "Print ISSN": "1089-778X",
            "Electronic ISSN": "1941-0026"
        },
        "authors_data": [
            {
                "name": "Niki van Stein",
                "labs": [
                    "Leiden Institute of Advanced Computer Science, Leiden University, Leiden, The Netherlands"
                ]
            },
            {
                "name": "Thomas Bäck",
                "labs": [
                    "Leiden Institute of Advanced Computer Science, Leiden University, Leiden, The Netherlands"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Benchmark testing",
                "Evolutionary computation",
                "Metaheuristics",
                "Codes",
                "Large language models",
                "Closed box",
                "Heuristic algorithms",
                "Mathematical models",
                "Vectors",
                "Systematics"
            ],
            "Author Keywords": [
                "Automated code generation",
                "evolutionary computation (EC)",
                "large language models (LLMs)",
                "metaheuristics",
                "optimization"
            ]
        }
    },
    {
        "Title": "QuIM-RAG: Advancing Retrieval-Augmented Generation With Inverted Question Matching for Enhanced QA Performance",
        "Link": "https://ieeexplore.ieee.org/document/10781379/",
        "Abstract": "This work presents a novel architecture for building Retrieval-Augmented Generation (RAG) systems to improve Question Answering (QA) tasks from a target corpus. Large Language Models (LLMs) have revolutionized the analyzing and generation of human-like text. These models rely on pre-trained data and lack real-time updates unless integrated with live data tools. RAG enhances LLMs by integrating online resources and databases to generate contextually appropriate responses. However, traditional RAG still encounters challenges like information dilution and hallucinations when handling vast amounts of data. Our approach addresses these challenges by converting corpora into a domain-specific dataset and RAG architecture is constructed to generate responses from the target document. We introduce QuIM-RAG (Question-to-question Inverted Index Matching), a novel approach for the retrieval mechanism in our system. This strategy generates potential questions from document chunks and matches these with user queries to identify the most relevant text chunks for generating accurate answers. We have implemented our RAG system on top of the open-source Meta-LLaMA3-8B-instruct model by Meta Inc. that is available on Hugging Face. We constructed a custom corpus of 500+ pages from a high-traffic website accessed thousands of times daily for answering complex questions, along with manually prepared ground truth QA for evaluation. We compared our approach with traditional RAG models using BERT-Score and RAGAS, state-of-the-art metrics for evaluating LLM applications. Our evaluation demonstrates that our approach outperforms traditional RAG architectures on both metrics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3513155",
            "Date of Publication": "09 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Binita Saha",
                "labs": [
                    "North Dakota State University, Fargo, ND, USA"
                ]
            },
            {
                "name": "Utsha Saha",
                "labs": [
                    "North Dakota State University, Fargo, ND, USA"
                ]
            },
            {
                "name": "Muhammad Zubair Malik",
                "labs": [
                    "North Dakota State University, Fargo, ND, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Accuracy",
                "Indexes",
                "Large language models",
                "Reliability",
                "Prototypes",
                "Data models",
                "Computational modeling",
                "Question answering (information retrieval)",
                "Faces"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "retrieval-augmented generation (RAG)",
                "question answering (QA)",
                "ChatGPT",
                "GPT-3.5-turbo",
                "Meta-LLaMA3-8B-instruct",
                "hallucination mitigation",
                "information dilution"
            ]
        }
    },
    {
        "Title": "Robust Vulnerability Detection in Solidity-Based Ethereum Smart Contracts Using Fine-Tuned Transformer Encoder Models",
        "Link": "https://ieeexplore.ieee.org/document/10720785/",
        "Abstract": "The rapid expansion of blockchain technology, particularly Ethereum, has driven widespread adoption of smart contracts. However, the security of these contracts remains a critical concern due to the increasing frequency and complexity of vulnerabilities. This paper presents a comprehensive approach to detecting vulnerabilities in Ethereum smart contracts using pre-trained Large Language Models (LLMs). We apply transformer-based LLMs, leveraging their ability to understand and analyze Solidity code to identify potential security flaws. Our methodology involves fine-tuning eight distinct pre-trained LLM models on curated datasets varying in types and distributions of vulnerabilities, including multi-class vulnerabilities. The datasets-SB Curate, Benmark Solidity Smart Contract, and ScrawID-were selected to ensure a thorough evaluation of model performance across different vulnerability types. We employed over-sampling techniques to address class imbalances, resulting in more reliable training outcomes. We extensively evaluate these models using precision, recall, accuracy, F1 score, and Receiver Operating Characteristics (ROC) curve metrics. Our results demonstrate that the transformer encoder architecture, with its multi-head attention and feed-forward mechanisms, effectively captures the nuances of smart contract vulnerabilities. The models show promising potential in enhancing the security and reliability of Ethereum smart contracts, offering a robust solution to challenges posed by software vulnerabilities in the blockchain ecosystem.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482389",
            "Date of Publication": "17 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thi-Thu-Huong Le",
                "labs": [
                    "Blockchain Platform Research Center, Pusan National University, Busan, South Korea",
                    "IoT Research Center, Pusan National University, Busan, South Korea"
                ]
            },
            {
                "name": "Jaehyun Kim",
                "labs": [
                    "School of Computer Science and Engineering, Pusan National University, Busan, South Korea"
                ]
            },
            {
                "name": "Sangmyeong Lee",
                "labs": [
                    "School of Computer Science and Engineering, Pusan National University, Busan, South Korea"
                ]
            },
            {
                "name": "Howon Kim",
                "labs": [
                    "School of Computer Science and Engineering, Pusan National University, Busan, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Smart contracts",
                "Codes",
                "Transformers",
                "Security",
                "Solid modeling",
                "Analytical models",
                "Training",
                "Encoding",
                "Biological system modeling",
                "Large language models"
            ],
            "Author Keywords": [
                "Ethereum smart contracts",
                "large language models",
                "multi-class imbalance",
                "multi-class classification",
                "smart contract vulnerability",
                "solidity code"
            ]
        }
    },
    {
        "Title": "Empowering Few-Shot Recommender Systems With Large Language Models-Enhanced Representations",
        "Link": "https://ieeexplore.ieee.org/document/10440582/",
        "Abstract": "Recommender systems utilizing explicit feedback have witnessed significant advancements and widespread applications over the past years. However, generating recommendations in few-shot scenarios remains a persistent challenge. Recently, large language models (LLMs) have emerged as a promising solution for addressing natural language processing (NLP) tasks, thereby offering novel insights into tackling the few-shot scenarios encountered by explicit feedback-based recommender systems. To bridge recommender systems and LLMs, we devise a prompting template that generates user and item representations based on explicit feedback. Subsequently, we integrate these LLM-processed representations into various recommendation models to evaluate their significance across diverse recommendation tasks. Our ablation experiments and case study analysis collectively demonstrate the effectiveness of LLMs in processing explicit feedback, highlighting that LLMs equipped with generative and logical reasoning capabilities can effectively serve as a component of recommender systems to enhance their performance in few-shot scenarios. Furthermore, the broad adaptability of LLMs augments the generalization potential of recommender models, despite certain inherent constraints. We anticipate that our study can inspire researchers to delve deeper into the multifaceted dimensions of LLMs’ involvement in recommender systems and contribute to the advancement of the explicit feedback-based recommender systems field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3368027",
            "Date of Publication": "20 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhoumeng Wang",
                "labs": [
                    "Marketing Programme, The Chinese University of Hong Kong Business School, Hong Kong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Recommender systems",
                "Task analysis",
                "Reviews",
                "Predictive models",
                "Motion pictures",
                "Training",
                "Large language models",
                "Representation learning"
            ],
            "Author Keywords": [
                "Large language models",
                "recommender systems",
                "ChatGPT",
                "representations"
            ]
        }
    },
    {
        "Title": "Integrating Large Language Model, EEG, and Eye-Tracking for Word-Level Neural State Classification in Reading Comprehension",
        "Link": "https://ieeexplore.ieee.org/document/10636286/",
        "Abstract": "With the recent proliferation of large language models (LLMs), such as Generative Pre-trained Transformers (GPT), there has been a significant shift in exploring human and machine comprehension of semantic language meaning. This shift calls for interdisciplinary research that bridges cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals’ neural states during a semantic inference reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use feature engineering to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60% across 12 subjects. Words highly relevant to the inference keyword received significantly more eye fixations per word: 1.0584 compared to 0.6576, including words with no fixations. This study represents the first attempt to classify brain states at a word level using LLM-generated labels. It provides valuable insights into human cognitive abilities and Artificial General Intelligence (AGI), and offers guidance for developing potential reading-assisted technologies.",
        "Details": {
            "DOI": "10.1109/TNSRE.2024.3435460",
            "Date of Publication": "14 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
        },
        "issn_info": {
            "Print ISSN": "1534-4320",
            "Electronic ISSN": "1558-0210"
        },
        "authors_data": [
            {
                "name": "Yuhong Zhang",
                "labs": [
                    "Shu Chien-Gene Lay Department of Bioengineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Qin Li",
                "labs": [
                    "Department of Bioengineering, University of California at Los Angeles, Los Angeles, CA, USA"
                ]
            },
            {
                "name": "Sujal Nahata",
                "labs": [
                    "Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Tasnia Jamal",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Shih-Kuen Cheng",
                "labs": [
                    "Institute of Cognitive Neuroscience, National Central University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "Gert Cauwenberghs",
                "labs": [
                    "Shu Chien-Gene Lay Department of Bioengineering and the Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Tzyy-Ping Jung",
                "labs": [
                    "Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electroencephalography",
                "Task analysis",
                "Brain modeling",
                "Semantics",
                "Gaze tracking",
                "Electronic mail",
                "Accuracy"
            ],
            "Author Keywords": [
                "Large language model",
                "brain-computer interface",
                "human-computer interface",
                "EEG",
                "eye-fixation",
                "cognitive computing",
                "pattern recognition",
                "reading comprehension",
                "computational linguistics"
            ]
        }
    },
    {
        "Title": "MagicItem: Dynamic Behavior Design of Virtual Objects With Large Language Models in a Commercial Metaverse Platform",
        "Link": "https://ieeexplore.ieee.org/document/10843684/",
        "Abstract": "To create rich experiences in virtual reality (VR) environments, it is essential to define the behavior of virtual objects through programming. However, programming in 3D spaces requires a wide range of background knowledge and programming skills. Although Large Language Models (LLMs) have provided programming support, they are still primarily aimed at programmers. In metaverse platforms, where many users inhabit VR spaces, most users are unfamiliar with programming, making it difficult for them to modify the behavior of objects in the VR environment easily. Existing LLM-based script generation methods for VR spaces require multiple lengthy iterations to implement the desired behaviors and are difficult to integrate into the operation of metaverse platforms. To address this issue, we propose a tool that generates behaviors for objects in VR spaces from natural language within Cluster, a metaverse platform with a large user base. By integrating LLMs with the Cluster Script provided by this platform, we enable users with limited programming experience to define object behaviors within the platform freely. We have also integrated our tool into a commercial metaverse platform and are conducting online experiments with 63 general users of the platform. The experiments show that even users with no programming background can successfully generate behaviors for objects in VR spaces, resulting in a highly satisfying system. Our research contributes to democratizing VR content creation by enabling non-programmers to design dynamic behaviors for virtual objects in metaverse platforms.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3530439",
            "Date of Publication": "16 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ryutaro Kurai",
                "labs": [
                    "Cluster, Inc., Shinagawa, Tokyo, Japan",
                    "Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Nara, Japan"
                ]
            },
            {
                "name": "Takefumi Hiraki",
                "labs": [
                    "Cluster Metaverse Lab, Shingawa, Tokyo, Japan",
                    "Institute of Library, Information and Media Science, University of Tsukuba, Tsukuba, Ibaraki, Japan"
                ]
            },
            {
                "name": "Yuichi Hiroi",
                "labs": [
                    "Cluster Metaverse Lab, Shingawa, Tokyo, Japan"
                ]
            },
            {
                "name": "Yutaro Hirao",
                "labs": [
                    "Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Nara, Japan"
                ]
            },
            {
                "name": "Monica Perusquía-Hernández",
                "labs": [
                    "Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Nara, Japan"
                ]
            },
            {
                "name": "Hideaki Uchiyama",
                "labs": [
                    "Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Nara, Japan"
                ]
            },
            {
                "name": "Kiyoshi Kiyokawa",
                "labs": [
                    "Graduate School of Science and Technology, Nara Institute of Science and Technology, Ikoma, Nara, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Metaverse",
                "Codes",
                "Three-dimensional displays",
                "Large language models",
                "Natural languages",
                "Aerospace electronics",
                "Web servers",
                "Usability",
                "Programming profession",
                "Hands"
            ],
            "Author Keywords": [
                "Large-language model",
                "low-code programming",
                "metaverse platform",
                "virtual reality"
            ]
        }
    },
    {
        "Title": "Toward Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal Cross- and Self-Attention Large Language Model Approach",
        "Link": "https://ieeexplore.ieee.org/document/10438452/",
        "Abstract": "This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL’s performance with state-of-the-art LLM-based models and traditional time sequence models, demonstrating its superiority in accuracy and robustness, achieving an accuracy of 95.94% and an AUC of 0.98. This NLP-based approach enables, for the first time, the creation of exploits directly from design documents, making remarkable progress in scalable system verification and validation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3366803",
            "Date of Publication": "16 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jingda Yang",
                "labs": [
                    "School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Ying Wang",
                "labs": [
                    "School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Protocols",
                "Formal verification",
                "5G mobile communication",
                "Natural languages",
                "Iterative methods",
                "Transformers",
                "Complexity theory",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Formal verification",
                "cross-attention",
                "self-attention",
                "natural language protocol",
                "formal flow graph"
            ]
        }
    },
    {
        "Title": "A Security Risk Taxonomy for Prompt-Based Interaction With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10648691/",
        "Abstract": "As large language models (LLMs) permeate more and more applications, an assessment of their associated security risks becomes increasingly necessary. The potential for exploitation by malicious actors, ranging from disinformation to data breaches and reputation damage, is substantial. This paper addresses a gap in current research by specifically focusing on security risks posed by LLMs within the prompt-based interaction scheme, which extends beyond the widely covered ethical and societal implications. Our work proposes a taxonomy of security risks along the user-model communication pipeline and categorizes the attacks by target and attack type alongside the commonly used confidentiality, integrity, and availability (CIA) triad. The taxonomy is reinforced with specific attack examples to showcase the real-world impact of these risks. Through this taxonomy, we aim to inform the development of robust and secure LLM applications, enhancing their safety and trustworthiness.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3450388",
            "Date of Publication": "26 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Erik Derner",
                "labs": [
                    "ELLIS Alicante, Alicante, Spain",
                    "Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Prague, Czech Republic"
                ]
            },
            {
                "name": "Kristina Batistič",
                "labs": [
                    "Independent Researcher, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Jan Zahálka",
                "labs": [
                    "Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Prague, Czech Republic"
                ]
            },
            {
                "name": "Robert Babuška",
                "labs": [
                    "Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Prague, Czech Republic",
                    "Department of Cognitive Robotics, Delft University of Technology, Delft, The Netherlands"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Taxonomy",
                "Chatbots",
                "Large language models",
                "Data models",
                "Codes",
                "Privacy",
                "Natural language processing",
                "Risk analysis"
            ],
            "Author Keywords": [
                "Large language models",
                "security",
                "jailbreak",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Retail Resilience Engine: An Agentic AI Framework for Building Reliable Retail Systems With Test-Driven Development Approach",
        "Link": "https://ieeexplore.ieee.org/document/10930951/",
        "Abstract": "System reliability and operational resilience are two critical success factors in the retail industry that are directly connected to customer satisfaction and business sustainability. Staying competitive in today’s dynamic and rapidly evolving market requires rapid adaptability. However, it contradicts the reliability and resilience. This paper proposes an innovative solution, the Retail Resilience Engine (RRE), to establish a balance between these success factors and market demand. It is a unique framework that combines Test-Driven Development (TDD) with a Large Language Model (LLM). This framework follows the state-of-the-art Agentic-AI architecture. It effectively evaluates the decision-making process at rapid speed in retail by incorporating diverse factors, including inventory management, demand forecasting, and customer feedback. As a result, the system reliability is improved significantly. The experimental analysis of the proposed framework shows its decision-making is similar to human experts with a similarity index of 97.5%. It further proves the reliability of the system. The framework also scales effectively, maintaining high accuracy, precision, recall, and F1 scores across varying dataset sizes. The robustness analysis of the system demonstrates the agility enhancement across diverse retail domains, ensuring consistent performance with accuracy exceeding 90% across all tested scenarios. The integration of a creative filtering mechanism further enhances the performance of the RRE framework by preventing 98.2% of the irrelevant inputs. Overall, the proposed RRE framework demonstrates the impressive potential to transform retail systems by enhancing reliability, scalability, and decision-making quality through an Agentic-AI approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3552592",
            "Date of Publication": "18 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lalit Narayan Mishra",
                "labs": [
                    "Lowe’s, Charlotte, NC, USA"
                ]
            },
            {
                "name": "Biswaranjan Senapati",
                "labs": [
                    "Department of Computer Science, UALR, Little Rock, AR, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reliability",
                "Industries",
                "Systematic literature review",
                "Resilience",
                "Software reliability",
                "Engines",
                "Automation",
                "Software development management",
                "Codes",
                "Software engineering"
            ],
            "Author Keywords": [
                "Retail systems",
                "test-driven development",
                "large language model",
                "artificial intelligence",
                "agentic-AI",
                "resilience engine"
            ]
        }
    },
    {
        "Title": "Recent Advances in Interactive Machine Translation With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10737082/",
        "Abstract": "This paper explores the role of Large Language Models (LLMs) in revolutionizing interactive Machine Translation (MT), providing a comprehensive analysis across nine innovative research directions. LLMs demonstrate exceptional capabilities in handling complex tasks through advanced text generation and interactive human-machine collaboration, significantly enhancing translation accuracy and efficiency, especially in low-resource language scenarios. This study also outlines potential advancements in LLM applications, emphasizing the integration of domain-specific knowledge and the exploration of model combinations to optimize performance. Future research is suggested to focus on enhancing model adaptability to diverse linguistic environments and refining human-machine interaction frameworks to better serve practical translation needs. The findings contribute to the ongoing discourse on the strategic deployment of MT with LLMs, aiming to direct future developments towards more robust and nuanced language processing solutions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3487352",
            "Date of Publication": "28 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanshu Wang",
                "labs": [
                    "Art and Design College, Shenyang Ligong University, Shenyang, China"
                ]
            },
            {
                "name": "Jinyi Zhang",
                "labs": [
                    "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China",
                    "Faculty of Engineering, Gifu University, Gifu, Japan"
                ]
            },
            {
                "name": "Tianrong Shi",
                "labs": [
                    "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China"
                ]
            },
            {
                "name": "Dashuai Deng",
                "labs": [
                    "School of Information Science and Engineering, Shenyang Ligong University, Shenyang, China"
                ]
            },
            {
                "name": "Ye Tian",
                "labs": [
                    "Zhuzhou CRRC Times Electric Company Ltd., Zhuzhou, China"
                ]
            },
            {
                "name": "Tadahiro Matsumoto",
                "labs": [
                    "Faculty of Engineering, Gifu University, Gifu, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Machine translation",
                "Chatbots",
                "Transformers",
                "Adaptation models",
                "Accuracy",
                "Privacy",
                "Large language models",
                "Context modeling",
                "Tuning"
            ],
            "Author Keywords": [
                "Machine translation",
                "large language models",
                "pre-trained language model",
                "in-context learning",
                "post-editing"
            ]
        }
    },
    {
        "Title": "How to Regulate Large Language Models for Responsible AI",
        "Link": "https://ieeexplore.ieee.org/document/10536000/",
        "Abstract": "Large Language Models (LLMs) are predictive probabilistic models capable of passing several professional tests at a level comparable to humans. However, these capabilities come with ethical concerns. Ethical oversights in several LLM-based products include: (i) a lack of content or source attribution, and (ii) a lack of transparency in what was used to train the model. This paper identifies four touchpoints where ethical safeguards can be applied to realize a more responsible AI in LLMs. The key finding is that applying safeguards before the training occurs aligns with established engineering practices of addressing issues at the source. However, this approach is currently shunned. Finally, historical parallels are drawn with the U.S. automobile industry, which initially resisted safety regulations but later embraced them once consumer attitudes evolved.",
        "Details": {
            "DOI": "10.1109/TTS.2024.3403681",
            "Date of Publication": "21 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Technology and Society"
        },
        "issn_info": {
            "Electronic ISSN": "2637-6415"
        },
        "authors_data": [
            {
                "name": "J. Berengueres",
                "labs": [
                    "College of Information Technology, UAE University, Al Ain, UAE"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ethics",
                "Codes",
                "Artificial intelligence",
                "Benchmark testing",
                "Regulation",
                "General Data Protection Regulation",
                "Large language models",
                "Predictive models",
                "Probabilistic logic",
                "Training",
                "Data integrity",
                "Information integrity",
                "Data integrity"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "ethical computing",
                "codes of ethics",
                "algorithmic bias",
                "AI governance",
                "accountability in AI",
                "responsible AI"
            ]
        }
    },
    {
        "Title": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code",
        "Link": "https://ieeexplore.ieee.org/document/11080380/",
        "Abstract": "This survey reviews how large language models (LLMs) are transforming synthetic training data generation in both natural language and code domains. By producing artificial but task-relevant examples, these models can significantly augment or even substitute for real-world datasets, particularly in scenarios where labeled data is scarce, expensive, or sensitive. This paper surveys recent advances in leveraging LLMs to create synthetic text and code, highlighting key techniques such as prompt-based generation, retrieval-augmented pipelines, and iterative self-refinement. We examine how these methods can enrich low-resource tasks (e.g. classification, question answering) and facilitate code-centric applications (e.g. instruction tuning, code translation, bug repair) through automated verification of functional correctness. Alongside potential benefits—cost-effectiveness, broad coverage, and controllable diversity—we discuss the accompanying challenges, including factual inaccuracies in generated text, insufficient stylistic or distributional realism, and risks of bias amplification. Proposed mitigation strategies range from filtering and weighting synthetic outputs to reinforcement learning with execution feedback in code domains. We conclude by outlining open research directions, such as automated prompt engineering, cross-modal data synthesis, and robust evaluation frameworks, underscoring the growing importance of LLM-generated synthetic data in accelerating AI development while emphasizing ethical and quality safeguards.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3589503",
            "Date of Publication": "15 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mihai Nadǎş",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania"
                ]
            },
            {
                "name": "Laura Dioşan",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania"
                ]
            },
            {
                "name": "Andreea Tomescu",
                "labs": [
                    "KlusAI Laboratories, Cluj-Napoca, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Synthetic data",
                "Surveys",
                "Data models",
                "Translation",
                "Reviews",
                "Tuning",
                "Natural language processing",
                "Large language models",
                "Training"
            ],
            "Author Keywords": [
                "Synthetic data generation",
                "large language models (LLMs)",
                "text data augmentation",
                "code data synthesis",
                "prompt engineering",
                "instruction tuning",
                "machine learning training data",
                "natural language processing (NLP)",
                "code generation",
                "reinforcement learning for code",
                "automated data annotation",
                "bias and fairness in synthetic data",
                "retrieval-augmented generation (RAG)",
                "evaluation of synthetic data",
                "model collapse in LLMs"
            ]
        }
    },
    {
        "Title": "FlakyFix: Using Large Language Models for Predicting Flaky Test Fix Categories and Test Code Repair",
        "Link": "https://ieeexplore.ieee.org/document/10704582/",
        "Abstract": "Flaky tests are problematic because they non-deterministically pass or fail for the same software version under test, causing confusion and wasting development effort. While machine learning models have been used to predict flakiness and its root causes, there is much less work on providing support to fix the problem. To address this gap, in this paper, we focus on predicting the type of fix that is required to remove flakiness and then repair the test code on that basis. We do this for a subset of flaky tests where the root cause of flakiness is in the test itself and not in the production code. One key idea is to guide the repair process with additional knowledge about the test's flakiness in the form of its predicted fix category. Thus, we first propose a framework that automatically generates labeled datasets for 13 fix categories and trains models to predict the fix category of a flaky test by analyzing the test code only. Our experimental results using code models and few-shot learning show that we can correctly predict most of the fix categories. To show the usefulness of such fix category labels for automatically repairing flakiness, we augment the prompts of GPT 3.5 Turbo, a Large Language Model (LLM), with such extra knowledge to request repair suggestions. The results show that our suggested fix category labels, complemented with in-context learning, significantly enhance the capability of GPT 3.5 Turbo in generating fixes for flaky tests. Based on the execution and analysis of a sample of GPT-repaired flaky tests, we estimate that a large percentage of such repairs, (roughly between 51% and 83%) can be expected to pass. For the failing repaired tests, on average, 16% of the test code needs to be further changed for them to pass.",
        "Details": {
            "DOI": "10.1109/TSE.2024.3472476",
            "Date of Publication": "02 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Software Engineering"
        },
        "issn_info": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "authors_data": [
            {
                "name": "Sakina Fatima",
                "labs": [
                    "School of EECS, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Hadi Hemmati",
                "labs": [
                    "Electrical Engineering and Computer Science Department, York University, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Lionel C. Briand",
                "labs": [
                    "School of EECS, University of Ottawa, Ottawa, ON, Canada",
                    "Lero SFI Centre for Software Research, University of Limerick, Limerick, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Predictive models",
                "Maintenance engineering",
                "Analytical models",
                "Production",
                "Large language models",
                "Java",
                "Few shot learning",
                "Python",
                "Manuals"
            ],
            "Author Keywords": [
                "Flaky tests",
                "fix category",
                "test repair",
                "large language models",
                "code models",
                "few shot learning",
                "software testing"
            ]
        }
    },
    {
        "Title": "A State-of-the-Art Review on Phishing Website Detection Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10788671/",
        "Abstract": "Phishing attacks remain a significant cybersecurity threat, with phishing websites serving as a primary tool for attackers to deceive users and steal sensitive information. The rapid evolution of phishing tactics has spurred the development of increasingly sophisticated detection mechanisms. This paper provides a comprehensive review of state-of-the-art techniques for phishing website detection, highlighting recent advancements in the field. In particular, it addresses emerging methods for detection, such as graph-based, large language model (LLM)-based approaches and phishing kit-based detection methods, which have not been extensively covered in previous surveys. By critically reviewing recent works from reliable databases, this study constructs a new taxonomy for phishing detection techniques. This review offers a comparison of these techniques, highlighting their strengths and limitations, and explores the challenges of real-world applications of these detection systems. Furthermore, the role of artificial intelligence (AI) in phishing website detection is discussed, and future research directions to improve detection capabilities are suggested. This work addresses emerging and uncovered phishing website detection methods in previous review papers and provides valuable insights for both researchers and practitioners working to develop more robust phishing website detection systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3514972",
            "Date of Publication": "11 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wenhao Li",
                "labs": [
                    "Cybersecurity Research Centre, Universiti Sains Malaysia, George Town, Penang, Malaysia"
                ]
            },
            {
                "name": "Selvakumar Manickam",
                "labs": [
                    "Cybersecurity Research Centre, Universiti Sains Malaysia, George Town, Penang, Malaysia"
                ]
            },
            {
                "name": "Yung-Wey Chong",
                "labs": [
                    "School of Computer Sciences, Universiti Sains Malaysia, George Town, Penang, Malaysia"
                ]
            },
            {
                "name": "Weilan Leng",
                "labs": [
                    "Research Institute of Drilling and Production Engineering Technology, Chuanqing Drilling Engineering Company Ltd., CNPC, Guanghan, China"
                ]
            },
            {
                "name": "Priyadarsi Nanda",
                "labs": [
                    "Faculty of Engineering and IT, University of Technology Sydney, Sydney, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Reviews",
                "Surveys",
                "Feature extraction",
                "Visualization",
                "Uniform resource locators",
                "Convolutional neural networks",
                "Blocklists",
                "Analytical models",
                "Organizations"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "deep learning",
                "machine learning",
                "phishing website detection"
            ]
        }
    },
    {
        "Title": "Hardware Trojan Detection in Open-Source Hardware Designs Using Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/10904479/",
        "Abstract": "The globalization of the hardware supply chain reduces costs but increases security challenges with the potential insertion of hardware trojans by third parties. Traditional detection methods face scalability limitations by relying solely on simple examples (e.g., AES). Although open-source hardware promotes transparency, it does not guarantee security. In this research, Natural Language Processing (NLP) and Machine Learning (ML) techniques were applied to identify hardware trojans in complex open hardware designs (e.g., RISC-V, MIPS). Using data from existing benchmarks (ISCAS85-89, TrustHub) and synthetic data generated with Large Language Models (LLM), a dataset of 3,808 instances was used in this research. The approach using TF-IDF and Decision Tree (DT) achieved 97.26%, surpassing the state of the art. The use of LLMs with prompt optimization achieved a recall of 99%, minimizing false negatives. A novel framework integrating NLP, ML, and LLMs was developed to enhance the security of open-source hardware.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3546156",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Victor Takashi Hayashi",
                "labs": [
                    "Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil"
                ]
            },
            {
                "name": "Wilson Vicente Ruggiero",
                "labs": [
                    "Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hardware",
                "Trojan horses",
                "Machine learning",
                "Hardware design languages",
                "Open source hardware",
                "Benchmark testing",
                "Static analysis",
                "Integrated circuit modeling",
                "Hardware security",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Hardware security",
                "hardware trojan",
                "machine learning",
                "natural language processing",
                "large language models",
                "open hardware",
                "open source"
            ]
        }
    },
    {
        "Title": "A Privacy Policy Text Compliance Reasoning Framework with Large Language Models for Healthcare Services",
        "Link": "https://ieeexplore.ieee.org/document/10908666/",
        "Abstract": "The advancement of artificial intelligence-generated content drives the diversification of healthcare services, resulting in increased private information collection by healthcare service providers. Therefore, compliance with privacy regulations has increasingly become a paramount concern for both regulatory authorities and consumers. Privacy policies are crucial for consumers to understand how their personal information is collected, stored, and processed. In this work, we propose a privacy policy text compliance reasoning framework called FACTOR, which harnesses the power of large language models (LLMs). Since the General Data Protection Regulation (GDPR) has broad applicability, this work selects Article 13 of the GDPR as regulation requirements. FACTOR segments the privacy policy text using a sliding window strategy and employs LLM-based text entailment to assess compliance for each segment. The framework then applies a rule-based ensemble approach to aggregate the entailment results for all regulation requirements from the GDPR. Our experiments on a synthetic corpus of 388 privacy policies demonstrate the effectiveness of FACTOR. Additionally, we analyze 100 randomly selected websites offering healthcare services, revealing that nine of them lack a privacy policy altogether, while 29 have privacy policy texts that fail to meet the regulation requirements.",
        "Details": {
            "DOI": "10.26599/TST.2024.9010089",
            "Date of Publication": "03 March 2025",
            "Publisher": "TUP",
            "Published In": "Tsinghua Science and Technology"
        },
        "issn_info": {
            "Electronic ISSN": "1007-0214"
        },
        "authors_data": [
            {
                "name": "Jintao Chen",
                "labs": [
                    "College of Computer Science and Technology, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Fan Wang",
                "labs": [
                    "College of Computer Science and Technology, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Shengye Pang",
                "labs": [
                    "College of Computer Science and Technology, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Mingshuai Chen",
                "labs": [
                    "College of Computer Science and Technology, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Meng Xi",
                "labs": [
                    "School of Software Technology, Zhejiang University, Ningbo, China"
                ]
            },
            {
                "name": "Tiancheng Zhao",
                "labs": [
                    "Binjiang Institute of Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Jianwei Yin",
                "labs": [
                    "College of Computer Science and Technology, Zhejiang University, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Pediatrics",
                "Technological innovation",
                "Sensitivity",
                "Large language models",
                "Medical services",
                "Regulation",
                "Cognition",
                "General Data Protection Regulation",
                "Protection"
            ],
            "Author Keywords": [
                "service regulation",
                "privacy policy",
                "compliance reasoning",
                "healthcare services"
            ]
        }
    },
    {
        "Title": "Leveraging ChatGPT for Enhancing Arabic NLP: Application for Semantic Role Labeling and Cross-Lingual Annotation Projection",
        "Link": "https://ieeexplore.ieee.org/document/10820541/",
        "Abstract": "Semantic role labeling involves assigning semantic roles to sentence arguments, providing rich information for various NLP tasks and applications. Annotated corpora with semantic roles are a critical factor in improving the performance of semantic-based models. Besides, Arabic as a low resourced language, have to pay more attention to alternative methods to build such annotated corpora. To this end, two traditional methods have been intensively used, namely, manual annotation and crowed-resourced annotation. The former is highly precise but it demands substantial training and extensive resources, while, the latter, reduce human effort but often results in lower-quality annotations. Recently, Large language model (LLM) based conversational systems like ChatGPT have emerged as a promising tool for text annotation across various NLP tasks. In this paper, we leverage ChatGPT for two main sub-tasks in Arabic language processing. (1) Creating an Arabic annotated resource with emotional semantic roles from an English corpus, using cross-lingual annotation projection approach. (2) Annotating the Arabic corpus of emotional sentences with emotion categories and semantic roles. Furthermore, we evaluate ChatGPT’s potential for translating English sentences into Arabic. From the perspective of generalization, we test the performance of open-LLMs, specifically, mBERT, and mBART for the same tasks. The evaluation process includes assessing the impact of sentence complexity on the performance of ChatGPT, and open-LLMs in semantic role labeling, and cross-lingual annotation projection. We compared the obtained zero-shot annotation accuracy with that of human base annotations, where the GPT results achieved an accuracy of 0.94 for cross-lingual projection and 0.76 in semantic role labelling, While the open-LLMs achieved notable accuracies of 0.72, and 0.38 respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3525493",
            "Date of Publication": "02 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ferial Senator",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria",
                    "Department of Computer Science, Faculty of Sciences, Laboratory of Networks and Distributed Systems (LRSD), Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Abdelaziz Lakhfif",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Imene Zenbout",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Hanane Boutouta",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Chahrazed Mediani",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Annotations",
                "Semantics",
                "Translation",
                "Labeling",
                "Accuracy",
                "Training",
                "Sentiment analysis",
                "Manuals",
                "Large language models"
            ],
            "Author Keywords": [
                "Semantic role labeling",
                "cross-lingual annotation projection",
                "emotion analysis",
                "ChatGPT",
                "Arabic language"
            ]
        }
    },
    {
        "Title": "Time Series Classification With Large Language Models via Linguistic Scaffolding",
        "Link": "https://ieeexplore.ieee.org/document/10706904/",
        "Abstract": "Time series classification requires specialized models that can effectively capture temporal structures. Consequently, Large Language Models (LLMs) have emerged as promising candidates due to their proficiency in sequence modeling and semantic reasoning. However, converting time series data into text results in sequences that exceed the maximum token limit, necessitating truncation or the removal of word embeddings for fixed-length time series embeddings. This restriction not only sacrifices semantic reasoning capabilities accessed through natural language but also limits the ability to handle temporal irregularities. To overcome these challenges, we propose the Language-Scaffolded Time Series Transformer (LSTST), which combines linguistic components and time series embeddings to effectively harness LLMs while overcoming dimensional constraints. Our Language Scaffold reformulates time series classification as a contextual question-answering task, with time series embeddings as context, facilitating the LLM to utilize its inherent semantic knowledge. Moreover, the preserved linguistic structure allows a dynamic number of input context embeddings with real-time positional encoding, handling length restrictions and irregularity in the temporal dimension. Through experiments, we show that LSTST achieves state-of-the-art performance on regular time series classification and also handles irregular time series without any model modifications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3475471",
            "Date of Publication": "07 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyeongwon Jang",
                "labs": [
                    "Department of Mathematical Sciences, Seoul National University, Seoul, South Korea",
                    "Kim Jaechul Graduate School of Artificial Intelligence, KAIST, Yuseong-gu, Daejeon, Republic of Korea"
                ]
            },
            {
                "name": "June Yong Yang",
                "labs": [
                    "Kim Jaechul Graduate School of Artificial Intelligence, KAIST, Yuseong-gu, Daejeon, Republic of Korea"
                ]
            },
            {
                "name": "Jaeryong Hwang",
                "labs": [
                    "Department of Cyber Science, Republic of Korea Naval Academy, Jinhae-gu, Changwon-si, Republic of Korea"
                ]
            },
            {
                "name": "Eunho Yang",
                "labs": [
                    "Kim Jaechul Graduate School of Artificial Intelligence, KAIST, Yuseong-gu, Daejeon, Republic of Korea",
                    "AITRICS, Gangnam-gu, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Transformers",
                "Linguistics",
                "Large language models",
                "Semantics",
                "Cognition",
                "Predictive models",
                "Vectors",
                "Sensors",
                "Encoding",
                "Artificial neural networks",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Artificial neural networks",
                "deep learning",
                "irregular time series classification",
                "pre-trained language models",
                "time series classification"
            ]
        }
    },
    {
        "Title": "Federated Transfer Learning for On-Device LLMs Efficient Fine Tuning Optimization",
        "Link": "https://ieeexplore.ieee.org/document/10856857/",
        "Abstract": "The proliferation of Large Language Models (LLMs) has catalyzed the growth of various industries. It is therefore imperative to ensure the controlled and beneficial application of LLMs across specific domains for downstream tasks through transfer learning, while preserving their general capabilities. We propose a novel and on-device efficient fine-tuning optimization algorithm for LLMs, utilizing federated transfer learning. Specifically, we introduce the Fusion of low Rank Adaptation (FoRA) optimization algorithm from a micro perspective, which enhances multi-dimensional feature aggregation through the addition of efficient parameters. From a meso perspective, we extend the application of the FoRA algorithm across all linear layers within the Transformer architecture to facilitate downstream task performance. Finally, from a macro perspective and with a focus on the medical domain, we incorporate quantization techniques into the federated learning framework to achieve on-device efficient fine-tuning optimization, thereby offering dual protection for data and model integrity. Our results indicate that, compared to existing state-of-the-art methods, our algorithm significantly improves LLM performance while ensuring dual privacy protection of both data and models.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020068",
            "Date of Publication": "28 January 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Chuantao Li",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Networks, Jinan, China"
                ]
            },
            {
                "name": "Bruce Gu",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Networks, Jinan, China"
                ]
            },
            {
                "name": "Zhigang Zhao",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "Department of Computer Science, Fudan University, Shanghai, China"
                ]
            },
            {
                "name": "Youyang Qu",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Networks, Jinan, China"
                ]
            },
            {
                "name": "Guomao Xin",
                "labs": [
                    "TelChina Group Co. Ltd., Jinan, China"
                ]
            },
            {
                "name": "Jidong Huo",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "College Oceanography and Space Informatics, China University of Petroleum (East China), Qingdao, China"
                ]
            },
            {
                "name": "Longxiang Gao",
                "labs": [
                    "Key Laboratory of Computing Power Network and Information Security, Shandong Computer Science Center (National Supercomputer Center in Jinan), (Shandong Academy of Sciences), Qilu University of Technology, Jinan, China",
                    "Shandong Provincial Key Laboratory of Computer Networks, Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Industries",
                "Quantization (signal)",
                "Federated learning",
                "Large language models",
                "Transfer learning",
                "Transformers",
                "Data models",
                "Protection",
                "Optimization",
                "Tuning"
            ],
            "Author Keywords": [
                "Federated learning",
                "fine-tuning",
                "deep learning",
                "Large Language Models (LLMs)"
            ]
        }
    },
    {
        "Title": "Uncovering the Risks and Drawbacks Associated With the Use of Synthetic Data for Grammatical Error Correction",
        "Link": "https://ieeexplore.ieee.org/document/10234394/",
        "Abstract": "In a Data-Centric AI paradigm, the model performance is enhanced without altering the model architecture, as evidenced by real-world and benchmark dataset demonstrations. With the advancements of large language models (LLM), it has become increasingly feasible to generate high-quality synthetic data, while considering the need to construct fully synthetic datasets for real-world data containing numerous personal information. However, in-depth validation of the solely synthetic data setting has yet to be conducted, despite the increased possibility of models trained exclusively on fully synthetic data emerging in the future. Therefore, we examined the question, “Do data quality control techniques (known to positively impact data-centric AI) consistently aid models trained exclusively on synthetic datasets?”. To explore this query, we performed detailed analyses using synthetic datasets generated for speech recognition postprocessing using the BackTranScription (BTS) approach. Our study primarily addressed the potential adverse effects of data quality control measures (e.g., noise injection and balanced data) and training strategies in the context of synthetic-only experiments. As a result of the experiment, we observed the negative effect that the data-centric methodology drops by a maximum of 44.03 points in the fully synthetic data setting.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3310257",
            "Date of Publication": "30 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seonmin Koo",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            },
            {
                "name": "Chanjun Park",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea",
                    "Upstage, Yongin-si, South Korea"
                ]
            },
            {
                "name": "Seolhwa Lee",
                "labs": [
                    "Department of Computer Science, Technical University of Darmstadt, Darmstadt, Germany"
                ]
            },
            {
                "name": "Jaehyung Seo",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            },
            {
                "name": "Sugyeong Eo",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            },
            {
                "name": "Hyeonseok Moon",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            },
            {
                "name": "Heuiseok Lim",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Synthetic data",
                "Data models",
                "Chatbots",
                "Data integrity",
                "Artificial intelligence",
                "Training",
                "Perturbation methods",
                "Grammar",
                "Error analysis",
                "Noise measurement"
            ],
            "Author Keywords": [
                "Korean grammatical error correction",
                "synthetic data",
                "noise injection",
                "balanced data"
            ]
        }
    },
    {
        "Title": "Advancing Tinnitus Therapeutics: GPT-2 Driven Clustering Analysis of Cognitive Behavioral Therapy Sessions and Google T5-Based Predictive Modeling for THI Score Assessment",
        "Link": "https://ieeexplore.ieee.org/document/10485416/",
        "Abstract": "Cognitive Behavioral Therapy (CBT) for tinnitus alleviates psychological discomfort caused by severe tinnitus symptoms. During CBT, the patients will have various homework assignments, including writing daily diaries and self-monitoring. Most of these homework assignments are hand-written, textual data. This paper proposes that tinnitus therapeutics can utilize Large Language Models (LLMs) to analyze CBT and predict the outcomes of CBT treatments to manage high caseloads. We anonymized patient data and examined it with GPT-2-based-embedding, dimensionality reduction, and clustering process to observe how patients themselves changed their misconceptions and developed less unnecessary excessive emotional discomfort and how their Tinnitus Handicap Inventory (THI) scores were improved after the CBT treatment. We also discussed clustering results as a part of the demonstrations that LLMs can give us insights into the CBT. Then, we augmented textual patient data in three ways to minimize augmentation bias with a corresponding penalty to overcome the constraints of limitation of the number of datasets. We trained the Google T5 Transformer with the augmented data to predict the THI score outcomes at the end of the CBT sessions. We measured the performance using the ROUGE-L metric during the training and validation. The generated THI scores by Google T5 were converted from strings to floats to measure RMSE performance, which proved that the LLM could predict the outcome of CBT treatment with CBT data. Even though there is a risk of overfitting issues, this work demonstrated that tinnitus therapeutics experts can employ LLMs to manage caseloads.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3383020",
            "Date of Publication": "29 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yongwoo Jeong",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jae-Jun Song",
                "labs": [
                    "Neurive Company Ltd., Gimhae-si, Republic of Korea",
                    "Department of Otorhinolaryngology-Head and Neck Surgery, Korea University Medical Center, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jiseon Yang",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Sungmin Kang",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical treatment",
                "Internet",
                "Depression",
                "Clustering algorithms",
                "Transformers",
                "Support vector machines",
                "Principal component analysis",
                "Social networking (online)",
                "Cognition",
                "Behavioral sciences",
                "Ear",
                "Patient monitoring",
                "Writing",
                "Large language models"
            ],
            "Author Keywords": [
                "Augmentation",
                "cognitive",
                "CBT",
                "GPT-2",
                "Google",
                "tinnitus",
                "T5",
                "RMSE",
                "ROUGE-L"
            ]
        }
    },
    {
        "Title": "Mamba as a Motion Encoder for Robotic Imitation Learning",
        "Link": "https://ieeexplore.ieee.org/document/10966860/",
        "Abstract": "Recent advancements in imitation learning, particularly with the integration of Large Language Model (LLM) techniques, are set to significantly improve robots’ dexterity and adaptability. This paper proposes using Mamba, a state-of-the-art architecture with potential applications in LLMs, for robotic imitation learning, highlighting its ability to function as an encoder that effectively captures contextual information. By reducing the dimensionality of the state space, Mamba operates similarly to an autoencoder. It effectively compresses the sequential information into state variables while preserving the essential temporal dynamics necessary for accurate motion prediction. Experimental results in multiple tasks demonstrate that Mamba achieves smaller estimation errors and superior success rates compared to Transformers in practical task execution. This performance is attributed to Mamba’s structure, which encompasses the state space model. Additionally, the study investigates Mamba’s capacity to serve as a real-time motion generator with a limited amount of training data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3561283",
            "Date of Publication": "16 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Toshiaki Tsuji",
                "labs": [
                    "Graduate School of Science and Engineering, Saitama University, Saitama, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Imitation learning",
                "Robot sensing systems",
                "Autoencoders",
                "Real-time systems",
                "Adaptation models",
                "Context modeling",
                "Transformers",
                "Training data",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Bilateral control",
                "imitation learning",
                "large language model",
                "learning from demonstration",
                "motion control",
                "motion generation"
            ]
        }
    },
    {
        "Title": "Accelerating Digital Twin Development With Generative AI: A Framework for 3D Modeling and Data Integration",
        "Link": "https://ieeexplore.ieee.org/document/10786996/",
        "Abstract": "Digital twins (DTs) have been introduced as valuable tools for digitally representing physical objects or assets. However, developing comprehensive and accurate DTs remains challenging due to the complexity of adding diverse data sources, creating realistic models, and enabling real-time synchronization. In this paper, we propose a DT framework that uses Generative Artificial Intelligence (GenAI) techniques integrated into the DT development pipeline to address these challenges and accelerate the creation of these virtual representations. We demonstrate how 3D generative models utilizing pre-trained 2D diffusion models, and Large Language Models (LLMs) can automate and accelerate key stages of the DT development process, which include 3D modeling, data acquisition and integration, as well as simulation and monitoring. By providing a use-case scenario of a smart medical cooler box, we demonstrate the effectiveness of the proposed framework, highlighting the potential of GenAI to reduce manual effort and streamline the integration of DT components. In particular, we illustrate how it can accelerate the creation of 3D models for DTs from 2D images by using 2D-to-3D generative models. Additionally, we show the use of LLM-based agents in automating the integration of data sources with a DT and connecting physical devices with their virtual counterparts. Challenges related to computational scalability, data privacy, and model hallucinations are highlighted, which need to be addressed for the widespread adoption of GenAI in DT development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3514175",
            "Date of Publication": "09 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Senay Gebreab",
                "labs": [
                    "Department of Computer and Information Engineering, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Ahmad Musamih",
                "labs": [
                    "Department of Management Science and Engineering, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Khaled Salah",
                "labs": [
                    "Department of Computer and Information Engineering, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Raja Jayaraman",
                "labs": [
                    "Department of Industrial Engineering, New Mexico State University, Las Cruces, NM, USA"
                ]
            },
            {
                "name": "Dragan Boscovic",
                "labs": [
                    "Center for AI and Data Analytics, Blockchain Research Laboratory, Arizona State University, Tempe, AZ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Three-dimensional displays",
                "Solid modeling",
                "Data models",
                "Rendering (computer graphics)",
                "Monitoring",
                "Computational modeling",
                "Adaptation models",
                "Accuracy",
                "Surface treatment",
                "Soft sensors"
            ],
            "Author Keywords": [
                "Generative AI",
                "large language models",
                "3D generative models",
                "diffusion models",
                "digital twin"
            ]
        }
    },
    {
        "Title": "BVQA: Connecting Language and Vision Through Multimodal Attention for Open-Ended Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/10878995/",
        "Abstract": "Visual Question Answering (VQA) is a challenging problem of Artificial Intelligence (AI) that requires an understanding of natural language and computer vision to respond to inquiries based on visual content within images. Research on VQA has gained immense traction due to its wide range of applications in aiding visually impaired individuals, enhancing human-computer interaction, facilitating content-based image retrieval systems, etc. While there has been extensive research on VQA, most were predominantly focused on English, often overlooking the complexity associated with low-resource languages, especially in Bengali. To facilitate research in this arena, we have developed a large scale Bengali Visual Question Answering (BVQA) dataset by harnessing the in-context learning abilities of the Large Language Model (LLM). Our BVQA dataset encompasses around 17,800 diverse open-ended QA Pairs generated from the human-annotated captions of ≈3,500 images. Replicating existing VQA systems for a low-resource language poses significant challenges due to the complex nature of their architectures and adaptations for particular languages. To overcome this challenge, we proposed Multimodal CRoss-Attention Network (MCRAN), a novel framework that leverages pretrained transformer architectures to encode the visual and textual information. Furthermore, our method utilizes a multi-head attention mechanism to generate three distinct vision-language representations and fuses them using a sophisticated gating mechanism to answer the query regarding an image. Extensive experiments on BVQA dataset show that the proposed method outperformed the existing baseline across various answer categories. The benchmark and source code is available at https://github.com/eftekhar-hossain/Bengali-VQA.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3540388",
            "Date of Publication": "10 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md. Shalha Mucha Bhuyan",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Eftekhar Hossain",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Khaleda Akhter Sathi",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Md. Azad Hossain",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "M. Ali Akber Dewan",
                "labs": [
                    "School of Computing and Information Systems, Faculty of Science and Technology, Athabasca University, Athabasca, AB, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Artificial intelligence",
                "Question answering (information retrieval)",
                "Natural languages",
                "Translation",
                "Large language models",
                "Image coding",
                "Complexity theory",
                "Benchmark testing",
                "Long short term memory"
            ],
            "Author Keywords": [
                "Visual question answering",
                "multimodal deep learning",
                "large language model",
                "natural language processing",
                "multi-head attention mechanism"
            ]
        }
    },
    {
        "Title": "Feature-Based Text Search Engine Mitigating Data Diversity Problem Using Pre-Trained Large Language Model for Fast Deployment Services",
        "Link": "https://ieeexplore.ieee.org/document/10459082/",
        "Abstract": "The fairness & bias of narrow coverage of AI becomes another challenge for AI researchers. If a commercial AI trains with a biased dataset, there will be severe gender or racial fairness and bias issues. Since the researchers use primary language datasets to train AI, the broad audience cannot be satisfied if a novel LLM (Large Language Model) AI shows a knowledge or creativity limitation on their specific spoken language. Narrow coverage of the LLMs can lead the audience to misinterpretation and confusion if the service involves STT (Speech-To-Text). In this paper, to overcome this issue of data diversity, we propose the idea that the embedded, extracted features have captured semantic proximity information that can be useful to mitigate diversity issues. This project focused on the Korean language food dataset for STT services, where a narrow-trained A.I. is prone to show its limitations, such as lifestyle-related elements. To present our proof of concept, we trained a baseline model, GPT2, with the Korean Wikipedia dataset in 2022. Then, we employed DistilBERT and KoBERT for comparison. The extracted hidden_state_output features from each model were utilized to build feature-extraction-based text search engines. We used the same idea of Local Sensitive Hashing (LSH) but effectively located a similar hash by applying transposed weights. We also present conventional classification benchmarks for performance comparison using top-k measurements, times for training and memory & disc consumptions. In the discussion, we proposed that our idea can mitigate the diversity problem without re-training the model and tokenizer.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3373470",
            "Date of Publication": "04 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yongwoo Jeong",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jiseon Yang",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            },
            {
                "name": "In Ho Choi",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Juyeon Lee",
                "labs": [
                    "Rowan Inc., Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Artificial intelligence",
                "Internet",
                "Online services",
                "Feature extraction",
                "Encyclopedias",
                "Text processing",
                "Data dissemination",
                "Web sites",
                "Encyclopedias",
                "Large language models",
                "Speech-to-text"
            ],
            "Author Keywords": [
                "Data diversity",
                "DistilBERT",
                "embedded",
                "GPT2",
                "KoBERT",
                "Korean",
                "language",
                "local sensitive hashing",
                "proximity",
                "semantic",
                "Wikipedia"
            ]
        }
    },
    {
        "Title": "LAMARS: Large Language Model-Based Anticipation Mechanism Acceleration in Real-Time Robotic Systems",
        "Link": "https://ieeexplore.ieee.org/document/10819383/",
        "Abstract": "Large language models (LLMs) have assumed an increasingly crucial role in robotic systems because of their ability to leverage the extensive knowledge they possess in robotic inference and task handling. Although LLMs offer significant potential, their integration into robotic systems poses substantial challenges, particularly with regard to computational efficiency and latency. To address this challenge, this study presents LAMARS, an LLM-based anticipation mechanism designed to accelerate real-time robotic systems. LAMARS leverages the predictive power and zero-shot capabilities of LLMs combined with an anticipation mechanism and vision-language processing to position a robot in advance for upcoming tasks. This reduces latency and optimizes path planning without requiring expensive training data. Our evaluations in a realistic simulation environment and with a variation of the RLBench dataset demonstrated that LAMARS achieved an average success rate of 0.79 and improves efficiency by up to 52.4% compared to existing methods, significantly lowering path planning costs. These results indicate that LAMARS effectively accelerates directive execution, making it a promising solution to minimize delays in real-time robotic systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3524906",
            "Date of Publication": "31 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yifang Gao",
                "labs": [
                    "School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Nibong Tebal, Penang, Malaysia"
                ]
            },
            {
                "name": "Wei Luo",
                "labs": [
                    "School of Electrical Engineering, Beijing Jiaotong University, Beijing, China"
                ]
            },
            {
                "name": "Xuye Wang",
                "labs": [
                    "School of Pharmaceutical Sciences, Universiti Sains Malaysia, Gelugor, Penang, Malaysia"
                ]
            },
            {
                "name": "Shunshun Zhang",
                "labs": [
                    "School of Automation, Guangxi University of Science and Technology, Liuzhou, China"
                ]
            },
            {
                "name": "Patrick Goh",
                "labs": [
                    "School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Nibong Tebal, Penang, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robot kinematics",
                "Real-time systems",
                "Hidden Markov models",
                "Visualization",
                "Costs",
                "Data models",
                "Planning",
                "Adaptation models",
                "Predictive models",
                "Vectors"
            ],
            "Author Keywords": [
                "Human-robot interaction",
                "large language models",
                "latency reduction",
                "vision-language models",
                "path planning"
            ]
        }
    },
    {
        "Title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10869316/",
        "Abstract": "Under the context of the increasing social demand for fine-grained sentiment analysis (SA), implicit sentiment analysis (ISA) poses a significant challenge owing to the absence of salient cue words in expressions. Thus, reliable reasoning is required to understand how sentiment is evoked, enabling the identification of implicit sentiments. In the era of large language models (LLMs), encoder-decoder (ED) LLMs have emerged as popular backbone models for SA applications, given their impressive text comprehension and reasoning capabilities across diverse tasks. In comparison, decoder-only (DO) LLMs exhibit superior natural language generation and in-context learning capabilities. However, their responses may contain misleading or inaccurate information. To accurately identify implicit sentiments with reliable reasoning, this study introduces a two-stage reasoning framework named Reasoning and Verification for Implicit Sentiment Analysis (RVISA), which leverages the generation ability of DO LLMs and reasoning ability of ED LLMs to train an enhanced reasoner. The framework involves three-hop reasoning prompting to explicitly furnish sentiment elements as cues. The generated rationales are then used to fine-tune an ED LLM into a skilled reasoner. Additionally, we develop a straightforward yet effective answer-based verification mechanism to ensure the reliability of reasoning learning. Evaluation of the proposed method on two benchmark datasets demonstrates that it achieves state-of-the-art performance in ISA.",
        "Details": {
            "DOI": "10.1109/TAFFC.2025.3537799",
            "Date of Publication": "03 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Affective Computing"
        },
        "issn_info": {
            "Electronic ISSN": "1949-3045"
        },
        "authors_data": [
            {
                "name": "Wenna Lai",
                "labs": [
                    "Department of Computing, Hong Kong Polytechnic University, Hong Kong, SAR, China"
                ]
            },
            {
                "name": "Haoran Xie",
                "labs": [
                    "School of Data Science, Lingnan University, Hong Kong, SAR, China"
                ]
            },
            {
                "name": "Guandong Xu",
                "labs": [
                    "School of Computer Science and the Data Science Institute, University of Technology Sydney, Sydney, NSW, Australia",
                    "Education University of Hong Kong, Hong Kong, SAR, China"
                ]
            },
            {
                "name": "Qing Li",
                "labs": [
                    "Department of Computing, Hong Kong Polytechnic University, Hong Kong, SAR, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Sentiment analysis",
                "Reliability",
                "Training",
                "Computational modeling",
                "Multitasking",
                "Gold",
                "Affective computing",
                "Context modeling",
                "Benchmark testing"
            ],
            "Author Keywords": [
                "Implicit sentiment analysis",
                "large language models",
                "multi-task learning",
                "chain-of-thought"
            ]
        }
    },
    {
        "Title": "A Comprehensive Evaluation of Large Language Models for Turkish Abstractive Dialogue Summarization",
        "Link": "https://ieeexplore.ieee.org/document/10664023/",
        "Abstract": "Text summarization is the task of generating a short and concise summary of a source text. In an abstractive text summarization, the generated summaries may potentially contain new phrases that do not appear in the source text. Dialogue summarization is a special case of text summarization in which the source text is a dialogue between two or more people. Dialogue summarization can be a crucial step especially when the source dialogues are complex and long such as call center conversations. Large language models (LLMs) show remarkable performance in natural language generation tasks and thus they can be a suitable modeling approach for abstractive text summarization. Although LLMs are extensively studied for common languages, there are only a few studies for underrepresented languages such as Turkish. In this paper, we make a comprehensive evaluation of LLMs for Turkish abstractive dialogue summarization. For this purpose, we translated 3 datasets in English to Turkish. Additionally, we make use of a test set that contains real call center dialogues originally collected in Turkish. In the experiments, we observe that fine-tuning LLMs to the dialogue summarization task significantly improves the performance. We obtain 21% overall absolute improvement with the fine-tuning over a baseline Turkish LLM. The performance is improved in all 4 test cases. Additionally, we observe that the length of the summaries plays a crucial role in the performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3454342",
            "Date of Publication": "04 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Osman Büyük",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Izmir Demokrasi University, Izmir, Türkiye",
                    "Department of Research and Development, Sestek Speech Enabled Software Technologies Inc., Istanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Oral communication",
                "Large language models",
                "Adaptation models",
                "Accuracy",
                "Training",
                "Text summarization",
                "Natural language processing",
                "Abstracts"
            ],
            "Author Keywords": [
                "Abstractive dialogue summarization",
                "large language models",
                "natural language generation",
                "text summarization"
            ]
        }
    },
    {
        "Title": "Unveiling the Power of Large Language Models: A Comparative Study of Retrieval-Augmented Generation, Fine-Tuning, and Their Synergistic Fusion for Enhanced Performance",
        "Link": "https://ieeexplore.ieee.org/document/10887212/",
        "Abstract": "Large-language model optimization for a particular application is crucial and challenging in natural language processing. This study compares two salient techniques for retrieve-augmented generation (RAG) and fine-tuning along with a new hybrid method that combines both. In this study, we investigate the effectiveness of various methods using the Stanford Question Answering Dataset (SQuAD), Microsoft Machine Reading Comprehension (MS MARCO) and SQL CREATE TABLE statements. RAG is used because it enriches the model responses with external data without much computational load during the inference. Fine-tuning updates the model parameters to improve the contextual accuracy. Our hybrid model balances the accuracy and efficiency of the two techniques. While fine-tuning entails semantic precision, RAG is more resource efficient. The hybrid approach while it may not offer surpassing results over fine-tuning-offers a balanced solution in scenarios where the application demands both efficiency and accuracy. These findings represent the trade-off involved in LLM optimization and offers a scope for further studies and practical applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3542334",
            "Date of Publication": "14 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gülsüm Budakoglu",
                "labs": [
                    "Graduate School, Applied Data Science, TED University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Hakan Emekci",
                "labs": [
                    "Graduate School, Applied Data Science, TED University, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Retrieval augmented generation",
                "Question answering (information retrieval)",
                "Adaptation models",
                "Tuning",
                "Hands",
                "Accuracy",
                "Training",
                "Solid modeling",
                "Online services",
                "Large language models"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "retrieval-augmented generation (RAG)",
                "fine-tuning",
                "hybrid models",
                "performance optimization"
            ]
        }
    },
    {
        "Title": "A Study on the Representativeness Heuristics Problem in Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10706240/",
        "Abstract": "Large language models (LLMs) exhibit remarkable proficiency in text generation. However, their logical reasoning capabilities require enhancement. Major strides have been achieved in reasoning techniques for LLM, such as Few-shot, Zero-shot, and Chain-of-Thought (CoT). Nevertheless, these techniques have shortcomings, particularly in addressing the representativeness heuristic (RH) phenomenon. RH is a cognitive bias that occurs when a person judges the probability of an event or the likelihood that an object belongs to a particular category based on how well it matches the prototype or stereotype of that category. In this study, we investigated the pervasive issue of RH errors in LLMs. This research surpasses the constraints of previous studies by analyzing various RH scenarios that they did not cover and by directly constructing and testing the corresponding datasets. Moreover, a novel prompt called zero-shot-RH is proposed to augment the reasoning ability of LLMs, mitigate RH errors, and thus bolster logical reasoning. This approach seeks to enable LLMs to comprehend the given information better and reduce the biases stemming from RH errors. The prompt zero-shot-RH achieved an average accuracy higher than zero-shot-CoT by 0.145 and 0.277 in the tasks of correct reasoning and correct reasonings by sex, respectively, without relying on RH. The outcomes of this research endeavor are a deeper understanding of RH errors in LLMs and novel strategies to mitigate these biases, thereby advancing the domain of logical reasoning within LLMs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3474677",
            "Date of Publication": "07 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jongwon Ryu",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jungeun Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Junyeong Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Problem-solving",
                "Gender issues",
                "Large language models",
                "Accuracy",
                "Standards",
                "Planning",
                "Usability",
                "Transformers",
                "Prompt engineering",
                "Zero-shot learning",
                "Heuristic algorithms",
                "Text processing"
            ],
            "Author Keywords": [
                "Prompt engineering",
                "zero-shot learning",
                "large language model",
                "representativeness heuristic"
            ]
        }
    },
    {
        "Title": "LISE: A Logic-Based Interactive Similarity Explainer for Clusters of RDF Data",
        "Link": "https://ieeexplore.ieee.org/document/11007163/",
        "Abstract": "Clustering methods are instrumental in the preliminary analysis of unstructured data, yet interpreting the resulting groups—-especially in the context of RDF (Resource Description Framework) data—-poses significant challenges. This paper introduces LISE (Logic-based Interactive Similarity Explainer), an integrated and model-agnostic framework designed to generate explainable, human-readable insights into clusters of RDF resources. LISE combines four core components: (i) a machine learning module leveraging vector embeddings and k-means clustering; (ii) a logic-based reasoning component that computes the common semantic features of clustered items via an optimized Least Common Subsumer (LCS); (iii) a Natural Language Generation (NLG) module that verbalizes these features into structured and human-readable explanations; and (iv) an interactive user feedback loop that captures user perception of explanation relevance to iteratively enhance embedding quality and cluster interpretability. An extensive use case on the DrugBank dataset demonstrates LISE’s ability to generate meaningful, context-aware cluster explanations and adapt to user preferences, advancing the state of explainable AI for semantic web technologies and knowledge graph analytics. The paper investigates also the integration in LISE of an LLM-based NLG approach, both in the DrugBank use case and through an extended experiment in a general-purpose dataset: YAGO3-10.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571518",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Simona Colucci",
                "labs": [
                    "Dipartimento di Ingegneria Elettrica e dell’Informazione, Politecnico di Bari, Bari, Italy"
                ]
            },
            {
                "name": "Francesco Maria Donini",
                "labs": [
                    "Dipartimento di Scienze Umanistiche, della Comunicazione e del Turismo, Università della Tuscia, Viterbo, Italy"
                ]
            },
            {
                "name": "Verdiana Schena",
                "labs": [
                    "Dipartimento di Ingegneria Elettrica e dell’Informazione, Politecnico di Bari, Bari, Italy"
                ]
            },
            {
                "name": "Floriano Scioscia",
                "labs": [
                    "Dipartimento di Ingegneria Elettrica e dell’Informazione, Politecnico di Bari, Bari, Italy"
                ]
            },
            {
                "name": "Eugenio Di Sciascio",
                "labs": [
                    "Dipartimento di Ingegneria Elettrica e dell’Informazione, Politecnico di Bari, Bari, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Resource description framework",
                "Knowledge graphs",
                "Drugs",
                "Feature extraction",
                "Natural language generation",
                "Clustering methods",
                "Vectors",
                "Legged locomotion",
                "Compounds",
                "Biology"
            ],
            "Author Keywords": [
                "Knowledge graph embeddings",
                "resource description framework",
                "interactive clustering",
                "user interaction",
                "natural language generation",
                "explainable artificial intelligence"
            ]
        }
    },
    {
        "Title": "Siamese Neural Networks Method for Semantic Requirements Similarity Detection",
        "Link": "https://ieeexplore.ieee.org/document/10697170/",
        "Abstract": "Detecting semantic similarity between textual requirements is a crucial task for various natural language processing (NLP)-based requirements engineering (RE) applications. It is also challenging due to the nature of these requirements, which are written in natural language (NL), include domain knowledge, and often follow pre-defined templates that contain duplicated words. Recently, deep neural networks (DNNs) have shown promising results in measuring semantic similarity between texts. Siamese neural networks (SNNs), a class of DNNs, are widely used for measuring similarity between various data types, demonstrating their capability and independence of language and domain. Nevertheless, SNNs have a limited use in measuring semantic requirements similarity (SRS). In this paper, a novel metric-based learning method is proposed using SNNs that combines a sentence Transformer model (LLM) and long short-term memory (LSTM) networks with a backward network layer to measure semantic similarity between pairs of requirements. The proposed method is evaluated on an annotated SRS dataset that was built based on public datasets (i.e., PROMISE and PURE) and compared with other state-of-the-art methods (i.e., fine-tuning and zero-shot methods) using accuracy, precision, recall, and F1-score classification metrics. The results show that the proposed method achieved an accuracy of 95.42% and an F1-score of 95.71%, outperforming the state-of-the-art methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3469636",
            "Date of Publication": "27 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nojoom A. Alnajem",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Manal Binkhonain",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "M. Shamim Hossain",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Transformers",
                "Accuracy",
                "Vectors",
                "Software",
                "Long short term memory",
                "Requirements engineering",
                "Computer architecture",
                "Natural language processing",
                "XML",
                "Artificial intelligence",
                "Neural networks"
            ],
            "Author Keywords": [
                "Artificial intelligence for requirements engineering",
                "large language models",
                "long short-term memory networks",
                "requirements",
                "requirements engineering",
                "requirements similarity",
                "semantic requirements similarity",
                "Siamese neural networks",
                "similarity",
                "transformer models"
            ]
        }
    },
    {
        "Title": "QueryMintAI: Multipurpose Multimodal Large Language Models for Personal Data",
        "Link": "https://ieeexplore.ieee.org/document/10695061/",
        "Abstract": "QueryMintAI, a versatile multimodal Language Learning Model (LLM) designed to address the complex challenges associated with processing various types of user inputs and generating corresponding outputs across different modalities. The proliferation of diverse data formats, including text, images, videos, documents, URLs, and audio recordings, necessitates an intelligent system capable of understanding and responding to user queries effectively. Existing models often exhibit limitations in handling multimodal inputs and generating coherent outputs across different modalities. The proposed QueryMintAI framework leverages state-of-the-art language models such as GPT-3.5 Turbo, DALL-E-2, TTS-1 and Whisper v2 among others, to enable seamless interaction with users across multiple modalities. By integrating advanced natural language processing (NLP) techniques with domain-specific models, QueryMintAI offers a comprehensive solution for text-to-text, text-to-image, text-to-video, and text-to-audio conversions. Additionally, the system supports document processing, URL analysis, image description, video summarization, audio transcription, and database querying, catering to diverse user needs and preferences. The proposed model addresses several limitations observed in existing approaches, including restricted modality support, lack of adaptability to various data formats, and limited response generation capabilities. QueryMintAI overcomes these challenges by employing a combination of advanced NLP algorithms, deep learning architectures, and multimodal fusion techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3468996",
            "Date of Publication": "26 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ananya Ghosh",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology (VIT), Vellore, India"
                ]
            },
            {
                "name": "K. Deepa",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology (VIT), Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Accuracy",
                "Videos",
                "Natural language processing",
                "Computational modeling",
                "Adaptation models",
                "Deep learning",
                "Large language models",
                "Generative AI",
                "Open source software"
            ],
            "Author Keywords": [
                "Multimodal large language models",
                "generative AI",
                "private database",
                "Langchain",
                "OpenAI"
            ]
        }
    },
    {
        "Title": "Building Lightweight Domain-Specific Consultation Systems via Inter-External Knowledge Fusion Contrastive Learning",
        "Link": "https://ieeexplore.ieee.org/document/10613847/",
        "Abstract": "Large language models (LLMs) have demonstrated their vast potential and value in natural language processing tasks and beyond. However, when these models are applied to develop consultation systems for industrial domains, such as e-government, intelligent diagnosis, and legal consultancy, they encounter many unresolved technical issues. These include the vast scale of the models, lack of tight fusion with existing industry knowledge, along with occurrences of model hallucinations and inadequate explainability. Unlike general-purpose dialogue systems, building a consultation system for a specific industrial domain requires not only the integration of extensive external knowledge from the Internet but also the incorporation of precise, specialized knowledge from specific industries, making the challenges even more complex. In response to these challenges, we propose the Inter-External Knowledge Fusion Contrastive Learning Technique. This technique facilitates the integration of internal industry knowledge with widely accessible external knowledge from the Internet and provides a universal framework for building lightweight, domain-specific consultation systems. Utilizing this technique enables the straightforward creation of precise, professional, and constantly updated domain-specific consultation systems applicable across various industries. Overcoming the inherent limitations associated with LLMs, this technique achieves a performance level comparable to LLMs. To validate the effectiveness of our proposed technique, we conducted extensive experiments in the development of real-world industry consulting systems. By testing on seven real datasets covering diverse tasks, we demonstrate the system’s exceptional performance: our lightweight consultation system utilizes only 4% of the parameters of an LLM but achieves over 90% of its performance level.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3434648",
            "Date of Publication": "29 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiabin Zheng",
                "labs": [
                    "School of Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Hanlin Wang",
                "labs": [
                    "Institute of Social Science Survey, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Jiahui Yao",
                "labs": [
                    "Institute of Social Science Survey, Peking University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Industries",
                "Accuracy",
                "Contrastive learning",
                "Law",
                "Internet",
                "Electronic government",
                "Large language models"
            ],
            "Author Keywords": [
                "Knowledge fusion",
                "domain-specific consultation system",
                "contrastive learning",
                "large language models",
                "lightweight system"
            ]
        }
    },
    {
        "Title": "STraVEns: Sentence Transformer Voting Ensemble for Intent Classification-Based Chatbot Model",
        "Link": "https://ieeexplore.ieee.org/document/10804807/",
        "Abstract": "Natural Language Processing has experienced significant advancements in recent years, leading to the widespread adoption of Large Language Model-based chatbots. These chatbots are popular due to their ability to engage in context-aware conversations. However, deploying LLM-based chatbots can be resource-intensive, making them less suitable for smaller applications or focused tasks. To address this issue, we propose a robust and flexible approach to intent classification for chatbots using STraVEns (Sentence Transformer Voting Ensemble), which includes both hard voting and soft voting ensembles of sentence transformers. Our proposed method aims to improve accuracy and versatility in intent-based chatbots model. We use five sentence transformer models for this ensemble framework: RoBERTa, DistilRoBERTa, MPNet, MiniLM L6, and MiniLM L12, and evaluated our approach by training and testing using four distinct datasets: ATIS, IDE, Small Talk, and CLINC150 which cover a range of scenarios from general conversation to specific tasks and out-of-scope intent classification. The results demonstrate that the STraVEns approach is a promising solution for intent classification-based chatbot model. Results show that our ensemble models outperformed previous benchmarks, achieving the highest accuracy and F1-scores across all datasets. The soft voting method provided flexibility and robustness, while hard voting ensured stability in specific contexts. Overall, our study suggests that ensemble-based approaches can enhance the performance of intent classification chatbots model, providing a scalable solution for various applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3519223",
            "Date of Publication": "17 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anindya Apriliyanti Pravitasari",
                "labs": [
                    "Department of Statistics, Faculty of Mathematics and Natural Sciences, Universitas Padjadjaran, Bandung, Indonesia"
                ]
            },
            {
                "name": "Mohammad Hamid Asnawi",
                "labs": [
                    "Department of Data Science and Artificial Intelligence, Faculty of Information Technology, Monash University, Clayton, VIC, Australia"
                ]
            },
            {
                "name": "Afrida Helen",
                "labs": [
                    "Department of Computer Sciences, Faculty of Mathematics and Natural Sciences, Universitas Padjadjaran, Bandung, Indonesia"
                ]
            },
            {
                "name": "Budhi Handoko",
                "labs": [
                    "Department of Statistics, Faculty of Mathematics and Natural Sciences, Universitas Padjadjaran, Bandung, Indonesia"
                ]
            },
            {
                "name": "Dianne Amor Kusuma",
                "labs": [
                    "Department of Mathematics, Faculty of Mathematics and Natural Sciences, Universitas Padjadjaran, Bandung, Indonesia"
                ]
            },
            {
                "name": "Tutut Herawan",
                "labs": [
                    "Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Triyani Hendrawati",
                "labs": [
                    "Department of Statistics, Faculty of Mathematics and Natural Sciences, Universitas Padjadjaran, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Intent recognition",
                "Transformers",
                "Accuracy",
                "Ensemble learning",
                "Atmospheric modeling",
                "Robustness",
                "Training",
                "Oral communication",
                "Business"
            ],
            "Author Keywords": [
                "Chatbot",
                "ensemble learning",
                "intent classification",
                "machine learning",
                "natural language processing",
                "sentence transformer",
                "voting classifier"
            ]
        }
    },
    {
        "Title": "Automated Testing for Service-Oriented Architecture: Leveraging Large Language Models for Enhanced Service Composition",
        "Link": "https://ieeexplore.ieee.org/document/11007529/",
        "Abstract": "This article explores the application of Large Language Models (LLMs), including proprietary models such as OpenAI’s ChatGPT 4o and ChatGPT 4o-mini, Anthropic’s Claude 3.5 Sonnet and Claude 3.7 Sonnet, and Google’s Gemini 1.5 Pro, Gemini 2.0 Flash, and Gemini 2.0 Flash-Lite, as well as open-source alternatives including Qwen2.5-14B-Instruct-1M, and commercially accessed models such as DeepSeek R1 and DeepSeek V3, which were tested via APIs despite having open-source variants, to automate validation and verification in Application Programming Interface (API) testing within a Service-Oriented Architecture (SOA). Our system compares internal responses from the Enuygun Web Server against third-party API outputs in both JSON and XML formats, validating critical parameters such as flight prices, baggage allowances, and seat availability. We generated 100 diverse test scenarios across varying complexities (1-4 flight results) by randomly altering request and response parameters. Experimental results show that Google Gemini 2.0 Flash achieved high accuracy (up to 99.98%) with the lowest completion time (85.34 seconds), while Qwen2.5-14B-Instruct-1M exhibited limited capability in processing complex formats. Models such as OpenAI’s ChatGPT and Anthropic’s Claude Sonnet models also demonstrated strong performance in single-flight validation scenarios, making them suitable for low-latency, high-precision tasks. Our findings indicate that some open-source models can offer promising cost-effective alternatives, though performance significantly varies. This integration of LLMs reduced manual workload, improved test scalability, and enabled real-time validation across large-scale datasets. As LLM technologies mature, we anticipate further advances in automation, accuracy, and efficiency in software validation systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571994",
            "Date of Publication": "20 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mahsun Altin",
                "labs": [
                    "Department of Computer Engineering, Istanbul Technical University, İstanbul, Türkiye",
                    "Wingie Enuygun Group, İstanbul, Türkiye"
                ]
            },
            {
                "name": "Behcet Mutlu",
                "labs": [
                    "Wingie Enuygun Group, İstanbul, Türkiye"
                ]
            },
            {
                "name": "Deniz Kilinc",
                "labs": [
                    "Department of Computer Engineering, University of Bakirçay, İzmir, Türkiye"
                ]
            },
            {
                "name": "Altan Cakir",
                "labs": [
                    "Department of Data Science and Analytics, Istanbul Technical University, İstanbul, Türkiye",
                    "Artificial Intelligence, Data Science Research, and Application Center, Istanbul Technical University, İstanbul, Türkiye",
                    "Parton Big Data Analytics and Consulting, ITU Ari Teknokent, İstanbul, Türkiye",
                    "Adin.Ai, Wilmington, DE, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Indexing",
                "Service-oriented architecture",
                "Software testing",
                "Software systems",
                "Scalability",
                "Accuracy",
                "Software development management",
                "Real-time systems",
                "Complexity theory",
                "Software reliability"
            ],
            "Author Keywords": [
                "AI-driven automation",
                "large language models",
                "scalability in API testing",
                "service-oriented architecture",
                "software validation"
            ]
        }
    },
    {
        "Title": "A Few-Shot Collapsed Transmission Tower Detection Method Combining Large and Small Models in Remote Sensing Image",
        "Link": "https://ieeexplore.ieee.org/document/10909435/",
        "Abstract": "Detecting collapsed transmission line towers in remote sensing images is of great importance for post-disaster reconstruction of transmission lines. However, the scarcity of such fault samples makes it challenging for mainstream deep learning-based object detection algorithms to perform effectively, leading to unsatisfactory detection results. Recently, large language model (LLM) and multi-modal large models (MMLM) have demonstrated strong zero-shot and few-shot detection capabilities. However, due to their reliance on text-based understanding of image content, they struggle with fine-grained image details, making it difficult to accurately detect the targets and locations of collapsed towers in remote sensing images. This paper proposes a hybrid method combining large vision model and our improved small model for few-shot detection of collapsed transmission towers. We firstly improve YOLO V10 method by replace its large kernel structure with our new structure called IKL. And then we propose a collapsed tower detection method which leverages the strong zero-shot and few-shot learning capabilities of MMLM, while utilizing the fine-grained localization and detailed description capabilities of our improved small model. This synergy overcomes the limitations of each model type while retaining their advantages. Experimental results demonstrate that the proposed method effectively distinguishes between collapsed and intact towers and achieves superior few-shot learning performance compared to using MMLM or small models alone, significantly improving the accuracy of collapse detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3547831",
            "Date of Publication": "04 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cheng Huanyu",
                "labs": [
                    "Information and Communication Branch, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China"
                ]
            },
            {
                "name": "Gu Yingcheng",
                "labs": [
                    "Information and Communication Branch, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China"
                ]
            },
            {
                "name": "Xi Mengting",
                "labs": [
                    "Information and Communication Branch, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China"
                ]
            },
            {
                "name": "Zhong Qiuyuan",
                "labs": [
                    "Information and Communication Branch, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China"
                ]
            },
            {
                "name": "Wei Liu",
                "labs": [
                    "Information and Communication Branch, State Grid Jiangsu Electric Power Company Ltd., Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Poles and towers",
                "Adaptation models",
                "Convolution",
                "Remote sensing",
                "Intelligent agents",
                "Sensors",
                "YOLO",
                "Kernel",
                "Cognition",
                "Brain modeling"
            ],
            "Author Keywords": [
                "Multi-modal large model",
                "collapsed tower",
                "remote sensing images",
                "intelligent agent",
                "object detection"
            ]
        }
    },
    {
        "Title": "Transformer and Large Language Models for Automatic Multiple-Choice Question Generation: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/11084803/",
        "Abstract": "Developing multiple-choice questions manually requires a lot of time and effort. Automatic multiple-choice question generation is one of the solutions to alleviate the problem. The research in automatic multiple-choice question generation has been growing with the recent use of Transformer and Large-Language Models. However, existing literature reviews have not thoroughly covered the recent advances in methods and evaluation conducted on the multiple-choice question generation domain. This research conducted a systematic literature review on multiple-choice question generation using Transformer and Large Language Models. This research aims to discover recent methods and evaluation strategies that have been used in the domain. We obtained 28 primary studies. We presented a taxonomy covering strategy of using the Transformer and Large Language Models for multiple-choice question generation, including fine-tuning and prompt engineering with zero-shot, few-shot, chain-of-thought, and retrieval augmented generation. Primary studies used either or both automatic and manual evaluation for the generated questions from Transformer and LLM. We found that studies are still primarily in English, with few studies utilizing learning components such as learning objective, limited use of chain-of-thought, retrieval augmented generation, and open problem in automatic evaluation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3590423",
            "Date of Publication": "18 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Halim Wildan Awalurahman",
                "labs": [
                    "Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia"
                ]
            },
            {
                "name": "Rizal Fathoni Aji",
                "labs": [
                    "Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia"
                ]
            },
            {
                "name": "Indra Budi",
                "labs": [
                    "Faculty of Computer Science, Universitas Indonesia, Depok, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Question generation",
                "Systematic literature review",
                "Large language models",
                "Deep learning",
                "Data models",
                "Databases",
                "Planning",
                "Quality assessment",
                "Libraries"
            ],
            "Author Keywords": [
                "Transformer",
                "large language models",
                "multiple-choice question generation",
                "systematic literature review"
            ]
        }
    },
    {
        "Title": "The Impact of Prompt Programming on Function-Level Code Generation",
        "Link": "https://ieeexplore.ieee.org/document/11077752/",
        "Abstract": "Large Language Models (LLMs) are increasingly used by software engineers for code generation. However, limitations of LLMs such as irrelevant or incorrect code have highlighted the need for prompt programming (or prompt engineering) where engineers apply specific prompt techniques (e.g., chain-of-thought or input-output examples) to improve the generated code. While some prompt techniques have been studied, the impact of different techniques — and their interactions — on code generation is still not fully understood. In this study, we introduce CodePromptEval, a dataset of 7072 prompts designed to evaluate five prompt techniques (few-shot, persona, chain-of-thought, function signature, list of packages) and their effect on the correctness, similarity, and quality of complete functions generated by three LLMs (GPT-4o, Llama3, and Mistral). Our findings show that while certain prompt techniques significantly influence the generated code, combining multiple techniques does not necessarily improve the outcome. Additionally, we observed a trade-off between correctness and quality when using prompt techniques. Our dataset and replication package enable future research on improving LLM-generated code and evaluating new prompt techniques.",
        "Details": {
            "DOI": "10.1109/TSE.2025.3587794",
            "Date of Publication": "10 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Software Engineering"
        },
        "issn_info": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "authors_data": [
            {
                "name": "Ranim Khojah",
                "labs": [
                    "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden"
                ]
            },
            {
                "name": "Francisco Gomes de Oliveira Neto",
                "labs": [
                    "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden"
                ]
            },
            {
                "name": "Mazen Mohamad",
                "labs": [
                    "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden",
                    "RISE Research Institutes of Sweden, Borås, Sweden"
                ]
            },
            {
                "name": "Philipp Leitner",
                "labs": [
                    "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Software",
                "Programming",
                "Few shot learning",
                "Benchmark testing",
                "Accuracy",
                "Training",
                "Software engineering",
                "Prompt engineering",
                "Encoding"
            ],
            "Author Keywords": [
                "Large language models",
                "prompt programming",
                "code generation"
            ]
        }
    },
    {
        "Title": "Exploring the Integration of Generative AI Tools in Software Testing Education: A Case Study on ChatGPT and Copilot for Preparatory Testing Artifacts in Postgraduate Learning",
        "Link": "https://ieeexplore.ieee.org/document/10904141/",
        "Abstract": "Software testing education is important for building qualified testing professionals. To ensure that software testing graduates are ready for real-world challenges, it is necessary to integrate modern tools and technologies into the curriculum. With the emergence of Large Language Models (LLMs), their potential use in software engineering has become a focus, but their application in software testing education remains largely unexplored. This study, conducted in the Capstone Project course of a postgraduate software testing program, was carried out over two semesters with two distinct groups of students. A custom-built Travel Application limited to a web platform was used in the first semester. In the second semester, a new set of students worked with an open-source application, offering a larger-scale, multi-platform experience across web, desktop, and mobile platforms. Students initially created preparatory testing artifacts manually as a group deliverable. Following this, they were assigned an individual assignment to generate the same artifacts using LLM tools such as ChatGPT 3.5 in the first semester and Microsoft Copilot in the second. This process directly compared manually created artifacts and those generated using LLMs, leveraging AI for faster outputs. After completion, they responded to a set of assigned questions. The students’ responses were assessed using an integrated methodology, including quantitative and qualitative assessments, sentiment analysis to understand emotions, and a thematic approach to extract deeper insights. The findings revealed that while LLMs can assist and augment manual testing efforts, they cannot entirely replace the need for manual testing. By incorporating innovative technology into the curriculum, this study highlights how Generative AI can support active learning, connect theoretical concepts with practical applications, and align educational practices with industry needs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3545882",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Susmita Haldar",
                "labs": [
                    "School of Information Technology, Fanshawe College, London, ON, Canada"
                ]
            },
            {
                "name": "Mary Pierce",
                "labs": [
                    "Faculty of Business, Information Technology and Part-Time Studies, Fanshawe College, London, ON, Canada"
                ]
            },
            {
                "name": "Luiz Fernando Capretz",
                "labs": [
                    "Department of Electrical and Computer Engineering, Western University, London, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software testing",
                "Education",
                "Generative AI",
                "Industries",
                "Chatbots",
                "Software engineering",
                "Sentiment analysis",
                "Large language models",
                "Accuracy",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Capstone project",
                "ChatGPT",
                "generative AI",
                "software testing education",
                "Microsoft Copilot",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "TepiSense: A Social Computing-Based Real-Time Epidemic Surveillance System Using Artificial Intelligence",
        "Link": "https://ieeexplore.ieee.org/document/10858732/",
        "Abstract": "Artificial Intelligence (AI) technologies have enabled researchers to develop tools to monitor real-world events and user behavior using social media platforms. Twitter is particularly useful for gathering invaluable information related to diseases and public health to build real-time disease surveillance systems. Such systems offer a cost-effective and efficient alternative to the passive, expensive, and time-consuming process of using data from healthcare organizations and hospitals. In this paper, we propose a novel system of TepiSense to automatically perform disease surveillance of epidemic-prone diseases. Our system classifies tweets related to diseases and further identifies ‘indication’ tweets that highlight the presence of patients. Our system consists of four distinct modules of pre-processor, feature extractor, classifier, and evaluator. TepiSense compares the performance of 3 feature extraction techniques, 9 machine/deep learning models, and 3 Large Language Models (LLMs). To test the performance of our system, we build a dataset of Twitter Epidemic Surveillance Corpus (TESC) containing 23.9K English and 13K labelled Urdu tweets related to six diseases: COVID19, hepatitis, malaria, flu, dengue, and HIV/AIDS. Our results show that mBERT LLM achieves the highest F-measure values of 0.96 and 0.83 for topic and indication tweets classification, respectively. Furthermore, we compute the correlation of signals generated by our system with real-world cases to test the efficacy on COVID19 disease. We notice that real-world cases have a correlation of 0.58-0.63 with the indication category tweets. Finally, we develop an interactive and user-friendly dashboard to disseminate the analytics of our system. Overall, our system offers a powerful tool for real-time disease surveillance using social media with potential implications for public health policy and decision-making.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3537168",
            "Date of Publication": "30 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bilal Tahir",
                "labs": [
                    "Al-Khawarizmi Institute of Computer Science, University of Engineering and Technology, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Amir Mehmood",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Diseases",
                "Surveillance",
                "COVID-19",
                "Social networking (online)",
                "Epidemics",
                "Medical services",
                "Real-time systems",
                "Viruses (medical)",
                "Liver diseases",
                "Correlation"
            ],
            "Author Keywords": [
                "Natural language processing",
                "epidemic intelligence",
                "public health",
                "data mining",
                "smart city",
                "e-health"
            ]
        }
    },
    {
        "Title": "Unstructured Electronic Health Records of Dysphagic Patients Analyzed by Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11006689/",
        "Abstract": "Objective: Dysphagia is a common and complex disorder that complicates both diagnoses and treatment. Consequently, the associated electronic health records (EHR) are often unstructured and complex, posing challenges for systematic data analysis.Methods and procedures: In this study, we employ natural language processing (NLP) techniques and large language models (LLMs) to automatically analyze clinical narratives and extract diagnostic information from a diverse set of EHRs. Our dataset includes medical records from 486 patients, representing a group with diverse dysphagic conditions. We analyze diagnoses provided in unstructured free text that do not follow a standardized structure. We utilize clustering algorithms on the extracted diagnostic features to identify distinct groups of patients who share similar pathophysiological swallowing dysfunctions.Results: We found that basic NLP techniques often provide limited insights due to the high variability of the data. In contrast, LLMs help to bridge the gap in understanding the nuanced medical information about dysphagia and related conditions. Although applying these advanced LLM models is not straightforward, our results demonstrate that leveraging closed-source models can effectively cluster different categories of dysphagia.Conclusion: Our study provides therefore evidence that LLMs are highly promising in future dysphagia research.Clinical impact: Dysphagia is a symptom associated with various diseases, though its underlying relationships remain unclear. This study demonstrates how analyzing large volumes of electronic health records can help clarify the causes of dysphagia and identify contributing factors. By applying natural language processing, we aim to enhance both understanding and treatment, supporting clinical staff in improving individualized care by identifying relevant patient cohorts. Clinical and Translational Impact Statement: This study uses LLMs to efficiently preprocess unstructured EHRs, improving dysphagia diagnosis and patient clustering. It aligns with Clinical Research, enhancing diagnostic speed and enabling personalized treatment.\nShow Less",
        "Details": {
            "DOI": "10.1109/JTEHM.2025.3571255",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Translational Engineering in Health and Medicine"
        },
        "issn_info": {
            "Electronic ISSN": "2168-2372"
        },
        "authors_data": [
            {
                "name": "Luisa Neubig",
                "labs": [
                    "Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany"
                ]
            },
            {
                "name": "Deirdre Larsen",
                "labs": [
                    "Department of Communication Sciences and Disorders, East Carolina University, Greenville, NC, USA"
                ]
            },
            {
                "name": "Melda Kunduk",
                "labs": [
                    "Department of Communication Sciences and Disorders, Louisiana State University, Baton Rouge, LA, USA"
                ]
            },
            {
                "name": "Andreas M. Kist",
                "labs": [
                    "Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical diagnostic imaging",
                "Natural language processing",
                "Translation",
                "Encoding",
                "Medical services",
                "Semantics",
                "Pathology",
                "Large language models",
                "Electronic medical records",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Dysphagia",
                "EHR",
                "clustering analysis",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "CD-LLMCARS: Cross Domain Fine-Tuned Large Language Model for Context-Aware Recommender Systems",
        "Link": "https://ieeexplore.ieee.org/document/10771726/",
        "Abstract": "Recommender systems are essential for providing personalized content across various platforms. However, traditional systems often struggle with limited information, known as the cold start problem, and with accurately interpreting a user's comprehensive preferences, referred to as context. The proposed study, CD-LLMCARS (Cross-Domain fine-tuned Large Language Model for Context-Aware Recommender Systems), presents a novel approach to addressing these issues. CD-LLMCARS leverages the substantial capabilities of the Large Language Model (LLM) Llama 2. Fine-tuning Llama 2 with information from multiple domains can enhance the generation of contextually relevant recommendations that align with a user's preferences in areas such as movies, music, books, and CDs. Techniques such as Low-Rank Adaptation (LoRA) and Half Precision Training (FP16) are both effective and resource-efficient, allowing CD-LLMCARS to perform optimally in cold start scenarios. Extensive testing of CD-LLMCARS indicates outstanding accuracy, particularly in challenging scenarios characterized by limited user history data relevant to the cold start problem. CD-LLMCARS offers precise and pertinent recommendations to users, effectively mitigating the limitations of traditional recommender systems.",
        "Details": {
            "DOI": "10.1109/OJCS.2024.3509221",
            "Date of Publication": "28 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Adeel Ashraf Cheema",
                "labs": [
                    "Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan"
                ]
            },
            {
                "name": "Muhammad Shahzad Sarfraz",
                "labs": [
                    "Department of Computer Science, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan"
                ]
            },
            {
                "name": "Usman Habib",
                "labs": [
                    "FAST School of Computing, National University of Computer and Emerging Sciences, Islamabad Campus, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Qamar Uz Zaman",
                "labs": [
                    "Department of Software Engineering, National University of Computer and Emerging Sciences, Chiniot-Faisalabad Campus, Chiniot, Pakistan"
                ]
            },
            {
                "name": "Ekkarat Boonchieng",
                "labs": [
                    "Department of Computer Science, Faculty of Science, Chiang Mai University, Chiang Mai, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Recommender systems",
                "Large language models",
                "Reviews",
                "Accuracy",
                "History",
                "Context modeling",
                "Collaborative filtering",
                "Tuning",
                "Training",
                "User experience"
            ],
            "Author Keywords": [
                "Collaborative filtering",
                "context-aware recommeder systems (CARS)",
                "cross-domain recommender systems (CDRS)",
                "large language models (LLMs)",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "Anomaly Detection Using Generative Language Models and Deep Feature-Based Time Series Similarity",
        "Link": "https://ieeexplore.ieee.org/document/11145036/",
        "Abstract": "Time series data play a critical role in decision-making across domains such as environmental monitoring, industrial equipment management, and financial market analysis. However, these data are highly susceptible to distortions caused by noise, anomalies, and sensor failures. Early detection and interpretability of abnormal patterns are essential to ensuring the reliability of data-driven systems. This paper proposes a novel anomaly detection framework that integrates large language models (LLMs) with time series retrieval-augmented generation. Traditional anomaly detection methods often rely on statistical models or single deep learning architectures, which struggle to capture irregular patterns and lack interpretability. Our method segments time series into interpretable subsequences, embeds them into high-dimensional vectors, and retrieves similar historical cases from a vector database. In addition, structural similarity across spatially adjacent sensors is quantified using Dynamic Time Warping (DTW) and Z-score metrics. These analytical results are then used to construct prompts, which are passed to an LLM to generate natural language decisions and explanations. The proposed framework enables both accurate detection and human-readable reasoning. Evaluated on real-world air quality monitoring data from South Korea, our approach reduced the false positive rate by over 50%, while maintaining recall, thereby validating its practical reliability and explainability compared to a segmentation-only approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3604216",
            "Date of Publication": "29 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junpyo Lee",
                "labs": [
                    "Department of Electrical and Computer Engineering, Inha University, Incheon, Republic of Korea"
                ]
            },
            {
                "name": "Jungmu Choi",
                "labs": [
                    "Department of Computer Engineering, Inha University, Incheon, Republic of Korea"
                ]
            },
            {
                "name": "Jung Min Park",
                "labs": [
                    "Atmospheric Environmental Research Department, National Institute of Environmental Research, Incheon, South Korea"
                ]
            },
            {
                "name": "Yong-Jae Lim",
                "labs": [
                    "Atmospheric Environmental Research Department, National Institute of Environmental Research, Incheon, South Korea"
                ]
            },
            {
                "name": "Hae-Jin Jung",
                "labs": [
                    "Atmospheric Environmental Research Department, National Institute of Environmental Research, Incheon, South Korea"
                ]
            },
            {
                "name": "Soyoung Kang",
                "labs": [
                    "Atmospheric Environmental Research Department, National Institute of Environmental Research, Incheon, South Korea"
                ]
            },
            {
                "name": "Chanjung An",
                "labs": [
                    "Atmospheric Environmental Research Department, National Institute of Environmental Research, Incheon, South Korea"
                ]
            },
            {
                "name": "Jangwoo Kwon",
                "labs": [
                    "Department of Computer Engineering, Inha University, Incheon, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Anomaly detection",
                "Retrieval augmented generation",
                "Vectors",
                "Noise",
                "Natural languages",
                "Large language models",
                "Forecasting",
                "Pipelines",
                "Indexes"
            ],
            "Author Keywords": [
                "Anomaly detection",
                "large language model",
                "retrieval-augmented generation",
                "time series",
                "time series segmentation"
            ]
        }
    },
    {
        "Title": "A Multi-Agent System for Cybersecurity Threat Detection and Correlation Using Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11141466/",
        "Abstract": "As cyber-attacks rapidly evolve across communication, infrastructure and data layers, traditional security solutions such as rule-based intrusion detection systems (IDS) or signature-based antivirus programs are effective at detecting known threats, but they often lack the contextual understanding and semantic interpretation necessary to detect complex or evolving attacks. For example, spear-phishing campaigns, advanced persistent threats (APTs), and multi-stage attacks often escape detection due to their subtle and context-dependent nature. This limitation creates a critical gap in detecting coordinated or subtle attack patterns that span multiple systems and domains. The need for semantic understanding, cross-domain visibility, and adaptive detection is increasingly urgent, particularly as threat actors employ polymorphic and AI-driven strategies that traditional systems cannot interpret or correlate effectively. This paper presents a modular multi-agent architecture that integrates established cybersecurity analysis tools with large language models (LLMs) to achieve intelligent, explicable and highly accurate detection of threats across diverse data types. Three specialized agents: 1) email verification, 2) log analysis, and 3) IP address scanning each operate independently with tailored detection pipelines that combine domain-specific tools and LLM-powered semantic analysis components to identify, characterize, and report threats specific to their domain. At the core of the system lies a contextual recommendation system that processes and cross-analyzes the outputs of all specialized agents to detect complex threat patterns such as multi-vector, time-based, or stealth attacks that would otherwise evade isolated detection mechanisms. The evaluation on benchmark datasets, including CIC-IDS 2017, SpamAssassin, and custom simulated network environments, demonstrates threat detection accuracy of 93.6%, multi-agent correlation accuracy of 87%, and false positive reduction of 41.3% compared to traditional approaches. The use of LLMs for both structured explanations and chain-of-thought reporting further enhances analyst confidence and reduces triage time.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3602681",
            "Date of Publication": "25 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yasser Hmimou",
                "labs": [
                    "Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco",
                    "2IACS Laboratory, ENSET, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Mohamed Tabaa",
                "labs": [
                    "Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco"
                ]
            },
            {
                "name": "Azeddine Khiat",
                "labs": [
                    "2IACS Laboratory, ENSET, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Zineb Hidila",
                "labs": [
                    "Multidisciplinary Laboratory of Research and Innovation (LPRI), Moroccan School of Engineering Sciences (EMSI), Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Correlation",
                "Phishing",
                "Computer security",
                "Semantics",
                "Pipelines",
                "IP networks",
                "Electronic mail",
                "Recommender systems",
                "Cognition",
                "Accuracy"
            ],
            "Author Keywords": [
                "Multi-agent systems",
                "LLMs",
                "contextual threat analysis",
                "semantic analysis",
                "email phishing detection",
                "log-based anomaly detection",
                "IP scanning"
            ]
        }
    },
    {
        "Title": "Make Large Language Models Efficient: A Review",
        "Link": "https://ieeexplore.ieee.org/document/11146704/",
        "Abstract": "Large Language Models (LLMs) have achieved remarkable success across a variety of natural language processing tasks, with larger architectures often exhibiting superior performance. This scaling behavior has fueled intense competition in generative AI, supported by projected investments that exceed\n$\n1 trillion to develop increasingly sophisticated LLMs. This competition has in turn nurtured a vibrant ecosystem, inspiring new open-source models such as DeepSeek, and motivating application developers to harness state-of-the-art LLMs for real-world deployments. However, the extensive memory and computational requirements of large models present serious obstacles for small-medium organizations, leading to significant scalability concerns. This paper offers a comprehensive review of recent techniques to improve LLM efficiency through four categories: parameter-centric, architecture-centric, training-centric and data-centric. For a better understanding of the newcomer’s perspective, it covers the entire lifecycle when developing and deploying LLMs. Thus, this paper is organized around five core tasks: model compression for local deployment, accelerated pre-training to reduce time-to-train, efficient fine-tuning on custom data, optimized inference under resource constraints, and streamlined data preparation. Rather than focusing on broad strategies, we emphasize specialized techniques tailored to each stage of development. By applying targeted optimizations at each phase, the computational overhead can be reduced by 50–95% without compromising the quality of the model, making LLMs more accessible to researchers and practitioners with limited computational resources.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605110",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aman Mussa",
                "labs": [
                    "Al-Farabi Kazakh National University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Zhanseit Tuimebayev",
                "labs": [
                    "Al-Farabi Kazakh National University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Madina Mansurova",
                "labs": [
                    "Al-Farabi Kazakh National University, Almaty, Kazakhstan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Computational modeling",
                "Biological system modeling",
                "Adaptation models",
                "Quantization (signal)",
                "Large language models",
                "Hardware",
                "Graphics processing units",
                "Tuning",
                "Data models"
            ],
            "Author Keywords": [
                "Fine tuning",
                "large language model",
                "natural language processing",
                "artificial intelligence"
            ]
        }
    },
    {
        "Title": "A Survey of Cooperative Multi-Agent Reinforcement Learning for Multi-Task Scenarios",
        "Link": "https://ieeexplore.ieee.org/document/11077963/",
        "Abstract": "Cooperative multi-agent reinforcement learning (MARL) is a key technology for enabling cooperation in complex multi-agent systems. It has achieved remarkable progress in areas such as gaming, autonomous driving, and multi-robot control. Empowering cooperative MARL with multi-task decision-making capabilities is expected to further broaden its application scope. In multi-task scenarios, cooperative MARL algorithms need to address 3 types of multi-task problems: reward-related multi-task, arising from different reward functions; multi-domain multi-task, caused by differences in state and action spaces, state transition functions; and scalability-related multi-task, resulting from the dynamic variation in the number of agents. Most existing studies focus on scalability-related multi-task problems. However, with the increasing integration between large language models (LLMs) and multi-agent systems, a growing number of LLM-based multi-agent systems have emerged, enabling more complex multi-task cooperation. This paper provides a comprehensive review of the latest advances in this field. By combining multi-task reinforcement learning with cooperative MARL, we categorize and analyze the 3 major types of multi-task problems under multi-agent settings, offering more fine-grained classifications and summarizing key insights for each. In addition, we summarize commonly used benchmarks and discuss future directions of research in this area, which hold promise for further enhancing the multi-task cooperation capabilities of multi-agent systems and expanding their practical applications in the real world.",
        "Details": {
            "DOI": "10.23919/AISE.2025.000008",
            "Date of Publication": "June 2025",
            "Publisher": "Southwest University",
            "Published In": "Artificial Intelligence Science and Engineering"
        },
        "issn_info": {},
        "authors_data": [
            {
                "name": "Jiajun Chai",
                "labs": [
                    "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
                    "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Zijie Zhao",
                "labs": [
                    "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
                    "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Yuanheng Zhu",
                "labs": [
                    "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
                    "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Dongbin Zhao",
                "labs": [
                    "State Key Laboratory of Multimodal Artificial Intelligence Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
                    "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Reviews",
                "Large language models",
                "Heuristic algorithms",
                "Decision making",
                "Reinforcement learning",
                "Benchmark testing",
                "Multitasking",
                "Market research",
                "Multi-agent systems"
            ],
            "Author Keywords": [
                "multi-task",
                "multi-agent reinforcement learning",
                "large language models"
            ]
        }
    },
    {
        "Title": "When Multimodal Large Language Models Meet Computer Vision: Progressive GPT Fine-Tuning and Stress Testing",
        "Link": "https://ieeexplore.ieee.org/document/11036181/",
        "Abstract": "The rapid evolution of Multimodal Large Language Models (LLMs) has redefined the landscape of artificial intelligence, with OpenAI’s GPT-4o representing a transformative leap in multimodal learning and processing. This study pioneers the fine-tuning of GPT-4o on image data, addressing a critical gap in evaluating its performance beyond zero-shot capabilities. It investigates the potential of GPT-4o multimodal LLM for computer vision classification tasks, focusing on e-commerce product categorization through a novel, progressive, few-shot learning fine-tuning framework. Leveraging GPT-4o’s newly available multimodal capabilities, we implemented a four-phase progressive training procedure across varying image resolutions (100, 200, and 400 pixels). Each phase was rigorously evaluated for training duration, computational cost, loss metrics, and validation performance. Predictions were assessed using accuracy, precision, recall, and F1-score metrics while closely monitoring prediction costs and processing time. To establish a benchmark, we replicated the process with ResNet-50 and ConvNeXt-tiny models, applying Bayesian optimization for hyperparameter tuning. We explored a range of batch sizes and learning rates using the Optuna library, conducting 100 trials over a maximum of 50 epochs with early stopping and the successive halving pruner to identify optimal configurations for each model. Although ResNet-50 and ConvNeXt-tiny exhibited lower fine-tuning costs, achieving comparable performance required larger batch sizes and lower learning rates. GPT-4o’s multimodal learning approach achieved 87% accuracy with minimal training—just three epochs and a batch size of one—highlighting its efficiency in few-shot learning with limited labeled data. Our findings highlight key trade-offs between cost-efficiency and performance, offering actionable insights for deploying multimodal Large Language Models in resource-constrained scenarios. GPT-4o’s progressive fine-tuning approach showed promising results in computer vision classification tasks, suggesting its potential as a scalable, multimodal AI tool for real-world multimodal learning and vision-based applications.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3579420",
            "Date of Publication": "13 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Konstantinos I. Roumeliotis",
                "labs": [
                    "Department of Informatics and Telecommunications, Faculty of Economics and Technology, University of Peloponnese, Tripoli, Greece"
                ]
            },
            {
                "name": "Nikolaos D. Tselikas",
                "labs": [
                    "Department of Informatics and Telecommunications, Faculty of Economics and Technology, University of Peloponnese, Tripoli, Greece"
                ]
            },
            {
                "name": "Dimitrios K. Nasiopoulos",
                "labs": [
                    "Department of Agribusiness and Supply Chain Management, School of Applied Economics and Social Sciences, Agricultural University of Athens, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer vision",
                "Visualization",
                "Accuracy",
                "Computational modeling",
                "Artificial intelligence",
                "Image classification",
                "Electronic commerce",
                "Large language models",
                "Training",
                "Few shot learning"
            ],
            "Author Keywords": [
                "Multimodal large language models",
                "multimodal classification",
                "computer vision classification"
            ]
        }
    },
    {
        "Title": "Generating Authentic Grounded Synthetic Maintenance Work Orders",
        "Link": "https://ieeexplore.ieee.org/document/11124200/",
        "Abstract": "Large language models (LLMs) are promising for generating synthetic technical data, particularly for industrial maintenance where real datasets are often limited and unbalanced. This study generates synthetic maintenance work orders (MWOs) that are grounded to accurately represent engineering knowledge and authentic–reflecting technician language, jargon, and abbreviations. First, we extracted valid engineering paths from a knowledge graph constructed using the MaintIE gold-annotated industrial MWO dataset. Each path encodes engineering knowledge as a triple. These paths are used to constrain the output of an LLM (GPT-4o mini) to generate grounded synthetic MWOs using few-shot prompting. The synthetic MWOs are made authentic by incorporating human-like elements, such as contractions, abbreviations, and typos. Evaluation results show that the synthetic data is 86% as natural and 95% as correct as real MWOs. Turing test experiments reveal that subject matter experts could distinguish real from synthetic data only 51% of the time while exhibiting near-zero agreement, indicating random guessing. Statistical hypothesis testing confirms the results from the Turing Test. This research offers a generic approach to extracting legitimate paths from a knowledge graph to ensure that synthetic data generated are grounded in engineering knowledge while reflecting the style and language of the technicians who write them. To enable replication and reuse, code, data and documentation are at https://github.com/nlp-tlp/LLM-KG-Synthetic-MWO",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3598751",
            "Date of Publication": "13 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Allison Lau",
                "labs": [
                    "Department of Computer Science and Software Engineering, The University of Western Australia, Perth, WA, Australia"
                ]
            },
            {
                "name": "Jadeyn Feng",
                "labs": [
                    "Department of Computer Science and Software Engineering, The University of Western Australia, Perth, WA, Australia"
                ]
            },
            {
                "name": "Melinda Hodkiewicz",
                "labs": [
                    "School of Engineering, The University of Western Australia, Perth, WA, Australia"
                ]
            },
            {
                "name": "Caitlin Woods",
                "labs": [
                    "Department of Computer Science and Software Engineering, The University of Western Australia, Perth, WA, Australia"
                ]
            },
            {
                "name": "Michael Stewart",
                "labs": [
                    "Department of Computer Science and Software Engineering, The University of Western Australia, Perth, WA, Australia"
                ]
            },
            {
                "name": "Adriano Polpo",
                "labs": [
                    "Department of Mathematics and Statistics, The University of Western Australia, Perth, WA, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Maintenance",
                "Synthetic data",
                "Annotations",
                "Oils",
                "Engines",
                "Australia",
                "Knowledge engineering",
                "Training data",
                "Knowledge graphs",
                "Silver"
            ],
            "Author Keywords": [
                "Maintenance work orders",
                "large language models",
                "GPT",
                "knowledge graphs",
                "grounded synthetic data",
                "synthetic data generation",
                "technical language processing",
                "Turing test"
            ]
        }
    },
    {
        "Title": "Intent-Based Infrastructure and Service Orchestration Using Agentic-AI",
        "Link": "https://ieeexplore.ieee.org/document/11131150/",
        "Abstract": "This paper introduces a novel framework that integrates agentic Artificial Intelligence (AI) with Intent-Based Networks (IBN) to enable autonomous management, configuration, and optimization of mobile network services and resources. Leveraging the advanced reasoning and natural language processing capabilities of an Large Language Model (LLM), the proposed architecture translates high-level user intents into precise network actions, facilitating user-friendly and scalable network orchestration. The framework employs a distributed multi-agent system, where specialized agents collaborate to decompose user intents, provide computational infrastructure, and deploy services using industry-standard Infrastructure-as-Code (IaC) tools. By supporting natural language interactions, the system reduces operational complexity and enhances accessibility for users with varying technical expertise. Experimental evaluations demonstrate significant improvements in task completion rates, response accuracy, and operational efficiency compared to traditional manual methods, particularly for complex network management tasks. In essence, this work creates an intelligent network orchestration framework that adapts to user needs by automatically configuring network and computing resources while operating with minimal human intervention.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2025.3600706",
            "Date of Publication": "20 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Dimitrios Brodimas",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Patras, Patras, Greece"
                ]
            },
            {
                "name": "Alexios Birbas",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Patras, Patras, Greece"
                ]
            },
            {
                "name": "Dimitrios Kapolos",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Patras, Patras, Greece"
                ]
            },
            {
                "name": "Spyros Denazis",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Patras, Patras, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Cognition",
                "Translation",
                "Industries",
                "5G mobile communication",
                "Planning",
                "Oral communication",
                "Context modeling",
                "Computer architecture",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Agentic artificial intelligence",
                "intent based networks",
                "infrastructure as code",
                "model context protocol"
            ]
        }
    },
    {
        "Title": "IoT Rule Generation With Cross-View Contrastive Learning and Perplexity-Based Ranking",
        "Link": "https://ieeexplore.ieee.org/document/11036749/",
        "Abstract": "Trigger-action platforms (TAPs) streamline task automation in Internet of Things (IoT) ecosystems through intuitive IF-THEN rules. However, the rapid expansion of TAP devices, combined with the diversity and overlap of their functionalities, presents significant challenges for users in formulating rules that accurately capture their intentions and effectively map these intents to the appropriate device actions. This article presents Trigger-Action Rule GEneration (TARGE), a novel framework for generating IoT automation rules directly from natural language user intents. TARGE leverages large language models (LLMs) to interpret user intents and employs cross-view contrastive learning to generate rule embeddings that capture TAP functionality and device relationships. Its ranking mechanism combines semantic consistency with LLM-derived perplexity to prioritize contextually coherent rules. Evaluated on a dataset of IFTTT rules, TARGE demonstrates robust performance across scenarios involving both well-defined and ambiguous user intents, consistently outperforming state-of-the-art methods by at least 46% in exact match accuracy and 35% in multirule recommendations.",
        "Details": {
            "DOI": "10.1109/JIOT.2025.3579920",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Internet of Things Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2327-4662"
        },
        "authors_data": [
            {
                "name": "Gaetano Cimino",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Vincenzo Deufemia",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Mattia Limone",
                "labs": [
                    "Electronics Division, Leonardo S.p.A., Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Automation",
                "Internet of Things",
                "Natural languages",
                "Semantics",
                "Contrastive learning",
                "Smart homes",
                "Accuracy",
                "Translation",
                "Training",
                "Programming"
            ],
            "Author Keywords": [
                "Cross-view contrastive learning",
                "Internet of Things (IoT) rule generation",
                "natural language processing (NLP)",
                "smart home"
            ]
        }
    },
    {
        "Title": "Broken Bags: Disrupting Service Through the Contamination of Large Language Models With Misinformation",
        "Link": "https://ieeexplore.ieee.org/document/11048579/",
        "Abstract": "Large language models (LLMs) have progressively become essential production tools in contemporary society, owing to their formidable natural language generation and contextual reasoning skills. To facilitate the development of current responses by LLMs, individuals have used retrieval-augmented generation (RAG) technology, which extracts material from the corpus to assist large language models in producing relevant replies. The extensive utilization of huge language models necessitates urgent RAG security research. Conventional RAG attack techniques exhibit inadequate hiding and a substantial volume of harmful messages. Consequently, we have introduced an innovative attack mechanism termed “Broken Bags,” which adeptly injects a minimal quantity of toxic text to mislead large language models. The attack is executed through a hybrid approach that incorporates artificial prompt templates, toxic content generated by LLMs, and filtering mechanisms. For instance, when the RAG system engages with publicly available knowledge bases, adversaries can take advantage of the accessibility of these RAG knowledge bases to introduce malicious texts into the retrieval database, so as to intentionally alter the model’s behavior. This work employs the linguistic similarity between toxic content and the geographical vector characteristics of the “query question” to influence the information returned by RAG, hence preventing the LLM from generating responses to the target questions. We developed and refined an artificial prompt template to render toxic language more akin to authentic human expressions and less detectable. Experimental data indicates that our attack success rate attains 94%. Ultimately, we systematically evaluate state-of-the-art defenses (including perplexity-based detection and knowledge extension, among others), and the findings indicate that these measures are unable to counter “Broken Bags,” hence significantly enhancing the success rate of assaults on RAG systems.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3582519",
            "Date of Publication": "23 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yonghua Mo",
                "labs": [
                    "School of Information Engineering, Guilin Institute of Information Technology, Guilin, China"
                ]
            },
            {
                "name": "Maoyang Tang",
                "labs": [
                    "School of Information Engineering, Guilin Institute of Information Technology, Guilin, China"
                ]
            },
            {
                "name": "Ruohan Lin",
                "labs": [
                    "School of Information Engineering, Guilin Institute of Information Technology, Guilin, China"
                ]
            },
            {
                "name": "Bohao Zhou",
                "labs": [
                    "School of Information Engineering, Guilin Institute of Information Technology, Guilin, China"
                ]
            },
            {
                "name": "Xiaojian Li",
                "labs": [
                    "School of Electronic Engineering, Guilin Institute of Information Technology, Guilin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Security",
                "Large language models",
                "Internet",
                "Knowledge based systems",
                "Databases",
                "Computer crime",
                "Information technology",
                "Generators",
                "Fake news",
                "Writing"
            ],
            "Author Keywords": [
                "Information security",
                "information retrieval",
                "large language models",
                "RAG attack",
                "prompt injection attacks"
            ]
        }
    },
    {
        "Title": "Adapting LLMs for Satellite Communications: Methodology, Challenges, and Impact",
        "Link": "https://ieeexplore.ieee.org/document/11146720/",
        "Abstract": "The application of large language models (LLMs) to specialized fields, such as Satellite Communications (SatCom), presents unique challenges due to the extensive and cutting-edge knowledge required. SatCom encompasses a wide range of technical details, protocols, and operational guidelines that must be addressed to produce effective and accurate models for practical use. This paper presents a fine-tuning approach for adapting 7-billion-parameter instructed LLMs (Llama-3v and Mistral) to SatCom, using a proprietary corpus sourced from the European Space Agency (ESA) consisting of domain-specific PDF documents. The confidential nature of this corpus imposes constraints on both model training and evaluation, demanding a sensible text extraction pipeline capable of handling complex structures, such as tables, to preserve critical information. Our fine-tuning methodology employs a carefully configured process, followed by an automatic evaluation framework using a curated Q&A set tailored to SatCom. Models were created in both non-quantified and 8-bit quantized formats, ensuring feasibility for desktop-level inference. The fine-tuned models demonstrated a 6,6% improvement over the baseline LLM, as well as significant gains when compared to retrieval-augmented generation (RAG) methods. These results indicate a promising advancement in the development of LLMs for domain-specific applications within the SatCom field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605022",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alejandro Mozo",
                "labs": [
                    "Department of Languages and Computer Sciences, University of Malaga (Andalucia Tech), Malaga, Spain"
                ]
            },
            {
                "name": "Sergio Gálvez",
                "labs": [
                    "Department of Languages and Computer Sciences, University of Malaga (Andalucia Tech), Malaga, Spain"
                ]
            },
            {
                "name": "Ioannis T. Christou",
                "labs": [
                    "Department of Information Technology, Cybersecurity and Computer Science, The American College of Greece, Aghia Paraskevi, Greece"
                ]
            },
            {
                "name": "Dimitrios Vogiatzis",
                "labs": [
                    "Department of Information Technology, Cybersecurity and Computer Science, The American College of Greece, Aghia Paraskevi, Greece"
                ]
            },
            {
                "name": "Tomás Navarro",
                "labs": [
                    "European Centre for Space Applications and Telecommunications (ECSAT), European Space Agency, Didcot, U.K."
                ]
            },
            {
                "name": "Francisco L. Valverde",
                "labs": [
                    "Department of Languages and Computer Sciences, University of Malaga (Andalucia Tech), Malaga, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Biological system modeling",
                "Adaptation models",
                "Satellite communications",
                "European Space Agency",
                "Portable document format",
                "Computational modeling",
                "Training",
                "Satellites",
                "Accuracy"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "evaluation models",
                "large language models",
                "fine tuning LLMs",
                "preprocessing for LLMs",
                "satellite communications"
            ]
        }
    },
    {
        "Title": "The Role of Large Language Models in Designing Reliable Networks for Internet of Things: A Short Review of Most Recent Developments",
        "Link": "https://ieeexplore.ieee.org/document/11179972/",
        "Abstract": "The rapid growth of Internet of Things (IoT) networks has increased the need for intelligent, flexible, and scalable networking solutions. This paper reviews the use of Large Language Models (LLMs) to improving network protocols, automate decision-making, and strengthen security in IoT networks. A detailed analysis was conducted to classify the existing research based on applications, network types, methodologies, and performance metrics. LLMs have been used in network configuration, security monitoring, cyber threat detection, federated learning, and for improving network performance. Their integration with edge computing, 6G networks, and AI-driven network control enables real-time network adjustment, automated troubleshooting, and efficient traffic management. However, challenges such as high computing demands, high energy consumption, security risks, and slow adaptation in dynamic networks still exist. This study identifies emerging trends, including LLM-based self-learning networks, privacy-aware AI training, and hybrid AI models that combine graph-based neural networks, reinforcement learning, and multimodal AI. By reviewing recent research from 2023 to early-2025, this study provides a clear understanding of how LLMs transform the IoT and network management. The discussion highlights future research directions, focusing on decentralized AI frameworks, optimized model training, and AI-driven network automation, with the aim of developing more efficient, secure, and reliable network infrastructures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3614246",
            "Date of Publication": "25 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Melchizedek Alipio",
                "labs": [
                    "Department of Electronics and Computer Engineering, De La Salle University, Manila, Philippines"
                ]
            },
            {
                "name": "Miroslav Bures",
                "labs": [
                    "System Testing Intelligent Laboratory, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Security",
                "Reviews",
                "Artificial intelligence",
                "Real-time systems",
                "Computational modeling",
                "Reliability",
                "Protocols",
                "Adaptation models",
                "Biological system modeling"
            ],
            "Author Keywords": [
                "Large language models",
                "Internet of Things",
                "machine learning",
                "network optimization",
                "reliable networks"
            ]
        }
    },
    {
        "Title": "Zero-Shot Knowledge-Based Visual Question Answering with Frozen Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11164407/",
        "Abstract": "Knowledge-based Visual Question Answering (VQA) is a challenging task that requires models to access external knowledge for reasoning. Large Language Models (LLMs) have recently been employed for zero-shot knowledge-based VQA due to their inherent knowledge storage and in-context learning capabilities. However, LLMs are commonly perceived as implicit knowledge bases, and their generative and in-context learning potential remains underutilized. Existing works demonstrate that the performance of in-context learning strongly depends on the quality and order of demonstrations in prompts. In light of this, we propose Knowledge Generation with Frozen Language Models (KGFLM), a novel method for generating explicit knowledge statements to improve zero-shot knowledge-based VQA. Our knowledge generation strategy aims to identify effective demonstrations and determine their optimal order, thereby activating the frozen LLM to produce more useful knowledge statements for better predictions. The generated knowledge statements can also serve as interpretable rationales. In our method, the selection and arrangement of demonstrations are based on semantic similarity and quality of demonstrations for each question, without requiring additional annotations. Furthermore, a series of experiments are conducted on A-OKVQA and OKVQA datasets. The results show that our method outperforms some superior zero-shot knowledge-based VQA methods.",
        "Details": {
            "DOI": "10.26599/BDMA.2025.9020032",
            "Date of Publication": "15 September 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Jing Liu",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Lizong Zhang",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Chenpeng Cao",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Yinong Shi",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Chong Mu",
                "labs": [
                    "School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Jiaxin Li",
                "labs": [
                    "Miaozhendida (Beijing) Network Technology Co. Ltd., Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Visualization",
                "Large language models",
                "Knowledge based systems",
                "Zero shot learning",
                "Semantics",
                "Question answering (information retrieval)",
                "Cognition",
                "Reliability",
                "Data mining"
            ],
            "Author Keywords": [
                "knowledge-based Visual Question Answering (VQA)",
                "zero-shot learning",
                "Large Language Models (LLMs)"
            ]
        }
    },
    {
        "Title": "Structured Extraction and BPMN Generation From Chinese Procedural Texts via Hybrid Attention-Based Domain Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11170450/",
        "Abstract": "Understanding and modeling workflows is crucial for advancing digital transformation and intelligent process management in the electric power industry. While recent progress in large language models (LLMs) has significantly enhanced natural language processing capabilities, data in the power sector presents unique challenges—including complex formatting, limited structured annotations, and extensive use of domain-specific terminology—that hinder the direct application of general-purpose LLMs. Moreover, conventional attention mechanisms often struggle with long procedural texts due to high computational overhead, excessive resource consumption, and unstable global semantic representations, further limiting their effectiveness in power workflow modeling tasks. To address these challenges, this paper proposes a domain-adapted LLM framework tailored for the standardization of electric power workflows and introduces a specialized model, Lumina BPM, designed for this task. The model incorporates a hybrid sparse self-attention mechanism that retains attention on initial tokens and dynamically selects the most relevant historical tokens based on query context. This design reduces the need to compute full-sequence dense attention matrices, thereby lowering computational costs while improving the model’s ability to capture critical information from lengthy and complex process descriptions. Experimental results show that Lumina BPM accurately transforms standardized procedural texts into executable piperflow statements and generates corresponding BPMN 2.0 diagrams. The proposed approach significantly improves both the accuracy and interpretability of workflow modeling, offering a practical pathway toward intelligent process standardization in critical infrastructure domains.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611811",
            "Date of Publication": "18 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shan Li",
                "labs": [
                    "State Grid Information & Telecommunication Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Zesan Liu",
                "labs": [
                    "State Grid Information & Telecommunication Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Xinyi Liu",
                "labs": [
                    "State Grid Information & Telecommunication Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Gang Chen",
                "labs": [
                    "State Grid Information & Telecommunication Group Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Yongjian Zhang",
                "labs": [
                    "State Grid Zhejiang Electric Power Company Ltd., Zhejiang, China"
                ]
            },
            {
                "name": "Haojie Ling",
                "labs": [
                    "AOSTAR Information Technologies Company Ltd., Sichuan, China"
                ]
            },
            {
                "name": "Xing Huang",
                "labs": [
                    "AOSTAR Information Technologies Company Ltd., Sichuan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Power systems",
                "Semantics",
                "Business",
                "Attention mechanisms",
                "Standardization",
                "Computational efficiency",
                "Additives",
                "Law",
                "Large language models"
            ],
            "Author Keywords": [
                "Large language models",
                "hybrid sparse attention",
                "natural language processing",
                "business process modeling",
                "workflow standardization"
            ]
        }
    },
    {
        "Title": "Mixture of Experts for Depression and Anxiety Disorder Prediction From Textual and Non-Textual Social Media Data",
        "Link": "https://ieeexplore.ieee.org/document/11050409/",
        "Abstract": "In Natural Language Processing (NLP) and related fields, computational models of mental health screening aim to detect early signs of mental health issues based on an individual’s behaviour on social media. Models of this kind, which are mostly devoted to depression disorders and to the English language, present many open research questions. First, since context-free social media data are prone to noise, the task may involve processing large amounts of data with little or no relation to mental health, which may hinder both model efficiency and accuracy. Second, existing work has been largely devoted to text processing, even though social media also include a wide range of non-textual information, which may be useful predictors of mental health as well. Finally, existing models are usually validated in a single domain, often involving one dataset of a particular text genre and language, and it is not clear whether their results may generalise to other scenarios. Based on these observations, the present work introduces a number of computational models for the prediction of depression and anxiety disorder using large language models (LLM) to handle noisy, context-free social media data. Our models combine textual and non-textual information with the aid of mixture of experts (MoE), and are evaluated in both the Twitter/X domain in Portuguese and in the Reddit domain in English using both machine learning metrics and human assessment provided by mental health specialists. Results show a number of improvements over the previous work and suggest new lines of investigation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583259",
            "Date of Publication": "25 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wesley Ramos Dos Santos",
                "labs": [
                    "School of Arts, Sciences, and Humanities, University of São Paulo (USP), São Paulo, Brazil"
                ]
            },
            {
                "name": "Ivandré Paraboni",
                "labs": [
                    "School of Arts, Sciences, and Humanities, University of São Paulo (USP), São Paulo, Brazil"
                ]
            },
            {
                "name": "Elton Hiroshi Matsushima",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Camila Azevedo Da Silva",
                "labs": [
                    "Graduate Program in Neurology and Neuroscience, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Emily Samara De Moura Meira",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "João Victor Rodrigues Ferreira Guimarães",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Julia Da Silva Lins",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Laura Enham De Azeredo",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Luiz Guilherme Cerqueira Nunes",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Vittória Thiengo Silveira Moreira Rego",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Mental health",
                "Depression",
                "Computational modeling",
                "Anxiety disorders",
                "Blogs",
                "Chatbots",
                "Predictive models",
                "Biological system modeling",
                "Data models"
            ],
            "Author Keywords": [
                "Anxiety",
                "depression",
                "mental health",
                "natural language processing",
                "social media analysis"
            ]
        }
    },
    {
        "Title": "Development of OCR Service for Page-Level Recognition for Camera-Captured Document Images",
        "Link": "https://ieeexplore.ieee.org/document/11007558/",
        "Abstract": "The emergence of Large Language Models (LLMs) has driven significant advancements in Natural Language Processing (NLP) and introduced new text-related applications, such as Visual Question Answering (VQA). As a result, there is a growing need for Optical Character Recognition (OCR) systems that can extract textual contents from document images for LLM applications. However, most existing methods have primarily focused on scene text or well-structured document images, and typically limit text detection and recognition to the word level. In this paper, we propose a novel OCR framework capable of detecting and recognizing text at both the text-line and text-block levels. Specifically, we design a new deep neural network (DNN) to replace the Connected Component (CC) extraction and state estimation processes used in conventional methods. Despite being trained solely on synthetic datasets, the proposed OCR system performs robust text detection and layout analysis. Furthermore, we propose a recognition metric to evaluate content preservation in OCR systems and introduce a new OCR benchmark consisting of camera-captured document images. Our method demonstrates superior performance on this benchmark, outperforming existing OCR APIs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3572001",
            "Date of Publication": "20 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junyoung Park",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea",
                    "FuriosaAI, Seoul, South Korea"
                ]
            },
            {
                "name": "Wonjun Kang",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea",
                    "FuriosaAI, Seoul, South Korea"
                ]
            },
            {
                "name": "Seonji Park",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Keuntek Lee",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Hyung Il Koo",
                "labs": [
                    "FuriosaAI, Seoul, South Korea",
                    "Department of Electrical and Computer Engineering, Ajou University, Suwon, South Korea"
                ]
            },
            {
                "name": "Nam Ik Cho",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical character recognition",
                "Text detection",
                "Text recognition",
                "Layout",
                "Benchmark testing",
                "Image recognition",
                "Training",
                "Synthetic data",
                "Accuracy",
                "Tensors"
            ],
            "Author Keywords": [
                "Document image processing",
                "layout analysis",
                "optical character recognition",
                "scene text detection"
            ]
        }
    },
    {
        "Title": "Automatic Evaluation of Programming Tasks Supported by Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11132331/",
        "Abstract": "Large language models are also increasingly used in education, both by students and teachers. Newly introduced LLM-based tools, such as Codex, Code Llama, and Microsoft’s Copilot, show that LLMs are effective in code generation. In this paper, we evaluate the effectiveness of using LLMs in code evaluation. In programming courses, traditional manual code evaluation is very slow, and the participation of multiple instructors reduces consistency. Test-based code evaluation does not help novice programmers; for low-achieving students, the score attributed by such automatic tests is usually lower than what would have been gained after manual correction. Using LLMs might combine the benefits of manual correction and automatic testing. In order to apply LLMs to the task, detailed scoring guidelines were provided for the language models. The experiment involved 40 students in the first exam and 45 in the second exam in a C++ language course, with six teachers manually assessing the code fragments. The exams consisted of several different programming exercises, and the number of code snippets evaluated exceeded 350. We found a strong correlation between manual scoring and the scores given by the language models. Depending on the language model and the exam set examined, we measured correlation values between 0.6 and 0.9. The results of the experiment were significantly influenced by inconsistent teacher evaluations, so during the research phase, a single teacher was assigned to manual evaluation, which significantly improved the results. Based on these results, we repeated the experiment with an increased number of students (160) learning the Java programming language. The results again show a strong correlation (between 0.6 and 0.7). To clarify the results, we compared the models based on rubric specificity. Still, more research and testing are needed to explore the differences between manual evaluation and evaluation by large language models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3601448",
            "Date of Publication": "21 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zoltán István Karsa",
                "labs": [
                    "Department of Control Engineering and Information Technology, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            },
            {
                "name": "Balázs Goldschmidt",
                "labs": [
                    "Department of Control Engineering and Information Technology, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Manuals",
                "Large language models",
                "Programming profession",
                "Java",
                "Encoding",
                "Correlation",
                "Biological system modeling",
                "Training",
                "Reviews"
            ],
            "Author Keywords": [
                "Automatic evaluation",
                "computer science tasks",
                "generative artificial intelligence",
                "GPT",
                "grading",
                "large language models",
                "NXCode",
                "programming"
            ]
        }
    },
    {
        "Title": "Joint User Association and Beamforming Design for ISAC Networks With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11152592/",
        "Abstract": "Integrated sensing and communication (ISAC) has been envisioned to play a more important role in future wireless networks. However, the design of ISAC networks is challenging, especially when there are multiple communication and sensing (C&S) nodes and multiple sensing targets. We investigate a multi-base station (BS) ISAC network in which multiple BSs equipped with multiple antennas simultaneously provide C&S services for multiple ground communication users (CUs) and targets. To enhance the overall performance of C&S, we formulate a joint user association (UA) and multi-BS transmit beamforming optimization problem with the objective of maximizing the total sum rate of all CUs while ensuring both the minimum target detection and parameter estimation requirements in terms of the radar signal-to-noise ratio (SNR) and the Cramér-Rao bound (CRB), respectively. To efficiently solve the highly non-convex mixed integer nonlinear programming (MINLP) optimization problem, we propose an alternating optimization (AO)-based algorithm that decomposes the problem into two sub-problems, i.e., UA optimization and multi-BS transmit beamforming optimization. Inspired by the huge potential of large language models (LLMs) for prediction and inference, we propose a unified framework integrating LLMs with convex-based optimization methods to benefit from the theoretical rigor and convergence guarantees of convex-based methods, and the adaptability and flexibility of LLMs. First, we propose a comprehensive design of prompt engineering based on in-context, few-shot, chain of thought, and self-reflection techniques to guide LLMs in solving the binary integer programming UA optimization problem. Second, we utilize convex-based optimization methods to handle the non-convex beamforming optimization problem based on fractional programming (FP), majorization minimization (MM), and the alternating direction method of multipliers (ADMM) with an optimized UA from LLMs. Numerical results demonstrate that our proposed LLM-enabled AO-based algorithm achieves fast convergence and near upper-bound performance with the GPT-o1 model, outperforming various benchmark schemes, which shows the advantages of integrating LLMs into convex-based optimization for wireless networks.\nShow Less",
        "Details": {
            "DOI": "10.1109/OJCOMS.2025.3606812",
            "Date of Publication": "05 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Haoyun Li",
                "labs": [
                    "Division of Information Science and Engineering, KTH Royal Institute of Technology, Stockholm, Sweden"
                ]
            },
            {
                "name": "Ming Xiao",
                "labs": [
                    "Division of Information Science and Engineering, KTH Royal Institute of Technology, Stockholm, Sweden"
                ]
            },
            {
                "name": "Kezhi Wang",
                "labs": [
                    "Department of Computer Science, Brunel University of London, Uxbridge, U.K"
                ]
            },
            {
                "name": "Robert Schober",
                "labs": [
                    "Institute for Digital Communications, Friedrich-Alexander-University Erlangen-Nurnberg, Erlangen, Germany"
                ]
            },
            {
                "name": "Dong In Kim",
                "labs": [
                    "Department of Electrical and Computer Engineering, Sungkyunkwan University, Suwon, South Korea"
                ]
            },
            {
                "name": "Yong Liang Guan",
                "labs": [
                    "Continental-NTU Corporate Lab, Nanyang Technological University, Nanyang Ave, Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Integrated sensing and communication",
                "Array signal processing",
                "Radar antennas",
                "Convergence",
                "Wireless networks",
                "Copper",
                "Signal to noise ratio",
                "Optimization methods",
                "Large language models"
            ],
            "Author Keywords": [
                "Integrated sensing and communication",
                "large language model",
                "user association",
                "beamforming",
                "optimization"
            ]
        }
    },
    {
        "Title": "Chest X-Ray Report Generation Using Abnormality Guided Vision Language Model",
        "Link": "https://ieeexplore.ieee.org/document/11153468/",
        "Abstract": "Automated radiology report generation is essential for assisting radiologists in managing the growing volume of chest radiographs. Unlike conventional image captioning models, radiology report generation must prioritize abnormality-specific feature extraction over generic image features. However, existing models lack an inherent mechanism to extract clinically significant abnormality features directly from radiographs without relying on external knowledge bases or auxiliary models. Additionally, most existing approaches use a single vision encoder, limiting their ability to capture complementary visual cues essential for accurate abnormality identification. To address these limitations, we introduce META-CXR (Multimodal Expert Tokens-based VLM for Abnormality-Guided Chest X-ray Reporting), a vision-language model (VLM) designed to enhance both abnormality classification and radiology report generation. META-CXR employs a multi-encoder visual backbone that combines CNNs, ViTs, and Swin Transformers to extract diverse and complementary visual features. These multi-encoder features serve as a shared representation and are utilized in two key components of the architecture: the META-Former module, a modified Q-Former designed to fuse heterogeneous encoder outputs into a unified token space for effective report generation, and the Multi-Head Cross Attention Classification (MHCAC) module, which performs multi-class, multi-label abnormality classification, including an explicit “uncertain” category. The identified abnormalities are then integrated into the language modeling process as soft prompts to ensure clinically coherent and diagnosis-aware report generation using a large language model (LLM). META-CXR achieves state-of-the-art performance, demonstrating an F1-score of 0.699 for cross-domain multi-class, multi-label abnormality classification on the CheXpert dataset. Additionally, it achieves strong natural language generation results, with a BERTScore of 0.426 and a METEOR score of 0.173 on the MIMIC-CXR test set. Ablation studies validate the contributions of the multi-encoder backbone, hierarchical classification via MHCAC, the META-Former fusion strategy, and classification-aware report generation. Furthermore, attention map visualizations improve interpretability by highlighting clinically relevant image regions, offering radiologists transparent insights into model decisions. By addressing key challenges in abnormality-specific feature extraction, uncertainty-aware classification, and diagnosis-driven reporting, META-CXR establishes a new benchmark for vision-language models in radiology AI.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3606961",
            "Date of Publication": "08 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dasith Edirisinghe",
                "labs": [
                    "Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Moratuwa, Sri Lanka"
                ]
            },
            {
                "name": "Wimukthi Nimalsiri",
                "labs": [
                    "Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Moratuwa, Sri Lanka"
                ]
            },
            {
                "name": "Mahela Hennayake",
                "labs": [
                    "Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Moratuwa, Sri Lanka"
                ]
            },
            {
                "name": "Dulani Meedeniya",
                "labs": [
                    "Department of Computer Science and Engineering, University of Moratuwa, Katubedda, Moratuwa, Sri Lanka"
                ]
            },
            {
                "name": "Gilbert Lim",
                "labs": [
                    "SingHealth AI Health Program, SingHealth Group, Central Singapore, Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Feature extraction",
                "Radiology",
                "Medical diagnostic imaging",
                "Accuracy",
                "Transformers",
                "X-ray imaging",
                "Large language models",
                "Computational modeling",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "abnormality classification",
                "chest X-ray reporting",
                "computer vision",
                "deep learning",
                "multi-modal",
                "vision-language model"
            ]
        }
    },
    {
        "Title": "Revolutionize 3D-Chip Design With Open3DFlow, an Open-Source AI-Enhanced Solution",
        "Link": "https://ieeexplore.ieee.org/document/11052893/",
        "Abstract": "The escalating demand for high-performance and energy-efficient electronics has propelled 3D integrated circuits (3D ICs) as a promising solution. However, major obstacles have been the lack of specialized electronic design automation (EDA) software and standardized design flows for 3D chiplets. To bridge the gap, we introduce Open3DFlow,1 an open-source design platform for 3D ICs. It is a seven-step workflow that incorporates essential ASIC back-end processes while supporting multi-physics analysis, such as through silicon via (TSV) modeling, thermal analysis, and signal integrity (SI) evaluations. To illustrate all functionalities of Open3DFlow, we use it to implement a 3D RISC-V CPU design with a vertically stacked L2 cache on a separated die. We harden both CPU logic and 3D-cache die in a GlobalFoundries\n0.18μ\nm (GF180) process with open-source PDK support. We enable face-to-face (F2F) coupling of the top and bottom die by constructing a bonding layer based on the original technology file. Open3DFlow’s open-source nature allows seamless integration of custom AI optimization algorithms. As a showcase, we leverage large language models (LLMs) to help the bonding pad placement. In addition, we apply LLM on back-end Tcl script generations to improve design productivity. We expect Open3DFlow to open up a brand-new paradigm for future 3D IC innovations.",
        "Details": {
            "DOI": "10.1109/OJCAS.2024.3518754",
            "Date of Publication": "26 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Circuits and Systems"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1225"
        },
        "authors_data": [
            {
                "name": "Yifei Zhu",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Zhenxuan Luan",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Dawei Feng",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Weiwei Chen",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Lei Ren",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Zhangxi Tan",
                "labs": [
                    "RIOS Lab, Tsinghua University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Productivity",
                "Three-dimensional displays",
                "Large language models",
                "Collaboration",
                "Software",
                "Central Processing Unit",
                "Through-silicon vias",
                "Bonding",
                "Signal integrity",
                "Optimization"
            ],
            "Author Keywords": [
                "3D IC",
                "EDA",
                "large language model",
                "open-source",
                "signal integrity",
                "thermal",
                "TSV"
            ]
        }
    },
    {
        "Title": "AVCaps: An Audio-Visual Dataset With Modality-Specific Captions",
        "Link": "https://ieeexplore.ieee.org/document/11029114/",
        "Abstract": "This paper introduces AVCaps, an audio-visual dataset that contains separate textual captions for the audio, visual, and audio-visual contents of video clips. The dataset contains 2061 video clips constituting a total of 28.8 hours. We provide up to 5 captions for the audio, visual, and audio-visual content of each clip, crowdsourced separately. Existing datasets focus on a single modality or do not provide modality-specific captions, limiting the study of how each modality contributes to overall comprehension in multimodal settings. Our dataset addresses this critical gap in multimodal research by offering a resource for studying how audio and visual content are captioned individually, as well as how audio-visual content is captioned in relation to these individual modalities. Crowdsourced audio-visual captions are prone to favor visual content over audio content. To avoid this we use large language models (LLMs) to generate three balanced audio-visual captions for each clip based on the crowdsourced captions. We present captioning and retrieval experiments to illustrate the effectiveness of modality-specific captions in evaluating model performance. Specifically, we show that the modality-specific captions allow us to quantitatively assess how well a model understands audio and visual information from a given video. Notably, we find that a model trained on the balanced LLM-generated audio-visual captions captures audio information more effectively compared to a model trained on crowdsourced audio-visual captions. This model achieves a 14% higher Sentence-BERT similarity on crowdsourced audio captions compared to a model trained on crowdsourced audio-visual captions, which are typically more biased towards visual information. We also discuss the possibilities in multimodal representation learning, question answering, developing new video captioning metrics, and generative AI that this dataset unlocks. The dataset is available publicly at Zenodo and Hugging Face.\nShow Less",
        "Details": {
            "DOI": "10.1109/OJSP.2025.3578296",
            "Date of Publication": "09 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Signal Processing"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1322"
        },
        "authors_data": [
            {
                "name": "Parthasaarathy Sudarsanam",
                "labs": [
                    "Audio Research Group, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Irene Martín-Morató",
                "labs": [
                    "Audio Research Group, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Aapo Hakala",
                "labs": [
                    "Audio Research Group, Tampere University, Tampere, Finland"
                ]
            },
            {
                "name": "Tuomas Virtanen",
                "labs": [
                    "Audio Research Group, Tampere University, Tampere, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Acoustics",
                "Natural languages",
                "Web sites",
                "Pediatrics",
                "Indexes",
                "Grammar",
                "Error correction",
                "Cleaning",
                "Vocabulary"
            ],
            "Author Keywords": [
                "AVCaps",
                "audio-visual",
                "captioning",
                "dataset",
                "multimodal",
                "retrieval"
            ]
        }
    },
    {
        "Title": "DBCON: Dual Bias Control in Zero-Shot Video Moment Retrieval",
        "Link": "https://ieeexplore.ieee.org/document/11176035/",
        "Abstract": "Zero-shot Video Moment Retrieval (ZVMR) is a task that localizes temporal moments within a video using only natural language queries, without requiring large-scale datasets or extensive training resources. While previous ZVMR studies have focused on aligning high-quality video and query representations, they have faced performance limitations by overlooking the ‘Dual Bias’ problem, which arises from the excessive specificity of queries and the generality of video captions. To address this challenge, we propose the DBCON (Dual Bias CONtrol) framework, which simultaneously controls caption specificity and query generalization. DBCON employs ‘Query-Aware Caption Refinement’ to induce captions that explicitly reflect the core information of the query, and ‘Query Debiasing’ to rephrase the user query into a more universal expression via an LLM. Our experiments show that DBCON effectively mitigates this dual bias, achieving up to 1.73% higher retrieval accuracy on mAP@avg compared to the state-of-the-art model on the QVHighlights test benchmark. This study is significant as it presents a new direction for developing scalable and efficient video-language retrieval systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613635",
            "Date of Publication": "23 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mingyu Jeon",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Minuk Ma",
                "labs": [
                    "Department of Computer Science, The University of British Columbia, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "Junyeong Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Videos",
                "Semantics",
                "Training",
                "Legged locomotion",
                "Flowering plants",
                "Pipelines",
                "Distortion",
                "Benchmark testing",
                "Accuracy",
                "Planning"
            ],
            "Author Keywords": [
                "Video moment retrieval",
                "zero-shot Learning",
                "multimodal learning",
                "video understanding",
                "bias control",
                "specificity mismatch",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "AI-Driven Post-Earthquake Emergency Material Demand Prediction: Integrating RAG With Reasoning Large Language Model",
        "Link": "https://ieeexplore.ieee.org/document/11029010/",
        "Abstract": "The supply of emergency rescue materials plays a pivotal role in post-earthquake relief operations. However, varying disaster scenarios generate differentiated demands for emergency resources, where factors such as seasonal impacts, geographic environment of affected areas, population density, and requirements of emergency response protocols significantly influence the categories and quantities of required supplies. Current research predominantly focuses on essential materials, while determinations of scenario-specific material demands rely heavily on expert empirical inference, resulting in discrepancies between model predictions and actual requirements. This study proposes a reasoning-enhanced large language model (LLM) framework integrated with Retrieval-Augmented Generation (RAG) technology for post-earthquake emergency material demand prediction. By simulating expert decision-making processes, we construct an emergency knowledge base amalgamating standardized protocols, historical seismic case data, and disaster scenario characteristics extracted from digital resources. The framework employs RAG to enhance domain-specific knowledge integration within the reasoning model, utilizing Chain-of-Thought generation to produce differentiated prediction schemes that specify material categories and per-capita demand metrics. Through dynamic updating of population statistics and material requirements via post-disaster network information monitoring, the system achieves real-time demand prediction based on evolving victim counts and individualized allocation parameters. Validation through expert evaluations using the 2013 Ya’an Lushan earthquake and simulated disaster scenarios demonstrates effectiveness, with successful practical implementation observed in the January 7, 2025, Dingri M6.8 earthquake case.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3578192",
            "Date of Publication": "09 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Song Zhang",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Meng Huang",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Shuai Liu",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Fanxin Meng",
                "labs": [
                    "Sichuan Disaster Reduction Center, Chengdu, China"
                ]
            },
            {
                "name": "Yingyao Xie",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Xirui Ren",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Yuanwang Zhang",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            },
            {
                "name": "Wenbo Shao",
                "labs": [
                    "Institute of Disaster Prevention, Sanhe, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Sanhe, Langfang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Disasters",
                "Earthquakes",
                "Predictive models",
                "Prediction algorithms",
                "Large language models",
                "Cognition",
                "Social networking (online)",
                "Data models",
                "Biological neural networks",
                "Retrieval augmented generation"
            ],
            "Author Keywords": [
                "Emergency relief supply prediction",
                "large language models",
                "retrieval-augmented generation"
            ]
        }
    },
    {
        "Title": "Innamark: A Whitespace Replacement Information-Hiding Method",
        "Link": "https://ieeexplore.ieee.org/document/11052249/",
        "Abstract": "Large language models (LLMs) have gained significant popularity in recent years. Differentiating between a text written by a human and one generated by an LLM has become almost impossible. Information-hiding techniques such as digital watermarking or steganography can help by embedding information inside text in a form that is unlikely to be noticed. However, existing techniques, such as linguistic-based or format-based methods, change the semantics or cannot be applied to pure, unformatted text. In this paper, we introduce a novel method for information hiding called Innamark, which can conceal any byte-encoded sequence within a sufficiently long cover text. This method is implemented as a multi-platform library using the Kotlin programming language, which is accompanied by a command-line tool and a web interface. By substituting conventional whitespace characters with visually similar Unicode whitespace characters, our proposed scheme preserves the semantics of the cover text without changing the number of characters. Furthermore, we propose a specified structure for secret messages that enables configurable compression, encryption, hashing, and error correction. An experimental benchmark comparison on a dataset of 1 000 000 Wikipedia articles compares ten algorithms. The results demonstrate the robustness of our proposed Innamark method in various applications and the imperceptibility of its watermarks to humans. We discuss the limits to the embedding capacity and robustness of the algorithm and how these could be addressed in future work.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583591",
            "Date of Publication": "26 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Malte Hellmeier",
                "labs": [
                    "Fraunhofer ISST, Dortmund, Germany"
                ]
            },
            {
                "name": "Hendrik Norkowski",
                "labs": [
                    "Montsecure GmbH, Bochum, Germany"
                ]
            },
            {
                "name": "Ernst-Christoph Schrewe",
                "labs": [
                    "Fraunhofer ISST, Dortmund, Germany"
                ]
            },
            {
                "name": "Haydar Qarawlus",
                "labs": [
                    "Fraunhofer ISST, Dortmund, Germany"
                ]
            },
            {
                "name": "Falk Howar",
                "labs": [
                    "Fraunhofer ISST, Dortmund, Germany",
                    "Department of Computer Science, Technical University Dortmund, Dortmund, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Watermarking",
                "Steganography",
                "Robustness",
                "Standards",
                "Aerospace electronics",
                "Particle separators",
                "Encryption",
                "Terminology",
                "Semantics",
                "Operating systems"
            ],
            "Author Keywords": [
                "Blind watermarking",
                "copyright protection",
                "data hiding",
                "data sovereignty",
                "digital text watermarking",
                "information hiding",
                "steganography",
                "Unicode characters"
            ]
        }
    },
    {
        "Title": "LinguaShrink: Reducing Token Overhead With Psycholinguistics",
        "Link": "https://ieeexplore.ieee.org/document/10699333/",
        "Abstract": "As large language models (LLMs) improve their capabilities in handling complex tasks, the issues of computational cost and efficiency due to long prompts are becoming increasingly prominent. To accelerate model inference and reduce costs, we propose an innovative prompt compression framework called LinguaShrink. Inspired by the observation that LLM performance depends on the density and position of key information in the input prompts, LinguaShrink leverages psycholinguistic principles and the Ebbinghaus memory curve to achieve task-agnostic prompt compression. This effectively reduces prompt length while preserving essential information. We adopted the training method from OpenChat. The framework introduces part-of-speech priority compression and data distillation techniques, using smaller models to learn compression targets and employing a KL-regularized reinforcement learning strategy for training. Additionally, we adopt a chunk-based compression algorithm to achieve adjustable compression rates. We evaluate our method on multiple datasets, including LongBench, ZeroScrolls, Arxiv Articles, and a newly constructed novel test set. Experimental results show that LinguaShrink maintains semantic similarity while achieving up to 26 times compression. Compared to existing prompt compression methods, LinguaShrink improves end-to-end latency by 1.43 times.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3470512",
            "Date of Publication": "30 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Feihu Ma",
                "labs": [
                    "School of Transportation Engineering, East China Jiaotong University, Nanchang, Jiangxi, China"
                ]
            },
            {
                "name": "Xuechen Liang",
                "labs": [
                    "School of Transportation Engineering, East China Jiaotong University, Nanchang, Jiangxi, China"
                ]
            },
            {
                "name": "Meiling Tao",
                "labs": [
                    "School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Reinforcement learning",
                "Data models",
                "Computational modeling",
                "Maximum likelihood estimation",
                "Probability distribution",
                "Natural language processing",
                "Training",
                "Optimization",
                "Loss measurement"
            ],
            "Author Keywords": [
                "LinguaShrink",
                "prompt compression framework",
                "KL-regularized reinforcement learning",
                "compression ratio",
                "semantic similarity preservation"
            ]
        }
    },
    {
        "Title": "Utterance-Aware Adaptive Data Labeling and Summarization: Exploiting Large Language Models for Unbiased Dialog Annotation",
        "Link": "https://ieeexplore.ieee.org/document/10711180/",
        "Abstract": "The field of dialogue summarization has advanced significantly with large language models (LLMs), but their effectiveness can be limited by the size and diversity of training data, as well as concerns about bias. This study proposes a data augmentation method to address the lack of open-source dialogue datasets for summarization while reducing potential biases. Our method uses algorithms that process relationships between key phrases in a dialogue and its summary points, considering two distinct approaches for dialogues smaller or larger than the model’s context. We extract necessary relationships between dialogue and summarization using an LLM adapted to pre-labeled data, which demonstrates results up to 88.26% of accuracy compare to human annotation. We achieved a 4.33x expansion of the original DialogSum, SAMSum, and TweetSumm training sets, leading to a 0.16-point improvement in ROUGE-Lsum (up to 76% growth compared to the baseline). Additionally, we introduce a novel summarization metric tailored to larger than context summarization models during inference, capturing semantic similarity and comprehensiveness of summary points. This metric contributes to the credibility and sustainability of dialogue summarization systems by providing a more robust evaluation framework.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3476981",
            "Date of Publication": "09 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nikita Glazkov",
                "labs": [
                    "AI Center, National University of Science and Technology (NUST) MISIS, Moscow, Russia"
                ]
            },
            {
                "name": "Ilya Makarov",
                "labs": [
                    "AI Center, National University of Science and Technology (NUST) MISIS, Moscow, Russia",
                    "AIRI, Moscow, Russia",
                    "ISP RAS Research Center for Trusted Artificial Intelligence, Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Labeling",
                "Measurement",
                "Data models",
                "Annotations",
                "Data augmentation",
                "Transformers",
                "Semantics",
                "Iterative methods",
                "Training data",
                "Text analysis",
                "Text processing"
            ],
            "Author Keywords": [
                "Abstractive summarization",
                "conversational summarization",
                "data augmentation",
                "evaluation",
                "language models biases",
                "semantic textual similarity"
            ]
        }
    },
    {
        "Title": "A Linguistic Features-Based Approach for the Functional Analysis of Disinformation in Spanish",
        "Link": "https://ieeexplore.ieee.org/document/11112592/",
        "Abstract": "Information disorder has significant negative impacts on contemporary societies. This study presents a hybrid methodology that combines machine learning and natural language processing to analyze corpora of disinformation texts in Spanish. The approach not only adapts linguistic features originally developed for English to another major but less researched language, but also incorporates 251 features organized into six categories, surpassing previous methods in both the number and organization of features. Applied to the CLNews dataset of Spanish rumors, the analysis identified 17 features with statistically significant differences between false and real rumors. Linguistic analysis reveals that false rumors are characterized by more emotional language, greater sentence fragmentation, frequent use of auxiliary verbs, and lower information density, which creates an appearance of detail. Additionally, using BERT, a large language model (LLM), five topics were identified among false rumors, each exhibiting different strategies in terms of fragmentation, grammatical complexity, and information density. Given the above, linguistic features were employed to develop machine learning classifiers, with a linear SVM achieving 86% accuracy. This methodology offers a replicable framework for future research on disinformation and text analysis in Spanish, enhancing the interpretability of results. The methodology shows that classical machine learning models trained on carefully chosen linguistic features can deliver competitive results, surpassing BETO (57%) and RoBERTa-BNE (64%) in accuracy on the CLNews dataset. Moreover, these models demonstrate strong performance when the same features are applied to a different dataset and continue to perform well when the feature selection is adjusted to fit the new context.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595750",
            "Date of Publication": "04 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eduardo Puraivan",
                "labs": [
                    "Escuela de Ciencias, Universidad Viña del Mar, Viña del Mar, Chile",
                    "Escuela de Ingeniería Informática, Universidad de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Fabián Riquelme",
                "labs": [
                    "Escuela de Ingeniería Informática, Universidad de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "René Venegas",
                "labs": [
                    "Instituto de Literatura y Ciencias del Lenguaje, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Linguistics",
                "Feature extraction",
                "Lexicon",
                "Machine learning",
                "Natural language processing",
                "Semantics",
                "Organizations",
                "Electronic mail",
                "Context modeling"
            ],
            "Author Keywords": [
                "Information disorder",
                "disinformation",
                "natural language processing",
                "linguistic feature",
                "machine learning"
            ]
        }
    },
    {
        "Title": "OWNER — Toward Unsupervised Open-World Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10930473/",
        "Abstract": "Named Entity Recognition (NER) is a crucial task in Natural Language Processing (NLP), traditionally addressed through supervised learning, which requires extensive annotated corpora. This requirement poses challenges, particularly in specialized domains with limited labeled data. In response, the field has shifted towards lower-resource approaches, such as few-shot and zero-shot learning, which reduce the dependency on annotated data. However, even zero-shot models require prior knowledge of entity types, limiting their applicability in exploratory scenarios. In this context, we introduce OWNER, our unsupervised and open-world NER model, designed to operate without annotated documents or predefined entity types. OWNER leverages Encoder-only Language Models like BERT to infer and organize entities into dynamic entity types through a two-step process: mention detection and entity typing. Mention detection employs a BIO sequence labeling approach to locate entities, while entity typing uses BERT-based embeddings, refined through contrastive learning, for clustering and naming entity types. This method allows OWNER to automatically identify and structure unknown entity types, offering advantages for exploratory dataset analysis and knowledge graph construction. Our experimental evaluation on 13 domain-specific datasets demonstrates that OWNER surpasses existing LLM-based open-world NER models and remains competitive with more supervised and closed-world zero-shot models. OWNER’s architecture provides a lightweight, easily deployable solution that advances the state of the art in unsupervised and open-world NER. The source code of OWNER is publicly available at https://github.com/alteca/OWNER, facilitating future research in this domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3552122",
            "Date of Publication": "17 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pierre-Yves Genest",
                "labs": [
                    "Alteca, Villeurbanne, France",
                    "INSA Lyon, CNRS, LIRIS, UMR5205, Université Claude Bernard Lyon 1, Villeurbanne, France"
                ]
            },
            {
                "name": "Pierre-Edouard Portier",
                "labs": [
                    "Caisse d’Epargne Rhône Alpes, Lyon, France"
                ]
            },
            {
                "name": "Előd Egyed-Zsigmond",
                "labs": [
                    "INSA Lyon, CNRS, LIRIS, UMR5205, Université Claude Bernard Lyon 1, Villeurbanne, France"
                ]
            },
            {
                "name": "Martino Lovisetto",
                "labs": [
                    "Alteca, Villeurbanne, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Named entity recognition",
                "Bidirectional control",
                "Biological system modeling",
                "Labeling",
                "Computer architecture",
                "Vectors",
                "Contrastive learning",
                "Source coding",
                "Predictive models",
                "Metalearning"
            ],
            "Author Keywords": [
                "Named entity recognition",
                "open information extraction",
                "open-world named entity recognition",
                "unsupervised named entity recognition"
            ]
        }
    },
    {
        "Title": "Advancing Sentiment Analysis for Low-Resource Languages Using Fine-Tuned LLMs: A Case Study of Customer Reviews in Turkish Language",
        "Link": "https://ieeexplore.ieee.org/document/10980352/",
        "Abstract": "This study investigates the application of advanced fine-tuned Large Language Models (LLMs) for Turkish Sentiment Analysis (SA), focusing on e-commerce product reviews. Our research utilizes four open-source Turkish SA datasets: Turkish Sentiment Analysis version 1 (TRSAv1), Vitamins and Supplements Customer Review (VSCR), Turkish Sentiment Analysis Dataset (TSAD), and TR Customer Review (TRCR). While these datasets were initially labeled based on star ratings, we implemented a comprehensive relabeling process using state-of-the-art LLMs to enhance data quality. To ensure reliable annotations, we first conducted a comparative analysis of different LLMs using the Cohen’s Kappa agreement metric, which led to the selection of ChatGPT-4o-mini as the best-performing model for dataset annotation. Our methodology then focuses on evaluating the SA capabilities of leading instruction-tuned LLMs through a comparative analysis of zero-shot models and Low-Rank Adaptation (LoRA) fine-tuned LlaMA-3.2-1B-IT and Gemma-2-2B-IT models. Evaluations were conducted on both in-domain and out-domain test sets derived from the original star-ratings-based labels and the newly generated GPT labels. The results demonstrate that our fine-tuned models outperformed leading commercial LLMs by 6% in both in-domain and out-domain evaluations. Notably, models fine-tuned on GPT-generated labels achieved superior performance, with in-domain and out-domain F1-scores reaching 0.912 and 0.9184, respectively. These findings underscore the transformative potential of combining LLM relabeling with LoRA fine-tuning for optimizing SA, demonstrating robust performance across diverse datasets and domains.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3566000",
            "Date of Publication": "30 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rukiye Savran Kiziltepe",
                "labs": [
                    "Department of Software Engineering, Ankara University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Ercan Ezin",
                "labs": [
                    "Department of Computer Engineering, Harran University, Şanlıurfa, Türkiye"
                ]
            },
            {
                "name": "Ömer Yentür",
                "labs": [
                    "Software Solutions-Data Security and Data Management, Kron Technology, İstanbul, Türkiye"
                ]
            },
            {
                "name": "Arwa M. Basbrain",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Murat Karakus",
                "labs": [
                    "Department of Software Engineering, Ankara University, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Reviews",
                "Adaptation models",
                "Natural language processing",
                "Lexicon",
                "Accuracy",
                "Stars",
                "Analytical models",
                "Transformers",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Machine learning",
                "natural language processing",
                "large language models",
                "sentiment analysis",
                "low-resource languages",
                "Turkish language"
            ]
        }
    },
    {
        "Title": "Leveraging RAG With Transformer for Context-Based Personalized Recommendations",
        "Link": "https://ieeexplore.ieee.org/document/11016029/",
        "Abstract": "Recent advancements in large language models (LLMs) have shown significant progress in addressing challenges related to data sparsity and the cold-start problem. In e-commerce, recommendation systems are widely used as strategic tools to boost sales and enhance the customer experience by helping users find relevant products. Custom LLMs, leveraging textual features from user feedback, have been successfully applied to recommendation systems, yielding improvements across various recommendation scenarios. However, most existing methods rely on training-free recommendation approaches, which depend heavily on pre-trained knowledge. When LLMs are trained on sparse data or lack historical information, their performance in recommendation systems can be negatively impacted. Furthermore, inference with LLMs tends to be slow due to autoregressive generation, which limits the efficiency of traditional recommendation methods. To address these challenges, our contributions are: We proposed the Retrieval Augmented Generation with Transformer Recommendation (RAGX11Rec) framework. This framework integrated LLMs with a transformer-based model in a two-step process: 1) RankRAG is used to filter the top-k preferences via tuning the LLM for effective context ranking, 2) a transformer model with 11 embedded layers generated the top-N recommendations based on ranked preferences. Our instruction-tuned transformer module demonstrates superior performance by incorporating a fraction of ranked data into the training process. We evaluated the effectiveness of RAGX11Rec against state-of-the-art baseline methods using two public datasets taken from AliExpress and Epinions. Experimental results indicate that RAGX11Rec consistently outperforms other methods in recommendation accuracy and efficiency. Our key findings are; 1) RAGX11Rec effectively addresses the cold-start problem by leveraging retrieval-augmented generation (RAG) and transformer-based ranking. Unlike traditional models, it can deliver high-quality recommendations even when user interaction data is limited. 2) Tested on public datasets, RAGX11Rec delivered consistent improvements over other models and proved its scalability and adaptability across diverse product categories. This suggests the framework is robust and adaptable enough for large-scale commercial use.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574073",
            "Date of Publication": "27 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Faten S. Alamri",
                "labs": [
                    "Department of Mathematical Sciences, College of Science, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Amjad Rehman",
                "labs": [
                    "CCIS Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Bayan Alghofaily",
                "labs": [
                    "CCIS Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Adeel Ahmed",
                "labs": [
                    "Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Khalid Saleem",
                "labs": [
                    "Department of Computer Science, Quaid-i-Azam University, Islamabad, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Recommender systems",
                "Retrieval augmented generation",
                "Large language models",
                "Computational modeling",
                "Data models",
                "Context modeling",
                "Attention mechanisms",
                "Accuracy",
                "Electronic commerce"
            ],
            "Author Keywords": [
                "Recommender systems",
                "transformer model",
                "large language model",
                "e-commerce",
                "ranking",
                "context",
                "retrieval",
                "augmented generation"
            ]
        }
    },
    {
        "Title": "Advancing Anomaly Detection: Non-Semantic Financial Data Encoding With Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11131120/",
        "Abstract": "Detecting anomalies in general ledger data is of utmost importance to ensure the trustworthiness of financial records. Financial audits increasingly rely on machine learning (ML) algorithms to identify irregular or potentially fraudulent journal entries, each characterized by a varying number of transactions. In machine learning, heterogeneity in feature dimensions adds significant complexity to data analysis. In this paper, we introduce a novel approach to anomaly detection in financial data using Large Language Model (LLM) embeddings. To encode non-semantic categorical data (i.e., attributes lacking inherent linguistic meaning) from real-world financial records, we tested 3 pretrained general-purpose sentence-transformer models. For the downstream classification task, we implemented and evaluated 5 optimized ML models, including Logistic Regression, Random Forest, Gradient Boosting Machines, Support Vector Machines, and Neural Networks. Our experiments demonstrate that LLMs contribute valuable information to anomaly detection as our models outperform the baselines, in selected settings by a large margin. The findings further underscore the effectiveness of LLMs in enhancing anomaly detection in financial journal entries, particularly by tackling feature sparsity. We discuss a promising perspective on using SBERT embeddings for non-semantic data in the financial context and beyond.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3600967",
            "Date of Publication": "20 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alexander Bakumenko",
                "labs": [
                    "Clemson University, Charleston, SC, USA"
                ]
            },
            {
                "name": "Kateřina Hlaváčková-Schindler",
                "labs": [
                    "Research Group Data Mining and Machine Learning, Faculty of Computer Science, University of Vienna, Vienna, Austria",
                    "Data Science @Uni Vienna, Vienna, Austria"
                ]
            },
            {
                "name": "Claudia Plant",
                "labs": [
                    "Research Group Data Mining and Machine Learning, Faculty of Computer Science, University of Vienna, Vienna, Austria",
                    "Data Science @Uni Vienna, Vienna, Austria"
                ]
            },
            {
                "name": "Nina C. Hubig",
                "labs": [
                    "IT:U Interdisciplinary Transformation University Austria, Linz, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Anomaly detection",
                "Encoding",
                "Fraud",
                "Data models",
                "Feature extraction",
                "Finance",
                "Large language models",
                "Complexity theory",
                "Linguistics",
                "Vectors"
            ],
            "Author Keywords": [
                "Accounting",
                "anomaly detection",
                "auditing",
                "embeddings",
                "general ledger",
                "large language models (LLMs)",
                "machine learning"
            ]
        }
    },
    {
        "Title": "PMF-CEC: Phoneme-Augmented Multimodal Fusion for Context-Aware ASR Error Correction With Error-Specific Selective Decoding",
        "Link": "https://ieeexplore.ieee.org/document/11027557/",
        "Abstract": "End-to-end automatic speech recognition (ASR) models often struggle to accurately recognize rare words. Previously, we introduced an ASR postprocessing method called error detection and context-aware error correction (ED-CEC), which leverages contextual information such as named entities and technical terms to improve the accuracy of ASR transcripts. Although ED-CEC achieves a notable success in correcting rare words, its accuracy remains low when dealing with rare words that have similar pronunciations but different spellings. To address this issue, we proposed a phoneme-augmented multimodal fusion method for context-aware error correction (PMF-CEC) method on the basis of ED-CEC, which allowed for better differentiation between target rare words and homophones. Additionally, we observed that the previous ASR error detection module suffers from overdetection. To mitigate this, we introduced a retention probability mechanism to filter out editing operations with confidence scores below a set threshold, preserving the original operation to improve error detection accuracy. Experiments conducted on five datasets demonstrated that our proposed PMF-CEC maintains reasonable inference speed while further reducing the biased word error rate compared with ED-CEC, showing a stronger advantage in correcting homophones. Moreover, our method outperforms other contextual biasing methods, and remains valuable compared with LLM-based methods in terms of faster inference and better robustness under large biasing lists.",
        "Details": {
            "DOI": "10.1109/TASLPRO.2025.3577356",
            "Date of Publication": "06 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Audio, Speech and Language Processing"
        },
        "issn_info": {
            "Electronic ISSN": "2998-4173"
        },
        "authors_data": [
            {
                "name": "Jiajun He",
                "labs": [
                    "Graduate School of Informatics, Nagoya University, Nagoya, Japan"
                ]
            },
            {
                "name": "Tomoki Toda",
                "labs": [
                    "Information Technology Center, Nagoya University, Nagoya, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Error correction",
                "Accuracy",
                "Training",
                "Decoding",
                "Adaptation models",
                "Training data",
                "Robustness",
                "Phonetics",
                "Interpolation"
            ],
            "Author Keywords": [
                "Automatic speech recognition (ASR)",
                "context-aware error correction",
                "error detection",
                "multimodal fusion",
                "phoneme information",
                "rare word list"
            ]
        }
    },
    {
        "Title": "Balancing Minds and Data: The Privacy Dilemma of LLMs and Anthropomorphism in LLMs",
        "Link": "https://ieeexplore.ieee.org/document/11184734/",
        "Abstract": "This essay examines the intricate relationship between large language models (LLMs) and privacy, investigating the ethical and practical issues stemming from cutting-edge artificial intelligence (AI) technologies. The research delves into the evolving understanding of privacy in the digital era, with a specific emphasis on the risks posed by anthropomorphic AI design. The analysis highlights critical privacy concerns: (1) Trust and accountability: The lack of true moral agency in AI systems complicates traditional notions of trust and responsibility; (2) Nissenbaum's Contextual Integrity Framework as a tool to explore privacy issues in general and with LLM; (3) Data collection challenges: LLMs collect extensive user data, often without explicit consent, potentially breaching contextual privacy norms; (4) Anthropomorphism risks: Human-like AI interfaces can foster over-trust, leading users to share sensitive information inappropriately. This article underscores that privacy is a complex, multidimensional concept profoundly shaped by technological, cultural, and social forces. As AI technologies continue to advance, safeguarding privacy will necessitate a nuanced approach that strikes a balance between individual rights, societal needs, and technological progress. We conclude with user-oriented guidelines and future research directions, offering a comprehensive framework for understanding and addressing the privacy implications of LLMs.",
        "Details": {
            "DOI": "10.23919/JSC.2025.0014",
            "Date of Publication": "29 September 2025",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Raffael Meier",
                "labs": [
                    "Institute for Media and School (IMS), Schwyz University of Teacher Education, Goldau, Switzerland",
                    "Institute of Education, University of Zurich, Zurich, Switzerland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Data privacy",
                "Ethics",
                "Technological innovation",
                "Social computing",
                "Translation",
                "Large language models",
                "Reliability",
                "Anthropomorphism",
                "Guidelines"
            ],
            "Author Keywords": [
                "large language models (LLMs)",
                "privacy",
                "anthropomorphic artificial intelligence (AI)",
                "trust calibration",
                "contextual integrity",
                "data protection",
                "membership inference attack",
                "human-AI interaction"
            ]
        }
    },
    {
        "Title": "It’s Dangerous to Prompt Alone! Exploring How Fine-Tuning GPT-4o Affects Novices’ Programming Error Resolution",
        "Link": "https://ieeexplore.ieee.org/document/11176024/",
        "Abstract": "Large language models (LLMs) like GPT-4o are increasingly being incorporated into computer science classrooms in tasks such as helping students resolve programming error messages. Prior work has found weak or insignificant support that LLM-generated error explanations help students resolve errors faster, especially compared to expert-handwritten error explanations. This work explores how GPT-4o can be influenced through fine-tuning to produce error explanations that resemble expert-handwritten explanations. We evaluate how three error message styles (traditional Python error messages, baseline GPT-4o explanations, fine-tuned GPT-4o explanations) affect novice programmers’ ability to resolve programming errors. Eighty (\nn=80\n) CS1 students completed six debugging tasks using a within-subjects study design that ensured each participant saw each of the three error message styles twice. We measured time-to-fix, number of code reruns, task failure rate, and then asked for students’ preferences. Participants were found to resolve errors significantly faster with the fine-tuned GPT-4o messages, but, like prior work, we could not find a statistically significant difference between the baseline GPT-4o and traditional Python error messages. Error message style had no effect on number of reruns and task failures; however, the particular debugging task had a significant difference on both. Despite solving problems faster with the fine-tuned GPT-4o model, participants preferred the baseline GPT-4o output (similar to unmodified ChatGPT). These findings strongly suggest that the nature of the debugging task has a greater effect on novice programmers’ error resolution than whether or not the students use a GenAI system to help them debug.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613500",
            "Date of Publication": "23 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eddie Antonio Santos",
                "labs": [
                    "School of Computer Science, University College Dublin, Dublin 4, Ireland",
                    "Department of Computing Science, University of Alberta, Edmonton, Canada"
                ]
            },
            {
                "name": "Audrey Salmon",
                "labs": [
                    "Department of Computer Science, The University of North Carolina at Chapel Hill, Chapel Hill, NC, USA"
                ]
            },
            {
                "name": "Katie Hammer",
                "labs": [
                    "School of Computer Science, North Carolina State University, Raleigh, NC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Python",
                "Programming profession",
                "Codes",
                "Chatbots",
                "Source coding",
                "Manuals",
                "Large language models",
                "Debugging",
                "Electronic mail",
                "Accuracy"
            ],
            "Author Keywords": [
                "AI",
                "compiler error messages",
                "computing education",
                "CS1",
                "debugging",
                "feedback",
                "fine-tuning",
                "GenAI",
                "generative AI",
                "GPT-4o",
                "LLMs",
                "large language models",
                "novice programmers",
                "PEM",
                "programming error messages",
                "Python"
            ]
        }
    },
    {
        "Title": "A Taxonomy-Driven Survey of AI for Seizure Detection: Thalamic Signals, Phase Dynamics, and Translational Gaps",
        "Link": "https://ieeexplore.ieee.org/document/11177257/",
        "Abstract": "Seizure prediction and postictal recovery remain critical challenges in epilepsy care, particularly in real-world, resource-constrained settings. This survey presents a taxonomy-driven synthesis of 150+ peer-reviewed studies spanning seizure phase modeling, thalamic EEG biomarkers, edge inference, and clinical AI integration. We introduce an eight-axis framework covering neurophysiological foundations, machine learning advances, wearable inference pipelines, large language model (LLM) assistants, and privacy-preserving architectures. A key focus is the emerging role of thalamic stereo-EEG (SEEG) as a high-fidelity substrate for modeling seizure transitions and informing closed-loop interventions. Unlike prior reviews, this work explicitly unifies preictal and postictal phase dynamics with modern AI tools—such as federated learning, explainable deep learning, and agentic reasoning. We highlight gaps in dataset diversity, clinical interpretability, and cross-center generalization, while proposing a translational roadmap toward ethical, explainable, and deployment-ready seizure care.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3614148",
            "Date of Publication": "24 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bhargava Ganti",
                "labs": [
                    "Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, Coimbatore, India"
                ]
            },
            {
                "name": "Karthi Balasubramanian",
                "labs": [
                    "Department of Electronics and Communication Engineering, Amrita School of Engineering, Coimbatore, Amrita Vishwa Vidyapeetham, Coimbatore, India"
                ]
            },
            {
                "name": "Sandipan Pati",
                "labs": [
                    "Department of Neurology, Epilepsy Division, University of Minnesota, Minneapolis, MN, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electroencephalography",
                "Brain modeling",
                "Computational modeling",
                "Artificial intelligence",
                "Surveys",
                "Predictive models",
                "Neurophysiology",
                "Data models",
                "Thalamus",
                "Pipelines"
            ],
            "Author Keywords": [
                "Thalamic stereo-EEG (SEEG)",
                "seizure phase transition modeling",
                "postictal recovery analysis",
                "edge AI for EEG inference",
                "artificial intelligence in neurology",
                "clinical decision support systems",
                "large language models (LLMs)",
                "federated and privacy-preserving learning",
                "neurophysiological signal processing",
                "taxonomy-based literature review"
            ]
        }
    },
    {
        "Title": "A Hybrid Large Language Model for Context-Aware Document Ranking in Telecommunication Data",
        "Link": "https://ieeexplore.ieee.org/document/11071302/",
        "Abstract": "Large language models (LLMs) have drawn a lot of attention due to their exceptional comprehension and reasoning capabilities. The development of LLM methods are leading to countless prospects for the automation of numerous tasks in the telecommunication industry. Following pre-training and fine-tuning, LLMs are able to carry out a variety of downstream activities in response to human instructions. This paper presents hybrid document retrieval and ranking approach that integrates statistical, probabilistic, and neural network-based retrieval models to enhance information retrieval performance in telecommunication domain. Traditional methods such as Term Frequency–Inverse Document Frequency (TF-IDF), and Best Match 25 (BM25) provide effective lexical matching, while deep learning-based models like Sentence-BERT (SBERT), and Word to Vector (Word2Vec) improve semantic understanding by capturing contextual relationships between query and document representations. The proposed framework introduces a novel multi-stage ranking mechanism that strategically integrates term-frequency-based scoring with semantic similarity modelling using Sentence-BERT and Word2Vec. Unlike existing models, our method dynamically adjusts weights across lexical and semantic components based on query features, enabling real-time adaptation for telecom-specific QA tasks. Performance evaluation is conducted using BLEU Score, ROUGE metrics, Cosine Similarity, and Word2Vec Similarity, demonstrating that the hybrid model outperforms conventional retrieval baselines in both precision and recall-oriented tasks. The proposed model effectively aligns query intent with retrieved documents, increase in efficiency of domain-specific search. The future scope includes dynamic embedding techniques to handle domain adaptation and attention-based ranking optimizations for long-form information retrieval. This research enhances information retrieval by combining machine learning-based ranking with traditional methods, improving knowledge discovery and decision-making in telecommunications and technical document processing.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3585637",
            "Date of Publication": "03 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abhay Bindle",
                "labs": [
                    "ECE Department, MMDU, Mullana, India"
                ]
            },
            {
                "name": "Preeti Singla",
                "labs": [
                    "CSE Department, MMDU, Mullana, India"
                ]
            },
            {
                "name": "Sachin Sharma",
                "labs": [
                    "State Bank of India, Panchkula, India"
                ]
            },
            {
                "name": "Abdukodir Khakimov",
                "labs": [
                    "Institute of Computer Science and Telecommunications, RUDN University, Moscow, Russia"
                ]
            },
            {
                "name": "Reem Ibrahim Alkanhel",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ammar Muthanna",
                "labs": [
                    "Institute of Computer Science and Telecommunications, RUDN University, Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Communications technology",
                "Semantics",
                "Synthetic data",
                "Context modeling",
                "Adaptation models",
                "Telecommunications",
                "Standards",
                "Optimization",
                "Industries",
                "Data models"
            ],
            "Author Keywords": [
                "BM25",
                "document ranking",
                "information retrieval",
                "large language models",
                "semantic similarity",
                "telecommunication",
                "vector space analysis"
            ]
        }
    }
]