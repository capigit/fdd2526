[
    {
        "Title": "Exploring LLMs Applications in Law: A Literature Review on Current Legal NLP Approaches",
        "Link": "https://ieeexplore.ieee.org/document/10850911/",
        "Abstract": "Artificial Intelligence (AI) is reshaping the legal landscape, with software tools now impacting various aspects of legal work. The intersection of Natural Language Processing (NLP) and law holds potential to transform how legal professionals, including lawyers and judges, operate, resolve disputes, and retrieve case information to formulate their decisions. To identify the current state of the applications of Transformers (also known as Large Language Models or LLMs) in the legal domain, we analysed the existing literature from 2017 to 2023 through a database search and snowballing method. From 61 selected publications, we identified key application categories such as legal document analysis, case prediction, and contract review, along with their main characteristics. We observed a discernible upsurge in the volume of scholarly publications, a diversification of tasks undertaken (e.g., legal research, contract analysis, and regulatory compliance), and an increased range of languages considered. There has been a notable enhancement in the methodological sophistication employed by researchers in practical applications. The performance of models grounded in the Generative Pre-trained Transformer (GPT) architecture has consistently improved across various legal domains, including contract review, legal document summarization, and case outcome prediction. This paper makes several significant contributions to the field. Firstly, it identifies emerging trends in the application of LLMs within the legal domain, highlighting the growing interest and investment in this area. Secondly, it pinpoints methodological gaps in current research, suggesting areas where further development and refinement are needed. Lastly, it discusses the broader implications of these advancements for real-world legal tasks, offering insights into how LLM-based AI can enhance legal practice while addressing the associated challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3533217",
            "Date of Publication": "23 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marco Siino",
                "labs": [
                    "Department of Electrical, Electronics and Informatics Engineering, University of Catania, Catania, Italy",
                    "Department of Engineering, University of Palermo, Palermo, Italy",
                    "Palermo Research Unit, National Inter-University Consortium for Telecommunications (CNIT), Palermo, Italy"
                ]
            },
            {
                "name": "Mariana Falco",
                "labs": [
                    "Department of Engineering, University of Palermo, Palermo, Italy"
                ]
            },
            {
                "name": "Daniele Croce",
                "labs": [
                    "Department of Engineering, University of Palermo, Palermo, Italy",
                    "Palermo Research Unit, National Inter-University Consortium for Telecommunications (CNIT), Palermo, Italy"
                ]
            },
            {
                "name": "Paolo Rosso",
                "labs": [
                    "PRHLT Research Center, Universitat Politècnica de València, Valencia, Spain",
                    "ValgrAI–Valencian Graduate School and Research Network of Artificial Intelligence, Valencia, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Artificial intelligence",
                "Transformers",
                "Systematic literature review",
                "Contracts",
                "Attention mechanisms",
                "Databases",
                "Reliability",
                "Question answering (information retrieval)",
                "Quality assessment"
            ],
            "Author Keywords": [
                "Natural language processing",
                "law",
                "AI for law",
                "legal NLP",
                "legal tech",
                "GPT",
                "transformers",
                "literature review"
            ]
        }
    },
    {
        "Title": "Systematic Literature Review of Dialectal Arabic: Identification and Detection",
        "Link": "https://ieeexplore.ieee.org/document/9354635/",
        "Abstract": "It is becoming increasingly difficult to know who is working on what and how in computational studies of Dialectal Arabic. This study comes to chart the field by conducting a systematic literature review that is intended to give insight into the most and least popular research areas, dialects, machine learning approaches, neural network input features, data types, datasets, system evaluation criteria, publication venues, and publication trends. It is a review that is guided by the norms of systematic reviews. It has taken account of all the research that adopted a computational approach to dialectal Arabic identification and detection and that was published between 2000 and 2020. It collected, analyzed, and collated this research, discovered its trends, and identified research gaps. It revealed, inter alia, that our research effort has not been directed evenly between speech and text or between the vernaculars; there is some bias favoring text over speech, regional varieties over individual vernaculars, and Egyptian over all other vernaculars. Furthermore, there is a clear preference for shallow machine learning approaches, for the use of n-grams, TF-IDF, and MFCC as neural network features, and for accuracy as a statistical measure of validation of results. This paper also pointed to some glaring gaps in the research: (1) total neglect of Mauritanian and Bahraini in the continuous Arabic language area and of such enclave varieties as Anatolian Arabic, Khuzistan Arabic, Khurasan Arabic, Uzbekistan Arabic, the Subsaharan Arabic of Nigeria and Chad, Djibouti Arabic, Cypriot Arabic and Maltese; (2) scarcity of city dialect resources; (3) rarity of linguistic investigations that would complement our research; (4) and paucity of deep machine learning experimentation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3059504",
            "Date of Publication": "15 February 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ashraf Elnagar",
                "labs": [
                    "Department of Computer Science, University of Sharjah, Sharjah, United Arab Emirates",
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Sane M. Yagi",
                "labs": [
                    "Department of Foreign Language, University of Sharjah, Sharjah, United Arab Emirates",
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Ali Bou Nassif",
                "labs": [
                    "Department of Computer Engineering, University of Sharjah, Sharjah, United Arab Emirates",
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Ismail Shahin",
                "labs": [
                    "Department of Electrical Engineering, University of Sharjah, Sharjah, United Arab Emirates",
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Said A. Salloum",
                "labs": [
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Standards",
                "Systematics",
                "Speech recognition",
                "Machine learning",
                "Machine translation",
                "Tools",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Arabic dialects",
                "Arabic natural language processing",
                "dialect identification",
                "modern standard Arabic",
                "systematic review"
            ]
        }
    },
    {
        "Title": "The NLP Cookbook: Modern Recipes for Transformer Based Deep Learning Architectures",
        "Link": "https://ieeexplore.ieee.org/document/9422763/",
        "Abstract": "In recent years, Natural Language Processing (NLP) models have achieved phenomenal success in linguistic and semantic tasks like text classification, machine translation, cognitive dialogue systems, information retrieval via Natural Language Understanding (NLU), and Natural Language Generation (NLG). This feat is primarily attributed due to the seminal Transformer architecture, leading to designs such as BERT, GPT (I, II, III), etc. Although these large-size models have achieved unprecedented performances, they come at high computational costs. Consequently, some of the recent NLP architectures have utilized concepts of transfer learning, pruning, quantization, and knowledge distillation to achieve moderate model sizes while keeping nearly similar performances as achieved by their predecessors. Additionally, to mitigate the data size challenge raised by language models from a knowledge extraction perspective, Knowledge Retrievers have been built to extricate explicit data documents from a large corpus of databases with greater efficiency and accuracy. Recent research has also focused on superior inference by providing efficient attention to longer input sequences. In this paper, we summarize and examine the current state-of-the-art (SOTA) NLP models that have been employed for numerous NLP tasks for optimal performance and efficiency. We provide a detailed understanding and functioning of the different architectures, a taxonomy of NLP designs, comparative evaluations, and future directions in NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3077350",
            "Date of Publication": "04 May 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sushant Singh",
                "labs": [
                    "Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA"
                ]
            },
            {
                "name": "Ausif Mahmood",
                "labs": [
                    "Department of Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Task analysis",
                "Computer architecture",
                "Computational modeling",
                "Natural language processing",
                "Recurrent neural networks",
                "Quantization (signal)"
            ],
            "Author Keywords": [
                "Deep learning",
                "natural language processing (NLP)",
                "natural language understanding (NLU)",
                "natural language generation (NLG)",
                "information retrieval (IR)",
                "knowledge distillation (KD)",
                "pruning",
                "quantization"
            ]
        }
    },
    {
        "Title": "A Survey of Text Representation and Embedding Techniques in NLP",
        "Link": "https://ieeexplore.ieee.org/document/10098736/",
        "Abstract": "Natural Language Processing (NLP) is a research field where a language in consideration is processed to understand its syntactic, semantic, and sentimental aspects. The advancement in the NLP area has helped solve problems in the domains such as Neural Machine Translation, Name Entity Recognition, Sentiment Analysis, and Chatbots, to name a few. The topic of NLP broadly consists of two main parts: the representation of the input text (raw data) into numerical format (vectors or matrix) and the design of models for processing the numerical data. This paper focuses on the former part and surveys how the NLP field has evolved from rule-based, statistical to more context-sensitive learned representations. For each embedding type, we list their representation, issues they addressed, limitations, and applications. This survey covers the history of text representations from the 1970s and onwards, from regular expressions to the latest vector representations used to encode the raw text data. It demonstrates how the NLP field progressed from where it could comprehend just bits and pieces to all the significant aspects of the text over time.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3266377",
            "Date of Publication": "11 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rajvardhan Patil",
                "labs": [
                    "School of Computing, Grand Valley State University, Allendale, MI, USA"
                ]
            },
            {
                "name": "Sorio Boit",
                "labs": [
                    "School of Computing, Grand Valley State University, Allendale, MI, USA"
                ]
            },
            {
                "name": "Venkat Gudivada",
                "labs": [
                    "Department of Computer Science, East Carolina University, Greenville, NC, USA"
                ]
            },
            {
                "name": "Jagadeesh Nandigam",
                "labs": [
                    "School of Computing, Grand Valley State University, Allendale, MI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Grammar",
                "Sparse matrices",
                "Semantics",
                "Indexes",
                "Electronic mail",
                "Vocabulary",
                "Text mining"
            ],
            "Author Keywords": [
                "Natural language processing",
                "embeddings",
                "text representation",
                "word vectors",
                "survey",
                "word embeddings",
                "literature review",
                "NLP",
                "language models"
            ]
        }
    },
    {
        "Title": "BATRACIO: BAsic, TRAnslational, Clinical, Research Phase Identification in BiOmedical Publications",
        "Link": "https://ieeexplore.ieee.org/document/10684170/",
        "Abstract": "The increasing interest from research agencies, governments, and universities in understanding research funding and prioritising research efforts has highlighted the need for reliable and efficient methods for exploring research portfolios. In biomedical research, this involves exploring research across what is normally considered fundamental and applied research. As research done in these different categories does not have the same behaviour, such as time to impact or citation behaviour, it is often important to address them separately. Moreover, research is increasingly complex, interdisciplinary and transversal, and increasingly of translational nature. Currently, there are no available tools, as far as we know, that do this. Scientific publications offer a valuable source of information for this purpose, but the growth in the number of biomedical publications makes manual inspection and classification of papers unfeasible. To address this challenge, we present BATRACIO, a new task that aims to classify biomedical publications into the following research types: Basic, Translational, Clinical, and Public Health. We develop and release an expert annotated dataset for the task and evaluate state-of-the-art models to determine the effectiveness of domain-specific pre-trained language models in comparison to general pre-trained language models. We also investigate methods for handling imbalanced datasets in the biomedical domain with adjacent categories. Our results demonstrate that domain-specific pre-trained language models can effectively classify scientific papers based on the research type, overcoming challenges such as the use of abbreviations and acronyms. These findings have important implications for policymakers and funding agencies in understanding research activities and allocating resources effectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3463717",
            "Date of Publication": "19 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nicolau Durán-Silva",
                "labs": [
                    "SIRIS Laboratory, Research Division, SIRIS Academic, Barcelona, Spain",
                    "DLaSTUS Laboratory, TALN Group, Universitat Pompeu Fabra, Barcelona, Spain"
                ]
            },
            {
                "name": "Jorge Carrillo-de-Albornoz",
                "labs": [
                    "NLP and IR UNED, Madrid, Spain"
                ]
            },
            {
                "name": "Laura Plaza",
                "labs": [
                    "NLP and IR UNED, Madrid, Spain"
                ]
            },
            {
                "name": "Sara Ricardo",
                "labs": [
                    "SIRIS Laboratory, Research Division, SIRIS Academic, Barcelona, Spain"
                ]
            },
            {
                "name": "Francesco A. Massucci",
                "labs": [
                    "SIRIS Laboratory, Research Division, SIRIS Academic, Barcelona, Spain"
                ]
            },
            {
                "name": "Sonia Veiga",
                "labs": [
                    "SIRIS Laboratory, Research Division, SIRIS Academic, Barcelona, Spain"
                ]
            },
            {
                "name": "Arnau Ramos-Prats",
                "labs": [
                    "Department of Pharmacology, Medical University of Innsbruck, Innsbruck, Austria",
                    "Friedrich Miescher Institute for Biomedical Research, Basel, Switzerland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Text categorization",
                "Terminology",
                "Feature extraction",
                "Adaptation models",
                "Natural language processing",
                "Manuals",
                "Research and development",
                "Biomedical engineering",
                "Document handling",
                "Text mining"
            ],
            "Author Keywords": [
                "Biomedical research",
                "natural language processing",
                "scholarly document processing",
                "science mapping",
                "text mining"
            ]
        }
    },
    {
        "Title": "Identifying Security and Privacy Violation Rules in Trigger-Action IoT Platforms With NLP Models",
        "Link": "https://ieeexplore.ieee.org/document/9953113/",
        "Abstract": "Trigger-action platforms are systems that enable users to easily define, in terms of conditional rules, custom behaviors concerning Internet of Things (IoT) devices and Web services. Unfortunately, although these tools stimulate the creativity of users in building automation, they may also introduce serious risks for the users. Indeed, trigger–action rules can lead to the possibility of users harming themselves, for example, by unintentionally disclosing nonpublic information, or unwillingly exposing their smart environment to cyber-threats. In this article, we propose to use natural language processing (NLP) techniques to detect automation rules, defined within trigger–action IoT platforms, that potentially violate the security or privacy of the users. The proposed NLP-based models capture the semantic and contextual information of the trigger-action rules by applying classification techniques to different combinations of rule’s features. We evaluate the proposed solution with the mainstream trigger-action platform, namely, If-This-Then-That, by training the NLP models with a data set of 76 741 rules labeled by using an ensemble of three semi-supervised learning techniques. The experimental results demonstrate that the model based on bidirectional encoder representations from transformers (BERTs) obtains the highest performances when trained on all features, achieving average Precision and Recall values between 88% and 93%. We also compare the achieved performances with those of a baseline system implementing information flow analysis.",
        "Details": {
            "DOI": "10.1109/JIOT.2022.3222615",
            "Date of Publication": "16 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Internet of Things Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2327-4662"
        },
        "authors_data": [
            {
                "name": "Bernardo Breve",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Gaetano Cimino",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Vincenzo Deufemia",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Internet of Things",
                "Security",
                "Behavioral sciences",
                "Analytical models",
                "Natural language processing",
                "Prototypes"
            ],
            "Author Keywords": [
                "Internet of Things (IoT) platforms",
                "natural language processing (NLP)",
                "privacy and security",
                "trigger–action rules"
            ]
        }
    },
    {
        "Title": "Privacy-Preserving Deep Learning NLP Models for Cancer Registries",
        "Link": "https://ieeexplore.ieee.org/document/9069186/",
        "Abstract": "Population cancer registries can benefit from Deep Learning (DL) to automatically extract cancer characteristics from the high volume of unstructured pathology text reports they process annually. The success of DL to tackle this and other real-world problems is proportional to the availability of large labeled datasets for model training. Although collaboration among cancer registries is essential to fully exploit the promise of DL, privacy and confidentiality concerns are main obstacles for data sharing across cancer registries. Moreover, DL for natural language processing (NLP) requires sharing a vocabulary dictionary for the embedding layer which may contain patient identifiers. Thus, even distributing the trained models across cancer registries causes a privacy violation issue. In this article, we propose DL NLP model distribution via privacy-preserving transfer learning approaches without sharing sensitive data. These approaches are used to distribute a multitask convolutional neural network (MT-CNN) NLP model among cancer registries. The model is trained to extract six key cancer characteristics – tumor site, subsite, laterality, behavior, histology, and grade – from cancer pathology reports. Using 410,064 pathology documents from two cancer registries, we compare our proposed approach to conventional transfer learning without privacy-preserving, single-registry models, and a model trained on centrally hosted data. The results show that transfer learning approaches including data sharing and model distribution outperform significantly the single-registry model. In addition, the best performing privacy-preserving model distribution approach achieves statistically indistinguishable average micro- and macro-F1 scores across all extraction tasks (0.823,0.580) as compared to the centralized model (0.827,0.585).",
        "Details": {
            "DOI": "10.1109/TETC.2020.2983404",
            "Date of Publication": "16 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Emerging Topics in Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2168-6750"
        },
        "authors_data": [
            {
                "name": "Mohammed Alawad",
                "labs": [
                    "Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA"
                ]
            },
            {
                "name": "Hong-Jun Yoon",
                "labs": [
                    "Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA"
                ]
            },
            {
                "name": "Shang Gao",
                "labs": [
                    "Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA"
                ]
            },
            {
                "name": "Brent Mumphrey",
                "labs": [
                    "Louisiana Tumor Registry, Louisiana State University Health Sciences Center School of Public Health, New Orleans, LA, USA"
                ]
            },
            {
                "name": "Xiao-Cheng Wu",
                "labs": [
                    "Louisiana Tumor Registry, Louisiana State University Health Sciences Center School of Public Health, New Orleans, LA, USA"
                ]
            },
            {
                "name": "Eric B. Durbin",
                "labs": [
                    "Kentucky Cancer Registry, University of Kentucky, Lexington, KY, USA",
                    "Division of Biomedical Informatics, College of Medicine, University of Kentucky, Lexington, KY, USA",
                    "Cancer Research Informatics Shared Resource Facility, Markey Cancer Center, University of Kentucky, Lexington, KY, USA"
                ]
            },
            {
                "name": "Jong Cheol Jeong",
                "labs": [
                    "Division of Biomedical Informatics, College of Medicine, University of Kentucky, Lexington, KY, USA",
                    "Cancer Research Informatics Shared Resource Facility, Markey Cancer Center, University of Kentucky, Lexington, KY, USA"
                ]
            },
            {
                "name": "Isaac Hands",
                "labs": [
                    "Kentucky Cancer Registry, University of Kentucky, Lexington, KY, USA",
                    "Cancer Research Informatics Shared Resource Facility, Markey Cancer Center, University of Kentucky, Lexington, KY, USA"
                ]
            },
            {
                "name": "David Rust",
                "labs": [
                    "Kentucky Cancer Registry, University of Kentucky, Lexington, KY, USA"
                ]
            },
            {
                "name": "Linda Coyle",
                "labs": [
                    "Information Management Services Inc., Calverton, MD, USA"
                ]
            },
            {
                "name": "Lynne Penberthy",
                "labs": [
                    "Surveillance Research Program, Division of Cancer Control and Population Sciences, National Cancer Institute, Bethesda, MD, USA"
                ]
            },
            {
                "name": "Georgia Tourassi",
                "labs": [
                    "Computational Sciences and Engineering Division and the Health Data Sciences Institute, Oak Ridge National Laboratory, Oak Ridge, TN, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cancer",
                "Pathology",
                "Data models",
                "Natural language processing",
                "Training",
                "Vocabulary",
                "Tumors"
            ],
            "Author Keywords": [
                "Privacy-preserving",
                "multi-task CNN",
                "transfer learning",
                "NLP",
                "information extraction",
                "cancer pathology reports"
            ]
        }
    },
    {
        "Title": "NLP-Based Automated Compliance Checking of Data Processing Agreements Against GDPR",
        "Link": "https://ieeexplore.ieee.org/document/10167495/",
        "Abstract": "When the entity processing personal data (the processor) differs from the one collecting personal data (the controller), processing personal data is regulated in Europe by the General Data Protection Regulation (GDPR) through data processing agreements (DPAs). Checking the compliance of DPAs contributes to the compliance verification of software systems as DPAs are an important source of requirements for software development involving the processing of personal data. However, manually checking whether a given DPA complies with GDPR is challenging as it requires significant time and effort for understanding and identifying DPA-relevant compliance requirements in GDPR and then verifying these requirements in the DPA. Legal texts introduce additional complexity due to convoluted language and inherent ambiguity leading to potential misunderstandings. In this paper, we propose an automated solution to check the compliance of a given DPA against GDPR. In close interaction with legal experts, we first built two artifacts: (i) the “shall” requirements extracted from the GDPR provisions relevant to DPA compliance and (ii) a glossary table defining the legal concepts in the requirements. Then, we developed an automated solution that leverages natural language processing (NLP) technologies to check the compliance of a given DPA against these “shall” requirements. Specifically, our approach automatically generates phrasal-level representations for the textual content of the DPA and compares them against predefined representations of the “shall” requirements. By comparing these two representations, the approach not only assesses whether the DPA is GDPR compliant but it further provides recommendations about missing information in the DPA. Over a dataset of 30 actual DPAs, the approach correctly finds 618 out of 750 genuine violations while raising 76 false violations, and further correctly identifies 524 satisfied requirements. The approach has thus an average precision of 89.1%, a recall of 82.4%, and an accuracy of 84.6%. Compared to a baseline that relies on off-the-shelf NLP tools, our approach provides an average accuracy gain of\n≈\n20 percentage points. The accuracy of our approach can be improved to\n≈\n94% with limited manual verification effort.\nShow Less",
        "Details": {
            "DOI": "10.1109/TSE.2023.3288901",
            "Date of Publication": "27 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Software Engineering"
        },
        "issn_info": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "authors_data": [
            {
                "name": "Orlando Amaral Cejas",
                "labs": [
                    "SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Muhammad Ilyas Azeem",
                "labs": [
                    "SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Sallam Abualhaija",
                "labs": [
                    "SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Lionel C. Briand",
                "labs": [
                    "SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg",
                    "School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Process control",
                "General Data Protection Regulation",
                "Companies",
                "Data processing",
                "Data breach",
                "Standards organizations",
                "Software systems"
            ],
            "Author Keywords": [
                "Requirements engineering (RE)",
                "the general data protection regulation (GDPR)",
                "regulatory compliance",
                "natural language processing (NLP)",
                "data processing agreement (DPA)",
                "privacy"
            ]
        }
    },
    {
        "Title": "Clinical Errors From Acronym Use in Electronic Health Record: A Review of NLP-Based Disambiguation Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10147227/",
        "Abstract": "The adoption of Electronic Health Record (EHR) and other e-health infrastructures over the years has been characterized by an increase in medical errors. This is primarily a result of the widespread usage of medical acronyms and abbreviations with multiple possible senses (i.e., ambiguous acronyms). The advent of Artificial Intelligence (AI) technology, specifically Natural Language Processing (NLP), has presented a promising avenue for tackling the intricate issue of automatic sense resolution of acronyms. Notably, the application of Machine Learning (ML) techniques has proven to be highly effective in the development of systems aimed at this objective, garnering significant attention and interest within the research and industry domains in recent years. The significance of automating the resolution of medical acronym senses cannot be overstated, especially in the context of modern healthcare delivery with the widespread use of EHR. However, it is disheartening to note that comprehensive studies examining the global adoption of EHR, assessing the impact of acronym usage on medical errors within EHR systems, and reporting on the latest trends and advancements in ML-based NLP solutions for disambiguating medical acronyms remain severely limited. In this current study, we present a detailed overview on medical error, its origins, unintended effects, and EHR-related errors as a subclass of clinical error. Furthermore, this paper investigates the adoption of EHR systems in developed and developing nations, as well as the review concludes with an examination of various artificial intelligence techniques, particularly machine learning algorithms for medical acronym and abbreviation disambiguation in EHRs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3284682",
            "Date of Publication": "09 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Temitope Ibrahim Amosa",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia"
                ]
            },
            {
                "name": "Lila Iznita Bt Izhar",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia",
                    "Institute of Health and Analytics, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia"
                ]
            },
            {
                "name": "Patrick Sebastian",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia",
                    "Institute of Autonomous Systems, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia"
                ]
            },
            {
                "name": "Idris B. Ismail",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia"
                ]
            },
            {
                "name": "Oladimeji Ibrahim",
                "labs": [
                    "Department of Electrical and Electronic Engineering, University of Ilorin, Ilorin, Nigeria"
                ]
            },
            {
                "name": "Shehu Lukman Ayinla",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Universiti Teknologi PETRONAS, Seri Iskandar, Malaysia",
                    "Department of Computer Engineering, University of Ilorin, Ilorin, Nigeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Terminology",
                "Medical diagnostic imaging",
                "Medical services",
                "Machine learning",
                "Taxonomy",
                "Machine learning algorithms",
                "Injuries"
            ],
            "Author Keywords": [
                "Medical NLP",
                "health informatics",
                "artificial intelligence",
                "EHRs",
                "computerized health records",
                "word sense disambiguation"
            ]
        }
    },
    {
        "Title": "Automatic Classification of Sexism in Social Networks: An Empirical Study on Twitter Data",
        "Link": "https://ieeexplore.ieee.org/document/9281090/",
        "Abstract": "During the last decade, hateful and sexist content towards women is being increasingly spread on social networks. The exposure to sexist speech has serious consequences to women's life and limits their freedom of speech. Previous studies have focused on identifying hatred or violence towards women. However, sexism is expressed in very different forms: it includes subtle stereotypes and attitudes that, although frequently unnoticed, are extremely harmful for both women and society. In this work, we propose a new task that aims to understand and analyze how sexism, from explicit hate or violence to subtle expressions, is expressed in online conversations. To this end, we have developed and released the first dataset of sexist expressions and attitudes in Twitter in Spanish (MeTwo) and investigate the feasibility of using machine learning techniques (both traditional and novel deep learning models) for automatically detecting different types of sexist behaviours. Our results show that sexism is frequently found in many forms in social networks, that it includes a wide range of behaviours, and that it is possible to detect them using deep learning approaches. We discuss the performance of automatic classification methods to deal with different types of sexism and the generalizability of our task to other subdomains, such as misogyny.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3042604",
            "Date of Publication": "04 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Francisco Rodríguez-Sánchez",
                "labs": [
                    "NLP & IR Group, UNED, Madrid, Spain"
                ]
            },
            {
                "name": "Jorge Carrillo-de-Albornoz",
                "labs": [
                    "NLP & IR Group, UNED, Madrid, Spain"
                ]
            },
            {
                "name": "Laura Plaza",
                "labs": [
                    "NLP & IR Group, UNED, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Task analysis",
                "Voice activity detection",
                "Internet",
                "Deep learning",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Sexism detection",
                "social media",
                "natural language processing",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Integration of Bayesian Inference and Anemotaxis for Robotics Gas Source Localization in a Large Cluttered Outdoor Environment",
        "Link": "https://ieeexplore.ieee.org/document/10022312/",
        "Abstract": "Finding a gas source in a cluttered outdoor environment using autonomous robot is a complex challenge. The gas movement is difficult to predict as it is significantly affected by the wind and the shape of objects in the environment. In this paper, we propose a new probabilistic model and an integration of Bayesian inference and anemotaxis methods used for a robot to find a gas source in a large cluttered outdoor environment. An autonomous robot installed with a gas sensor is expected to find the location of the gas source after the gas leak occurs for a particular time. The advantage of the Bayesian inference technique has been presented previously so that a robot can find the gas source in an isolated indoor building without any significant wind flow. The large environment is divided into some particular regions. A set of probability density function was collected previously from a large amount of gas dispersion simulation to estimate the maximum likelihood of where the gas source is. The challenge gets more extensive if the Bayesian inference method is applied in an outdoor and cluttered environment. Instead of only measuring the gas concentration, the wind angle is also used as the wind profile significantly affects the gas dispersion. Therefore, the probability model is modified to allow the wind direction as a new variable. Moreover, an anemotaxis method is incorporated as the decision-making support as it may be more efficient to direct the robot explicitly to the upwind direction. Evaluations of the proposed method were carried out and its advantage was shown through simulation in a number of different scenarios.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3238470",
            "Date of Publication": "20 January 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yaqub A. Prabowo",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang R. Trilaksono",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Egi M. I. Hidayat",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Brian Yuliarto",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous robots",
                "Bayes methods",
                "Robot sensing systems",
                "Probability density function",
                "Gas detectors",
                "Biological system modeling"
            ],
            "Author Keywords": [
                "Gas source localization",
                "Bayesian inference",
                "anemotaxis"
            ]
        }
    },
    {
        "Title": "Utilizing a Rapidly Exploring Random Tree for Hazardous Gas Exploration in a Large Unknown Area",
        "Link": "https://ieeexplore.ieee.org/document/9698065/",
        "Abstract": "The use of robotics olfaction for gas source localization or mapping has become a concern given the issues of terrorism or industrial accidents that may cause damage to the environment. A typical scenario is to send a robot to a place where a dangerous gas leak has just occurred. The robot’s task is to map gas concentrations in the region of interest as effectively as possible. This paper addresses how the robot performs gas exploration in a large and unknown environment. One of the issues that needs to be addressed is the fact that the computation time of the path planning, frontier detection, goal decision making and gas distribution mapping is slower if all cells in the occupancy grid map are involved in a large environment. Consequently, the Rapidly-exploring Random Tree (RRT) algorithm is chosen as the main algorithm. The RRT graph guides the robot’s navigation, utilizes the vertices as goal candidates, gas mean and variance value, and searches for a new frontier. A new strategy is proposed to address the frontier exploration and gas exploitation trade-off. Finally, a Robot Operating System (ROS), Gazebo, and a 3D gas simulator are used to compare the proposed strategy performance with the others in a large outdoor environment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3147720",
            "Date of Publication": "31 January 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yaqub A. Prabowo",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang R. Trilaksono",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Egi M. I. Hidayat",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Brian Yuliarto",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Kernel",
                "Pollution measurement",
                "Area measurement",
                "Time measurement",
                "Service robots",
                "Contamination"
            ],
            "Author Keywords": [
                "Robot olfaction",
                "robot exploration",
                "rapidly-exploring random trees"
            ]
        }
    },
    {
        "Title": "Time Series Impact Through Topic Modeling",
        "Link": "https://ieeexplore.ieee.org/document/9869829/",
        "Abstract": "A time-series of numerical data and a sequence of time-ordered documents are often correlated. This paper aims at modeling the impact that the underlying themes discussed in the text data have on the time series. To do so, we introduce an original topic model, Time Series Impact Through Topic Modeling (TSITM), that includes contextual data by coupling Latent Dirichlet Allocation (LDA) with linear regression, using an elastic net prior to set to zero the impact of uncorrelated topics. The resulting topics act as explanatory variables for the regression of the numerical time series, which allows us to understand the time series movements based on the events described on the text data. We have tested our model on two datasets: first, we used political news to explain the US president’s disapproval ratings; then, we considered a corpus of economic news to explain the financial returns of 4 different multinational corporations. Our experiments show that an appropriate selection of hyperparameters (via repeated random subsampling validation and Bayesian optimization) leads to significant correlations: both an intrinsic baseline and state of the art methods were significantly outperformed by TSITM in MSE, MAE and out-of-sample\nR\n2\n, according to our hypothesis tests. We believe that this framework can be useful in the context of reputational risk management.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3202960",
            "Date of Publication": "29 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Julián Cendrero",
                "labs": [
                    "Department of Artificial Intelligence, MrHouston Tech Solutions, Madrid, Spain",
                    "NLP & IR Research Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            },
            {
                "name": "Julio Gonzalo",
                "labs": [
                    "NLP & IR Research Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            },
            {
                "name": "Marcos Galletero",
                "labs": [
                    "Department of Artificial Intelligence, MrHouston Tech Solutions, Madrid, Spain",
                    "NLP & IR Research Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            },
            {
                "name": "Ivar Zapata",
                "labs": [
                    "Department of Artificial Intelligence, MrHouston Tech Solutions, Madrid, Spain",
                    "Department of Materials Physics, Universidad Complutense de Madrid (UCM), Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Numerical models",
                "Correlation",
                "Data models",
                "Predictive models",
                "Social networking (online)",
                "Vocabulary",
                "Natural language processing",
                "Text analysis"
            ],
            "Author Keywords": [
                "Expectation-maximization algorithms",
                "natural language processing",
                "regression analysis",
                "text mining",
                "text analysis",
                "time series analysis"
            ]
        }
    },
    {
        "Title": "Multi-Robot Gas Sources Localization and Mapping Using Adaptive Voronoi-PSO and Bayesian Inference",
        "Link": "https://ieeexplore.ieee.org/document/10328611/",
        "Abstract": "Gas sources localization (GSL) and gas distribution mapping (GDM) are vital when hazardous gas leaks occur, as finding the sources and mapping the contaminant are crucial for containment and prevention. This paper addresses the challenge of simultaneous GSL and GDM through a multi-robot coordination algorithm in a large area. Bayesian inference methods are employed to estimate areas with the highest gas concentration. The robots are directed towards the most probable locations of the highest gas concentration. Even after locating all the gas sources, the robot group focuses on mapping the more contaminated areas. Voronoi tessellation is utilized to partition the working area among the robots. The Particle Swarm Optimization (PSO) method is employed, allowing one robot to share the current highest probability of the gas source’s location to others. The weighting constant of the PSO method is eliminated, enabling GSL and GDM to be performed in an adaptive manner. The proposed method is referred to as “adaptive Voronoi-PSO”. The method is evaluated in both free-space and cluttered environments. Monte Carlo simulation is suitable for free-space environments as it rapidly generates gas distribution. Evaluating the method in cluttered environments is more challenging, requiring complex simulations to generate the gas distribution. Overall, the adaptive Voronoi-PSO method offers more advantages than solely using Voronoi or non-adaptive Voronoi-PSO methods. Its only drawback is observed in cluttered environments. Nevertheless, the adaptive Voronoi-PSO method remains advantageous as it eliminates the need to select a weighting constant, which is a challenging task in practice.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3336560",
            "Date of Publication": "23 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yaqub A. Prabowo",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang R. Trilaksono",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Egi M. I. Hidayat",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Brian Yuliarto",
                "labs": [
                    "Bandung Institute of Technology, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robot kinematics",
                "Genetic algorithms",
                "Bayes methods",
                "Location awareness",
                "Task analysis",
                "Estimation",
                "Position measurement",
                "Gases",
                "Multi-robot systems"
            ],
            "Author Keywords": [
                "Gas sources localization",
                "gas distribution mapping",
                "multi-robot coordination"
            ]
        }
    },
    {
        "Title": "Automatic Identification of Narratives: Evaluation Framework, Annotation Methodology, and Dataset Creation",
        "Link": "https://ieeexplore.ieee.org/document/10706846/",
        "Abstract": "One of the fundamental components of understanding online discourse in social networks is the identification of narratives. For example, the analysis of disinformation campaigns requires some inference about their communication goals that, in turn, requires the identification of the narratives that they promote. The research in this task involves a number of challenges such as the limited availability of labelled datasets, the subjectivity of the annotators and the time cost of annotation. This article present a definition of the Narrative Identification task, proposes an evaluation framework for Narrative Identification, and a methodology for the creation and annotation of Narrative Identification datasets taking into account the subjectivity of the task. Keeping in mind the goal of comparing systems performance, we explore how to reduce the annotation time while maintaining the reliability of the evaluation. Following this methodology, a set of eight tasks for narrative identification in the political domain has been developed in Spanish and English. Finally, we validated the evaluation framework by analysing its application to DIPROMATS 2024 shared task, together with the performance analysis of baseline and participant systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3475579",
            "Date of Publication": "07 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jesús M. Fraile-Hernández",
                "labs": [
                    "UNED NLP & IR Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            },
            {
                "name": "Anselmo Peńas",
                "labs": [
                    "UNED NLP & IR Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            },
            {
                "name": "Pablo Moral",
                "labs": [
                    "UNED NLP & IR Group, Universidad Nacional de Educación a Distancia (UNED), Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Social networking (online)",
                "Costs",
                "Measurement",
                "Labeling",
                "Blogs",
                "Upper bound",
                "System performance",
                "Object recognition",
                "Natural language processing",
                "Media",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Narrative identification",
                "natural language processing",
                "social media analysis",
                "evaluation methodology",
                "datasets"
            ]
        }
    },
    {
        "Title": "Improving Data Entry Quality in Enterprise Applications With NLP Methods: A Model Proposal Based on BERT and Deep Learning",
        "Link": "https://ieeexplore.ieee.org/document/11086599/",
        "Abstract": "In digital transformation, which is one of the most important keywords of our time, the completeness and accuracy of the data that users enter into applications directly affects the quality of the process, the accuracy of decision-making systems, and the speed at which data turns into information. Incorrect or incomplete data causes many problems such as prolonged approval processes, decreased trust in data, and negative impact on analysis capabilities. In this study, a data validation system was developed to improve the accuracy of risk management data collected from an ERP application and to minimize data entry errors. In order to prevent users from incorrectly entering or confusing important data such as Potential Risk, Internal Control, Control and Impact of the Risk during data entry, it is aimed to ensure accurate data entry by using NLP methods. Within the scope of the study, training was conducted on historical data and errors in user data entry were detected with various classification methods. Different methods such as BERT, RoBERTa, GPT-2, TFIDF+SVM, Word2Vec+SVM, Embedding GRU and Embedding LSTM were used to prevent these errors. The results show that the BERT model achieves the highest success rate with 94% accuracy. The strong language modelling capabilities of BERT gave it a significant advantage over other methods in detecting errors in data input.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3590983",
            "Date of Publication": "21 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "H. Canli",
                "labs": [
                    "Department of Software Engineering, İstanbul Gedik University, İstanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Data models",
                "Data integrity",
                "Reliability",
                "Machine learning",
                "Training",
                "Long short term memory",
                "Software",
                "Encoding",
                "Data mining"
            ],
            "Author Keywords": [
                "NLP",
                "BERT",
                "classification",
                "data validation",
                "risk management"
            ]
        }
    },
    {
        "Title": "Text Mining and Emotion Classification on Monkeypox Twitter Dataset: A Deep Learning-Natural Language Processing (NLP) Approach",
        "Link": "https://ieeexplore.ieee.org/document/10129946/",
        "Abstract": "Emotion classification has become a valuable tool in analyzing text and emotions people express in response to events or crises, particularly on social media and other online platforms. The recent news about monkeypox highlighted various emotions individuals felt during the outbreak. People’s opinions and concerns have been very different based on their awareness and understanding of the disease. Although there have been studies on monkeypox, emotion classification related to this virus has not been considered. As a result, this study aims to analyze the emotions individual expressed on social media posts related to the monkeypox disease. Our goal is to provide real-time information and identify critical concerns about the disease. To conduct our analysis, first, we extract and preprocess 800,000 datasets and then use NRCLexicon, a Python library, to predict and measure the emotional significance of each text. Secondly, we develop deep learning models based on Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), Bi-directional LSTM (BiLSTM), and the combination of Convolutional Neural Networks and Long Short-Term Memory (CLSTM) for emotion classification. We use SMOTE (Synthetic Minority Oversampling Technique) and Random Undersampling techniques to address the class imbalance in our training dataset. The results of our study revealed that the CNN model achieved the highest performance with an accuracy of 96%. Overall, emotion classification on the monkeypox dataset can be a powerful tool for improving our understanding of the disease. The findings of this study will help develop effective interventions and improve public health.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3277868",
            "Date of Publication": "19 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ruth Olusegun",
                "labs": [
                    "Department of Computer Science, Bowie State University, Bowie, MD, USA"
                ]
            },
            {
                "name": "Timothy Oladunni",
                "labs": [
                    "Department of Computer Science, Morgan State University, Baltimore, MD, USA"
                ]
            },
            {
                "name": "Halima Audu",
                "labs": [
                    "Department of Computer Science, Bowie State University, Bowie, MD, USA"
                ]
            },
            {
                "name": "YAO Houkpati",
                "labs": [
                    "Department of Computer Science, Bowie State University, Bowie, MD, USA"
                ]
            },
            {
                "name": "Staphord Bengesi",
                "labs": [
                    "Department of Computer Science, Bowie State University, Bowie, MD, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Diseases",
                "Sentiment analysis",
                "Blogs",
                "Public healthcare",
                "Deep learning",
                "COVID-19",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Monkeypox",
                "emotion detection",
                "deep learning",
                "natural language processing (NLP)",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Live Event Detection for People’s Safety Using NLP and Deep Learning",
        "Link": "https://ieeexplore.ieee.org/document/10379088/",
        "Abstract": "Today, humans pose the greatest threat to society by getting involved in robbery, assault, or homicide activities. Such circumstances threaten the people working alone at night in remote areas especially women. Any such kind of threat in real time is always associated with a sound/noise which may be used for an early detection. Numerous existing measures are available but none of them sounds efficient due to lack of accuracy, delays in exact prediction of threat. Hence a novel software-based prototype is developed to detect threats from a person’s surrounding sound/noise and automatically alert the registered contacts of victims by sending email, SMS, WhatsApp messages through their smartphones without any other hardware components. Audio signals from Kaggle dataset are visualized, analyzed using Exploratory Data Analytics (EDA) techniques. By feeding EDA outcomes into various Deep Learning models: Long short-term memory (LSTM), Convolutional Neural Networks (CNN) yields accuracy of 96.6% in classifying the audio-events.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3349097",
            "Date of Publication": "01 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amrit Sen",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Gayathri Rajakumaran",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Miroslav Mahdal",
                "labs": [
                    "Department of Control Systems and Instrumentation, Faculty of Mechanical Engineering, VSB-Technical University of Ostrava, Ostrava, Czech Republic"
                ]
            },
            {
                "name": "Shola Usharani",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Vezhavendhan Rajasekharan",
                "labs": [
                    "School of Mechanical and Building Sciences, Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "Rajiv Vincent",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Karthikeyan Sugavanan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Natural language processing",
                "Emergency services",
                "Computer science",
                "Cameras",
                "Social networking (online)",
                "Smart phones",
                "Audio recording",
                "Classification algorithms",
                "Predictive models"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "deep learning",
                "audio",
                "recording",
                "CNN",
                "LSTM",
                "classification",
                "prediction"
            ]
        }
    },
    {
        "Title": "NLP-Based Fusion Approach to Robust Image Captioning",
        "Link": "https://ieeexplore.ieee.org/document/10555151/",
        "Abstract": "Robustness in remote sensing image captioning is crucial for real-world applications. However, most of the research focuses on improving the performance of single captioning algorithms, either by introducing novel feature processing units or metatasks that indirectly improve the captioning performance. Despite indisputable improvements in performance, we argue that relying on the output of a single model can be critical, especially when data scarcity limits the generalization capability of the trained algorithms. Focusing on the advantages of ensembles for improving robustness, we propose different ways to select or generate a single most coherent caption from a set of predictions made by different captioning algorithms. The disjunction between the two phases of prediction and selection/generation provides high flexibility for inserting different captioning algorithms, each with its peculiarities and strengths. In this context, based on neural natural language processing tools, our approach can be considered as an additional fusion block that enables higher robustness with a contained complexity burden.",
        "Details": {
            "DOI": "10.1109/JSTARS.2024.3413323",
            "Date of Publication": "12 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing"
        },
        "issn_info": {
            "Print ISSN": "1939-1404",
            "Electronic ISSN": "2151-1535"
        },
        "authors_data": [
            {
                "name": "Riccardo Ricci",
                "labs": [
                    "Department of Information Engineering and Computer Science, University of Trento, Trento, Italy"
                ]
            },
            {
                "name": "Farid Melgani",
                "labs": [
                    "Department of Information Engineering and Computer Science, University of Trento, Trento, Italy"
                ]
            },
            {
                "name": "José Marcato Junior",
                "labs": [
                    "Federal University of Mato Grosso do Sul, Cidade Universitária, Campo Grande, MS, Brazil"
                ]
            },
            {
                "name": "Wesley Nunes Gonçalves",
                "labs": [
                    "Federal University of Mato Grosso do Sul, Cidade Universitária, Campo Grande, MS, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Remote sensing",
                "Visualization",
                "Transformers",
                "Training",
                "Robustness",
                "Vocabulary",
                "Natural language processing",
                "Ensemble learning",
                "Contrastive learning"
            ],
            "Author Keywords": [
                "Bidirectional encoder representations from transformers (BERT)",
                "contrastive language-image pretraining (CLIP)",
                "ensemble fusion",
                "generative pretrained transformer (GPT)",
                "image captioning",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "BERT2D: Two Dimensional Positional Embeddings for Efficient Turkish NLP",
        "Link": "https://ieeexplore.ieee.org/document/10542953/",
        "Abstract": "This study addresses the challenge of improving the downstream performance of pretrained language models for morphologically rich languages, with a focus on Turkish. Traditional BERT models use one-dimensional absolute positional embeddings, which, while effective, have limitations when dealing with complex languages. We propose BERT2D, which is a novel BERT-based model that contributes to positional embedding systems. This approach introduces a dual embedding system that targets all the words and their subwords. Remarkably, this modification, coupled with whole word masking, resulted in a significant increase in performance despite a negligible increase in the parameters. Our experiments showed that BERT2D consistently outperformed the leading Turkish-focused BERT model, BERTurk, in terms of various performance metrics in text classification, token classification, and question-answering downstream tasks. For a fair comparison, we pretrained our BERT2D language model on the same dataset as that of BERTurk. The results demonstrate that two-dimensional positional embeddings can significantly improve the performance of encoder-only models in Turkish and other morphologically rich languages, suggesting a promising direction for future research in natural language processing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3407983",
            "Date of Publication": "31 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yiğit Bekir Kaya",
                "labs": [
                    "Computer Engineering Department, Istanbul Technical University, Sarıyer, İstanbul, Turkey"
                ]
            },
            {
                "name": "A. Cüneyd Tantuğ",
                "labs": [
                    "Computer Engineering Department, Istanbul Technical University, Sarıyer, İstanbul, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Bidirectional control",
                "Task analysis",
                "Transformers",
                "Tokenization",
                "Vocabulary",
                "Sentiment analysis",
                "Natural language processing",
                "Named entity recognition"
            ],
            "Author Keywords": [
                "Transformer models",
                "BERT",
                "BERT2D",
                "sentiment analysis",
                "named entity recognition",
                "question answering",
                "Turkish",
                "NLP",
                "positional embeddings",
                "positional encoding"
            ]
        }
    },
    {
        "Title": "Polarity Classification of Low Resource Roman Urdu and Movie Reviews Sentiments Using Machine Learning-Based Ensemble Approaches",
        "Link": "https://ieeexplore.ieee.org/document/10707202/",
        "Abstract": "The complex linguistic characteristics and limited resources present sentiment analysis in Roman Urdu as a unique challenge, necessitating the development of accurate NLP models. In this study, we investigate the performance of prominent ensemble methods on two diverse datasets of UCL and IMDB movie reviews with Roman Urdu and English dialects, respectively. We perform a comparative examination to assess the effectiveness of ensemble techniques including stacking, bagging, random subspace, and boosting, optimized through grid search. The ensemble techniques employ four base learners (Support Vector Machine, Random Forest, Logistic Regression, and Naive Bayes) for sentiment classification. The experiment analysis focuses on different N-gram feature sets (unigrams, bigrams, and trigrams), Chi-square feature selection, and text representation schemes (Bag of Words and TF-IDF). Our empirical findings underscore the superiority of stacking across both datasets, achieving high accuracies and F1-scores: 80.30% and 81.76% on the UCL dataset, and 90.92% and 91.12% on the IMDB datasets, respectively. The proposed approach has significant performance compared to baseline approaches on the relevant tasks and improves the accuracy up to 7% on the UCL dataset.",
        "Details": {
            "DOI": "10.1109/OJCS.2024.3476378",
            "Date of Publication": "08 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Muhammad Ehtisham Hassan",
                "labs": [
                    "Department of Data Science, Computer Engineering, Ghulam Ishaq Khan Institute, Swabi, Pakistan"
                ]
            },
            {
                "name": "Iffat Maab",
                "labs": [
                    "Digital Content and Media Sciences Research Division, National Institute of Informatics, Tokyo, Japan"
                ]
            },
            {
                "name": "Masroor Hussain",
                "labs": [
                    "Department of Data Science, Computer Engineering, Ghulam Ishaq Khan Institute, Swabi, Pakistan"
                ]
            },
            {
                "name": "Usman Habib",
                "labs": [
                    "Software Engineering Department, FAST School of Computing, National University of Computer & Emerging Sciences, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Yutaka Matsuo",
                "labs": [
                    "The University of Tokyo, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Support vector machines",
                "Feature extraction",
                "Motion pictures",
                "Machine learning",
                "Ensemble learning",
                "Accuracy",
                "Social networking (online)",
                "Sentiment analysis",
                "Training"
            ],
            "Author Keywords": [
                "Chi-square",
                "ensemble learning",
                "grid search optimization",
                "low resource language",
                "machine learning",
                "natural language processing (NLP)",
                "n-gram",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Climate Change Sentiment Analysis Using Domain Specific Bidirectional Encoder Representations From Transformers",
        "Link": "https://ieeexplore.ieee.org/document/10632142/",
        "Abstract": "Climate change’s impact on human health poses unprecedented and diverse challenges. Unless proactive measures based on solid evidence are implemented, these threats will likely escalate and continue to endanger human well-being. The escalating advancements in information and communication technologies have facilitated the widespread availability and utilization of social media platforms. Individuals utilize platforms such as Twitter and Facebook to express their opinions, thoughts, and critiques on diverse subjects, encompassing the pressing issue of climate change. The proliferation of climate change-related content on social media necessitates comprehensive analysis to glean meaningful insights. This paper employs natural language processing (NLP) techniques to analyze climate change discourse and quantify the sentiment of climate change-related tweets. We collected a total number of 5506 tweets for the period of January 2022 and February 2023 and manually labeled them to make the dataset for this experiment. ClimateBERT, a pre-trained model fine-tuned specifically on the climate change domain was used to generate the context vectors. Several machine learning algorithms with different feature encoding techniques, such as TF-IDF and BERT, have been implemented to classify user sentiments. When comparing the performance of the classifiers using different evaluation metrics such as precision, recall, accuracy, and f-measure, the ClimateBERT + Random Forest model is found to be outperforming all the other baselines with an accuracy of 90.22%, recall of 85.22%, and an f-measure of 85.47%. The findings from this experiment unearth valuable insights into public sentiment and the entities associated with climate change discourse. Policymakers, researchers, and organizations can leverage such analyses to understand public perceptions, identify influential actors, and devise informed strategies to address climate change challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3441310",
            "Date of Publication": "09 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "V. S. Anoop",
                "labs": [
                    "NLP for Social Good Laboratory, School of Digital Sciences, Kerala University of Digital Sciences, Innovation and Technology, Thiruvananthapuram, India"
                ]
            },
            {
                "name": "T. K. Ajay Krishnan",
                "labs": [
                    "NLP for Social Good Laboratory, School of Digital Sciences, Kerala University of Digital Sciences, Innovation and Technology, Thiruvananthapuram, India"
                ]
            },
            {
                "name": "Ali Daud",
                "labs": [
                    "Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Ameen Banjar",
                "labs": [
                    "Department of Information Systems and Technology, College of Computer Science and Engineering (CCSE), University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Amal Bukhari",
                "labs": [
                    "Department of Information Systems and Technology, College of Computer Science and Engineering (CCSE), University of Jeddah, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Climate change",
                "Sentiment analysis",
                "Natural language processing",
                "Human factors",
                "User experience",
                "Social networking (online)",
                "Bidirectional control",
                "Encoders"
            ],
            "Author Keywords": [
                "Climate change",
                "sentiment analysis",
                "climateBERT",
                "public discourse",
                "natural language processing",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks",
        "Link": "https://ieeexplore.ieee.org/document/10534765/",
        "Abstract": "This research paper presents a comprehensive comparative study assessing the quality of annotations in Turkish, Indonesian, and Minangkabau Natural Language Processing (NLP) tasks, with a specific focus on the contrast between annotations generated by human annotators and those produced by Large Language Models (LLMs). In the context of NLP, high-quality annotations play a pivotal role in training and evaluating machine-learning models. The study encompasses three core NLP tasks: topic classification, tweet sentiment analysis, and emotion classification, each reflecting a distinct aspect of text analysis. The research methodology incorporates a meticulously curated dataset sourced from a variety of text data, spanning diverse topics and emotions. Human annotators, proficient in the Turkish, Indonesian, and Minangkabau language, were tasked with producing high-quality annotations, adhering to comprehensive annotation guidelines. Additionally, fine-tuned Turkish LLMs were employed to generate annotations for the same tasks. The evaluation process employed precision, recall, and F1-score metrics, tailored to each specific NLP task. The findings of this study underscore the nuanced nature of annotation quality. While LLM-generated annotations demonstrated competitive quality, particularly in sentiment analysis, human-generated annotations consistently outperformed LLM-generated ones in more intricate NLP tasks. The observed differences highlight LLM limitations in understanding context and addressing ambiguity. This research contributes to the ongoing discourse on annotation sources in Turkish, Indonesian, and Minangkabau NLP, emphasizing the importance of judicious selection between human and LLM-generated annotations. It also underscores the necessity for continued advancements in LLM capabilities, as they continue to reshape the landscape of data annotation in NLP and machine learning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3402809",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Arbi Haza Nasution",
                "labs": [
                    "Department of Informatics Engineering, Universitas Islam Riau, Pekanbaru, Riau, Indonesia"
                ]
            },
            {
                "name": "Aytuğ Onan",
                "labs": [
                    "Department of Computer Engineering, College of Engineering and Architecture, İzmir Kâtip Çelebi University, İzmir, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Task analysis",
                "Chatbots",
                "Sentiment analysis",
                "Natural language processing",
                "Reliability",
                "Data models"
            ],
            "Author Keywords": [
                "Annotation quality",
                "emotion classification",
                "Indonesian language processing",
                "language models",
                "low-resource languages",
                "natural language processing",
                "sentiment analysis",
                "topic classification",
                "Turkish language processing"
            ]
        }
    },
    {
        "Title": "A Comprehensive Review of NLP Techniques for Military Terminologies and Information Operations on Social Media",
        "Link": "https://ieeexplore.ieee.org/document/11146650/",
        "Abstract": "This paper presents a comprehensive study aimed at systematically analyzing and evaluating natural language processing (NLP) techniques for military information operations, with a special focus on social media intelligence. Among an ever-growing complicated information environment, NLP methods like sentiment analysis, named entity recognition, and topic modeling have been essential in tracking online propaganda efforts, discovering emerging issues and threats globally with dialogues on military operations. These techniques make an impact on available decision making via situational awareness and getting the added extraction from volumes of unstructured data outputs thus increasing the overall strategic benefits to military organizations. There are technical and operational challenges concerning the use of NLP in a military context such as requirements for real-time data processing; language diversity; and maintaining data privacy while preserving ethical standards. To address these challenges, the study conducts an exhaustive survey of NLP methods, reviewing their range of applications, and highlights the relevance of several approaches for military information operations, with special emphasis on social media intelligence. The work further provides discussion on the comprehensive adoption of artificial intelligence (AI), edge computing, and multilingual NLP models for enhancing adaptability, efficiency, and transparency of the systems. It also extols the need for explainable AI (XAI) to improve accountability and trust by making term or even whole early warning systems derived from NLP analyses, transparent and interpretable for these military research applications with significant financial consequences. The paper also emphasizes the strategic importance of multilingual and multimodal analysis and the integration of specialized military lexicons to improve the contextual understanding of military discourse in social media environments. We also elucidate the important capabilities of NLP in enabling military operations to be responsive, rapid and data-driven while also adapting to the evolving nature of warfare. Key conclusions suggest that applying advanced NLP tools enhances situational awareness, enables timely threat detection, and supports more agile, data-informed decision-making within modern military operations. The paper shows a perspective to optimize NLP and AI technologies, leveraging various perspectives to benefit the operational needs of military and defense sectors in more data-rich environments.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605354",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tamara Zhukabayeva",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Department of Information Systems, L. N. Gumilyov Eurasian National University, Astana, Kazakhstan"
                ]
            },
            {
                "name": "Zulfiqar Ahmad",
                "labs": [
                    "Department of Computer Science and Information Technology, Hazara University, Mansehra, Pakistan"
                ]
            },
            {
                "name": "Aigerim Yerimbetova",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Global Education and Training, University of Illinois Urbana–Champaign, Champaign, IL, USA"
                ]
            },
            {
                "name": "Madina Sambetbayeva",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Department of Information Systems, L. N. Gumilyov Eurasian National University, Astana, Kazakhstan"
                ]
            },
            {
                "name": "Duman Telman",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Global Education and Training, University of Illinois Urbana–Champaign, Champaign, IL, USA"
                ]
            },
            {
                "name": "Abdygalym Bayangali",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Department of Information Systems, L. N. Gumilyov Eurasian National University, Astana, Kazakhstan",
                    "Department of Software Engineering, Satbayev University, Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Elmira Daiyrbayeva",
                "labs": [
                    "Laboratory of Computer Engineering of Intelligent Systems, Institute of Information and Computational Technologies, Almaty, Kazakhstan",
                    "Department of Software Engineering, Satbayev University, Almaty, Kazakhstan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Social networking (online)",
                "Military computing",
                "Military communication",
                "Sentiment analysis",
                "Real-time systems",
                "Explainable AI",
                "Organizations",
                "Multilingual",
                "Decision making"
            ],
            "Author Keywords": [
                "Natural language processing",
                "military information operations",
                "social media analysis",
                "sentiment analysis",
                "edge computing",
                "data privacy",
                "multilingual analysis",
                "explainable AI"
            ]
        }
    },
    {
        "Title": "Leveraging NLP Techniques for Privacy Requirements Engineering in User Stories",
        "Link": "https://ieeexplore.ieee.org/document/10430095/",
        "Abstract": "Privacy requirements engineering acts as a role to systematically elicit privacy requirements from system requirements and legal requirements such as the GDPR. Many methodologies have been proposed, but the majority of them are focused on the waterfall approach, making adopting privacy engineering in agile software development difficult. The other major issue is that the process currently is to a high degree manual. This paper focuses on closing these gaps through the development of a machine learning-based approach for identifying privacy requirements in an agile software development environment, employing natural language processing (NLP) techniques. Our method aims to allow agile teams to focus on functional requirements while NLP tools assist them in generating privacy requirements. The main input for our method is a collection of user stories, which are typically used to identify functional requirements in agile software development. The NLP approach is then used to automate some human-intensive tasks such as identifying personal data and creating data flow diagrams from user stories. The data flow diagram forms the basis for the automatic creation of privacy requirements. Our evaluation shows that our NLP method achieves a fairly good performance in terms of F-Measure. We are also demonstrate the feasibility of our NLP approach in CamperPlus project. Lastly, we are developing a tool to integrate our NLP approach into the privacy requirements engineering pipeline, allowing for manual editing of results so that agile teams can maintain control over the automated approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3364533",
            "Date of Publication": "08 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guntur Budi Herwanto",
                "labs": [
                    "Faculty of Computer Science, University of Vienna, Vienna, Austria",
                    "Department of Computer Science and Electronics, Universitas Gadjah Mada, Yogyakarta, Indonesia"
                ]
            },
            {
                "name": "Gerald Quirchmayr",
                "labs": [
                    "Faculty of Computer Science, University of Vienna, Vienna, Austria"
                ]
            },
            {
                "name": "A. Min Tjoa",
                "labs": [
                    "Faculty of Computer Science, University of Vienna, Vienna, Austria",
                    "Institute of Information Engineering TU WIEN, Wien, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Natural language processing",
                "Requirements engineering",
                "Data protection",
                "Agile software development",
                "Planning",
                "Manuals",
                "Software development management",
                "User experience"
            ],
            "Author Keywords": [
                "Privacy requirements engineering",
                "natural language processing",
                "agile software development",
                "user stories"
            ]
        }
    },
    {
        "Title": "Automated Metric Analysis of Spanish Poetry: Two Complementary Approaches",
        "Link": "https://ieeexplore.ieee.org/document/9389793/",
        "Abstract": "The automatic metric analysis (commonly referred to as scansion) of Spanish poetry is not a trivial problem since it combines the nuances of the language, the different poetic traditions related to melodic patterns, and the personal stylistic preferences and intentions of the author. In this paper, we explore two alternative algorithmic approaches tailored to different applications scenarios. The first approach, Rantanplan, is a rule-based method that consists of four Natural Language Processing modules that work together to perform scansion and other related analysis: Part of Speech tagging, syllabification, stress assignment, and metrical adjustment. The second approach, Jumper, explores the possibility of performing scansion without syllabification, with a twofold purpose: to minimize the errors propagated in different parts of the linguistic processing pipeline (including the syllabification step), and to improve the efficiency of the process. Both systems outperform the state of the art and provide either a more informative solution (suitable, for instance, for teaching purposes) or a more efficient processing (when a correct scansion is all the linguistic knowledge required, as in scholar philological studies). The combined use of both systems turns out to provide a practical tool to clean-up manual annotation errors in corpora.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3069635",
            "Date of Publication": "30 March 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guillermo Marco",
                "labs": [
                    "Research Group in NLP & IR, National Distance Education University, Madrid, Spain"
                ]
            },
            {
                "name": "Javier De La Rosa",
                "labs": [
                    "Laboratory of Innovation on Digital humaities (LINHD), National Distance Education University, Madrid, Spain"
                ]
            },
            {
                "name": "Julio Gonzalo",
                "labs": [
                    "Research Group in NLP & IR, National Distance Education University, Madrid, Spain"
                ]
            },
            {
                "name": "Salvador Ros",
                "labs": [
                    "Laboratory of Innovation on Digital humaities (LINHD), National Distance Education University, Madrid, Spain"
                ]
            },
            {
                "name": "Elena González-Blanco",
                "labs": [
                    "IE School of Human Sciences and Technology, IE University, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tools",
                "Stress",
                "Measurement",
                "Natural language processing",
                "Manuals",
                "Annotations",
                "Task analysis"
            ],
            "Author Keywords": [
                "Natural language processing",
                "digital humanities",
                "automated metric analysis",
                "scansion",
                "corpus annotation",
                "poetry",
                "Spanish"
            ]
        }
    },
    {
        "Title": "Accelerating Multilingual Cryptocurrency Forensics: An NLP-Driven Approach for Efficient Mnemonic Identification",
        "Link": "https://ieeexplore.ieee.org/document/10838568/",
        "Abstract": "The increasing use of cryptocurrencies in criminal activities presents significant challenges to society and the judicial system, particularly in tracking and seizing illicit digital assets. Among all relevant digital evidence, mnemonic phrases, which are critical for accessing cryptocurrency wallets, are crucial digital evidence for confiscating criminal proceeds and conducting investigations. However, traditional digital forensics tools, such as the Mnemonic Library Matching Method, lack flexibility and efficiency when handling cryptocurrency-related data. This study introduces an innovative Natural Language Processing (NLP) and deep learning approach for rapid mnemonic identification across 11 languages, including English, Spanish, and Japanese. We trained and compared four NLP deep learning models: RNN, LSTM, BiLSTM, and TextCNN, on a large-scale, real-world dataset. Our analysis reveals that the Text Convolutional Neural Network (TextCNN) model exhibits superior performance, achieving a 99.9993% accuracy rate, nearly matching the 100% accuracy of the Mnemonic Library Matching Method. Crucially, our TextCNN-driven approach processes data 40.47 times faster than the traditional method, significantly enhancing efficiency in time-sensitive forensic environments. This NLP-driven method not only maintains high accuracy while dramatically reducing processing time but also offers greater adaptability for diverse forensic needs compared to traditional techniques. By enabling more effective tracking and seizure of criminal assets, this approach aims to address the broader societal and judicial challenges posed by cryptocurrency-related criminal activities. Our research showcases the potential of NLP and deep learning in digital forensics, providing law enforcement with advanced tools for investigating cryptocurrency-related crimes and curbing the misuse of cryptocurrencies in illicit activities.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3528829",
            "Date of Publication": "13 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hsin-Hsiung Kao",
                "labs": [
                    "Department of Information Management, Central Police University, Taoyuan, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Digital forensics",
                "Natural language processing",
                "Accuracy",
                "Deep learning",
                "Bitcoin",
                "Libraries",
                "Multilingual",
                "Law enforcement",
                "Data mining",
                "Data models"
            ],
            "Author Keywords": [
                "Cryptocurrency crime",
                "deep learning",
                "digital forensics",
                "mnemonic identification",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "The Use of NLP-Based Text Representation Techniques to Support Requirement Engineering Tasks: A Systematic Mapping Review",
        "Link": "https://ieeexplore.ieee.org/document/9794783/",
        "Abstract": "Natural Language Processing (NLP) is widely used to support the automation of different Requirements Engineering (RE) tasks. Most of the proposed approaches start with various NLP steps that analyze requirements statements, extract their linguistic information, and convert them to easy-to-process representations, such as lists of features or embedding-based vector representations. These NLP-based representations are usually used at a later stage as inputs for machine learning techniques or rule-based methods. Thus, requirements representations play a major role in determining the accuracy of different approaches. In this paper, we conducted a survey in the form of a systematic literature mapping (classification) to find out (1) what are the representations used in RE tasks literature, (2) what is the main focus of these works, (3) what are the main research directions in this domain, and (4) what are the gaps and potential future directions. After compiling an initial pool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we obtained a final pool containing 104 relevant papers. Our survey shows that the research direction has changed from the use of lexical and syntactic features to the use of advanced embedding techniques, especially in the last two years. Using advanced embedding representations has proved its effectiveness in most RE tasks (such as requirement analysis, extracting requirements from reviews and forums, and semantic-level quality tasks). However, representations that are based on lexical and syntactic features are still more appropriate for other RE tasks (such as modeling and syntax-level quality tasks) since they provide the required information for the rules and regular expressions used when handling these tasks. In addition, we identify four gaps in the existing literature, why they matter, and how future research can begin to address them.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3182372",
            "Date of Publication": "13 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Riad Sonbol",
                "labs": [
                    "Department of Informatics, Higher Institute for Applied Sciences and Technology (HIAST), Damascus, Syria"
                ]
            },
            {
                "name": "Ghaida Rebdawi",
                "labs": [
                    "Department of Informatics, Higher Institute for Applied Sciences and Technology (HIAST), Damascus, Syria"
                ]
            },
            {
                "name": "Nada Ghneim",
                "labs": [
                    "Faculty of Information and Communication Technology, Arab International University (AIU), Damascus, Syria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Semantics",
                "Syntactics",
                "Software",
                "Requirements engineering",
                "Systematics",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Natural language processing",
                "requirements engineering",
                "requirements representation",
                "syntax",
                "semantic"
            ]
        }
    },
    {
        "Title": "Unlink the Link Between COVID-19 and 5G Networks: An NLP and SNA Based Approach",
        "Link": "https://ieeexplore.ieee.org/document/9262907/",
        "Abstract": "Social media facilitates rapid dissemination of information for both factual and fictional information. The spread of non-scientific information through social media platforms such as Twitter has potential to cause damaging consequences. Situations such as the COVID-19 pandemic provides a favourable environment for misinformation to thrive. The upcoming 5G technology is one of the recent victims of misinformation and fake news and has been plagued with misinformation about the effects of its radiation. During the COVID-19 pandemic, conspiracy theories linking the cause of the pandemic to 5G technology have resonated with a section of people leading to outcomes such as destructive attacks on 5G towers. The analysis of the social network data can help to understand the nature of the information being spread and identify the commonly occurring themes in the information. The natural language processing (NLP) and the statistical analysis of the social network data can empower policymakers to understand the misinformation being spread and develop targeted strategies to counter the misinformation. In this paper, NLP based analysis of tweets linking COVID-19 to 5G is presented. NLP models including Latent Dirichlet allocation (LDA), sentiment analysis (SA) and social network analysis (SNA) were applied for the analysis of the tweets and identification of topics. An understanding of the topic frequencies, the inter-relationships between topics and geographical occurrence of the tweets allows identifying agencies and patterns in the spread of misinformation and equips policymakers with knowledge to devise counter-strategies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3039168",
            "Date of Publication": "18 November 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Bahja",
                "labs": [
                    "College of Engineering and Physical Sciences (EPS), University of Birmingham, Birmingham, U.K."
                ]
            },
            {
                "name": "Ghazanfar Ali Safdar",
                "labs": [
                    "School of Computer Science and Technology, University of Bedfordshire, Luton, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "COVID-19",
                "5G mobile communication",
                "Social networking (online)",
                "Pandemics",
                "Coherence",
                "Blogs",
                "Analytical models"
            ],
            "Author Keywords": [
                "5G conspiracy",
                "corona-5G link",
                "COVID-19",
                "radiation scare",
                "topic modelling",
                "tweet analysis"
            ]
        }
    },
    {
        "Title": "NLP-Based Recommendation Approach for Diverse Service Generation",
        "Link": "https://ieeexplore.ieee.org/document/10403887/",
        "Abstract": "In this study, we examine the potential of language models for natural language processing (NLP)-based recommendations, with a distinct focus on predicting users’ next product purchases based on their prior purchasing patterns. Our model specifically harnesses tokenized rather than complete product names for learning. This granularity allows for a refined understanding of the interrelations among different products. For instance, items like ‘Chocolate Milk’ and ‘Coffee Milk’ find linkage through the shared token ‘Milk.’ Additionally, we explored the impact of various n-grams (unigrams, bigrams, and trigrams) in tokenization to further refine our understanding of product relationships and recommendation efficacy. This nuanced method paves the way for generating product names that might not exist in current retail settings, exemplified by concoctions like ‘Coffee Chocolate Milk.’ Such potential offerings can provide retailers with fresh product brainstorming opportunities. Furthermore, scrutiny of the frequency of these generated product name tokens can reveal prospective trends in purchasing keywords. This facilitates enterprises in creative brainstorming of novel products and swiftly responding to the dynamic demands and trends of consumers. The datasets used in this study come from UK e-Commerce and Instacart Data, comprising 71,205 and 166,440 rows, respectively. This investigation juxtaposes the NLP-based recommendation model, which employs tokenization, with its non-tokenized counterpart, leveraging Hit-Rate and mean reciprocal rank (MRR) as evaluative benchmarks. The outcomes distinctly favor the tokenized NLP-based recommendation model across all evaluated metrics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3355546",
            "Date of Publication": "18 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Baek Jeong",
                "labs": [
                    "Department of Big Data Analytics, Kyung Hee University, Seoul, South Korea"
                ]
            },
            {
                "name": "Kyoung Jun Lee",
                "labs": [
                    "Department of Big Data Analytics, Kyung Hee University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Transformers",
                "Recommender systems",
                "Dairy products",
                "Tokenization",
                "Market research",
                "Semantics"
            ],
            "Author Keywords": [
                "Natural language processing",
                "recommendation",
                "tokenization",
                "n-grams",
                "service generation",
                "new product brainstorming",
                "keyword trend forecasting"
            ]
        }
    },
    {
        "Title": "Medical Information Extraction With NLP-Powered QABots: A Real-World Scenario",
        "Link": "https://ieeexplore.ieee.org/document/10651607/",
        "Abstract": "The advent of computerized medical recording systems in healthcare facilities has made data retrieval tasks easier, compared to manual recording. Nevertheless, the potential of the information contained within medical records remains largely untapped, mostly due to the time and effort required to extract data from unstructured documents. Natural Language Processing (NLP) represents a promising solution to this challenge, as it enables the use of automated text-mining tools for clinical practitioners. In this work, we present the architecture of the Virtual Dementia Institute (IVD), a consortium of sixteen Italian hospitals, using the NLP Extraction and Management Tool (NEMT), a (semi-) automated end-to-end pipeline that extracts relevant information from clinical documents and stores it in a centralized REDCap database. After defining a common Case Report Form (CRF) across the IVD hospitals, we implemented NEMT, the core of which is a Question Answering Bot (QABot) based on a modern NLP model. This QABot is fine-tuned on thousands of examples from IVD centers. Detailed descriptions of the process to define a common minimum dataset, Inter-Annotator Agreement calculated on clinical documents, and NEMT results are provided. The best QABot performance show an Exact Match score (EM) of 78.1%, a F1-score of 84.7%, a Lenient Accuracy (LAcc) of 0.834, and a Mean Reciprocal Rank (MRR) of 0.810. EM and F1 scores outperform the same metrics obtained with ChatGPTv3.5 (68.9% and 52.5%, respectively). With NEMT the IVD has been able to populate a database that will contain data from thousands of Italian patients, all screened with the same procedure. NEMT represents an efficient tool that paves the way for medical information extraction and exploitation for new research studies.",
        "Details": {
            "DOI": "10.1109/JBHI.2024.3450118",
            "Date of Publication": "27 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Biomedical and Health Informatics"
        },
        "issn_info": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "authors_data": [
            {
                "name": "Claudio Crema",
                "labs": [
                    "Laboratory of Neuroinformatics, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli, Brescia, Italy"
                ]
            },
            {
                "name": "Federico Verde",
                "labs": [
                    "Department of Neurology and Laboratory of Neuroscience, IRCCS Istituto Auxologico Italiano, Milan, Italy",
                    "Department of Pathophysiology and Transplantation of the Dino Ferrari Centre, Università degli Studi di Milano, Milan, Italy"
                ]
            },
            {
                "name": "Pietro Tiraboschi",
                "labs": [
                    "Division of Neurology, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy"
                ]
            },
            {
                "name": "Camillo Marra",
                "labs": [
                    "Memory Clinic, IRCCS Policlinico A. Gemelli Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Andrea Arighi",
                "labs": [
                    "Neurodegenerative Diseases Unit, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy"
                ]
            },
            {
                "name": "Silvia Fostinelli",
                "labs": [
                    "MAC - Memory Clinic and Molecular Markers Laboratory, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli, Brescia, Italy"
                ]
            },
            {
                "name": "Guido Maria Giuffré",
                "labs": [
                    "Memory Clinic, IRCCS Policlinico A. Gemelli Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Vera Pacoova Dal Maschio",
                "labs": [
                    "Department of Neuroscience “Rita Levi Montalcini”, University of Torino, Torino, Italy",
                    "Neurology 2 Unit, A.O.U. Città della Salute e della Scienza di Torino, Torino, Italy"
                ]
            },
            {
                "name": "Federica L'Abbate",
                "labs": [
                    "Memory Clinic, IRCCS Policlinico A. Gemelli Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Federica Solca",
                "labs": [
                    "Department of Neurology and Laboratory of Neuroscience, IRCCS Istituto Auxologico Italiano, Milan, Italy"
                ]
            },
            {
                "name": "Barbara Poletti",
                "labs": [
                    "Department of Neurology and Laboratory of Neuroscience, IRCCS Istituto Auxologico Italiano, Milan, Italy",
                    "Department of Oncology and Hemato-Oncology, Università degli Studi di Milano, Milan, Italy"
                ]
            },
            {
                "name": "Vincenzo Silani",
                "labs": [
                    "Department of Neurology and Laboratory of Neuroscience, IRCCS Istituto Auxologico Italiano, Milan, Italy",
                    "Department of Pathophysiology and Transplantation of the Dino Ferrari Centre, Università degli Studi di Milano, Milan, Italy"
                ]
            },
            {
                "name": "Emanuela Rotondo",
                "labs": [
                    "Neurodegenerative Diseases Unit, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy"
                ]
            },
            {
                "name": "Vittoria Borracci",
                "labs": [
                    "Neurodegenerative Diseases Unit, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy"
                ]
            },
            {
                "name": "Roberto Vimercati",
                "labs": [
                    "Neurodegenerative Diseases Unit, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy"
                ]
            },
            {
                "name": "Valeria Crepaldi",
                "labs": [
                    "Division of Neurology, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy"
                ]
            },
            {
                "name": "Emanuela Inguscio",
                "labs": [
                    "Division of Neurology, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy"
                ]
            },
            {
                "name": "Massimo Filippi",
                "labs": [
                    "Neurology Unit, IRCCS Ospedale San Raffaele, Milano, Italy",
                    "Neurorehabilitation Unit, Neurophysiology Service, IRCCS Ospedale San Raffaele, Milano, Italy",
                    "Neuroimaging Research Unit, Division of Neuroscience, IRCCS Ospedale San Raffaele, Milano, Italy",
                    "Vita-Salute San Raffaele University, Milano, Italy"
                ]
            },
            {
                "name": "Francesca Caso",
                "labs": [
                    "Neurology Unit, IRCCS Ospedale San Raffaele, Milano, Italy"
                ]
            },
            {
                "name": "Alessandra Maria Rosati",
                "labs": [
                    "Memory Clinic, IRCCS Policlinico A. Gemelli Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Davide Quaranta",
                "labs": [
                    "Neurology Unit, IRCCS Policlinico A. Gemelli Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Giuliano Binetti",
                "labs": [
                    "MAC - Memory Clinic and Molecular Markers Laboratory, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli, Brescia, Italy"
                ]
            },
            {
                "name": "Ilaria Pagnoni",
                "labs": [
                    "Neuropsychology Unit, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli, Brescia, Italy"
                ]
            },
            {
                "name": "Manuela Morreale",
                "labs": [
                    "Oasi Research Institute-IRCCS, Troina, Italy"
                ]
            },
            {
                "name": "Francesca Burgio",
                "labs": [
                    "Neuropsychology Department, IRCCS San Camillo Hospital, Venice, Italy"
                ]
            },
            {
                "name": "Michelangelo Stanzani-Maserati",
                "labs": [
                    "IRCCS Istituto delle Scienze Neurologiche di Bologna, Bologna, Italy"
                ]
            },
            {
                "name": "Sabina Capellari",
                "labs": [
                    "IRCCS Istituto delle Scienze Neurologiche di Bologna, Bologna, Italy",
                    "Department of Biomedical and Neuromotor Sciences, University of Bologna, Bologna, Italy"
                ]
            },
            {
                "name": "Matteo Pardini",
                "labs": [
                    "Department of Neuroscience, Rehabilitation, Ophthalmology, Genetics, Maternal and Child Health (DINOGMI), University of Genoa, Genoa, Italy",
                    "IRCCS Ospedale Policlinico S. Martino, Genoa, Italy"
                ]
            },
            {
                "name": "Nicola Girtler",
                "labs": [
                    "Department of Neuroscience, Rehabilitation, Ophthalmology, Genetics, Maternal and Child Health (DINOGMI), University of Genoa, Genoa, Italy",
                    "IRCCS Ospedale Policlinico S. Martino, Genoa, Italy"
                ]
            },
            {
                "name": "Federica Piras",
                "labs": [
                    "Clinical Neuroscience and Neurorehabilitation Department, IRCCS Santa Lucia Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Fabrizio Piras",
                "labs": [
                    "Clinical Neuroscience and Neurorehabilitation Department, IRCCS Santa Lucia Foundation, Rome, Italy"
                ]
            },
            {
                "name": "Stefania Lalli",
                "labs": [
                    "Department of Neurology, IRCCS Humanitas Research Hospital, Milan, Italy"
                ]
            },
            {
                "name": "Elena Perdixi",
                "labs": [
                    "Department of Neurology, IRCCS Humanitas Research Hospital, Milan, Italy"
                ]
            },
            {
                "name": "Gemma Lombardi",
                "labs": [
                    "Department of Neurosciences, Psychology, Drug Research and Child Health (NEUROFARBA), University of Florence, Florence, Italy",
                    "IRCCS Fondazione Don Carlo Gnocchi ONLUS, Florence, Italy"
                ]
            },
            {
                "name": "Sonia Di Tella",
                "labs": [
                    "Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy",
                    "IRCCS Fondazione Don Carlo Gnocchi ONLUS, Milan, Italy"
                ]
            },
            {
                "name": "Alfredo Costa",
                "labs": [
                    "Unit of Behavioral Neurology, IRCCS Mondino Foundation Pavia, Pavia, Italy",
                    "Department of Brain and Behavioral Sciences, University of Pavia, Pavia, Italy"
                ]
            },
            {
                "name": "Marco Capelli",
                "labs": [
                    "Unit of Behavioral Neurology, IRCCS Mondino Foundation Pavia, Pavia, Italy"
                ]
            },
            {
                "name": "Cira Fundarò",
                "labs": [
                    "Neurophysiopatology Unit, IRCCS Istituti Clinici Scientifici Maugeri, Pavia, Italy"
                ]
            },
            {
                "name": "Marina Manera",
                "labs": [
                    "Psychology Unit, IRCCS Istituti Clinici Scientifici Maugeri, Pavia, Italy"
                ]
            },
            {
                "name": "Cristina Muscio",
                "labs": [
                    "Division of Neurology, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy",
                    "ASST Bergamo Ovest, Bergamo, Italy"
                ]
            },
            {
                "name": "Elisa Pellencin",
                "labs": [
                    "Division of Neurology, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy"
                ]
            },
            {
                "name": "Raffaele Lodi",
                "labs": [
                    "IRCCS Istituto delle Scienze Neurologiche di Bologna, Bologna, Italy",
                    "Department of Biomedical and Neuromotor Sciences, University of Bologna, Bologna, Italy"
                ]
            },
            {
                "name": "Fabrizio Tagliavini",
                "labs": [
                    "Scientific Directorate, Fondazione IRCCS Istituto Neurologico Carlo Besta, Milan, Italy"
                ]
            },
            {
                "name": "Alberto Redolfi",
                "labs": [
                    "Laboratory of Neuroinformatics, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli, Brescia, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Data mining",
                "Question answering (information retrieval)",
                "Text mining",
                "Bioinformatics",
                "Clinical neuroscience",
                "Relational databases"
            ],
            "Author Keywords": [
                "Natural language processing",
                "question answering (information retrieval)",
                "text mining",
                "biomedical informatics",
                "clinical neuroscience"
            ]
        }
    },
    {
        "Title": "Enriching the transfer learning with pre-trained lexicon embedding for low-resource neural machine translation",
        "Link": "https://ieeexplore.ieee.org/document/9515788/",
        "Abstract": "Most State-Of-The-Art (SOTA) Neural Machine Translation (NMT) systems today achieve outstanding results based only on large parallel corpora. The large-scale parallel corpora for high-resource languages is easily obtainable. However, the translation quality of NMT for morphologically rich languages is still unsatisfactory, mainly because of the data sparsity problem encountered in Low-Resource Languages (LRLs). In the low-resource NMT paradigm, Transfer Learning (TL) has been developed into one of the most efficient methods. It is difficult to train the model on high-resource languages to include the information in both parent and child models, as well as the initially trained model that only contains the lexicon features and word embeddings of the parent model instead of the child languages feature. In this work, we aim to address this issue by proposing the language-independent Hybrid Transfer Learning (HTL) method for LRLs by sharing lexicon embedding between parent and child languages without leveraging back translation or manually injecting noises. First, we train the High-Resource Languages (HRLs) as the parent model with its vocabularies. Then, we combine the parent and child language pairs using the oversampling method to train the hybrid model initialized by the previously parent model. Finally, we fine-tune the morphologically rich child model using a hybrid model. Besides, we explore some exciting discoveries on the original TL approach. Experimental results show that our model consistently outperforms five SOTA methods in two languages Azerbaijani (Az) and Uzbek (Uz). Meanwhile, our approach is practical and significantly better, achieving improvements of up to 4.94 and 4.84 BLEU points for low-resource child languages Az ! Zh and Uz ! Zh, respectively.",
        "Details": {
            "DOI": "10.26599/TST.2020.9010029",
            "Date of Publication": "17 August 2021",
            "Publisher": "TUP",
            "Published In": "Tsinghua Science and Technology"
        },
        "issn_info": {
            "Electronic ISSN": "1007-0214"
        },
        "authors_data": [
            {
                "name": "Mieradilijiang Maimaiti",
                "labs": [
                    "Department of Computer Science and Technology, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Yang Liu",
                "labs": [
                    "Beijing Advanced Innovation Center for Language Resources, Beijing Academy of Artificial Intelligence, Beijing, China"
                ]
            },
            {
                "name": "Huanbo Luan",
                "labs": [
                    "Department of Computer Science and Technology, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Maosong Sun",
                "labs": [
                    "Department of Computer Science and Technology, Tsinghua University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Vocabulary",
                "Transfer learning",
                "Machine translation",
                "Data models",
                "Task analysis",
                "Artificial neural networks"
            ],
            "Author Keywords": [
                "artificial intelligence",
                "natural language processing",
                "neural network",
                "machine translation",
                "low-resource languages",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "Advanced NLP Models for Technical University Information Chatbots: Development and Comparative Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10440622/",
        "Abstract": "In order to achieve quality education as a defined one of the sustainable goals, it is necessary to provide information about the education system according to the stakeholders’ requirements. The process to obtain the information about university/institute is a critical stage in the academic journey of prospective students who are seeking information about the specific courses which makes that university/institute unique. This process begins with exploration to general information about universities through websites, rankings, and brochures from various sources. Most of the time, information available on different sources leads to discrepancies and influences student’s decisions. By addressing inquiries promptly and providing valuable information, universities can guide individuals in making informed choices about their academic future. To address this, the chatbot application is the most effective tool to be implemented and make it functional on university’s functional website. A chatbot is an artificially intelligent tool which can interact with humans and can mimic a conversation. This tool can be implemented using advanced Natural Language Processing (NLP) models to provide the pre-defined answers to the student’s queries. Chatbot is very helpful for query resolution during the counseling process of the institute as it will provide official/uniform information and can be accessed\n24×7\n. Therefore, the aim of this research work was to implement a chatbot using various NLP models and compare them to identify best one. In this work, five chatbot models were implemented using neural networks, TF-IDF vectorization, sequential modeling and pattern matching. From the results, it was observed that neural network-related models had better accuracy than TF-IDF and pattern matching model, and sequential modeling is the most accurate model because it prevents over-fitting. Furthermore, a chatbot having any kind of optimizer can improve the result and it is most important that pattern matching, and semantic analysis should be the parts of a chatbot for real time scenarios.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3368382",
            "Date of Publication": "20 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Girija Attigeri",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Ankit Agrawal",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Sucheta V. Kolekar",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Oral communication",
                "Artificial intelligence",
                "Virtual assistants",
                "Computational modeling",
                "Natural language processing",
                "Neural networks",
                "Pattern analysis",
                "Semantics",
                "Pattern matching",
                "Real-time systems",
                "Educational institutions",
                "Web design",
                "Web sites",
                "Content management",
                "Information management"
            ],
            "Author Keywords": [
                "Conversational AI",
                "natural language processing",
                "artificial intelligence",
                "chatbots",
                "neural networks",
                "sequential modeling",
                "pattern matching",
                "semantic analysis"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis of Twitter Data Using NLP Models: A Comprehensive Review",
        "Link": "https://ieeexplore.ieee.org/document/10883978/",
        "Abstract": "Social media platforms, particularly Twitter, have become vital sources for understanding public sentiment due to the rapid, large-scale generation of user opinions. Sentiment analysis of Twitter data has gained significant attention as a method for comprehending public attitudes, emotional responses, and trends which proves valuable in sectors such as marketing, politics, public health, and customer services. In this paper, we present a systematic review of research conducted on sentiment analysis using natural language processing (NLP) models, with a specific focus on Twitter data. We discuss various approaches and methodologies, including machine learning, deep learning, and hybrid models with their advantages, challenges, and performance metrics. The review identifies key NLP models commonly employed, such as transformer-based architectures like BERT, GPT, etc. Additionally, this study assesses the impact of pre-processing techniques, feature extraction methods, and sentiment lexicons on the effectiveness of sentiment analysis. The findings aim to provide researchers and practitioners with a comprehensive overview of current methodologies, insights into emerging trends, and guidance for future developments in the field of sentiment analysis on Twitter data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3541494",
            "Date of Publication": "13 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aish Albladi",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Minarul Islam",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Cheryl Seals",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Sentiment analysis",
                "Analytical models",
                "Natural language processing",
                "Context modeling",
                "Transformers",
                "Data models",
                "Deep learning",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "natural language processing",
                "machine learning",
                "deep learning",
                "GPT",
                "BERT"
            ]
        }
    },
    {
        "Title": "Fast Cross-Platform Binary Code Similarity Detection Framework Based on CFGs Taking Advantage of NLP and Inductive GNN",
        "Link": "https://ieeexplore.ieee.org/document/10410589/",
        "Abstract": "Cross-platform binary code similarity detection aims at detecting whether two or more pieces of binary code are similar or not. Existing approaches that combine control flow graphs (CFGs)-based function representation and graph convolutional network (GCN)-based similarity analysis are the best-performing ones. Due to a large amount of convolutional computation and the loss of structural information, the use of convolution networks will inevitably bring problems such as high overhead and sometimes inaccuracy. To address these issues, we propose a fast cross-platform binary code similarity detection framework that takes advantage of natural language processing (NLP) and inductive graph neural network (GNN) for basic blocks embedding and function representation respectively by simulating extracting structural features and temporal features. GNN's node-centric and small batch is a suitable training way for large CFGs, it can greatly reduce computational overhead. Various NLP basic block embedding models and GNNs are evaluated. Experimental results show that the scheme with long short term memory (LSTM) for basic blocks embedding and inductive learning-based GraphSAGE(GAE) for function representation outperforms the state-of-the-art works. In our framework, we can take only 45% overhead. Improve efficiency significantly with a small performance trade-off.",
        "Details": {
            "DOI": "10.23919/cje.2022.00.228",
            "Date of Publication": "22 January 2024",
            "Publisher": "CIE",
            "Published In": "Chinese Journal of Electronics"
        },
        "issn_info": {
            "Electronic ISSN": "2075-5597",
            "Print ISSN": "1022-4653"
        },
        "authors_data": [
            {
                "name": "Jinxue Peng",
                "labs": [
                    "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Yong Wang",
                "labs": [
                    "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Jingfeng Xue",
                "labs": [
                    "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Zhenyan Liu",
                "labs": [
                    "School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Semantics",
                "Process control",
                "Binary codes",
                "Feature extraction",
                "Natural language processing",
                "Graph neural networks"
            ],
            "Author Keywords": [
                "Control flow graph",
                "Natural language processing",
                "Inductive graph neural network",
                "Binary code similarity detection"
            ]
        }
    },
    {
        "Title": "Leveraging ChatGPT for Enhancing Arabic NLP: Application for Semantic Role Labeling and Cross-Lingual Annotation Projection",
        "Link": "https://ieeexplore.ieee.org/document/10820541/",
        "Abstract": "Semantic role labeling involves assigning semantic roles to sentence arguments, providing rich information for various NLP tasks and applications. Annotated corpora with semantic roles are a critical factor in improving the performance of semantic-based models. Besides, Arabic as a low resourced language, have to pay more attention to alternative methods to build such annotated corpora. To this end, two traditional methods have been intensively used, namely, manual annotation and crowed-resourced annotation. The former is highly precise but it demands substantial training and extensive resources, while, the latter, reduce human effort but often results in lower-quality annotations. Recently, Large language model (LLM) based conversational systems like ChatGPT have emerged as a promising tool for text annotation across various NLP tasks. In this paper, we leverage ChatGPT for two main sub-tasks in Arabic language processing. (1) Creating an Arabic annotated resource with emotional semantic roles from an English corpus, using cross-lingual annotation projection approach. (2) Annotating the Arabic corpus of emotional sentences with emotion categories and semantic roles. Furthermore, we evaluate ChatGPT’s potential for translating English sentences into Arabic. From the perspective of generalization, we test the performance of open-LLMs, specifically, mBERT, and mBART for the same tasks. The evaluation process includes assessing the impact of sentence complexity on the performance of ChatGPT, and open-LLMs in semantic role labeling, and cross-lingual annotation projection. We compared the obtained zero-shot annotation accuracy with that of human base annotations, where the GPT results achieved an accuracy of 0.94 for cross-lingual projection and 0.76 in semantic role labelling, While the open-LLMs achieved notable accuracies of 0.72, and 0.38 respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3525493",
            "Date of Publication": "02 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ferial Senator",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria",
                    "Department of Computer Science, Faculty of Sciences, Laboratory of Networks and Distributed Systems (LRSD), Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Abdelaziz Lakhfif",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Imene Zenbout",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Hanane Boutouta",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Chahrazed Mediani",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University-Ferhat ABBAS, Setif, Algeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Annotations",
                "Semantics",
                "Translation",
                "Labeling",
                "Accuracy",
                "Training",
                "Sentiment analysis",
                "Manuals",
                "Large language models"
            ],
            "Author Keywords": [
                "Semantic role labeling",
                "cross-lingual annotation projection",
                "emotion analysis",
                "ChatGPT",
                "Arabic language"
            ]
        }
    },
    {
        "Title": "Framework for Deep Learning-Based Language Models Using Multi-Task Learning in Natural Language Understanding: A Systematic Literature Review and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/9706456/",
        "Abstract": "Learning human languages is a difficult task for a computer. However, Deep Learning (DL) techniques have enhanced performance significantly for almost all-natural language processing (NLP) tasks. Unfortunately, these models cannot be generalized for all the NLP tasks with similar performance. NLU (Natural Language Understanding) is a subset of NLP including tasks, like machine translation, dialogue-based systems, natural language inference, text entailment, sentiment analysis, etc. The advancement in the field of NLU is the collective performance enhancement in all these tasks. Even though MTL (Multi-task Learning) was introduced before Deep Learning, it has gained significant attention in the past years. This paper aims to identify, investigate, and analyze various language models used in NLU and NLP to find directions for future research. The Systematic Literature Review (SLR) is prepared using the literature search guidelines proposed by Kitchenham and Charters on various language models between 2011 and 2021. This SLR points out that the unsupervised learning method-based language models show potential performance improvement. However, they face the challenge of designing the general-purpose framework for the language model, which will improve the performance of multi-task NLU and the generalized representation of knowledge. Combining these approaches may result in a more efficient and robust multi-task NLU. This SLR proposes building steps for a conceptual framework to achieve goals of enhancing the performance of language models in the field of NLU.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3149798",
            "Date of Publication": "07 February 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahul Manohar Samant",
                "labs": [
                    "Computer Science and Information Technology Department, Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India"
                ]
            },
            {
                "name": "Mrinal R. Bachute",
                "labs": [
                    "Department of Electronics and Telecommunication Engineering, Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India"
                ]
            },
            {
                "name": "Shilpa Gite",
                "labs": [
                    "Symbiosis Centre of Applied AI (SCAAI), Symbiosis International (Deemed University), Pune, India"
                ]
            },
            {
                "name": "Ketan Kotecha",
                "labs": [
                    "Symbiosis Centre of Applied AI (SCAAI), Symbiosis International (Deemed University), Pune, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Multitasking",
                "Transformers",
                "Feature extraction",
                "Deep learning",
                "Data models",
                "Symbiosis"
            ],
            "Author Keywords": [
                "Deep learning",
                "knowledge representation",
                "multi-task NLU",
                "unsupervised learning"
            ]
        }
    },
    {
        "Title": "NAS-Bench-NLP: Neural Architecture Search Benchmark for Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/9762315/",
        "Abstract": "Neural Architecture Search (NAS) is a promising and rapidly evolving research area. Training a large number of neural networks requires an exceptional amount of computational power, which makes NAS unreachable for those researchers who have limited or no access to high-performance clusters and supercomputers. A few benchmarks with precomputed neural architectures performances have been recently introduced to overcome this problem and ensure reproducible experiments. However, these benchmarks are only for the computer vision domain and, thus, are built from the image datasets and convolution-derived architectures. In this work, we step outside the computer vision domain by leveraging the language modeling task, which is the core of natural language processing (NLP). Our main contribution is as follows: we have provided search space of recurrent neural networks on the text datasets and trained 14k architectures within it; we have conducted both intrinsic and extrinsic evaluation of the trained models using datasets for semantic relatedness and language understanding evaluation; finally, we have tested several NAS algorithms to demonstrate how the precomputed results can be utilized. We consider that the benchmark will provide more reliable empirical findings in the community and stimulate progress in developing new NAS methods well suited for recurrent architectures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3169897",
            "Date of Publication": "22 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nikita Klyuchnikov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Ilya Trofimov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Ekaterina Artemova",
                "labs": [
                    "Models and methods for computational pragmatics Laboratory, Higher School of Economics University, Moscow, Russia",
                    "Huawei Noah’s Ark Lab, Moscow, Russia"
                ]
            },
            {
                "name": "Mikhail Salnikov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Maxim Fedorov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Alexander Filippov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Evgeny Burnaev",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer architecture",
                "Benchmark testing",
                "Task analysis",
                "Microprocessors",
                "Training",
                "Recurrent neural networks",
                "Transformers"
            ],
            "Author Keywords": [
                "Benchmark",
                "natural language processing",
                "neural architecture search",
                "recurrent neural network"
            ]
        }
    },
    {
        "Title": "CaPBug-A Framework for Automatic Bug Categorization and Prioritization Using NLP and Machine Learning Algorithms",
        "Link": "https://ieeexplore.ieee.org/document/9388660/",
        "Abstract": "Bug reports facilitate software development teams in improving the quality of software. These reports include significant information related to problems encountered within a software, possible enhancement suggestions, and other potential issues. Bug reports are typically complex and are too detailed; hence a lot of resources are required to analyze and process them manually. Moreover, it leads to delays in the resolution of high priority bugs. Accurate and timely processing of bug reports based on their category and priority plays a significant role in improving the quality of software maintenance. Therefore, an automated process of categorization and prioritization of bug reports is needed to address the aforementioned issues. Automated categorization and prioritization of bug reports have been explored recently by many researchers; however, limited progress has been made in this regard. In this research, we present a novel framework, titled CaPBug, for automated categorization and prioritization of bug reports. The framework is implemented using Natural Language Processing (NLP) and supervised machine learning algorithms. A baseline corpus is built with six categories and five prioritization levels by analyzing more than 2000 bug reports of Mozilla and Eclipse repository. Four classification algorithms i.e., Naive Bayes, Random Forest, Decision Tree, and Logistic Regression have been used to categorize and prioritize bug reports. We demonstrate that the CaPBug framework achieved an accuracy of 88.78% by using a Random Forest classifier with a textual feature for predicting the category. Similarly, using the CaPBug framework, an accuracy of 90.43% was achieved in predicting the priority of bug reports. Synthetic Minority Over-Sampling Technique (SMOTE) has been applied to address the class imbalance issue in priority classes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3069248",
            "Date of Publication": "29 March 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hafiza Anisa Ahmed",
                "labs": [
                    "Department of Computer Science and Software Engineering, Jinnah University for Women, Karachi, Pakistan"
                ]
            },
            {
                "name": "Narmeen Zakaria Bawany",
                "labs": [
                    "Department of Computer Science, National University of Computer and Emerging Sciences (NUCES), Karachi, Pakistan"
                ]
            },
            {
                "name": "Jawwad Ahmed Shamsi",
                "labs": [
                    "Department of Computer Science and Software Engineering, Jinnah University for Women, Karachi, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Software",
                "Machine learning algorithms",
                "Feature extraction",
                "Classification algorithms",
                "Prediction algorithms",
                "Location awareness"
            ],
            "Author Keywords": [
                "Bug reports",
                "natural language processing",
                "machine learning",
                "bug report categorization",
                "bug report prioritization"
            ]
        }
    },
    {
        "Title": "Empowering Real-Time Traffic Reporting Systems With NLP-Processed Social Media Data",
        "Link": "https://ieeexplore.ieee.org/document/9197640/",
        "Abstract": "Current urbanization trends are leading to heightened demand of smarter technologies to facilitate a variety of applications in intelligent transportation systems. Automated crowdsensing constitutes a strong base for ITS applications by providing novel and rich data streams regarding congestion tracking and real-time navigation. Along with these well-leveraged data streams, drivers and passengers tend to report traffic information to social media platforms. Despite their abundance, the use of social media data in ITS has gained more and more attention as of now. In this article, we develop an automated Natural Language Processing (NLP)-based framework to empower and complement traffic reporting solutions by text mining social media, extracting desired information, and generating alerts and warning for drivers. We employ the fine-tuned Bidirectional Encoder Representations from Transformers classification model to filer and classify data. Then, we apply the Question-Answering model to extract necessary information characterizing the reported incident such as its location, occurrence time, and nature of the incidents. Afterwards, we convert the collected information into alerts to be integrated into personal navigation assistants. Finally, we compare the recently posted incident reports from both official authorities and social media in order to provide more complete incident pictures and suggest some open research directions.",
        "Details": {
            "DOI": "10.1109/OJITS.2020.3024245",
            "Date of Publication": "15 September 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Intelligent Transportation Systems"
        },
        "issn_info": {
            "Electronic ISSN": "2687-7813"
        },
        "authors_data": [
            {
                "name": "Xiangpeng Wan",
                "labs": [
                    "School of System and Enterprise, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Michael C. Lucic",
                "labs": [
                    "School of System and Enterprise, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Hakim Ghazzai",
                "labs": [
                    "School of System and Enterprise, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Yehia Massoud",
                "labs": [
                    "School of System and Enterprise, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social network services",
                "Vehicles",
                "Data mining",
                "Navigation",
                "Urban areas",
                "Roads",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Intelligent transportation system",
                "natural language processing",
                "social media",
                "BERT",
                "question-answering",
                "name-entity recognition"
            ]
        }
    },
    {
        "Title": "NLP Powered Intent Based Network Management for Private 5G Networks",
        "Link": "https://ieeexplore.ieee.org/document/10097683/",
        "Abstract": "Intent driven networking holds the promise of simplifying network operations by allowing operators to use declarative, instead of imperative, interfaces. Adoption of this technology for 5G and beyond networks is however still in its infancy, where the required architectures, platforms, interfaces and algorithms are still being discussed. In this work, we present the design and implementation of a novel intent based platform for private 5G networks powered by a Natural Language Processing (NLP) interface. We demonstrate how our platform simplifies network operations in three relevant private network use cases, including: i) an intent based slice provisioning use case, ii) an intent based positioning use case, and iii) an intent based service deployment use case. Finally, all use cases are benchmarked in terms of intent provisioning time.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3265894",
            "Date of Publication": "10 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Joseph Mcnamara",
                "labs": [
                    "Ericsson LMI, Athlone, Westmeath, Ireland"
                ]
            },
            {
                "name": "Daniel Camps-Mur",
                "labs": [
                    "I2CAT Foundation, Barcelona, Spain"
                ]
            },
            {
                "name": "Meysam Goodarzi",
                "labs": [
                    "IHP—Leibniz-Institut für Innovative Mikroelektronik, Frankfurt (Oder), Germany",
                    "Department of Computer Science, Humboldt University of Berlin, Berlin, Germany"
                ]
            },
            {
                "name": "Hilary Frank",
                "labs": [
                    "Smart Internet Laboratory, University of Bristol, Bristol, U.K."
                ]
            },
            {
                "name": "Lorena Chinchilla-Romero",
                "labs": [
                    "Department of Signal Theory, Telematics and Communications (DTSTC), University of Granada, Granada, Spain"
                ]
            },
            {
                "name": "Ferrán Cañellas",
                "labs": [
                    "I2CAT Foundation, Barcelona, Spain"
                ]
            },
            {
                "name": "Adriana Fernández-Fernández",
                "labs": [
                    "I2CAT Foundation, Barcelona, Spain"
                ]
            },
            {
                "name": "Shuangyi Yan",
                "labs": [
                    "Smart Internet Laboratory, University of Bristol, Bristol, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "5G mobile communication",
                "Natural language processing",
                "3GPP",
                "Artificial intelligence",
                "Machine learning",
                "Computer architecture",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "intent based networking",
                "machine learning",
                "natural language processing",
                "private 5G networks"
            ]
        }
    },
    {
        "Title": "A Comparative NLP-Based Study on the Current Trends and Future Directions in COVID-19 Research",
        "Link": "https://ieeexplore.ieee.org/document/9437220/",
        "Abstract": "COVID-19 is a global health crisis that has altered human life and still promises to create ripples of death and destruction in its wake. The sea of scientific literature published over a short time-span to understand and mitigate this global phenomenon necessitates concerted efforts to organize our findings and focus on the unexplored facets of the disease. In this work, we applied natural language processing (NLP) based approaches on scientific literature published on COVID-19 to infer significant keywords that have contributed to our social, economic, demographic, psychological, epidemiological, clinical, and medical understanding of this pandemic. We identify key terms appearing in COVID literature that vary in representation when compared to other virus-borne diseases such as MERS, Ebola, and Influenza. We also identify countries, topics, and research articles that demonstrate that the scientific community is still reacting to the short-term threats such as transmissibility, health risks, treatment plans, and public policies, underpinning the need for collective international efforts towards long-term immunization and drug-related challenges. Furthermore, our study highlights several long-term research directions that are urgently needed for COVID-19 such as: global collaboration to create international open-access data repositories, policymaking to curb future outbreaks, psychological repercussions of COVID-19, vaccine development for SARS-CoV-2 variants and their long-term efficacy studies, and mental health issues in both children and elderly.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3082108",
            "Date of Publication": "20 May 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Priyankar Bose",
                "labs": [
                    "Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA"
                ]
            },
            {
                "name": "Satyaki Roy",
                "labs": [
                    "Department of Genetics, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA"
                ]
            },
            {
                "name": "Preetam Ghosh",
                "labs": [
                    "Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "COVID-19",
                "Coronaviruses",
                "Natural language processing",
                "Bibliometrics",
                "Analytical models",
                "Data models",
                "Public policy"
            ],
            "Author Keywords": [
                "COVID-19",
                "natural language processing",
                "coefficient of variation",
                "mean squared error"
            ]
        }
    },
    {
        "Title": "Leveraging Social Media as a Source of Mobility Intelligence: An NLP-Based Approach",
        "Link": "https://ieeexplore.ieee.org/document/10229505/",
        "Abstract": "This work presents a deep learning framework for analyzing urban mobility by extracting knowledge from messages collected from Twitter. The framework, which is designed to handle large-scale data and adapt automatically to new contexts, comprises three main modules: data collection and system configuration, data analytics, and aggregation and visualization. The text data is pre-processed using NLP techniques to remove informal words, slang, and misspellings. A pre-trained, unsupervised word embedding model, BERT, is used to classify travel-related tweets using a unigram approach with three dictionaries of travel-related target words: small, medium, and big. Public opinion is evaluated using VADER to classify travel-related tweets according to their sentiments. The mobility of three major cities was assessed: London, Melbourne, and New York. The framework demonstrates consistently high average performance, with a Precision of 0.80 for text classification and 0.77 for sentiment analysis. The framework can aggregate sparse information from social media and provide updated information in near real-time with high spatial resolution, enabling easy identification of traffic-related events. The framework is helpful for transportation decision-makers in operational control, tactical-strategic planning, and policy evaluation. For example, it can be used to improve the management of resources during traffic congestion or emergencies.",
        "Details": {
            "DOI": "10.1109/OJITS.2023.3308210",
            "Date of Publication": "24 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Intelligent Transportation Systems"
        },
        "issn_info": {
            "Electronic ISSN": "2687-7813"
        },
        "authors_data": [
            {
                "name": "Tânia Fontes",
                "labs": [
                    "CESE, INESC TEC, Porto, Portugal"
                ]
            },
            {
                "name": "Francisco Murços",
                "labs": [
                    "CESE, INESC TEC, Porto, Portugal"
                ]
            },
            {
                "name": "Eduardo Carneiro",
                "labs": [
                    "CESE, INESC TEC, Porto, Portugal"
                ]
            },
            {
                "name": "Joel Ribeiro",
                "labs": [
                    "CESE, INESC TEC, Porto, Portugal"
                ]
            },
            {
                "name": "Rosaldo J. F. Rossetti",
                "labs": [
                    "LIACC, Department of Informatics Engineering, Faculty of Engineering, University of Porto, Porto, Portugal"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Transportation",
                "Text mining",
                "Sentiment analysis",
                "Blogs",
                "Soft sensors",
                "Dictionaries",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "classification",
                "sentiment analysis",
                "framework"
            ]
        }
    },
    {
        "Title": "DiLBERT: Cheap Embeddings for Disease Related Medical NLP",
        "Link": "https://ieeexplore.ieee.org/document/9628010/",
        "Abstract": "Electronic Health Records include health-related information, among which there is text mentioning health conditions and diagnoses. Usually, text is also coded using appropriate terminologies and classifications. The act of coding is time consuming and prone to mistakes. Consequently, there is increasing demand for clinical text mining tools to help coding. In last few years Natural Language Processing (NLP) models has been shown to be effective in sentence-level tasks. Taking advantage from the transfer learning capabilities of those models, a number of biomedicine and health specific models have been also developed. However, also biomedical models can be seen as too general for some specific area like diagnostic expressions. In this paper, we describe a BERT model specialized on tasks related to diagnoses and health conditions. To obtain a disease-related language model, we created a pre-training corpora starting from ICD-11 entities, and enriched them with documents selected by querying PubMed and Wikipedia with entity names. Fine-tuning has been carried out towards three downstream tasks on two different datasets. Results show that our model, besides being trained on a much smaller corpora than state-of-the-art algorithms, leads to comparable or higher accuracy scores on all the considered tasks, in particular 97.53% accuracy on death certificate coding, and 81.32% on clinical document coding, which are both slightly higher than other models. To summarize the practical implications of our work, we pre-trained and fine-tuned a domain specific BERT model on a small corpora, with comparable or better performance than state-of-the-art models. This approach may also simplify the development of models for languages different from English, due to the minor quantity of data needed for training.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3131386",
            "Date of Publication": "30 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kevin Roitero",
                "labs": [
                    "Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy"
                ]
            },
            {
                "name": "Beatrice Portelli",
                "labs": [
                    "Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy"
                ]
            },
            {
                "name": "Mihai Horia Popescu",
                "labs": [
                    "Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy"
                ]
            },
            {
                "name": "Vincenzo Della Mea",
                "labs": [
                    "Department of Mathematics, Computer Science and Physics, University of Udine, Udine, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Task analysis",
                "Bit error rate",
                "Diseases",
                "Encoding",
                "Codes",
                "Data models"
            ],
            "Author Keywords": [
                "Natural language processing",
                "language models",
                "embeddings",
                "disease",
                "transformer",
                "ICD-11"
            ]
        }
    },
    {
        "Title": "An NLP-Inspired Data Augmentation Method for Adverse Event Prediction Using an Imbalanced Healthcare Dataset",
        "Link": "https://ieeexplore.ieee.org/document/9845410/",
        "Abstract": "This paper proposes a data augmentation method for imbalanced healthcare datasets. This method was inspired by a data augmentation method in natural language processing (NLP) that generates synthetic sentences for training by replacing some words with similar words. The proposed method generates synthetic patient records by replacing patient backgrounds with similar backgrounds. In this paper, the cosine similarity of the distributed representations was used as the similarity metric between patient backgrounds. The distributed representations of the patient backgrounds were generated by the skip-gram model. To confirm the performance improvement with the proposed data augmentation method, the prediction performance of adverse events (AEs) caused by drug administration was experimentally evaluated on a real-world medical dataset with 1,510,137 records. The combination of the proposed data augmentation method and a conventional undersampling method resulted in an 80.0% improvement in accuracy and a 40.0% improvement in the precision and F1-score. The multifaceted evaluation demonstrated that the proposed method is effective, especially for predicting AEs with positive ratios ranging from 1.0% to 2.1%, which are difficult to predict with conventional machine learning methods but should be predictable in the medical field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3195212",
            "Date of Publication": "01 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tomoki Ishikawa",
                "labs": [
                    "Graduate School of Science and Technology, Keio University, Yokohama, Japan"
                ]
            },
            {
                "name": "Takahiro Yakoh",
                "labs": [
                    "Department of System Design Engineering, Keio University, Yokohama, Japan"
                ]
            },
            {
                "name": "Hisashi Urushihara",
                "labs": [
                    "Division of Drug Development and Regulatory Science, Keio University, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Drugs",
                "Thesauri",
                "Medical services",
                "Distributed databases",
                "Roads",
                "Training",
                "Diseases"
            ],
            "Author Keywords": [
                "Adverse event prediction",
                "data augmentation",
                "distributed representation",
                "healthcare dataset",
                "imbalanced dataset"
            ]
        }
    },
    {
        "Title": "A Feasibility Study on Evasion Attacks Against NLP-Based Macro Malware Detection Algorithms",
        "Link": "https://ieeexplore.ieee.org/document/10345584/",
        "Abstract": "Machine learning-based models for malware detection have gained prominence in order to detect obfuscated malware. These models extract malicious features and endeavor to classify samples as either malware or benign entities. Conversely, these benign features can be employed to imitate benign samples. With respect to Android applications, numerous researchers have assessed the hazard and tackled the problem. This evasive technique can be extended to other malicious scripts, such as macro malware. In this paper, we investigate the potential for evasive attacks against natural language processing (NLP)-based macro malware detection algorithms. We assess three language models as methods for feature extraction: Bag of Words, Latent Semantic Analysis, and Paragraph Vector. Our experimental result demonstrates that the detection rate declines to 2 percent when benign features are inserted into actual macro malware. This approach is effective even against advanced language models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3339827",
            "Date of Publication": "05 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mamoru Mimura",
                "labs": [
                    "National Defense Academy of Japan, Yokosuka, Japan"
                ]
            },
            {
                "name": "Risa Yamamoto",
                "labs": [
                    "Japan Ground Self-Defense Force, Shinjuku-ku, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Malware",
                "Classification algorithms",
                "Source coding",
                "Machine learning algorithms",
                "Semantics",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Macro malware",
                "machine learning",
                "evasion attack",
                "LSA",
                "paragraph vector"
            ]
        }
    },
    {
        "Title": "Exploring T5 and RGAN for Enhanced Sarcasm Generation in NLP",
        "Link": "https://ieeexplore.ieee.org/document/10562282/",
        "Abstract": "Sarcasm, a figurative expression, plays a crucial role in human communication by conveying meanings often opposite to literal interpretation. Despite being common in daily conversations, sarcasm poses significant challenges for natural language processing (NLP) systems due to its intricate and context-sensitive nature. This study proposes a novel approach to sarcasm generation, leveraging advanced techniques in text augmentation, transfer learning, and evaluation. Our approach begins with pre-training a Transformer-based T5 model on a vast sarcastic and non-sarcastic text collection. Subsequently, we refine this model by fine-tuning it on an augmented dataset using Recurrent Generative Adversarial Networks (RGAN). Additionally, we incorporate top-p and top-k sampling techniques to promote diversity in generated text which is reflected in the robust BLEU and ROUGE scores of 0.82 and 0.8 indicating a high level of accuracy and quality in the generated sarcastic responses. These advancements highlight the potential for creating more nuanced and contextually appropriate sarcastic responses in chatbots, virtual assistants, and other AI-driven communication tools, ultimately enhancing human-computer interactions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3416692",
            "Date of Publication": "19 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Purnima Tummala",
                "labs": [
                    "School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India"
                ]
            },
            {
                "name": "Ch. Koteswara Roa",
                "labs": [
                    "School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Linguistics",
                "Generators",
                "Transformers",
                "Task analysis",
                "Ethics",
                "Data models",
                "Oral communication"
            ],
            "Author Keywords": [
                "Augmentation",
                "natural language processing",
                "sarcasm generation",
                "T5"
            ]
        }
    },
    {
        "Title": "New Avenues for Automated Railway Safety Information Processing in Enterprise Architecture: An NLP Approach",
        "Link": "https://ieeexplore.ieee.org/document/10114393/",
        "Abstract": "Enterprise Architecture (EA) is crucial in any organisation as it defines the basic building blocks of a business. It is typically presented as a set of documents that help all departments understand the business model. In EA, safety documents are used to manage and understand safety risks. A novel similarity system for railway safety document processing is presented in this work. It measures the feasibility of automated updating of EA models with the Rule Book by verifying whether Rail Safety and Standards Board (RSSB’s) Rule Book clauses are present and complete in existing EA models. Additionally, a Natural Language Processing (NLP) based search feature was developed to drill through the database to find similar existing rules, principles, and clauses based on semantic similarity. The result will display the most similar clauses and rules with similarity scores and document names. In this study, different pre-trained Electra Small, DistilBERT (Distillation Bidirectional Encoder Representations from Transformers) Base and BERT (Bidirectional Encoder Representations from Transformers) Base were used to embed text. Additionally, the similarity between document rules was measured by cosine similarity metrics. With conclusive evidence, our findings show that BERT Base exceeds the other embedding methods in the semantic comparison of documents.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3272610",
            "Date of Publication": "02 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdul Wahab Qurashi",
                "labs": [
                    "School of Computing and Engineering, University of Huddersfield, HD1 3DH Huddersfield, U.K"
                ]
            },
            {
                "name": "Zohaib A. Farhat",
                "labs": [
                    "Advanced Manufacturing Research Centre (North West), University of Sheffield, BB2 7HP Blackburn, U.K"
                ]
            },
            {
                "name": "Violeta Holmes",
                "labs": [
                    "School of Computing and Engineering, University of Huddersfield, HD1 3DH Huddersfield, U.K. (Deceased)"
                ]
            },
            {
                "name": "Anju P. Johnson",
                "labs": [
                    "School of Computing and Engineering, University of Huddersfield, HD1 3DH Huddersfield, U.K"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Rail transportation",
                "Safety",
                "Semantics",
                "Railway safety",
                "Industries",
                "Computer architecture",
                "Natural language processing",
                "Encoding"
            ],
            "Author Keywords": [
                "Natural language processing",
                "enterprise architecture models",
                "distillation bidirectional encoder representations from transformers",
                "cosine similarity"
            ]
        }
    },
    {
        "Title": "Comparative Analysis of Traditional and Modern NLP Techniques on the CoLA Dataset: From POS Tagging to Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10829978/",
        "Abstract": "The task of classifying linguistic acceptability, exemplified by the CoLA (Corpus of Linguistic Acceptability) dataset, poses unique challenges for natural language processing (NLP) models. These challenges include distinguishing between subtle grammatical errors, understanding complex syntactic structures, and detecting semantic inconsistencies, all of which make the task difficult even for human annotators. In this article, we compare a range of techniques, from traditional methods such as Part-of-Speech (POS) tagging and feature extraction methods like CountVectorizer with Term Frequency-Inverse Document Frequency (TF-IDF) and N-grams, to modern embeddings such as FastText and Embeddings from Language Models (ELMo), as well as deep learning architectures like transformers and Large Language Models (LLMs). Our experiments show a clear improvement in performance as models evolve from traditional to more advanced approaches. Notably, state-of-the-art (SOTA) results were obtained by fine-tuning GPT-4o with extensive hyperparameter tuning, including experimenting with various epochs and batch sizes. This comparative analysis provides valuable insights into the relative strengths of each technique for identifying morphological, syntactic, and semantic violations, highlighting the effectiveness of LLMs in these tasks.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3526712",
            "Date of Publication": "07 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Abdessamad Benlahbib",
                "labs": [
                    "Computer Science Department, LISAC Laboratory, Faculty of Sciences Dhar EL Mehraz (F.S.D.M), Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            },
            {
                "name": "Achraf Boumhidi",
                "labs": [
                    "Computer Science Department, LISAC Laboratory, Faculty of Sciences Dhar EL Mehraz (F.S.D.M), Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            },
            {
                "name": "Anass Fahfouh",
                "labs": [
                    "Computer Science Department, LISAC Laboratory, Faculty of Sciences Dhar EL Mehraz (F.S.D.M), Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            },
            {
                "name": "Hamza Alami",
                "labs": [
                    "Computer Science Department, LISAC Laboratory, Faculty of Sciences Dhar EL Mehraz (F.S.D.M), Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Linguistics",
                "Tagging",
                "Transformers",
                "Benchmark testing",
                "Computational modeling",
                "Syntactics",
                "Natural language processing",
                "Large language models",
                "Data models",
                "Correlation coefficient"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "linguistic acceptability",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Leveraging Cognitive Machine Reasoning and NLP for Automated Intent-Based Networking and e2e Service Orchestration",
        "Link": "https://ieeexplore.ieee.org/document/10854217/",
        "Abstract": "Modern networks are increasingly complex, necessitating dynamic and automated solutions to connect user intents with network actions effectively. This study presents a new framework for automating Intent Based Networking (IBN) by combining cognitive Machine Reasoning (MR) with Natural Language Processing (NLP) and utilizing the RASA (Robust Automated Speech Assistant) architecture. RASA is a flexible open-source framework for building conversational AI, adapted for end-to-end (e2e) network orchestration. In contrast to traditional static methods, this innovative system empowers network operators to manage and optimize networks dynamically through intuitive voice commands or a Graphical User Interface (GUI). The system identifies user intents, converts them into actionable network policies, and ensures they align with real-time network states and Quality of Service (QoS) requirements via a feedback loop. Cognitive MR and AI-based optimization techniques are integrated to enhance system performance, enabling intelligent adaptation to network conditions and ensuring optimal resource allocation. A simulated testbed was created to assess the system’s performance using Containernet, a lightweight Container-Based Network Emulator, and Open Networking Operating System (ONOS) Software Defined Networking (SDN) controllers. The results of the testbed indicated a 25% reduction in latency, a 30% increase in throughput, and a 40% enhancement in real-time response times, demonstrating the system’s effectiveness in a controlled environment. These impressive results underscore the system’s potential to enhance network performance, efficiency, and responsiveness. By effectively addressing modern networks’ challenges, this solution proves its ability to confidently and seamlessly convert user intents into automated network actions without manual intervention, providing adaptability and scalability for today’s network environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3534282",
            "Date of Publication": "27 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Asif",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            },
            {
                "name": "Talha Ahmed Khan",
                "labs": [
                    "Institute for Communication Systems, University of Surrey, Guildford, U.K."
                ]
            },
            {
                "name": "Wang-Cheol Song",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Real-time systems",
                "Natural language processing",
                "Quality of service",
                "Intent recognition",
                "Feedback loop",
                "Resource management",
                "Monitoring",
                "Engines",
                "Scalability"
            ],
            "Author Keywords": [
                "Intent based networking",
                "natural language processing",
                "machine reasoning",
                "software defined networking",
                "conversational AI"
            ]
        }
    },
    {
        "Title": "The Rise of Artificial Intelligence Phobia! Unveiling News-Driven Spread of AI Fear Sentiment Using ML, NLP, and LLMs",
        "Link": "https://ieeexplore.ieee.org/document/11079577/",
        "Abstract": "Contemporary public discourse surrounding artificial intelligence (AI) often displays disproportionate fear and confusion relative to AI’s actual potential. This study examines how the use of alarmist and fear-inducing language by news media contributes to negative public perceptions of AI. Nearly 70,000 AI-related news headlines were analyzed using natural language processing (NLP), machine learning (ML), and large language models (LLMs) to identify dominant themes and sentiment patterns. The theoretical framework draws on existing literature that posits the power of fear-inducing headlines to influence public perception and behavior, even when such headlines represent a relatively small proportion of total coverage. This research applies topic modeling and fear sentiment classification using BERT, LLaMA, and Mistral, alongside supervised ML techniques. The findings show a persistent presence of emotionally negative and fear-laden language in AI news coverage. This portrayal of AI as dangerous to humans or as an existential threat profoundly shapes public perception, fueling AI phobia that leads to behavioral resistance toward AI, which is ultimately detrimental to the science of AI. Furthermore, this can have an adverse impact on AI policies and regulations, leading to a stunted growth environment for AI. The study concludes with implications and recommendations to counter fear-driven narratives and suggests ways to improve public understanding of AI through responsible news media coverage, broad AI education, democratization of AI resources, and the drawing of clear distinctions between AI as a science versus commercial AI applications, to promote enhanced fact-based mass engagement with AI while preserving human dignity and agency.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3588179",
            "Date of Publication": "14 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jim Samuel",
                "labs": [
                    "Bloustein School, Rutgers University, New Brunswick, NJ, USA",
                    "AIXosphere AI Strategy, Woodbridge, NJ, USA"
                ]
            },
            {
                "name": "Tanya Khanna",
                "labs": [
                    "School of Arts and Sciences, Rutgers University, New Brunswick, NJ, USA"
                ]
            },
            {
                "name": "Julia Esguerra",
                "labs": [
                    "School of Graduate Studies, Rutgers University, New Brunswick, NJ, USA"
                ]
            },
            {
                "name": "Srinivasaraghavan Sundar",
                "labs": [
                    "School of Arts and Sciences, Rutgers University, New Brunswick, NJ, USA"
                ]
            },
            {
                "name": "Alexander Pelaez",
                "labs": [
                    "Zarb School of Business, Hofstra University, Hempstead, NY, USA",
                    "5e Analytics, Merrick, NY, USA"
                ]
            },
            {
                "name": "Soumitra S. Bhuyan",
                "labs": [
                    "Bloustein School, Rutgers University, New Brunswick, NJ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Media",
                "Road transportation",
                "Anxiety disorders",
                "Technological innovation",
                "Regulation",
                "Immune system",
                "Business",
                "Systematics",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "AI phobia",
                "emotion classification",
                "fear",
                "large language models",
                "sentiment analysis",
                "natural language processing",
                "automated news classification",
                "topic modeling",
                "text informatics"
            ]
        }
    },
    {
        "Title": "Bridging Language Barriers in Coding: An NLP-Powered Tool for Programming Education in Regional Languages",
        "Link": "https://ieeexplore.ieee.org/document/11072672/",
        "Abstract": "In the digital age, coding has become a critical skill for improving career prospects and participating in the global economy. However, most educational tools primarily cater to English-speaking learners, limiting access for individuals in rural areas who are proficient only in regional languages, such as Kannada. This study presents an interactive web-based tool that leverages Natural Language Processing (NLP) to teach fundamental programming concepts in Kannada. The tool allows users to input algorithmic statements in Kannada, which are then translated into English and converted into Python code using a fine-tuned Salesforce CodeT5 model. The model, trained on a custom dataset, achieved strong performance with a BLEU score of 87.64 and an Exact Match score of 81.62%. The study also evaluated other models such as T5, PLBART, and GPT-Neo for the same task. Additionally, the platform offers tutorials, quizzes, and an embedded coding environment for learners to test the generated code. A user study involving Kannada-speaking students from diverse academic backgrounds was conducted to evaluate the usability and educational effectiveness of the tool. Results indicated that the majority of participants found the tool easy to use, the code generation accurate, and the overall experience beneficial in understanding programming logic. Notably, over 65% of students without prior programming experience expressed interest in pursuing programming careers after using the tool. By addressing language barriers, this research contributes to United Nations Sustainable Development Goal 4 (SDG 4) by fostering inclusive and equitable quality education, enabling learners to acquire programming skills in their native language.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3587056",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Goutami Sooda",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "Arya Hariharan",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "Ahana Patil",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "Arya Vinod",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "S. Chandana",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "L. B. Manvith",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "Nihar Mandahas",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "H. Siri",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "G. Shobha",
                "labs": [
                    "School of Computer Science and Engineering, RV University, Bengaluru, India"
                ]
            },
            {
                "name": "N. Deepamala",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            },
            {
                "name": "Jyoti Shetty",
                "labs": [
                    "Department of Computer Science and Engineering, RV College of Engineering, Bengaluru, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Programming profession",
                "Encoding",
                "Education",
                "Translation",
                "Python",
                "Natural language processing",
                "Computational modeling",
                "Syntactics",
                "Accuracy"
            ],
            "Author Keywords": [
                "Algorithm-to-code translation",
                "code generation",
                "CodeT5",
                "GPT-Neo",
                "Kannada-to-Python",
                "natural language processing",
                "PLBART",
                "programming education",
                "T5 transformer"
            ]
        }
    },
    {
        "Title": "Lattice LSTM for Chinese Sentence Representation",
        "Link": "https://ieeexplore.ieee.org/document/9082853/",
        "Abstract": "Words provide a useful source of information for Chinese NLP, and word segmentation has been taken as a pre-processing step for most downstream tasks. For many NLP tasks, however, word segmentation can introduce noise and lead to error propagation. The rise of neural representation learning models allows sentence-level semantic information to be collected from characters directly. As a result, it is an empirical question whether a fully character-based model should be used instead of first performing word segmentation. We investigate a neural representation that simultaneously encodes character and word information without the need for segmentation. In particular, candidate words are found in a sentence by matching with a pre-defined lexicon. A lattice structured LSTM is used to encode the resulting word-character lattice, where gate vectors are used to control information flow through words, so that the more useful words can be automatically identified by end-to-end training. We compare the performance of the resulting lattice LSTM and baseline sequence LSTM structures over both character sequences and automatically segmented word sequences. Results on NER show that the character-word lattice model can significantly improve the performance. In addition, as a general sentence representation architecture, character-word lattice LSTM can also be used for learning contextualized representations. To this end, we compare lattice LSTM structure with its sequential LSTM counterpart, namely ELMo. Results show that our lattice version of ELMo gives better language modeling performances. On Chinese POS-tagging, chunking and syntactic parsing tasks, the resulting contextualized Chinese embeddings also give better performance than ELMo trained on the same data.",
        "Details": {
            "DOI": "10.1109/TASLP.2020.2991544",
            "Date of Publication": "30 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
        },
        "issn_info": {
            "Print ISSN": "2329-9290",
            "Electronic ISSN": "2329-9304"
        },
        "authors_data": [
            {
                "name": "Yue Zhang",
                "labs": [
                    "Zhejiang University, Hangzhou, China",
                    "School of Engineering, Westlake University, Hangzhou, China",
                    "Westlake Institute for Advanced Study, Hangzhou, China"
                ]
            },
            {
                "name": "Yile Wang",
                "labs": [
                    "Zhejiang University, Hangzhou, China",
                    "School of Engineering, Westlake University, Hangzhou, China",
                    "Westlake Institute for Advanced Study, Hangzhou, China"
                ]
            },
            {
                "name": "Jie Yang",
                "labs": [
                    "Harvard Medical School, Harvard University, Cambridge, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Lattices",
                "Task analysis",
                "Bridges",
                "Urban areas",
                "Rivers",
                "Training",
                "Labeling"
            ],
            "Author Keywords": [
                "Lattice LSTM",
                "NER",
                "language modeling",
                "contextualize representation"
            ]
        }
    },
    {
        "Title": "Benchmarking Open-Source Large Language Models for Sentiment and Emotion Classification in Indonesian Tweets",
        "Link": "https://ieeexplore.ieee.org/document/11016677/",
        "Abstract": "We benchmark 22 open-source large language models (LLMs) against ChatGPT-4 and human annotators on two NLP tasks—sentiment analysis and emotion classification—for Indonesian tweets. This study contributes to NLP in a relatively low-resource language (Bahasa Indonesia) by evaluating zero-shot classification performance on a labeled tweet corpus. The dataset includes sentiment labels (Positive, Negative, Neutral) and emotion labels (Love, Happiness, Sadness, Anger, Fear). We compare model predictions to human annotations and report precision, recall, and F1-score, along with inference time analysis. ChatGPT-4 achieves the highest macro F1-score (0.84) on both tasks, slightly outperforming human annotators. The best-performing open-source models—such as LLaMA3.1_70B and Gemma2_27B—achieve over 90% of ChatGPT-4’s performance, while smaller models lag behind. Notably, some mid-sized models (e.g., Phi-4 at 14B parameters) perform comparably to much larger models on select categories. However, certain classes—particularly Neutral sentiment and Fear emotion—remain challenging, with lower agreement even among human annotators. Inference time varies significantly: optimized models complete predictions in under an hour, while some large models require several days. Our findings show that state-of-the-art open models can approach closed-source LLMs like ChatGPT-4 on Indonesian classification tasks, though efficiency and consistency in edge cases remain open challenges. Future work should explore fine-tuning multilingual LLMs on Indonesian data and practical deployment strategies in real-world applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574629",
            "Date of Publication": "28 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Arbi Haza Nasution",
                "labs": [
                    "Department of Informatics Engineering, Universitas Islam Riau, Pekanbaru, Riau, Indonesia"
                ]
            },
            {
                "name": "Aytug Onan",
                "labs": [
                    "Department of Computer Engineering, College of Engineering and Architecture, Izmir Katip Celebi University, İzmir, Türkiye"
                ]
            },
            {
                "name": "Yohei Murakami",
                "labs": [
                    "Faculty of Information Science and Engineering, Ritsumeikan University, Osaka, Ibaraki, Japan"
                ]
            },
            {
                "name": "Winda Monika",
                "labs": [
                    "Department of Library Science, Universitas Lancang Kuning, Riau, Indonesia"
                ]
            },
            {
                "name": "Anggi Hanafiah",
                "labs": [
                    "Department of Informatics Engineering, Universitas Islam Riau, Pekanbaru, Riau, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Benchmark testing",
                "Sentiment analysis",
                "Large language models",
                "Analytical models",
                "Accuracy",
                "Natural language processing",
                "Social networking (online)",
                "Bidirectional long short term memory",
                "Annotations",
                "Predictive models"
            ],
            "Author Keywords": [
                "Annotation quality",
                "emotion classification",
                "sentiment analysis",
                "Indonesian language processing",
                "language models",
                "low-resource languages",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Machine Learning Techniques for Biomedical Natural Language Processing: A Comprehensive Review",
        "Link": "https://ieeexplore.ieee.org/document/9568778/",
        "Abstract": "The widespread use of electronic health records (EHR) systems in health care provides a large amount of real-world data, leading to new areas for clinical research. Natural language processing (NLP) techniques have been used as an artificial intelligence strategy to extract information from clinical narratives in electronic health records since they include a great amount of valuable clinical information. However, in a free-form text such as electronic health records, many clinical data are still hidden in a clinical narrative format. Therefore, the performance of biomedical NLP techniques is required to unlock the full potential of EHR data to convert a clinical narrative text automatically into structured clinical data. In this way, biomedical NLP applications can be used to direct clinical decisions, identify medical problems, and effectively postpone or avoid the occurrence of a disease. This review discusses the current literature on the secondary use of electronic health record data for clinical research on chronic diseases and addresses the potential, challenges, and applications of biomedical NLP techniques. We review some of the biomedical NLP methods and systems used over EHRs and give an overview of machine learning and deep learning methodologies used to process EHRs and improve the understanding of the patient’s clinical records and the prediction of chronic diseases risk, providing a great chance to extract previously unknown clinical information. Moreover, this review summarizes the utilizing of Deep Learning and Machine Learning techniques in biomedical NLP tasks based on chronic diseases related EHR data. Finally, this review presents the future trends and challenges in the biomedical NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3119621",
            "Date of Publication": "13 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Essam H. Houssein",
                "labs": [
                    "Faculty of Computers and Information, Minia University, Minia, Egypt"
                ]
            },
            {
                "name": "Rehab E. Mohamed",
                "labs": [
                    "Faculty of Computers and Information, Minia University, Minia, Egypt"
                ]
            },
            {
                "name": "Abdelmgeid A. Ali",
                "labs": [
                    "Faculty of Computers and Information, Minia University, Minia, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Diseases",
                "Codes",
                "Electronic medical records",
                "Data mining",
                "Task analysis",
                "Hospitals"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "clinical information",
                "deep learning",
                "electronic health records (EHR)",
                "machine learning",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Natural Language Processing-Based Software Testing: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/10542730/",
        "Abstract": "New approaches to software testing are required due to the rising complexity of today’s software applications and the rapid growth of software engineering practices. Among these methods, one that has shown promise is the introduction of Natural Language Processing (NLP) tools to software testing practices. NLP has witnessed a rise in popularity within all IT fields, especially in software engineering, where its use has improved the way we extract information from textual data. The goal of this systematic literature review (SLR) is to provide an in-depth analysis of the present body of the literature on the expanding subject of NLP-based software testing. Through a repeatable process, that takes into account the quality of the research, we examined 24 papers extracted from Web of Science and Scopus databases to extract insights about the usage of NLP techniques in the field of software testing. Requirements analysis and test case generation popped up as the most hot topics in the field. We also explored NLP techniques, software testing types, machine/deep learning algorithms, and NLP tools and frameworks used in the studied body of literature. This study also stressed some recurrent open challenges that need further work in future research such as the generalization of the NLP algorithm across domains and languages and the ambiguity in the natural language requirements. Software testing professionals and researchers can get important insights from the findings of this SLR, which will help them comprehend the advantages and challenges of using NLP in software testing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3407753",
            "Date of Publication": "31 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohamed Boukhlif",
                "labs": [
                    "LTI Laboratory, National School of Applied Sciences, Chouaib Doukkali University, El Jadida, Morocco"
                ]
            },
            {
                "name": "Mohamed Hanine",
                "labs": [
                    "LTI Laboratory, National School of Applied Sciences, Chouaib Doukkali University, El Jadida, Morocco"
                ]
            },
            {
                "name": "Nassim Kharmoum",
                "labs": [
                    "IPSS Team, Faculty of Sciences, Mohammed V University in Rabat, Rabat, Morocco",
                    "National Center for Scientific and Technical Research (CNRST), Rabat, Morocco"
                ]
            },
            {
                "name": "Atenea Ruigómez Noriega",
                "labs": [
                    "Universidad Europea del Atlántico, Santander, Spain",
                    "Universidad Internacional Iberoamericana, Campeche, Mexico",
                    "Universidad Internacional Iberoamericana, Arecibo, PR, USA"
                ]
            },
            {
                "name": "David García Obeso",
                "labs": [
                    "Universidad Europea del Atlántico, Santander, Spain",
                    "Universidade Internacional do Cuanza, Cuito, Bié, Angola",
                    "Universidad de La Romana, La Romana, Dominica"
                ]
            },
            {
                "name": "Imran Ashraf",
                "labs": [
                    "Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software testing",
                "Reviews",
                "Natural language processing",
                "Systematics",
                "Software algorithms",
                "Bibliographies",
                "Test pattern generators"
            ],
            "Author Keywords": [
                "Software testing",
                "natural language processing (NLP)",
                "systematic review",
                "test case generation"
            ]
        }
    },
    {
        "Title": "Legal Natural Language Processing From 2015 to 2022: A Comprehensive Systematic Mapping Study of Advances and Applications",
        "Link": "https://ieeexplore.ieee.org/document/10320368/",
        "Abstract": "The surge in legal text production has amplified the workload for legal professionals, making many tasks repetitive and time-consuming. Furthermore, the complexity and specialized language of legal documents pose challenges not just for those in the legal domain but also for the general public. This emphasizes the potential role and impact of Legal Natural Language Processing (Legal NLP). Although advancements have been made in this domain, particularly after 2015 with the advent of Deep Learning and Large Language Models (LLMs), a systematic exploration of this progress until 2022 is nonexistent. In this research, we perform a Systematic Mapping Study (SMS) to bridge this gap. We aim to provide a descriptive statistical analysis of the Legal NLP research between 2015 and 2022. Categorize and sub-categorize primary publications based on their research problems. Identify limitations and areas of improvement in current research. Using a robust search methodology across four reputable indexers, we filtered 536 papers down to 75 pivotal articles. Our findings reveal the diverse methods employed for tasks such as Multiclass Classification, Summarization, and Question Answering in the Legal NLP field. We also highlight resources, challenges, and gaps in current methodologies and emphasize the need for curated datasets, ontologies, and a focus on inherent difficulties like data accessibility. As the legal sector gradually embraces Natural Language Processing (NLP), understanding the capabilities and limitations of Legal NLP becomes vital for ensuring efficient and ethical application. The research offers insights for both Legal NLP researchers and the broader legal community, advocating for continued advancements in automation while also addressing ethical concerns.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3333946",
            "Date of Publication": "16 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ernesto Quevedo",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Tomas Cerny",
                "labs": [
                    "Systems and Industrial Engineering, The University of Arizona, Tucson, AZ, USA"
                ]
            },
            {
                "name": "Alejandro Rodriguez",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Pablo Rivas",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Jorge Yero",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Korn Sooksatra",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Alibek Zhakubayev",
                "labs": [
                    "Department of Computer Science, School of Engineering and Computer Science, Baylor University, Waco, TX, USA"
                ]
            },
            {
                "name": "Davide Taibi",
                "labs": [
                    "M3S Research Unit, University of Oulu, Oulu, Finland",
                    "CloudSEA Research Group, Tampere University, Tampere, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Natural language processing",
                "Task analysis",
                "Systematics",
                "Information retrieval",
                "Surveys",
                "Search problems",
                "Deep learning"
            ],
            "Author Keywords": [
                "Systematic-mapping-study",
                "legal-NLP",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Automatically Detecting Peer-to-Peer Lending Intermediary Risk—Top Management Team Profile Textual Features Perspective",
        "Link": "https://ieeexplore.ieee.org/document/8725485/",
        "Abstract": "Peer-to-Peer lending is developing quickly around the world as a new E-finance industry, especially in China. Yet fraudulence and business ceasing of Peer-to-Peer Lending Intermediaries (P2P-INTs) occur frequently, making P2P investors facing serious risk. This paper attempts to explore a bridge connecting managerial research with some most advanced natural language processing (NLP) technologies, and examines the risk assessing power of automatic learning text classifiers based on data of hazard status and top management team profile texts of the P2P-INTs. A risk evaluation model named MULTIPLE NLP Integrated Learning Text Classifier (MUN-LETCLA) based on five NLP techniques and meta-learning is proposed. Then risk classification power of the MUN-LETCLA and the single NLP models is assessed. The results show that the proposed model is effective in classifying low-risk and high-risk P2P-INTs. The NLP models can automatically detect the P2P-INTs risk from Top Management Team (TMT) members’ working experience, educational background, and TMT composition with a precision level of more than 75%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2919727",
            "Date of Publication": "29 May 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lei Li",
                "labs": [
                    "School of Computer, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yanjie Feng",
                "labs": [
                    "Management School, Institute of Artificial Intelligence and Change Management, Shanghai University of International Business and Economics, Shanghai, China"
                ]
            },
            {
                "name": "Yue Lv",
                "labs": [
                    "School of Computer, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Xiaoyue Cong",
                "labs": [
                    "School of Computer, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Xiangling Fu",
                "labs": [
                    "Software School, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Jiayin Qi",
                "labs": [
                    "Management School, Institute of Artificial Intelligence and Change Management, Shanghai University of International Business and Economics, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Peer-to-peer computing",
                "Companies",
                "Natural language processing",
                "Hazards",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Machine learning",
                "natural language processing (NLP)",
                "peer-to-peer (P2P) network lending",
                "risk evaluation",
                "text analysis"
            ]
        }
    },
    {
        "Title": "Detection of Anorexic Girls-In Blog Posts Written in Hebrew Using a Combined Heuristic AI and NLP Method",
        "Link": "https://ieeexplore.ieee.org/document/9743447/",
        "Abstract": "In this study, we aim to detect in social media texts written in Hebrew girls who are suspected of being anorexic. We constructed a dataset containing 100 blog posts written by females who are probably anorexic, and 100 blog posts written by females who are likely to be non-anorexic. The construction of this dataset was supervised and approved by an international expert on anorexia. We tested several text classification (TC) methods, using various feature sets (content-based and style-based), five machine learning (ML) methods, three RNN models, four BERT models, three basic preprocessing methods, three feature filtering methods, and parameter tuning. Several insights were found as follows. A set of 50-word n-grams (mostly word unigrams) given by an expert was found as a good basic detector. A heuristic process based on the random forest ML method has overcome a combinatorial explosion and led to significant improvement over a baseline result at a level of\nP=\n.01. Application of an iterative process that tests combinations of “k out of\nn\n′\n” where\nn\n′\n<\nn (n is the number of feature sets) lead to a result of 90.63%, using a combination of 300 features from ten feature sets.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3162685",
            "Date of Publication": "28 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yaakov Hacohen-Kerner",
                "labs": [
                    "Department of Computer Science, Jerusalem College of Technology, Jerusalem, Israel"
                ]
            },
            {
                "name": "Natan Manor",
                "labs": [
                    "Department of Computer Science, Jerusalem College of Technology, Jerusalem, Israel"
                ]
            },
            {
                "name": "Michael Goldmeier",
                "labs": [
                    "Department of Computer Science, Jerusalem College of Technology, Jerusalem, Israel"
                ]
            },
            {
                "name": "Eytan Bachar",
                "labs": [
                    "Department of Psychology, The Hebrew University of Jerusalem, Mount Scopus, Jerusalem, Israel"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Task analysis",
                "Feature extraction",
                "Depression",
                "Support vector machines",
                "Anxiety disorders"
            ],
            "Author Keywords": [
                "Mental disorders",
                "natural language processing",
                "supervised machine learning",
                "text analysis",
                "text classification",
                "text processing"
            ]
        }
    },
    {
        "Title": "Improved Prioritization of Software Development Demands in Turkish With Deep Learning-Based NLP",
        "Link": "https://ieeexplore.ieee.org/document/9756583/",
        "Abstract": "Management of software development demands including bug or defect fixes and new feature or change requests is a crucial part of software maintenance. Failure to prioritize demands correctly might result in inefficient planning and use of resources as well as user or customer dissatisfaction. In order to overcome the difficulty and inefficiency of manual processing, many automated prioritization approaches were proposed in the literature. However, existing body of research generally focused on bug report repositories of open-source software, where textual bug descriptions are in English. Additionally, they proposed solutions to the problem using mostly classical text mining methods and machine learning (ML) algorithms. In this study, we first introduce a demand prioritization dataset in Turkish, which is composed of manually labeled demand records taken from the demand management system of a private insurance company in Turkey. Second, we propose several deep learning (DL) architectures to improve software development demand prioritization. Through an extensive experimentation, we compared the effectiveness of our DL architectures trained with several combinations of different optimizers and activation functions in order to reveal the best combination for demand prioritization in Turkish. We empirically show that DL models can achieve much higher accuracy than classical ML models even with a small amount of training data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3167269",
            "Date of Publication": "13 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Volkan Tunali",
                "labs": [
                    "Department of Software Engineering, Faculty of Engineering and Natural Sciences, Maltepe University, Istanbul, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Software",
                "Deep learning",
                "Computer architecture",
                "Support vector machines",
                "Feature extraction",
                "Companies"
            ],
            "Author Keywords": [
                "Software engineering",
                "demand prioritization",
                "bug prioritization",
                "machine learning",
                "text classification",
                "deep learning"
            ]
        }
    },
    {
        "Title": "EMPOLITICON: NLP and ML Based Approach for Context and Emotion Classification of Political Speeches From Transcripts",
        "Link": "https://ieeexplore.ieee.org/document/10141612/",
        "Abstract": "Political speeches have played one of the most influential roles in shaping the world. Speeches of the written variety have been etched into history. These sorts of speeches have a great effect on the general people and their actions in the coming few days. Moreover, if left unchecked, political personnel or parties may cause major problems. In many cases, there may be a warning sign that the government needs to change its policies and also listen to the people. Understanding the emotion and context of a political speech is important, as they can be early indicators or warning signs for impending international crises, alignments, wars and future conflicts. In our research, we have focused on the presidents/prime ministers of China, Russia, the United Kingdom and the United States which are the permanent members of the United Nations Security Council and classified the speeches given by them based on the context and emotion of the speeches. The speeches were categorized into optimism, neutral, joy or upset in terms of emotion and five context categories, which are international affairs, nationalism, development, extremism and others. Here, optimism is a secondary emotion, whereas joy and upset are primary emotions. Apart from classifying the speeches based on context and emotion, one of the major works of our research is that we are introducing a dataset of political speeches that contains 2010 speeches labelled with emotion and context of the speech. The speeches we have worked on are large in word count. We propose EMPOLITICON-Context, a soft voting classifier ensemble learning model for context classification and EMPOLITICON-Emotion, a soft voting classifier ensemble learning model for emotion classification of political speeches. The proposed EMPOLITICON-Context model has achieved 73.13% accuracy in terms of context classification and the EMPOLITICON-Emotion model has achieved 53.07% accuracy in classifying the emotion of the political speeches.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3282162",
            "Date of Publication": "01 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Azher Ahmed Efat",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Asif Atiq",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Abrar Shahriar Abeed",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Armanul Momin",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Golam Rabiul Alam",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Bit error rate",
                "Voting",
                "Support vector machines",
                "Social networking (online)",
                "Security",
                "Emotion recognition",
                "Oral communication"
            ],
            "Author Keywords": [
                "Political speeches",
                "emotion classification",
                "context classification",
                "ensemble learning",
                "SMOTEN",
                "longformer",
                "EMPOLITICON"
            ]
        }
    },
    {
        "Title": "NLP-Powered Healthcare Insights: A Comparative Analysis for Multi-Labeling Classification With MIMIC-CXR Dataset",
        "Link": "https://ieeexplore.ieee.org/document/10529271/",
        "Abstract": "The digitization of the healthcare industry has led to a growing number of applications that use machine learning and image processing techniques to improve the diagnostic process. These applications utilize a variety of medical data, including laboratory results, clinical findings, MRI scans, tomographic images, and radiological images. In addition, free-text healthcare documentation, such as well-structured discharge summaries, contains valuable information. Natural Language Processing encompasses the development of automated systems for generating health reports. This process involves using domain-specific knowledge and prior knowledge to extract relevant information from medical records. This article investigates the use of natural language processing techniques for chest X-ray classification. A total of 14 distinct impressions derived from chest radiography findings from the MIMIC-CXR dataset were used in a multi-label classification procedure. Six distinct language models derived from the BERT language model, along with three distinct classification algorithms, were employed to evaluate the effectiveness of the models and the dataset for multi-label categorization. The experimental results showed a successful prediction rate of 80.47% for 14 distinct impressions within the dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3400007",
            "Date of Publication": "13 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ege Erberk Uslu",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Ege University, Bornova, İzmir, Turkey"
                ]
            },
            {
                "name": "Emine Sezer",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Ege University, Bornova, İzmir, Turkey"
                ]
            },
            {
                "name": "Zekeriya Anil Guven",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering and Architecture, İzmir Bakırçay University, Menemen, İzmir, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Medical services",
                "Radiology",
                "MIMICs",
                "Feature extraction",
                "Medical diagnostic imaging",
                "Data mining",
                "Labeling"
            ],
            "Author Keywords": [
                "BERT",
                "chest radiology report",
                "MIMIC-CXR",
                "multi-label classification",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Advanced Text Summarization Model Incorporating NLP Techniques and Feature-Based Scoring",
        "Link": "https://ieeexplore.ieee.org/document/10838534/",
        "Abstract": "The most common traditional approaches to summarizing large texts while retaining their importance are TF-IDF and TextRank. However, these methods often fail to retain narrative coherence and accuracy. This study’s improved summarization methodology overcomes these limitations by combining the linguistic and semantic resources. Moreover, although it is more computationally complex, it efficiently combines higher quality with faster summarization. Specifically, a method relies on a weighted feature score scheme. For example, various textual features such as Named Entity Counts, Noun Counts, and Sentence Position contribute to the summarization quality appropriately. This study’s summarization algorithm was tested using the CNN, XSum and BBC Summarization datasets, which aggregate documents from different areas. The methodology was checked against traditional methods using ROUGE-1 and ROUGE-2, ROUGE-L and BERTScore. The last one, BERTScore, evaluates the semantic similarity of the generated summaries and the references. This study shows that the proposed methodology generates summaries that are not only informative but even semantically faithfully reproduce the original textual information; it achieves high scores in terms of F1-measure across different evaluations like BERTSCORE (0.8857) and ROUGE-1(0.6388), ROUGE-2(0.5662) and ROUGE-L (0.6421). It thus suggests that the approach is applicable in real-life situations and deserves further research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3528830",
            "Date of Publication": "13 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Estabraq Abdulreda Kadhim",
                "labs": [
                    "Department of Computer Engineering, Computerized Intelligence Systems Laboratory, University of Tabriz, Tabriz, Iran"
                ]
            },
            {
                "name": "Mohammad-Reza Feizi-Derakhshi",
                "labs": [
                    "Department of Computer Engineering, Computerized Intelligence Systems Laboratory, University of Tabriz, Tabriz, Iran"
                ]
            },
            {
                "name": "Hadi S. Aghdasi",
                "labs": [
                    "Department of Computer Engineering, University of Tabriz, Tabriz, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Measurement",
                "Feature extraction",
                "Data mining",
                "Text summarization",
                "Computational modeling",
                "Coherence",
                "Encoding",
                "Computational efficiency",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Extractive text summarization",
                "sentences scoring",
                "weighted features",
                "BBC-news dataset",
                "rouge metric",
                "BERTScore metric"
            ]
        }
    },
    {
        "Title": "A BERT-Enhanced Exploration of Web and Mobile Request Safety Through Advanced NLP Models and Hybrid Architectures",
        "Link": "https://ieeexplore.ieee.org/document/10540091/",
        "Abstract": "In the rapidly evolving landscape of digital technology, the security of web and mobile applications stands paramount. As these platforms become increasingly integrated into our daily lives, the need for robust safety measures becomes imperative. This research paper delves into the intricate realm of web and mobile request safety, unraveling a multi-faceted exploration that combines traditional feature engineering with state-of-the-art machine learning models. Beginning with foundational models like TextCNN and TextRNN, we scrutinize their effectiveness in discerning the safety of requests. Advancing our investigation, we delve into the capabilities of sophisticated architectures, including Bidirectional LSTMs, DistilBERT, and RoBERTa. Beyond individual assessments, we introduce hybrid models that synergize the strengths of various approaches, establishing a comprehensive defense against emerging security threats. Throughout this research, we navigate the intricacies of model training, evaluation, and performance metrics. From accuracy and precision to recall and confusion matrices, each metric paints a nuanced picture of the efficacy of these models in ensuring the safety of web and mobile interactions. In a world where cyber threats loom large, the significance of this research lies not only in its technical contributions but also in its practical implications. By providing insights into innovative strategies for enhancing the security and resilience of digital applications, this paper contributes to the ongoing discourse on fortifying the digital infrastructure.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3406413",
            "Date of Publication": "28 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Salmi Salim",
                "labs": [
                    "National School of Applied Sciences, Engineering Systems and Applications Laboratory, Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            },
            {
                "name": "Oughdir Lahcen",
                "labs": [
                    "National School of Applied Sciences, Engineering Systems and Applications Laboratory, Sidi Mohamed Ben Abdellah University, Fez, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Long short term memory",
                "Bidirectional control",
                "Transformers",
                "Training",
                "Feature extraction",
                "Encoding",
                "Context modeling",
                "Network security",
                "Machine learning",
                "Natural language processing",
                "Computer security"
            ],
            "Author Keywords": [
                "Web and mobile security",
                "request safety",
                "machine learning",
                "natural language processing",
                "cybersecurity"
            ]
        }
    },
    {
        "Title": "InÉire: An Interpretable NLP Pipeline Summarizing Inclusive Policy Making Concerning Migrants in Ireland",
        "Link": "https://ieeexplore.ieee.org/document/10210388/",
        "Abstract": "Reaching marginal and other migrant communities to elicit their political views and opinions is a well-known challenge. Social media has enabled a certain amount of online activism and participation, especially in societies with abundant multicultural identities. However, it can be quite challenging to isolate the voice of the migrant in English-speaking countries, especially with an abundance of content in English on social media. In this paper, we pursue a case study of Ireland’s Twitter landscape, specifically migrant and native activists. We present a methodology that can accurately (\n>80%\n) isolate the Irish migrant voice with as little as 25 English tweets without relying on user metadata and using simple, highly explainable, out-of-the-box machine learning methods. Using this, we distil (via sentiment analysis) polarities of views, segment (via BERT-based topic modelling) and summarise (via ChatGPT) differentiated views in a consumable manner for policymakers. Our approach enables policymakers to further their understanding of multicultural communities and use this to inform their decision-making processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3303105",
            "Date of Publication": "07 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Arefeh Kazemi",
                "labs": [
                    "School of Computer Science, University College Dublin, Dublin 4, Ireland"
                ]
            },
            {
                "name": "Arjumand Younus",
                "labs": [
                    "School of Sociology, University College Dublin, Dublin 4, Ireland"
                ]
            },
            {
                "name": "Mingyeong Jeon",
                "labs": [
                    "ADAPT Centre, eXplainable Analytics Group, Faculty of Business, Technological University Dublin, Dublin 2, Ireland"
                ]
            },
            {
                "name": "M. Atif Qureshi",
                "labs": [
                    "ADAPT Centre, eXplainable Analytics Group, Faculty of Business, Technological University Dublin, Dublin 2, Ireland"
                ]
            },
            {
                "name": "Simon Caton",
                "labs": [
                    "School of Computer Science, University College Dublin, Dublin 4, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Metadata",
                "Social factors",
                "Sentiment analysis",
                "Cultural aspects",
                "Natural language processing",
                "Government policies"
            ],
            "Author Keywords": [
                "Natural language processing",
                "Ireland",
                "migrant",
                "Twitter",
                "summarization",
                "policy making"
            ]
        }
    },
    {
        "Title": "Efficient Retrieval of Data Using Semantic Search Engine Based on NLP and RDF",
        "Link": "https://ieeexplore.ieee.org/document/10246838/",
        "Abstract": "With the evolution of Web 3.0, the traditional algorithm of searching Web 2.0 would become obsolete and underperform in retrieving the precise and accurate information from the growing semantic web. It is very reasonable to presume that common users might not possess any understanding of the ontology used in the knowledge base or SPARQL query. Therefore, providing easy access of this enormous knowledge base to all level of users is challenging. The ability for all level of users to effortlessly formulate structure query such as SPARQL is very diverse. In this paper, semantic web based search methodology is proposed which converts user query in natural language into SPARQL query, which could be directed to domain ontology based knowledge base. Each query word is further mapped to the relevant concept or relations in ontology. Score is assigned to each mapping to find out the best possible mapping for the query generation. Mapping with highest score are taken into consideration along with interrogative or other function to finally formulate the user query into SPARQL query. If there is no search result retrieved from the knowledge base, then instead of returning null to the user, the query is further directed to the Web 3.0. The top “k” documents are considered to further converting them into RDF format using Text2Onto tool and the corpus of semantically structured web documents is build. Alongside, semantic crawl agent is used to get set from the semantic wiki. The Term Frequency Matrix and Co-occurrence Matrix are applied on the corpus following by singular Value decomposition (SVD) to find the results relevant for the user query. The result evaluations proved that the proposed system is efficient in terms of execution time, precision, recall and f-measures.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2084",
            "Date of Publication": "November 2021",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Usha Yadav",
                "labs": [
                    "National Institute of Fashion Technology, Jodhpur, India",
                    "YMCA, J. C. Bose University of Science & Technology, Faridabad, India"
                ]
            },
            {
                "name": "Neelam Duhan",
                "labs": [
                    "YMCA, J. C. Bose University of Science & Technology, Faridabad, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Web 2.0",
                "Semantic search",
                "Knowledge based systems",
                "Natural languages",
                "Ontologies",
                "Resource description framework",
                "Matrix decomposition"
            ],
            "Author Keywords": [
                "Domain ontology",
                "semantic search engine",
                "SPARQL",
                "natural language processing",
                "RDF"
            ]
        }
    },
    {
        "Title": "Identifying Top-Performing Students via VKontakte Social Media Communities Using Advanced NLP Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10812733/",
        "Abstract": "Identifying potentially high-performing students is crucial for universities aiming to enhance educational outcomes, for companies seeking to recruit top talents early, and for advertising platforms looking to optimize targeted marketing. This paper introduces an algorithm designed to identify students with exceptional academic performance by analyzing their subscriptions to communities on the social network VKontakte. The study examines a sample of 4445 students from Tomsk State University with publicly accessible VK profiles. The research methodology involves generating vector representations for each community based on embeddings, topic modeling, sentiment and emotion analysis, as well as text complexity metrics. To generate the embeddings, a separate model was trained and made publicly available on HuggingFace. The integration of diverse features was achieved using attention mechanisms, allowing the model to dynamically weigh their importance and capture intricate interrelations. These representations are then used to construct a digital user profile, capturing the students’ interests as reflected in their community subscriptions. Additionally, the machine learning pipeline incorporated stacking to combine predictions from multiple models, enhancing robustness and classification performance. Through a series of experiments, we developed a machine learning algorithm that effectively distinguishes between high- and low-performing students based on these profiles. This approach also enabled the identification and interpretation of key factors differentiating high-performing students from their lower-performing peers. Additionally, we investigated the factors positively and negatively associated with academic performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3521857",
            "Date of Publication": "23 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sergei S. Gorshkov",
                "labs": [
                    "Department of Computer Science, National Research University Higher School of Economics, Moscow, Russia"
                ]
            },
            {
                "name": "Dmitry I. Ignatov",
                "labs": [
                    "Department of Computer Science, National Research University Higher School of Economics, Moscow, Russia"
                ]
            },
            {
                "name": "Anastasia Yu. Chernysheva",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Skolkovo, Russia"
                ]
            },
            {
                "name": "Vyacheslav L. Goiko",
                "labs": [
                    "Laboratory of Big Data in Social Sciences, Tomsk State University, Tomsk, Russia"
                ]
            },
            {
                "name": "Vitaliy V. Kashpur",
                "labs": [
                    "Department of Sociology, Tomsk State University, Tomsk, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Encoding",
                "Bidirectional control",
                "Adaptation models",
                "Predictive models",
                "Natural language processing",
                "Transformers",
                "Vectors",
                "Prediction algorithms",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Digital footprint",
                "domain adaptation",
                "educational data mining",
                "information technologies in education",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Enhancing ECG Report Generation With Domain-Specific Tokenization for Improved Medical NLP Accuracy",
        "Link": "https://ieeexplore.ieee.org/document/10988804/",
        "Abstract": "The automation of medical report generation has been an area of interest for researchers over the years, with significant advancements in computational techniques and natural language processing. Traditionally, the focus has remained on rule-based or template-driven approaches to streamline the documentation process. However, recent breakthroughs in generative AI models have substantially enhanced the capabilities of automated medical report generation. Hence, the field has gained significant attention in recent years due to its potential to support healthcare professionals and improve diagnostic workflows. One key challenge in these models is the reliance on pre-trained, general-purpose tokenizers, which often fail to capture the domain-specific vocabulary essential for accurate medical reporting. When using a general tokenizer, the generated reports may lack coherence, relevance, or even correct medical terminology, leading to poor quality outputs. This problem is particularly acute in specialized fields like ECG, where precise terminology is critical. To address this gap, we train a Byte Pair Encoding (BPE) tokenizer to incorporate ECG-specific vocabulary, resulting in improved coherence and relevance in text generation. The custom tokenizer was integrated into a GPT-2 model for image-to-text generation tasks, where ECG reports were generated from ECG waveforms. Our experiments show that using the custom tokenizer leads to a 85% improvement in coherence and a 45% increase in relevance of generated reports compared to a general-purpose tokenizer.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3567566",
            "Date of Publication": "06 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Farzeen Ashfaq",
                "labs": [
                    "School of Computer Science, Taylor’s University, Subang Jaya, Malaysia"
                ]
            },
            {
                "name": "NZ Jhanjhi",
                "labs": [
                    "School of Computer Science, Taylor’s University, Subang Jaya, Malaysia"
                ]
            },
            {
                "name": "Navid Ali Khan",
                "labs": [
                    "School of Computer Science, Taylor’s University, Subang Jaya, Malaysia"
                ]
            },
            {
                "name": "Danish Javed",
                "labs": [
                    "School of Computer Science, Taylor’s University, Subang Jaya, Malaysia"
                ]
            },
            {
                "name": "Mehedi Masud",
                "labs": [
                    "Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammad Shorfuzzaman",
                "labs": [
                    "Department of Computer Science, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electrocardiography",
                "Medical diagnostic imaging",
                "Adaptation models",
                "Radiology",
                "Accuracy",
                "Vocabulary",
                "Transformers",
                "Tokenization",
                "Terminology",
                "X-rays"
            ],
            "Author Keywords": [
                "Fine-tuning",
                "GPT-2",
                "image-to-text conversion",
                "ECG report generation",
                "custom tokenizer"
            ]
        }
    },
    {
        "Title": "Implementing Holographic Reduced Representations for Spiking Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/11037669/",
        "Abstract": "Neuromorphic Computing surpasses conventional von Neumann architectures in terms of energy efficiency, parallelisation, scalability, and stochasticity. Given the inherent structure of neurons and synapses, neuromorphic computers can be directly implemented as spiking neural networks. Despite these advantages, neuromorphic computing applications are hitherto limited to benchmark datasets and empirical demonstrations. This is primarily due to the lack of a unifying computing framework that designates a middle-layer abstraction between the actual neuromorphic computing and the required application functionality. Drawing on the distributed vector representation of symbolic and numerical data structures and robust dual interface with diverse operational primitives, Vector Symbolic Architectures (VSA) have been positioned as a suitable candidate to address this middle-layer void. In this paper, we explore the potential of VSA as an intermediary abstraction layer to advance practical neuromorphic computing applications. We introduce a novel vectorised framework that efficiently processes parallel streams of spiking data by combining and computing them through VSA for real-time downstream learning tasks, leveraging spike latency encoding. Our implementation utilises containerised methods within Lava, an open-source framework for neuromorphic computing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3580582",
            "Date of Publication": "17 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vidura Sumanasena",
                "labs": [
                    "Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Daswin de Silva",
                "labs": [
                    "Centre for Data Analytics and Cognition, La Trobe University, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Evgeny Osipov",
                "labs": [
                    "Department of Computer Science, Luleå University of Technology, Luleå, Sweden"
                ]
            },
            {
                "name": "Dmitri A. Rachkovskij",
                "labs": [
                    "Department of Computer Science, Luleå University of Technology, Luleå, Sweden",
                    "Institute of Information Technologies and Systems, National Academy of Sciences of Ukraine, Kyiv, Ukraine"
                ]
            },
            {
                "name": "Ross W. Gayler",
                "labs": [
                    "Independent Researcher, Melbourne, VIC, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Neurons",
                "Neuromorphic engineering",
                "Encoding",
                "Computer architecture",
                "Decoding",
                "Computational modeling",
                "Biological information theory",
                "Robot sensing systems",
                "Real-time systems"
            ],
            "Author Keywords": [
                "Spiking neural networks (SNN)",
                "vector symbolic architecture (VSA)",
                "holographic reduced representations",
                "neuromorphic computing"
            ]
        }
    },
    {
        "Title": "HunEmBERT: A Fine-Tuned BERT-Model for Classifying Sentiment and Emotion in Political Communication",
        "Link": "https://ieeexplore.ieee.org/document/10149341/",
        "Abstract": "The growing number of digitally accessible text corpora and the accelerating development of NLP tools and methods (particularly the emergence of powerful large-scale language models) have allowed their widespread use in various classification tasks, including the vast field of sentiment analysis. However, these models must often be fine-tuned to perform this task efficiently. Therefore, we aimed to create a transformer-based fine-tuned model for the emotion and sentiment analysis of Hungarian political texts. The training data for the model were the manually annotated parliamentary speech texts from 2014 to 2018, which have the advantage of being rich in various emotions. The compiled corpus can be freely used for research purposes. In our work, we describe in detail the process of fine-tuning the Hungarian BERT model for sentiment and emotion classification, the performance achieved, and the typical classification errors, mainly due to a lack of recognition of pragmatic and other language use features by the fine-tuned models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3285536",
            "Date of Publication": "13 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "István Üveges",
                "labs": [
                    "Centre for Social Sciences, Budapest, Hungary"
                ]
            },
            {
                "name": "Orsolya Ring",
                "labs": [
                    "Centre for Social Sciences, Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Task analysis",
                "Sentiment analysis",
                "Dictionaries",
                "Social sciences",
                "Bit error rate",
                "Data models",
                "Emotion recognition"
            ],
            "Author Keywords": [
                "Fine-tuned BERT-model",
                "huBERT",
                "emotion analysis",
                "sentiment analysis",
                "political communication"
            ]
        }
    },
    {
        "Title": "Language Model-Driven Topic Clustering and Summarization for News Articles",
        "Link": "https://ieeexplore.ieee.org/document/8936376/",
        "Abstract": "Topic models have been widely utilized in Topic Detection and Tracking tasks, which aim to detect, track, and describe topics from a stream of broadcast news reports. However, most existing topic models neglect semantic or syntactic information and lack readable topic descriptions. To exploit semantic and syntactic information, Language Models (LMs) have been applied in many supervised NLP tasks. However, there are still no extensions of LMs for unsupervised topic clustering. Moreover, it is difficult to employ general LMs (e.g., BERT) to produce readable topic summaries due to the mismatch between the pretraining method and the summarization task. In this paper, noticing the similarity between content and summary, first we propose a Language Model-based Topic Model (LMTM) for Topic Clustering by using an LM to generate a deep contextualized word representation. Then, a new method of training a Topic Summarization Model is introduced, where it is not only able to produce brief topic summaries but also used as an LM in LMTM for topic clustering. Empirical evaluations of two different datasets show that the proposed LMTM method achieves better performance over four baselines for JC, FMI, precision, recall and F1-score. Additionally, the generated readable and reasonable summaries also validate the rationality of our model components.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2960538",
            "Date of Publication": "18 December 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Peng Yang",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "School of Cyber Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Wenhan Li",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Guangzhen Zhao",
                "labs": [
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China",
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Neural networks",
                "Computational modeling",
                "Syntactics",
                "Bit error rate",
                "Context modeling"
            ],
            "Author Keywords": [
                "Topic model",
                "topic summarization",
                "language model",
                "seq2seq"
            ]
        }
    },
    {
        "Title": "Embedding Logic Rules Into Recurrent Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/8610074/",
        "Abstract": "Incorporating prior knowledge into recurrent neural network (RNN) is of great importance for many natural language processing tasks. However, most of the prior knowledge is in the form of structured knowledge and is difficult to be exploited in the existing RNN framework. By extracting the logic rules from the structured knowledge and embedding the extracted logic rule into the RNN, this paper proposes an effective framework to incorporate the prior information in the RNN models. First, we demonstrate that commonly used prior knowledge could be decomposed into a set of logic rules, including the knowledge graph, social graph, and syntactic dependence. Second, we present a technique to embed a set of logic rules into the RNN by the way of feedback masks. Finally, we apply the proposed approach to the sentiment classification and named entity recognition task. The extensive experimental results verify the effectiveness of the embedding approach. The encouraging results suggest that the proposed approach has the potential for applications in other NLP tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2892140",
            "Date of Publication": "11 January 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bingfeng Chen",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Zhifeng Hao",
                "labs": [
                    "School of Mathematics and Big Data, Foshan University, Foshan, China"
                ]
            },
            {
                "name": "Xiaofeng Cai",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Ruichu Cai",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Wen Wen",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Jian Zhu",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Guangqiang Xie",
                "labs": [
                    "Department of Computer Science, Guangdong University of Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Recurrent neural networks",
                "Probabilistic logic",
                "Knowledge engineering",
                "Syntactics",
                "Graphical models"
            ],
            "Author Keywords": [
                "RNN",
                "logic rules",
                "sentiment classification",
                "named entity recognition"
            ]
        }
    },
    {
        "Title": "Toward the Development of Large-Scale Word Embedding for Low-Resourced Language",
        "Link": "https://ieeexplore.ieee.org/document/9770772/",
        "Abstract": "Word embedding is possessed by Natural language processing as a key procedure for semantically and syntactically manipulating the unlabeled text corpus. While this process represents the extracted features of corpus on vector space that enables to perform the NLP tasks such as summary generation, text simplification, next sentence prediction, etc. There exist some approaches for word embedding that consider co-occurrence and word frequency, such as Matrix Factorization, skip-gram, hierarchical-structure regularizer, and noise contrastive estimation. These approaches have created mature word vectors for most spoken languages in the world, on the other hand, the research community turned their minor attention towards the Urdu language having 231.3 million speakers. This paper focuses on creating Urdu word embedding. To perform this task, we used a dataset covering different categories of News such as Business, Sports, Health, Politics, Entertainment, Science, world, and others. This dataset was tokenized while creating 288 million tokens. Further, for word vector formation we utilized skip-gram also known as the word2vec model. The embedding was performed while limiting the vector dimensions to 100, 200, 300, 400, 500, 128, 256, and 512. For evaluation Wordsim-353 and Lexsim-999 annotated datasets were utilized. The proposed work achieved a 0.66 Spearman correlation coefficient value for wordsim-353 and 0.439 for Lexsim-999. The results were compared with state-of-the-art and were observed better.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3173259",
            "Date of Publication": "09 May 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shahzad Nazir",
                "labs": [
                    "Department of Computer Science, National Textile University, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Asif",
                "labs": [
                    "Department of Computer Science, National Textile University, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Shahbaz Ahmad Sahi",
                "labs": [
                    "Department of Computer Science, National Textile University, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Shahbaz Ahmad",
                "labs": [
                    "Department of Computer Science, National Textile University, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Yazeed Yasin Ghadi",
                "labs": [
                    "Department of Computer Science/Software Engineering, Al Ain University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Muhammad Haris Aziz",
                "labs": [
                    "Mechanical Engineering Department, University of Sargodha, Sargodha, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Task analysis",
                "Semantics",
                "Context modeling",
                "Training",
                "Bit error rate",
                "Predictive models"
            ],
            "Author Keywords": [
                "Word embedding",
                "Urdu language",
                "word vectors",
                "word2vec",
                "large-scale"
            ]
        }
    },
    {
        "Title": "Distractor Generation Through Text-to-Text Transformer Models",
        "Link": "https://ieeexplore.ieee.org/document/10418879/",
        "Abstract": "In recent years, transformer language models have made a significant impact on automatic text generation. This study focuses on the task of distractor generation in Spanish using a fine-tuned multilingual text-to-text model, namely mT5. Our method outperformed established baselines based on LSTM networks, confirming the effectiveness of Transformer architectures in such NLP tasks. While comparisons with other Transformer-based solutions yielded diverse outcomes based on the metric of choice, our method notably achieved superior results on the ROUGE metric compared to the GPT-2 approach. Although traditional evaluation metrics such as BLEU and ROUGE are commonly used, this paper argues for more context-sensitive metrics given the inherent variability in acceptable distractor generation results. Among the contributions of this research is a comprehensive comparison with other methods, an examination of the potential drawbacks of multilingual models, and the introduction of alternative evaluation metrics. Future research directions, derived from our findings and a review of related works are also suggested, with a particular emphasis on leveraging other language models and Transformer architectures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3361673",
            "Date of Publication": "02 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "David De-Fitero-Dominguez",
                "labs": [
                    "Universidad de Alcalá, Edificio Politécnico, Alcalá de Henares, Madrid, Spain"
                ]
            },
            {
                "name": "Eva Garcia-Lopez",
                "labs": [
                    "Universidad de Alcalá, Edificio Politécnico, Alcalá de Henares, Madrid, Spain"
                ]
            },
            {
                "name": "Antonio Garcia-Cabot",
                "labs": [
                    "Universidad de Alcalá, Edificio Politécnico, Alcalá de Henares, Madrid, Spain"
                ]
            },
            {
                "name": "Jesus-Angel Del-Hoyo-Gabaldon",
                "labs": [
                    "Universidad de Alcalá, Edificio Politécnico, Alcalá de Henares, Madrid, Spain"
                ]
            },
            {
                "name": "Antonio Moreno-Cediel",
                "labs": [
                    "Universidad de Alcalá, Edificio Politécnico, Alcalá de Henares, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Measurement",
                "Transformers",
                "Training",
                "Context modeling",
                "Computational modeling",
                "Natural language processing",
                "Artificial intelligence",
                "Computer applications",
                "Educational technology",
                "Text categorization",
                "Electronic messaging",
                "Text analysis"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "natural languages",
                "natural language processing",
                "computer applications",
                "educational technology"
            ]
        }
    },
    {
        "Title": "Word Embedding With Zipf’s Context",
        "Link": "https://ieeexplore.ieee.org/document/8907781/",
        "Abstract": "Word embeddings generated by neural language models have achieved great success in many NLP tasks. However, neural language models may be difficult to train and time consuming. In this paper, we introduce a simpler but efficient word embedding method based on cooccurrence matrix factorization. Our method drastically reduces the dimensions of the cooccurrence matrix according to the famous Zipf's word frequency law. We observe that if the sampling times of a target word increase to a certain extent, the context of the target word will follow the Zipf's distribution. Enlightened by this, we propose a novel transformation for the cooccurrence matrix. The built cooccurrence matrix is then factorized by PCA. As PCA simply factorizes the cooccurrence matrix linearly and cannot capture the nonlinear relations of features, we construct an autoencoder to further transform the vectors. We compare our method with some well-known neural language models. Our method shows a comparable performance though it is much simpler than the neural language models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2954691",
            "Date of Publication": "20 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lizheng Gao",
                "labs": [
                    "State Key Laboratory of Mathematical Engineering and Advanced Computing, Information Engineering University, Zhengzhou, China"
                ]
            },
            {
                "name": "Gang Zhou",
                "labs": [
                    "State Key Laboratory of Mathematical Engineering and Advanced Computing, Information Engineering University, Zhengzhou, China"
                ]
            },
            {
                "name": "Junyong Luo",
                "labs": [
                    "State Key Laboratory of Mathematical Engineering and Advanced Computing, Information Engineering University, Zhengzhou, China"
                ]
            },
            {
                "name": "Yongzhong Huang",
                "labs": [
                    "School of Computer Science and Information Security, Guilin University of Electronic Technology, Guilin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Microsoft Windows",
                "Task analysis",
                "Principal component analysis",
                "Matrix decomposition",
                "Neural networks",
                "Symmetric matrices"
            ],
            "Author Keywords": [
                "Word embedding",
                "co-occurrence matrix factorization",
                "Zipf’s law"
            ]
        }
    },
    {
        "Title": "Improving BERTScore for Machine Translation Evaluation Through Contrastive Learning",
        "Link": "https://ieeexplore.ieee.org/document/10540388/",
        "Abstract": "BERTScore is an automatic evaluation metric for machine translation. It calculates similarity scores between candidate and reference tokens through embeddings. The quality of embeddings is crucial, but embeddings of low-resource languages tend to be poor. Multilingual pre-trained models can transfer knowledge from rich-resource languages to low-resource languages, but embeddings from these models are not always well aligned. To improve BERTScore for low-resource languages, we attempt to align embeddings by fine-tuning pre-trained models via contrastive learning which shortens the distance between semantically similar sentences and increases the distance between dissimilar sentences. We experiment on Hausa, a low-resource language, in the WMT21 English-Hausa translation task. We conduct fine-tuning on three different pre-trained models (XLM-R, mBERT, LaBSE). Our experimental results show that our proposed method not only achieves higher correlation with human judgments than original BERTScore, but also surpass surface-based metrics such as BLEU, chrF, and the state-of-the-art metric COMET, when fine-tuning mBERT. Moreover, our proposed method generates better embeddings than pre-trained embedding models (E5, BGE, M3E) which are fine-tuned on different NLP tasks. We also extend our experiments to Chinese, a rich-resource language, in an English-Chinese translation task, and further confirms the effectiveness of our method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3406993",
            "Date of Publication": "28 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gongbo Tang",
                "labs": [
                    "School of Information Science, Beijing Language and Culture University, Beijing, China"
                ]
            },
            {
                "name": "Oreen Yousuf",
                "labs": [
                    "School of Information Science, Beijing Language and Culture University, Beijing, China",
                    "Department of Linguistics and Philology, Uppsala University, Uppsala, Sweden"
                ]
            },
            {
                "name": "Zeying Jin",
                "labs": [
                    "School of Information Science, Beijing Language and Culture University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Measurement",
                "Computational modeling",
                "Data models",
                "Correlation",
                "Comets",
                "Mathematical models",
                "Contrast resolution",
                "Natural language processing",
                "Translational research"
            ],
            "Author Keywords": [
                "BERTScore",
                "contrastive learning",
                "low-resource languages",
                "machine translation evaluation"
            ]
        }
    },
    {
        "Title": "Comparison of Neural Language Modeling Pipelines for Outcome Prediction From Unstructured Medical Text Notes",
        "Link": "https://ieeexplore.ieee.org/document/9698175/",
        "Abstract": "Machine learning techniques and algorithm-based approaches are becoming more and more vital to support clinical decision-making. In the medical area, natural language processing (NLP) techniques have shown the ability to extract useful information from electronic health records. On the one hand, statistic, semantic, and contextualized word embedding-based models and on the other hand preprocessing approaches are the keys to a better representation of a document. Using narratives from the Intensive Care Unit, we elaborated a comparison of the most used methods and preprocessing approaches to tackle an outcome prediction problem and guide researchers into NLP pipelines in the medical area. We used real data from Medical Information Mart for Intensive Care-III (MIMIC-III). We selected all notes related to patients with pneumonia. We conducted a deep analysis on text preprocessing tasks producing three datasets: raw data with minor preprocessing, meticulous preprocessing, and extreme preprocessing filtering only medical-related terminologies using Named Entity Recognition algorithms. We then used these three sets in five models, of which two are based on the traditional noncontextual word embedding techniques and three use contextualized word embedding based on a transformer. We demonstrated that transformer-based models outperform other word embedding models and a profound preprocessing yielded an accuracy of 98.2 F1-score. These results show the highly competitive ability of NLP predictive models against other models that use medical data. With an appropriate NLP pipeline, the information contained in medical narratives can be used to draw up a patient profile, and admission notes can help to ascertain a mortality risk of a patient admitted to the Intensive Care Unit.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3148279",
            "Date of Publication": "31 January 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cherubin Mugisha",
                "labs": [
                    "School of Computer Science and Engineering, The University of Aizu Tsuruga, Ikki-machi, Aizu-Wakamatsu, Fukushima, Japan"
                ]
            },
            {
                "name": "Incheon Paik",
                "labs": [
                    "School of Computer Science and Engineering, The University of Aizu Tsuruga, Ikki-machi, Aizu-Wakamatsu, Fukushima, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Predictive models",
                "Task analysis",
                "Medical diagnostic imaging",
                "Pipelines",
                "Natural language processing",
                "MIMICs"
            ],
            "Author Keywords": [
                "BERT",
                "medical notes",
                "NER",
                "NLP",
                "outcome prediction",
                "pre-trained language models",
                "text preprocessing",
                "word embedding"
            ]
        }
    },
    {
        "Title": "Pretrained Quantum-Inspired Deep Neural Network for Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10540458/",
        "Abstract": "Natural language processing (NLP) may face the inexplicable “black-box” problem of parameters and unreasonable modeling for lack of embedding of some characteristics of natural language, while the quantum-inspired models based on quantum theory may provide a potential solution. However, the essential prior knowledge and pretrained text features are often ignored at the early stage of the development of quantum-inspired models. To attacking the above challenges, a pretrained quantum-inspired deep neural network is proposed in this work, which is constructed based on quantum theory for carrying out strong performance and great interpretability in related NLP fields. Concretely, a quantum-inspired pretrained feature embedding (QPFE) method is first developed to model superposition states for words to embed more textual features. Then, a QPFE-ERNIE model is designed by merging the semantic features learned from the prevalent pretrained model ERNIE, which is verified with two NLP downstream tasks: 1) sentiment classification and 2) word sense disambiguation (WSD). In addition, schematic quantum circuit diagrams are provided, which has potential impetus for the future realization of quantum NLP with quantum device. Finally, the experiment results demonstrate QPFE-ERNIE is significantly better for sentiment classification than gated recurrent unit (GRU), BiLSTM, and TextCNN on five datasets in all metrics and achieves better results than ERNIE in accuracy, F1-score, and precision on two datasets (CR and SST), and it also has advantage for WSD over the classical models, including BERT (improves F1-score by 5.2 on average) and ERNIE (improves F1-score by 4.2 on average) and improves the F1-score by 8.7 on average compared with a previous quantum-inspired model QWSD. QPFE-ERNIE provides a novel pretrained quantum-inspired model for solving NLP problems, and it lays a foundation for exploring more quantum-inspired models in the future.",
        "Details": {
            "DOI": "10.1109/TCYB.2024.3398692",
            "Date of Publication": "29 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Cybernetics"
        },
        "issn_info": {
            "Print ISSN": "2168-2267",
            "Electronic ISSN": "2168-2275"
        },
        "authors_data": [
            {
                "name": "Jinjing Shi",
                "labs": [
                    "School of Electronic Information, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Tian Chen",
                "labs": [
                    "School of Electronic Information, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Wei Lai",
                "labs": [
                    "School of Electronic Information, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Shichao Zhang",
                "labs": [
                    "School of Electronic Information, Central South University, Changsha, China",
                    "Key Laboratory of MIMS, College of Computer Science and Technology, Guangxi Normal University, Guilin, China"
                ]
            },
            {
                "name": "Xuelong Li",
                "labs": [
                    "Institute of Artificial Intelligence, China Telecom Corporation Ltd., Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantum mechanics",
                "Quantum state",
                "Integrated circuit modeling",
                "Neural networks",
                "Logic gates",
                "Natural language processing",
                "Machine learning",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "neural networks",
                "quantum-inspired neural network",
                "quantum language model",
                "quantum machine learning",
                "sentiment classification",
                "word sense disambiguation (WSD)"
            ]
        }
    },
    {
        "Title": "Quantum Natural Language Processing: A Comprehensive Survey",
        "Link": "https://ieeexplore.ieee.org/document/10577116/",
        "Abstract": "By using the quantum mechanics phenomenon, quantum computers provide a new dimension of computational power that drastically accelerates solving complex and resource-intensive problems. One of the most evolving but, due to the computation power of standard computers, reasonably limited application domain is natural language processing (NLP). NLP seeks to give interactive systems the ability to understand and manipulate human language. Making systems understand and manipulate human languages requires large amounts of data and computational power during learning as well as during the execution of NLP. For handling these amounts of data like text and audio recordings and the complexity of classical NLP algorithms, quantum computation has emerged as a promising solution. This work gives an extensive overview of this new field, known as quantum natural language processing (QNLP). Introducing the basics of quantum computing, we discuss its use in NLP by explaining the different proposed embedding models, quantum algorithms, and other methods of QNLP. As QNLP is still in its infancy, this comprehensive overview is the foundation that points to the upcoming research direction.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3420707",
            "Date of Publication": "28 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Charles M. Varmantchaonala",
                "labs": [
                    "Department of Mathematics and Computer Science, Faculty of Science, University of Ngaoundéré, Ngaoundere, Cameroon"
                ]
            },
            {
                "name": "Jean Louis K. E. Fendji",
                "labs": [
                    "Department of Computer Engineering, University Institute of Technology, University of Ngaoundéré, Ngaoundere, Cameroon",
                    "Stellenbosch Institute for Advanced Study (STIAS), Wallenberg Research Centre at Stellenbosch University, Stellenbosch, South Africa"
                ]
            },
            {
                "name": "Julius Schöning",
                "labs": [
                    "Faculty of Engineering and Computer Science, Osnabrück University of Applied Sciences, Osnabrück, Germany"
                ]
            },
            {
                "name": "Marcellin Atemkeng",
                "labs": [
                    "Department of Mathematics, Rhodes University, Grahamstown, South Africa"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Quantum computing",
                "Qubit",
                "Logic gates",
                "Computational modeling",
                "Task analysis",
                "Surveys"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "quantum algorithms",
                "quantum computing",
                "quantum gates",
                "qubits"
            ]
        }
    },
    {
        "Title": "ArabSis: Arabic Corpus Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10990213/",
        "Abstract": "Despite rapid progress in natural language processing (NLP), the development of specialized resources for niche domains—critical for specialized applications like affective computing and emotionally intelligent AI—remains a persistent challenge. While benchmark datasets abound for general tasks, languages like Arabic and fields like multi-dimensional sentiment analysis beyond binary classification as positive or negative suffer from resource scarcity, limiting progress in human-centric applications. To address this gap, we present ArabSis: a novel Arabic corpus for multi-dimensional sentiment analysis across five categorical emotions (Joy, Sadness, Fear, Liking, Hatred). Our work introduces a reproducible framework for creating specialized corpora in low-resource languages, enabling future research in regressive dimensional sentiment analysis and other specialized NLP applications. The ArabSis corpus, developed through systematic data augmentation and human labelling, facilitates advanced analysis using traditional NLP techniques (TF-IDF, Bag of Words) and modern deep learning approaches. It also targets the universal Arabic language whereas previous research focuses on Arabic regardless of the dialect which make small nuances and inconsistencies among dialects unnoticeable and unfixable. We evaluate machine learning (ML) and deep learning (DL) models in one-vs-all classification tasks, demonstrating that ML models (e.g., SVMs, Random Forests) outperform DL counterparts on smaller datasets. An ensemble method combining top-performing models achieves 98.6% accuracy through score averaging and majority voting systems, though revealing inherent biases in ensemble voting mechanisms. The study provides a comprehensive pipeline encompassing data preprocessing, exploratory analysis, and model training, validated through 5-fold cross-validation, establishing a blueprint for developing specialized NLP resources, particularly for under-resourced languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3567755",
            "Date of Publication": "07 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ziad Doughan",
                "labs": [
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Beirut Arab University, Beirut, Lebanon"
                ]
            },
            {
                "name": "Sari Itani",
                "labs": [
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Beirut Arab University, Beirut, Lebanon"
                ]
            },
            {
                "name": "Samir Itani",
                "labs": [
                    "Department of Arabic Language and Literature, Faculty of Human Sciences, Beirut Arab University, Beirut, Lebanon"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Natural language processing",
                "Machine learning",
                "Data models",
                "Analytical models",
                "Computational modeling",
                "Deep learning",
                "Context modeling",
                "Tokenization",
                "Emotion recognition"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "artificial intelligence",
                "ensemble methods",
                "machine learning",
                "natural language processing",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Arabic Sentiment Analysis and Sarcasm Detection Using Probabilistic Projections-Based Variational Switch Transformer",
        "Link": "https://ieeexplore.ieee.org/document/10163795/",
        "Abstract": "Text classification is a common task in natural language processing (NLP), where the objective is to assign predefined categories or labels to a given text. Detecting sarcasm and classifying sentiment and dialect in NLP has practical applications, including spam detection, topic classification, and sentiment analysis. However, sarcasm and sentimental expressions, such as irony, humor, or criticism, can be difficult to identify through traditional NLP methods due to their implicit nature. To address this, we propose a Modified Switch Transformer (MST) for detecting sarcasm and classifying sentiment and dialect in Arabic text data. Our approach includes two key contributions: Variational Enmesh Expert’s Routing (\nV\nE\ne\nR\n) and Probabilistic Projections (\nP\nϕ\n). The switch transformer model incorporates probabilistic projections using a Variational Spatial Gated Unit-MLP to enhance the embedding generation mechanism. This updated mechanism introduces a variational aspect, providing dynamic control over the flow of information in the network, in contrast to the simpler embedding generation phase used in the original switch transformer. Moreover, we incorporate Variational Enmesh Expert’s Routing, which utilizes a hierarchical set of Variational experts, where each expert is a small and variational-directed acyclic graph network. The\nV\nE\ne\nR\nrouting technique allows the network to dynamically choose which path to take at each layer based on the input, using a set of weights learned during training to determine the best route for a given input. Instead of optimizing route paths deterministically, we utilize Variational Inference and model each route as a random variable from a distribution. Our study evaluates the effectiveness of the Modified Switch Transformer (MST) model on the ArSarcasm Dataset, which includes Arabic language data related to sarcasm, dialect, and sentiments. We compare the performance of our proposed model with existing state-of-the-art models in the literature. The results show that the switch transformer outperforms other models in detecting sarcasm and also performs well in classifying sentiment and dialect.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3289715",
            "Date of Publication": "26 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "S. Muhammad Ahmed Hassan Shah",
                "labs": [
                    "Medical Imaging and Diagnostics Laboratory (MIDL), National Center of Artificial Intelligence (NCAI), COMSATS University Islamabad, Islamabad, Pakistan",
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Syed Faizan Hussain Shah",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Asad Ullah",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Atif Rizwan",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Republic of Korea"
                ]
            },
            {
                "name": "Ghada Atteia",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Maali Alabdulhafith",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Deep learning",
                "Text categorization",
                "Sentiment analysis",
                "Switches",
                "Bayes methods",
                "Data models"
            ],
            "Author Keywords": [
                "Text classification",
                "Arabic sarcasm detection",
                "Arabic sentiment analysis",
                "switch transformer",
                "probabilistic projections",
                "variational expert routing",
                "NLP",
                "Bayesian inference",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Analytical Techniques for Developing Argumentative Writing in STEM: A Pilot Study",
        "Link": "https://ieeexplore.ieee.org/document/9566612/",
        "Abstract": "Contribution: Demonstrates how to use experiential learning (EL) to improve argumentative writing. Presents the design and development of a natural language processing (NLP) application for aiding instructors in providing feedback on student essays. Discusses how EL combined with automated support provides an analytical approach to improving written-communication skills. Background: High-quality, timely, feedback is an effective way to improve students’ writing. However, large class sizes and limited instructor backgrounds often make formative feedback impossible. Recent trends, including lowering entry requirements, have added to these challenges. Assistive technologies for implementing inclusive education provide viable solutions. Research Questions: 1) How and why can EL be used to develop argumentative writing skills in university STEM students? 2) How can technologies be developed to support using EL in teaching writing? and 3) How might the holistic impact of using such analytic techniques be evaluated? Methodology: Participants in an EL project were assigned two essays in sequence. They were given instructions on making good arguments and shown how to use an analytic rubric to maximize their scores. The essays were hand scored by tutors who provided scores for each dimension of the rubric. Subsequently, the content and argumentation of the essays were analyzed using NLP techniques to obtain independent scores. Qualitative data were also collected. Findings: The project produced transformative writing experiences for the participants. It showed how analytical techniques help improve writing skills and how relevant automated instructor assistance can be developed using NLP technologies.",
        "Details": {
            "DOI": "10.1109/TE.2021.3116202",
            "Date of Publication": "11 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Education"
        },
        "issn_info": {
            "Print ISSN": "0018-9359",
            "Electronic ISSN": "1557-9638"
        },
        "authors_data": [
            {
                "name": "Patricia Marybelle Davies",
                "labs": [
                    "College of Sciences and Human Studies, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia"
                ]
            },
            {
                "name": "Rebecca Jane Passonneau",
                "labs": [
                    "Department of Computer Science and Engineering, Penn State University, Pennsylvania, PA, USA"
                ]
            },
            {
                "name": "Smaranda Muresan",
                "labs": [
                    "Department of Computer Science, Columbia University, New York, NY, USA"
                ]
            },
            {
                "name": "Yanjun Gao",
                "labs": [
                    "Department of Computer Science and Engineering, Penn State University, Pennsylvania, PA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Writing",
                "Education",
                "Tools",
                "Natural language processing",
                "Task analysis",
                "Computer science",
                "Systematics"
            ],
            "Author Keywords": [
                "Argumentation",
                "content annotation",
                "experiential learning (EL)",
                "higher education (HE)",
                "natural language processing (NLP)",
                "rubric reliability",
                "STEM",
                "written communication"
            ]
        }
    },
    {
        "Title": "Detection of Sarcasm in Urdu Tweets Using Deep Learning and Transformer Based Hybrid Approaches",
        "Link": "https://ieeexplore.ieee.org/document/10508575/",
        "Abstract": "Sarcasm has a significant role in human communication especially on social media platforms where users express their sentiments through humor, satire, and criticism. The identification of sarcasm is crucial in comprehending the sentiment and the communication context on platforms like Twitter. This ambiguous nature of the expression of content presents the detection of sarcasm as a considerable challenge in natural language processing (NLP). The importance and challenges increase further, especially in languages like Urdu where resources for NLP are limited. The traditional rule-based approaches lack the desired performance because of the subtle and context-based nature of sarcasm. However, the recent advancements in NLP, particularly the transformer architecture-based large language models (LLMs) like BERT offer promising solutions. In this research, we have utilized a newly created Urdu sarcasm dataset comprising 12,910 tweets manually re-annotated into sarcastic and non-sarcastic classes. These tweets were derived from the public Urdu tweet dataset consisting of 19,995 tweets. We have established baseline results using deep learning classifiers comprising CNN, LSTM, GRU, BiLSTM, and CNN-LSTM. To comprehensively capture the contextual information, we propose a novel hybrid model architecture that integrates multilingual BERT (mBERT) embeddings with BiLSTM and multi-head attention (MHA) for Urdu sarcasm. The proposed mBERT-BiLSTM-MHA model demonstrates superior performance by achieving an accuracy of 79.51% and an F1 score of 80.04%, outperforming deep learning classifiers trained with fastText word embeddings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3393856",
            "Date of Publication": "25 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Ehtisham Hassan",
                "labs": [
                    "Department of Computer Engineering, Ghulam Ishaq Khan Institute of Engineering Sciences and Technology, Topi, Swabi, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Masroor Hussain",
                "labs": [
                    "Department of Computer Engineering, Ghulam Ishaq Khan Institute of Engineering Sciences and Technology, Topi, Swabi, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Iffat Maab",
                "labs": [
                    "Technology Management for Innovation, The University of Tokyo, Tokyo, Japan"
                ]
            },
            {
                "name": "Usman Habib",
                "labs": [
                    "Software Engineering Department, FAST School of Computing, National University of Computer & Emerging Sciences, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Attique Khan",
                "labs": [
                    "Department of Computer Science and Mathematics, Lebanese American University, Beirut, Lebanon"
                ]
            },
            {
                "name": "Anum Masood",
                "labs": [
                    "Department of Physics, Norwegian University of Science and Technology, Trondheim, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Machine learning",
                "Long short term memory",
                "Feature extraction",
                "Social networking (online)",
                "Reviews",
                "Support vector machines",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Urdu sarcasm detection",
                "NLP",
                "deep learning",
                "LLMs",
                "BERT embeddings",
                "hybrid model",
                "multi-head attention"
            ]
        }
    },
    {
        "Title": "A Novel Framework to Automatically Generate IFML Models From Plain Text Requirements",
        "Link": "https://ieeexplore.ieee.org/document/8933019/",
        "Abstract": "User Interfaces (UI's) are highly important in this era of web and mobile applications. Therefore, an efficient and accurate development of UI's is desirable in early Software Development Life Cycle (SDLC) phases. To achieve this, Object Management Group (OMG) introduced Interaction Flow Modeling Language (IFML) standard in 2013. IFML provides the modeling of manifold UI's for different applications like mobile, web and desktop. Although IFML is based on Model Driven Engineering (MDE) principle, the development of user interface models from initial requirements is still complex and time consuming task. Particularly, it requires domain expertise to understand several IFML concepts like domain model, view container etc. for the proper modeling of user interfaces. Consequently, there is a strong need of an approach to automate the development of IFML models from initial plain text requirements. This article presents a novel framework to automatically generate IFML models from textual requirements by utilizing the features of Natural Language Processing (NLP). Particularly, a set of NLP rules are developed to extract important IFML elements like View Components, Events etc. from textual requirements. Furthermore, a comprehensive algorithm is developed for the systematic execution of NLP rules in order to generate both IFML Domain and Core models. As a part of research, a sophisticated\nT\next to IF ML (T2IF) tool is developed. The feasibility of proposed framework is demonstrated through movie manager and online bookstore case studies. The evaluation results prove that the proposed framework is capable of generating IFML models from textual requirements with high accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2959813",
            "Date of Publication": "16 December 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maryum Hamdani",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Wasi Haider Butt",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Waseem Anwar",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Imran Ahsan",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Farooque Azam",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Mudassar Adeel Ahmed",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "User interfaces",
                "Unified modeling language",
                "Natural language processing",
                "Containers",
                "Software",
                "Standards"
            ],
            "Author Keywords": [
                "IFML",
                "NLP",
                "T2IF tool",
                "user interfaces",
                "artificial intelligence"
            ]
        }
    },
    {
        "Title": "Machine Reading Comprehension for the Tamil Language With Translated SQuAD",
        "Link": "https://ieeexplore.ieee.org/document/10844269/",
        "Abstract": "Machine Reading Comprehension (MRC) is a challenging task in Natural Language Processing (NLP), crucial for automated customer support, enabling chatbots and virtual assistants to accurately understand and respond to queries. It also enhances question-answering systems, benefiting educational tools, search engines, and help desks. The introduction of attention-based transformer models has significantly boosted MRC performance, especially for well-resourced languages such as English. However, MRC for low-resourced languages (LRL) remains an ongoing research area. Although Large Language Models show exceptional NLP performance, they are less effective for LRL and are expensive to train and deploy. Consequently, simpler language models that are targeted at specific tasks remain viable for these languages. This research examines high-performing language models on the Tamil MRC task, detailing the preparation of a Tamil-translated and processed SQuAD dataset to establish a standard dataset for Tamil MRC. The study analyzes the performance of multilingual transformer models on the Tamil MRC task, including Multilingual DistilBERT, Multilingual BERT, XLM-RoBERTa, MuRIL, and RemBERT. Additionally, it explores improving these models’ performance by fine-tuning them with English SQuAD, Tamil SQuAD, and a newly developed Tamil Short Story (TSS) dataset for MRC. Tamil’s agglutinative nature, which expresses grammatical information through suffixation, results in a high degree of word inflexion. Given this characteristic, the BERT score was chosen as the evaluation metric for MRC performance. The analysis shows that the XLM-RoBERTa model outperformed the others for Tamil MRC, achieving a BERT score of 86.29% on the TSS MRC test set. This superior performance is attributed to the model’s cross-lingual learning capability and the increased number of data records used for fine-tuning. The research underscores the necessity of language-specific fine-tuning of multilingual models to enhance NLP task performance, for low-resourced languages.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3530949",
            "Date of Publication": "17 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anton Vijeevaraj Ann Sinthusha",
                "labs": [
                    "University of Colombo School of Computing, Colombo, Sri Lanka"
                ]
            },
            {
                "name": "Eugene Y. A. Charles",
                "labs": [
                    "Department of Computer Science, University of Jaffna, Jaffna, Sri Lanka"
                ]
            },
            {
                "name": "Ruvan Weerasinghe",
                "labs": [
                    "University of Colombo School of Computing, Colombo, Sri Lanka"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multilingual",
                "Computational modeling",
                "Translation",
                "Benchmark testing",
                "Transformers",
                "Analytical models",
                "Data models",
                "Accuracy",
                "Training",
                "Standards"
            ],
            "Author Keywords": [
                "Machine reading comprehension (MRC)",
                "natural language processing (NLP)",
                "multilingual language models",
                "low-resourced languages (LRL)",
                "Tamil language processing",
                "transformer models",
                "language model fine-tuning",
                "cross-lingual learning",
                "multilingual BERT",
                "XLM-RoBERTa"
            ]
        }
    },
    {
        "Title": "Design and implementation of a Luganda text normalization module for a speech synthesis software program",
        "Link": "https://ieeexplore.ieee.org/document/9194384/",
        "Abstract": "This paper describes a Luganda text normalization module, a crucial component needed for a Luganda Text to Speech system. We describe the use of a rule-based approach for detection, classification and verbalization of Luganda text. At the core of this module are the Luganda grammar rules that were hand-built to normalize Non-Standard Words (NSWs) from different semiotic and noun classes. Input text is first analyzed, matched against handcrafted patterns developed using regular expressions to detect any NSWs. Upon detection, NSWs are tokenized and classified into one of the semiotic classes and then if necessary, into one of the Luganda noun classes. These are subsequently verbalized, each according to its semiotic as well as noun class, and a new text file is produced. We tested the module with 7 datasets and achieved average detection and normalization rates of 82% and 77.7% respectively.",
        "Details": {
            "DOI": "10.23919/SAIEE.2020.9194384",
            "Date of Publication": "10 September 2020",
            "Publisher": "SAIEE",
            "Published In": "SAIEE Africa Research Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1991-1696"
        },
        "authors_data": [
            {
                "name": "Ronald Kizito",
                "labs": [
                    "Department of Electrical and Computer Engineering, Makerere University, P.O. Box 7062, Kampala, Uganda"
                ]
            },
            {
                "name": "Wayne S. Okello",
                "labs": [
                    "netLabs!UG, a Research Centre of Excellence in the Department of Electrical and Computer Engineering, Makerere University, P.O. Box 7062, Kampala, Uganda"
                ]
            },
            {
                "name": "Sulaiman Kagumire",
                "labs": [
                    "netLabs!UG, a Research Centre of Excellence in the Department of Electrical and Computer Engineering, Makerere University, P.O. Box 7062, Kampala, Uganda"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semiotics",
                "Standards",
                "Currencies",
                "Natural language processing",
                "Speech synthesis",
                "Grammar",
                "Measurement units"
            ],
            "Author Keywords": [
                "Automatic Speech Recognition",
                "Detection-conversion",
                "Luganda",
                "Machine Translation",
                "NLP",
                "Number system",
                "Speech Synthesis",
                "Text Normalization",
                "Text-to-speech",
                "TTS"
            ]
        }
    },
    {
        "Title": "GPT (Generative Pre-Trained Transformer)— A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/10500411/",
        "Abstract": "The Generative Pre-trained Transformer (GPT) represents a notable breakthrough in the domain of natural language processing, which is propelling us toward the development of machines that can understand and communicate using language in a manner that closely resembles that of humans. GPT is based on the transformer architecture, a deep neural network designed for natural language processing tasks. Due to their impressive performance on natural language processing tasks and ability to effectively converse, GPT have gained significant popularity among researchers and industrial communities, making them one of the most widely used and effective models in natural language processing and related fields, which motivated to conduct this review. This review provides a detailed overview of the GPT, including its architecture, working process, training procedures, enabling technologies, and its impact on various applications. In this review, we also explored the potential challenges and limitations of a GPT. Furthermore, we discuss potential solutions and future directions. Overall, this paper aims to provide a comprehensive understanding of GPT, its enabling technologies, their impact on various applications, emerging challenges, and potential solutions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3389497",
            "Date of Publication": "15 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gokul Yenduri",
                "labs": [
                    "School of Computer Science and Engineering, VIT-AP University, Amaravati, Andhra Pradesh, India"
                ]
            },
            {
                "name": "M. Ramalingam",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "G. Chemmalar Selvi",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "Y. Supriya",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "Gautam Srivastava",
                "labs": [
                    "Department of Mathematics and Computer Science, Brandon University, Brandon, MB, Canada",
                    "Department of Computer Science and Mathematics, Lebanese American University, Chouran, Beirut, Lebanon"
                ]
            },
            {
                "name": "Praveen Kumar Reddy Maddikunta",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "G. Deepti Raj",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "Rutvij H. Jhaveri",
                "labs": [
                    "Department of Computer Science and Engineering, School of Technology, Pandit Deendayal Energy University, Gandhinagar, India"
                ]
            },
            {
                "name": "B. Prabadevi",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "Weizheng Wang",
                "labs": [
                    "Department of Computer Science, City University of Hong Kong, Hong Kong, SAR, China"
                ]
            },
            {
                "name": "Athanasios V. Vasilakos",
                "labs": [
                    "Center for AI Research (CAIR), University of Agder (UiA), Grimstad, Norway"
                ]
            },
            {
                "name": "Thippa Reddy Gadekallu",
                "labs": [
                    "Center of Research Impact and Outcome, Chitkara University, Rajpura, Punjab, India",
                    "Division of Research and Development, Lovely Professional University, Phagwara, India",
                    "Department of Electrical and Computer Engineering, Lebanese American University, Chouran, Beirut, Lebanon"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Solid modeling",
                "Artificial intelligence",
                "Surveys",
                "Task analysis",
                "Reviews",
                "Transformers"
            ],
            "Author Keywords": [
                "Generative pre-trained transformer",
                "natural language processing",
                "artificial intelligence"
            ]
        }
    },
    {
        "Title": "Learning to Detect Deceptive Opinion Spam: A Survey",
        "Link": "https://ieeexplore.ieee.org/document/8678638/",
        "Abstract": "With the development of e-commerce, more and more users begin to post reviews or comments about the quality of products on the internet. Meanwhile, people usually read previous reviews before purchasing online products. However, people are frequently deceived by deceptive opinion spam, which is usually used for promoting the products or damaging their reputations because of economic benefit. Deceptive opinion spam can mislead people's purchase behavior, so the techniques of detecting deceptive opinion spam have extensively been researched in past ten years. In particular, some work based on deep learning has been investigated in last three years for the task. However, there still lack a survey, which can systematically analyze and summarize the previous techniques. To address this issue, this paper first introduces the task of deceptive opinion spam detection. Then, we summarize the existing dataset resources and their construction methods. Third, existing methods are analyzed from two aspects: traditional statistical methods and neural network models. Finally, we give some future directions of the task.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2908495",
            "Date of Publication": "01 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yafeng Ren",
                "labs": [
                    "Collaborative Innovation Center for Language Research and Services, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            },
            {
                "name": "Donghong Ji",
                "labs": [
                    "Collaborative Innovation Center for Language Research and Services, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Neural networks",
                "Economics",
                "Deep learning",
                "Supervised learning",
                "Manuals"
            ],
            "Author Keywords": [
                "Deceptive opinion spam",
                "deceptive review",
                "machine learning",
                "feature engineering",
                "natural language processing",
                "deep learning"
            ]
        }
    },
    {
        "Title": "MGL-CNN: A Hierarchical Posts Representations Model for Identifying Depressed Individuals in Online Forums",
        "Link": "https://ieeexplore.ieee.org/document/8998086/",
        "Abstract": "More users suffering from depression turn to online forums to express their problems and seek help. In such forums, there is often a large volume of posts with sensitive content, indicating that the user has a risk of suicide and self-harm. Early detection of depression using appropriate deep learning models and social media data can prevent potential self-harm. However, existing depression detection models are not powerful enough to capture critical sentiment information from the large volume of posts published by each user, which makes the performance of these models not satisfying. To address this problem, we propose a hierarchical posts representations model named Multi-Gated LeakyReLU CNN (MGL-CNN) for identifying depressed individuals in online forums. The model consists of two parts: the first one is a post-level operation, which is used to learn the representation of each post of the user, and the second one is a user-level operation, which is used to obtain the overall representation of the user's emotional state. Besides, we propose another depression detection model by changing the number of gated units in the MGL-CNN, which is named Single-Gated LeakyReLU CNN (SGL-CNN). We show how to use our models to identify depressed users through a lot of posted content. Experimental results showed that our models performed better than the previous state-of-the-art models on the Reddit Self-reported Depression Diagnosis dataset, and also performed well on the Early Detection of Depression dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2973737",
            "Date of Publication": "13 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guozheng Rao",
                "labs": [
                    "College of Intelligence and Computing, Tianjin University, Tianjin, China",
                    "Tianjin Key Laboratory of Cognitive Computing and Applications, Tianjin University, Tianjin, China",
                    "School of New Media and Communication, Tianjin University of Science and Technology, Tianjin, China"
                ]
            },
            {
                "name": "Yue Zhang",
                "labs": [
                    "College of Intelligence and Computing, Tianjin University, Tianjin, China",
                    "Tianjin Key Laboratory of Cognitive Computing and Applications, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Li Zhang",
                "labs": [
                    "School of Economics and Management, Tianjin University of Science and Technology, Tianjin, China"
                ]
            },
            {
                "name": "Qing Cong",
                "labs": [
                    "College of Intelligence and Computing, Tianjin University, Tianjin, China",
                    "Tianjin Key Laboratory of Cognitive Computing and Applications, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Zhiyong Feng",
                "labs": [
                    "College of Intelligence and Computing, Tianjin University, Tianjin, China",
                    "Tianjin Key Laboratory of Cognitive Computing and Applications, Tianjin University, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Logic gates",
                "Social network services",
                "Computational modeling",
                "Task analysis",
                "Feature extraction",
                "Psychology",
                "Neural networks"
            ],
            "Author Keywords": [
                "Depression detection",
                "online forums",
                "MGL-CNN",
                "SGL-CNN",
                "neural network architecture"
            ]
        }
    },
    {
        "Title": "A Novel Document-Level Relation Extraction Method Based on BERT and Entity Information",
        "Link": "https://ieeexplore.ieee.org/document/9098945/",
        "Abstract": "Document-level relation extraction aims to extract the relationship among the entities in a paragraph of text. Compared with sentence-level, the text in document-level relation extraction is much longer and contains many more entities. It makes the document-level relation extraction a harder task. The number and complexity of entities make it necessary to provide enough information about the entities for the models in document-level relation extraction. To solve this problem, we put forward a document-level entity mask method with type information (DEMMT), which masks each mention of the entities by special tokens. By using this entity mask method, the model can accurately obtain every mention and type of the entities. Based on DEMMT, we propose a BERT-based one-pass model, through which we can predict the relationships among the entities by processing the text once. We test the proposed model on the DocRED dataset, which is a large scale open-domain document-level relation extraction dataset. The results on the manually annotated part of DocRED show that our approach obtains 6% F1 improvement compared with the state-of-the-art models that do not use pre-trained models and has 2% F1 improvement than BERT which does not use the DEMMT. On the distant supervision generated part of DocRED, the improvement of F1 is 2% compared with no pre-trained models, and 5% compared with pure BERT.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2996642",
            "Date of Publication": "22 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiaoyu Han",
                "labs": [
                    "Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China",
                    "Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China",
                    "School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Lei Wang",
                "labs": [
                    "Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China",
                    "Key Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Bit error rate",
                "Data mining",
                "Task analysis",
                "Semantics",
                "Australia",
                "Neural networks"
            ],
            "Author Keywords": [
                "Relation extraction",
                "document-level",
                "BERT",
                "entity information",
                "one-pass"
            ]
        }
    },
    {
        "Title": "BERT, XLNet or RoBERTa: The Best Transfer Learning Model to Detect Clickbaits",
        "Link": "https://ieeexplore.ieee.org/document/9617586/",
        "Abstract": "Clickbait can be a spam or an advert which more often provides a link to commercial website and it can also be a headline to news media website which makes money from page views by providing eye-catchy headlines with deceptive news. This paper focuses on the latter definition in order to identify news clickbaits that are published in Twitter. The aim of this work is to use recent Transfer Learning models to detect news clickbaits by adding various configuration changes to the existing models. Based on the author’s knowledge, this is the first attempt to adapt Transfer Learning to classify Clickbaits in social media. In this work we fine-tuned BERT, XLNet and RoBERTa models by integrating novel configuration changes into their default architectures such as model expansion, pruning and data augmentation strategies. Webis Clickbait dataset was used to train these models and the best performed model at the Webit Clickbait competition 2017 was considered as our benchmark. The analyses in this work are mainly focused on eight different scenarios after applying several fine-tuning approaches and model configuration changes to the default Transfer Learning models. The results shown that, our modified Transfer Learning approaches outperformed the considered benchmark. In our experiments, the best performed Transfer Learning model was RoBERTa with the integration of an additional non-linear layer with the hidden output tensor. this configuration has achieved 19.12% more accuracy in compared to the benchmark model for the binary classification. There is no significant performance improvement when each model expanded by adding an extra RNN layer(s). Apart from that, we experimented with another labelled clickbait dataset (Kaggle clickbait challenge) to explore the performance of our fine-tuned models under different scenarios.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3128742",
            "Date of Publication": "16 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Praboda Rajapaksha",
                "labs": [
                    "CNRS Lab UMR5157, Institut Polytechnique de Paris, Palaiseau, France"
                ]
            },
            {
                "name": "Reza Farahbakhsh",
                "labs": [
                    "CNRS Lab UMR5157, Institut Polytechnique de Paris, Palaiseau, France"
                ]
            },
            {
                "name": "Noel Crespi",
                "labs": [
                    "CNRS Lab UMR5157, Institut Polytechnique de Paris, Palaiseau, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transfer learning",
                "Bit error rate",
                "Task analysis",
                "Social networking (online)",
                "Adaptation models",
                "Blogs",
                "Data models"
            ],
            "Author Keywords": [
                "Clickbait",
                "fake news",
                "transfer learning",
                "BERT",
                "RoBERTa",
                "XLNet",
                "Twitter",
                "news clickbaits",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Multi-Head Self-Attention Transformation Networks for Aspect-Based Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9314135/",
        "Abstract": "Aspect-based sentiment analysis (ABSA) aims to analyze the sentiment polarity of an input sentence in a certain aspect. Many existing methods of ABSA employ long short-term memory (LSTM) networks and attention mechanism. However, the attention mechanism only models the local certain dependencies of the input information, which fails to capture the global dependence of the inputs. Simply improving the attention mechanism fails to solve the issue of target-sensitive sentiment expression, which has been proven to degrade the prediction effectiveness. In this work, we propose the multi-head self-attention transformation (MSAT) networks for ABSA tasks, which conducts more effective sentiment analysis with target specific self-attention and dynamic target representation. Given a set of review sentences, MSAT applies multi-head target specific self-attention to better capture the global dependence and introduces target-sensitive transformation to effectively tackle the problem of target-sensitive sentiment at first. Second, the part-of-speech (POS) features are integrated into MSAT to capture the grammatical features of sentences. A series of experiments carried on the SemEval 2014 and Twitter datasets show that the proposed model achieves better effectiveness compared with several state-of-the-art methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3049294",
            "Date of Publication": "05 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuming Lin",
                "labs": [
                    "Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"
                ]
            },
            {
                "name": "Chaoqiang Wang",
                "labs": [
                    "Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"
                ]
            },
            {
                "name": "Hao Song",
                "labs": [
                    "Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"
                ]
            },
            {
                "name": "You Li",
                "labs": [
                    "Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Task analysis",
                "Context modeling",
                "Feature extraction",
                "Analytical models",
                "Standards"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis",
                "self-attention",
                "transformation networks",
                "target-specific transformation"
            ]
        }
    },
    {
        "Title": "Few-Shot Transfer Learning for Text Classification With Lightweight Word Embedding Based Models",
        "Link": "https://ieeexplore.ieee.org/document/8693837/",
        "Abstract": "Many deep learning architectures have been employed to model the semantic compositionality for text sequences, requiring a huge amount of supervised data for parameters training, making it unfeasible in situations where numerous annotated samples are not available or even do not exist. Different from data-hungry deep models, lightweight word embedding-based models could represent text sequences in a plug-and-play way due to their parameter-free property. In this paper, a modified hierarchical pooling strategy over pre-trained word embeddings is proposed for text classification in a few-shot transfer learning way. The model leverages and transfers knowledge obtained from some source domains to recognize and classify the unseen text sequences with just a handful of support examples in the target problem domain. The extensive experiments on five datasets including both English and Chinese text demonstrate that the simple word embedding-based models (SWEMs) with parameter-free pooling operations are able to abstract and represent the semantic text. The proposed modified hierarchical pooling method exhibits significant classification performance in the few-shot transfer learning tasks compared with other alternative methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2911850",
            "Date of Publication": "18 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chongyu Pan",
                "labs": [
                    "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Jian Huang",
                "labs": [
                    "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Jianxing Gong",
                "labs": [
                    "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Xingsheng Yuan",
                "labs": [
                    "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Data models",
                "Training",
                "Computational modeling",
                "Text categorization",
                "Deep learning",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Few-shot learning",
                "transfer learning",
                "text classification",
                "word embedding based models",
                "pooling strategy"
            ]
        }
    },
    {
        "Title": "Multi-Element Hierarchical Attention Capsule Network for Stock Prediction",
        "Link": "https://ieeexplore.ieee.org/document/9159584/",
        "Abstract": "Stock prediction is a challenging task concerned by researchers due to its considerable returns. It is difficult because of the high randomness in the stock market. Stock price movement is mainly related to the capital situation and hot events. In recent years, researchers improved prediction accuracy with news and social media. However, the existing methods do not take into account the different influences of events. To solve this problem, we propose a multi-element hierarchical attention capsule network, which consists of two components. The former component, multi-element hierarchical attention, quantifies the importance of valuable information contained in multiple news and social media through its weights assignment process. And the latter component, capsule network, learns more context information from the events through its vector representation in the hidden layer. Moreover, we construct a combined data set to maintain the complementarity between social media and news. Finally, we achieve better results than baselines, and experiments show that our model improves prediction accuracy by quantifying the different influences of events.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3014506",
            "Date of Publication": "05 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jintao Liu",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Hongfei Lin",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Liang Yang",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Bo Xu",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China",
                    "State Key Laboratory of Cognitive Intelligence, iFLYTEK, Hefei, China"
                ]
            },
            {
                "name": "Dongzhen Wen",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Stock markets",
                "Social network services",
                "Feature extraction",
                "Predictive models",
                "Market research",
                "Weight measurement"
            ],
            "Author Keywords": [
                "Stock prediction",
                "hierarchical attention",
                "capsule network",
                "text mining",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "PersianQuAD: The Native Question Answering Dataset for the Persian Language",
        "Link": "https://ieeexplore.ieee.org/document/9729745/",
        "Abstract": "Developing Question Answering systems (QA) is one of the main goals in Artificial Intelligence. With the advent of Deep Learning (DL) techniques, QA systems have witnessed significant advances. Although DL performs very well on QA, it requires a considerable amount of annotated data for training. Many annotated datasets have been built for the QA task; most of them are exclusively in English. In order to address the need for a high-quality QA dataset in the Persian language, we present PersianQuAD, the native QA dataset for the Persian language. We create PersianQuAD in four steps: 1) Wikipedia article selection, 2) question-answer collection, 3) three-candidates test set preparation, and 4) Data Quality Monitoring. PersianQuAD consists of approximately 20,000 questions and answers made by native annotators on a set of Persian Wikipedia articles. The answer to each question is a segment of the corresponding article text. To better understand PersianQuAD and ensure its representativeness, we analyze PersianQuAD and show it contains questions of varying types and difficulties. We also present three versions of a deep learning-based QA system trained with PersianQuAD. Our best system achieves an F1 score of 82.97% which is comparable to that of QA systems on English SQuAD, made by the Stanford University. This shows that PersianQuAD performs well for training deep-learning-based QA systems. Human performance on PersianQuAD is significantly better (96.49%), demonstrating that PersianQuAD is challenging enough and there is still plenty of room for future improvement. PersianQuAD and all QA models implemented in this paper are freely available.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3157289",
            "Date of Publication": "08 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Arefeh Kazemi",
                "labs": [
                    "Department of Linguistics, Faculty of Foreign Languages, University of Isfahan, Isfahan, Iran"
                ]
            },
            {
                "name": "Jamshid Mozafari",
                "labs": [
                    "Big Data Research Group, Faculty of Computer Engineering, University of Isfahan, Isfahan, Iran"
                ]
            },
            {
                "name": "Mohammad Ali Nematbakhsh",
                "labs": [
                    "Department of Linguistics, Faculty of Foreign Languages, University of Isfahan, Isfahan, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet",
                "Online services",
                "Encyclopedias",
                "Training",
                "Task analysis",
                "Machine translation",
                "Buildings"
            ],
            "Author Keywords": [
                "Dataset",
                "deep learning",
                "natural language processing",
                "Persian",
                "question answering",
                "machine reading comprehension"
            ]
        }
    },
    {
        "Title": "Context-Aware Deep Markov Random Fields for Fake News Detection",
        "Link": "https://ieeexplore.ieee.org/document/9540871/",
        "Abstract": "Fake news is a serious problem, which has received considerable attention from both industry and academic communities. Over the past years, many fake news detection approaches have been introduced, and most of the existing methods rely on either news content or the social context of the news dissemination process on social media platforms. In this work, we propose a generic model that is able to take into account both the news content and the social context for the identification of fake news. Specifically, we explore different aspects of the news content by using both shallow and deep representations. The shallow representations are produced with word2vec and doc2vec models while the deep representations are generated via transformer-based models. These representations are able to jointly or separately address four individual tasks, namely bias detection, clickbait detection, sentiment analysis, and toxicity detection. In addition, we make use of graph convolutional neural networks and mean-field layers in order to exploit the underlying structural information of the news articles. That way, we are able to take into account the inherent correlation between the articles by leveraging their social context information. Experiments on widely-used benchmark datasets indicate the effectiveness of the proposed method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3113877",
            "Date of Publication": "17 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tien Huu Do",
                "labs": [
                    "Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium",
                    "imec, Leuven, Belgium"
                ]
            },
            {
                "name": "Marc Berneman",
                "labs": [
                    "Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium"
                ]
            },
            {
                "name": "Jasabanta Patro",
                "labs": [
                    "Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium",
                    "imec, Leuven, Belgium"
                ]
            },
            {
                "name": "Giannis Bekoulis",
                "labs": [
                    "Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium",
                    "imec, Leuven, Belgium"
                ]
            },
            {
                "name": "Nikos Deligiannis",
                "labs": [
                    "Department of Electronics and Informatics (ETRO), Vrije Universiteit Brussel (VUB), Brussels, Belgium",
                    "imec, Leuven, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Correlation",
                "Task analysis",
                "Feature extraction",
                "Social networking (online)",
                "Deep learning",
                "Transformers",
                "Linguistics"
            ],
            "Author Keywords": [
                "Fake news detection",
                "deep learning",
                "Markov random field",
                "representation learning",
                "question answering",
                "sentiment analysis",
                "clickbait detection",
                "toxicity detection",
                "bias detection"
            ]
        }
    },
    {
        "Title": "SciDeBERTa: Learning DeBERTa for Science Technology Documents and Fine-Tuning Information Extraction Tasks",
        "Link": "https://ieeexplore.ieee.org/document/9791256/",
        "Abstract": "Deep learning-based language models (LMs) have transcended the gold standard (human baseline) of SQuAD 1.1 and GLUE benchmarks in April and July 2019, respectively. As of 2022, the top five LMs on the SuperGLUE benchmark leaderboard have exceeded the gold standard. Even people with good general knowledge will struggle to solve problems in specialized fields such as medicine and artificial intelligence. Just as humans learn specialized knowledge through bachelor’s, master’s, and doctoral courses, LMs also require a process to develop the ability to understand domain specific knowledge. Thus, this study proposes SciDeBERTa and SciDeBERTa(CS) as a pre-trained LM (PLM) specialized in the science technology domain. We further pretrain the DeBERTa, which was trained with a general corpus, with the science technology domain corpus. Experiments verified that SciDeBERTa(CS) continually pre-trained in the computer science domain achieved 3.53% and 2.17% higher accuracies than SciBERT and S2ORC-SciBERT, respectively, which are science technology domain specialized PLMs, in the task of recognizing entity names in SciERC dataset. In the JRE task of the SciERC dataset, SciDeBERTa(CS) demonstrated a 6.7% higher performance than baseline SCIIE. In the Genia dataset, SciDeBERTa achieved the best performance compared to S2ORC-SciBERT, SciBERT, BERT, DeBERTa and SciDeBERTa(CS). Furthermore, re-initialization technology and optimizers after Adam were explored during fine-tuning to verify the language understanding of PLMs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3180830",
            "Date of Publication": "08 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuna Jeong",
                "labs": [
                    "Korea Institute of Science and Technology Information, Daejoen, Republic of Korea"
                ]
            },
            {
                "name": "Eunhui Kim",
                "labs": [
                    "Korea Institute of Science and Technology Information, Daejoen, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Training",
                "Transformers",
                "Data models",
                "Biological system modeling",
                "Benchmark testing"
            ],
            "Author Keywords": [
                "Deep neural network",
                "domain specific language model",
                "fine-tuning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Affective Knowledge Augmented Interactive Graph Convolutional Network for Chinese-Oriented Aspect-Based Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9980354/",
        "Abstract": "Aspect-based sentiment analysis(ABSA) aims to identify the sentiment polarity of specific aspects in sentences, which can more accurately mine the sentiment polarity of users towards different aspects. Most of the existing works derive the sentiment features of specific aspects by interactively learning the dependencies between different aspects of the context. However, the above work has neglected to use the external affective commonsense knowledge to augment the ability of the Graph Convolutional Networks(GCNs) to interactively capture sentiment dependencies of the inter-aspect words in different contexts. In addition, compared to the ABSA research in English, the existing research pays less attention to the Chinese-oriented research. Meanwhile, multi-head self-sttention(MHSA) is applied to extract richer context syntax and semantic interaction features. In this paper, we propose a novel knowledge-aware model in which affective knowledge augments interactive GCN for Chinese-oriented ABSA, namely AKM-IGCN. Moreover, this model can be applied to effectively analyze both Chinese and English comments simultaneously. Hence, we conducted experiments on four Chinese datasets(Camera, Phone, Notebook and Car) and six English benchmark datasets(Restaurant14, Restaurant15, Restaurant16, Twitter, MAMS, Tshirt). Experimental results illustrate that our proposed model outperforms or approaches state-of-the-art models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3228299",
            "Date of Publication": "12 December 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qian Yang",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China",
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Zaokere Kadeer",
                "labs": [
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Wenxia Gu",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Weiwei Sun",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Aishan Wumaier",
                "labs": [
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "China",
                "Sentiment analysis",
                "Syntactics",
                "Data mining",
                "Commonsense reasoning",
                "Semantics",
                "Convolutional neural networks",
                "Graph neural networks"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis",
                "Chinese sentiment analysis",
                "external affective knowledge",
                "graph convolutional networks",
                "multi-head self-attention"
            ]
        }
    },
    {
        "Title": "How Do Your Biomedical Named Entity Recognition Models Generalize to Novel Entities?",
        "Link": "https://ieeexplore.ieee.org/document/9730848/",
        "Abstract": "The number of biomedical literature on new biomedical concepts is rapidly increasing, which necessitates a reliable biomedical named entity recognition (BioNER) model for identifying new and unseen entity mentions. However, it is questionable whether existing models can effectively handle them. In this work, we systematically analyze the three types of recognition abilities of BioNER models: memorization, synonym generalization, and concept generalization. We find that although current best models achieve state-of-the-art performance on benchmarks based on overall performance, they have limitations in identifying synonyms and new biomedical concepts, indicating they are overestimated in terms of their generalization abilities. We also investigate failure cases of models and identify several difficulties in recognizing unseen mentions in biomedical literature as follows: (1) models tend to exploit dataset biases, which hinders the models’ abilities to generalize, and (2) several biomedical names have novel morphological patterns with weak name regularity, and models fail to recognize them. We apply a statistics-based debiasing method to our problem as a simple remedy and show the improvement in generalization to unseen mentions. We hope that our analyses and findings would be able to facilitate further research into the generalization capabilities of NER models in a domain where their reliability is of utmost importance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3157854",
            "Date of Publication": "08 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyunjae Kim",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jaewoo Kang",
                "labs": [
                    "Department of Computer Science and Engineering, Korea University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "COVID-19",
                "Benchmark testing",
                "Training",
                "Micromechanical devices",
                "Analytical models",
                "Surface morphology"
            ],
            "Author Keywords": [
                "Bioinformatics (in engineering in medicine and biology)",
                "natural language processing",
                "text mining"
            ]
        }
    },
    {
        "Title": "Analysis of Deep Learning Model Combinations and Tokenization Approaches in Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/10332170/",
        "Abstract": "Sentiment classification is a natural language processing task to identify opinions expressed in texts such as product or service reviews. In this work, we analyze the effects of different deep-learning model combinations, embedding methods, and tokenization approaches in sentiment classification. We feed non-contextualized (Word2Vec and GloVe) and contextualized (BERT and RoBERTa/XLM-RoBERTa) embeddings and also the output of the pretrained BERT and RoBERTa/XLM-RoBERTa models as input to neural models. We make a comprehensive analysis of eleven different tokenization approaches, including the commonly used subword methods and morphologically motivated segmentations. The experiments are conducted on three English and two Turkish datasets from different domains. The results show that BERT- and RoBERTa-/XLM-RoBERTa-based and contextualized embeddings outperform other neural models. We also observe that using words in raw or preprocessed form, stemming the words, and applying WordPiece tokenizations give the most promising results in the sentiment analysis task. We ensemble the models to find out which tokenization approaches produce better results together.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3337354",
            "Date of Publication": "28 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ali Erkan",
                "labs": [
                    "Department of Computer Engineering, Boğaziçi University, Istanbul, Turkey"
                ]
            },
            {
                "name": "Tunga Güngör",
                "labs": [
                    "Department of Computer Engineering, Boğaziçi University, Istanbul, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tokenization",
                "Analytical models",
                "Task analysis",
                "Sentiment analysis",
                "Encoding",
                "Social networking (online)",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Machine learning",
                "deep neural networks",
                "natural language processing",
                "sentiment classification",
                "word embedding",
                "tokenization",
                "morphology"
            ]
        }
    },
    {
        "Title": "Deep2s: Improving Aspect Extraction in Opinion Mining With Deep Semantic Representation",
        "Link": "https://ieeexplore.ieee.org/document/9107147/",
        "Abstract": "Syntactical rule based approaches for aspect extraction, which are free from expensive manual annotation, are promising in practice. These approaches extract aspects mainly through the dependency relations in the surface sentence structures. However, deep and rich semantic information hidden in sentences which can help improve aspect extraction, is difficult for them to capture. In order to address the problem, this paper first proposes to employ Logic Programming to explore the feasibility of deep semantic representation, then proposes Deep2S, a hybrid rule-based method to improve the performance of aspect extraction. Deep2S integrates deep semantic representation such as Abstract Meaning Representation (AMR) with syntactic structure. It can take advantage of the syntactical rules to obtain dependency relations in the surface structure as well as the semantic rules to capture deep semantic information. Our experiments are conducted on eight popular review datasets using two evaluation metrics. Experimental results demonstrate the usefulness of deep semantic representation and the ability of Deep2S to improve the performance of aspect extraction in opinion mining.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2999673",
            "Date of Publication": "03 June 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xuelian Li",
                "labs": [
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China",
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Bi Wang",
                "labs": [
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China",
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Lixin Li",
                "labs": [
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China",
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Zhiqiang Gao",
                "labs": [
                    "Key Laboratory of Computer Network and Information Integration, Ministry of Education, Southeast University, Nanjing, China",
                    "School of Computer Science and Engineering, Southeast University, Nanjing, China"
                ]
            },
            {
                "name": "Qian Liu",
                "labs": [
                    "School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China"
                ]
            },
            {
                "name": "Hancheng Xu",
                "labs": [
                    "International Studies College, National University of Defense Technology, Nanjing, China"
                ]
            },
            {
                "name": "Lanting Fang",
                "labs": [
                    "School of Cyber Science and Engineering, Southeast University, Nanjing, China",
                    "Purple Mountain Laboratories, Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Syntactics",
                "Feature extraction",
                "Task analysis",
                "Sentiment analysis",
                "Batteries",
                "Cameras"
            ],
            "Author Keywords": [
                "Opinion mining",
                "aspect extraction",
                "abstract meaning representation",
                "deep semantic representation",
                "logic programming"
            ]
        }
    },
    {
        "Title": "Human Versus Machine Intelligence: Assessing Natural Language Generation Models Through Complex Systems Theory",
        "Link": "https://ieeexplore.ieee.org/document/10413606/",
        "Abstract": "The introduction of Transformer architectures – with the self-attention mechanism – in automatic Natural Language Generation (NLG) is a breakthrough in solving general task-oriented problems, such as the simple production of long text excerpts that resemble ones written by humans. While the performance of GPT-X architectures is there for all to see, many efforts are underway to penetrate the secrets of these black-boxes in terms of intelligent information processing whose output statistical distributions resemble that of natural language. In this work, through the complexity science framework, a comparative study of the stochastic processes underlying the texts produced by the English version of GPT-2 with respect to texts produced by human beings, notably novels in English and programming codes, is offered. The investigation, of a methodological nature, consists first of all of an analysis phase in which the Multifractal Detrended Fluctuation Analysis and the Recurrence Quantification Analysis – together with Zipf's law and approximate entropy – are adopted to characterize long-term correlations, regularities and recurrences in human and machine-produced texts. Results show several peculiarities and trends in terms of long-range correlations and recurrences in the last case. The synthesis phase, on the other hand, uses the complexity measures to build synthetic text descriptors – hence a suitable text embedding – which serve to constitute the features for feeding a machine learning system designed to operate feature selection through an evolutionary technique. Using multivariate analysis, it is then shown the grouping tendency of the three analyzed text types, allowing to place GTP-2 texts in between natural language texts and computer codes. Similarly, the classification task demonstrates that, given the high accuracy obtained in the automatic discrimination of text classes, the proposed set of complexity measures is highly informative. These interesting results allow us to add another piece to the theoretical understanding of the surprising results obtained by NLG systems based on deep learning and let us to improve the design of new informetrics or text mining systems for text classification, fake news detection, or even plagiarism detection.\nShow Less",
        "Details": {
            "DOI": "10.1109/TPAMI.2024.3358168",
            "Date of Publication": "24 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
        },
        "issn_info": {
            "Print ISSN": "0162-8828",
            "Electronic ISSN": "1939-3539"
        },
        "authors_data": [
            {
                "name": "Enrico De Santis",
                "labs": [
                    "Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy"
                ]
            },
            {
                "name": "Alessio Martino",
                "labs": [
                    "Department of Business and Management, LUISS University, Rome, Italy"
                ]
            },
            {
                "name": "Antonello Rizzi",
                "labs": [
                    "Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza”, Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Complexity theory",
                "Writing",
                "Correlation",
                "Time series analysis",
                "Fractals",
                "Complex systems",
                "Task analysis"
            ],
            "Author Keywords": [
                "Natural language generation",
                "GPT models",
                "multifractal analysis",
                "recurrence quantification analysis",
                "Zipf's law",
                "quantitative linguistics",
                "complexity science",
                "text classification"
            ]
        }
    },
    {
        "Title": "BERT-NAR-BERT: A Non-Autoregressive Pre-Trained Sequence-to-Sequence Model Leveraging BERT Checkpoints",
        "Link": "https://ieeexplore.ieee.org/document/10373869/",
        "Abstract": "We introduce BERT-NAR-BERT (BnB) – a pre-trained non-autoregressive sequence-to-sequence model, which employs BERT as the backbone for the encoder and decoder for natural language understanding and generation tasks. During the pre-training and fine-tuning with BERT-NAR-BERT, two challenging aspects are considered by adopting the length classification and connectionist temporal classification models to control the output length of BnB. We evaluate it using a standard natural language understanding benchmark GLUE and three generation tasks – abstractive summarization, question generation, and machine translation. Our results show substantial improvements in inference speed (on average 10x faster) with only little deficiency in output quality when compared to our direct autoregressive baseline BERT2BERT model. Our code is publicly released on GitHub (https://github.com/aistairc/BERT-NAR-BERT) under the Apache 2.0 License.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3346952",
            "Date of Publication": "25 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Golam Sohrab",
                "labs": [
                    "Artificial Intelligence Research Center (AIRC), National Institute of Advanced Industrial Science and Technology, Tokyo, Japan"
                ]
            },
            {
                "name": "Masaki Asada",
                "labs": [
                    "Artificial Intelligence Research Center (AIRC), National Institute of Advanced Industrial Science and Technology, Tokyo, Japan"
                ]
            },
            {
                "name": "Matīss Rikters",
                "labs": [
                    "Artificial Intelligence Research Center (AIRC), National Institute of Advanced Industrial Science and Technology, Tokyo, Japan"
                ]
            },
            {
                "name": "Makoto Miwa",
                "labs": [
                    "Artificial Intelligence Research Center (AIRC), National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",
                    "Toyota Technological Institute, Nagoya, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Task analysis",
                "Predictive models",
                "Load modeling",
                "Biological system modeling",
                "Transformers",
                "Graphics processing units"
            ],
            "Author Keywords": [
                "Abstractive summarisation",
                "language understanding",
                "machine translation",
                "natural language processing",
                "non-autoregressive modelling"
            ]
        }
    },
    {
        "Title": "Answer Category-Aware Answer Selection for Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/9245487/",
        "Abstract": "As a key problem in artificial intelligence, question answering (QA) has always been a topic of intensive research. Most existing methods cast question answering as an answer selection task. The size of the candidate answer pool is usually very large, so it is difficult to accurately select the correct answer. One of the solutions is to narrow the range of candidate answer pool based on the category labels of the answers. However, QA tasks in reality usually only provide the category label of the question but not the category label of the answer. Based on this observation, we propose an Answer Category-Aware Answer Selection system (ACAAS), which jointly leverage unlabelled answer data and labelled question category data to generate answer category pseudo-labels in a joint embedding space. Experimental results on two public QA datasets demonstrate the effectiveness of the proposed method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3034920",
            "Date of Publication": "30 October 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Weijing Wu",
                "labs": [
                    "ICNLAB, School of Electronics and Computer Engineering (SECE), Peking University, Shenzhen, China"
                ]
            },
            {
                "name": "Yang Deng",
                "labs": [
                    "ICNLAB, School of Electronics and Computer Engineering (SECE), Peking University, Shenzhen, China",
                    "Department of Systems Engineering and Engineering Management, The Chinese University of Hong Kong, Hong Kong"
                ]
            },
            {
                "name": "Yuzhi Liang",
                "labs": [
                    "School of Electronics and Computer Engineering (SECE), Peking University Shenzhen Graduate School, Shenzhen, China"
                ]
            },
            {
                "name": "Kai Lei",
                "labs": [
                    "ICNLAB, School of Electronics and Computer Engineering (SECE), Peking University, Shenzhen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Knowledge discovery",
                "Speech recognition",
                "Semantics",
                "Encoding",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Answer selection",
                "label transfer",
                "question answering"
            ]
        }
    },
    {
        "Title": "Multifeature Fusion Keyword Extraction Algorithm Based on TextRank",
        "Link": "https://ieeexplore.ieee.org/document/9815884/",
        "Abstract": "Keyword extraction is the predecessor of many tasks, and its results directly affect search, recommendation, classification, and other tasks. In this study, we take Chinese text as the research object and propose a multi-feature fusion keyword extraction algorithm combined with BERT semantics and K-Truss graph(BSKT). The BSKT algorithm is based on the TextRank algorithm, which combines BERT semantic features, K-Truss features, and other features. First, the BSKT algorithm obtains the word vectors from the BERT pretraining model to calculate the semantic difference, which is used to optimize the iterative process of the TextRank word graph. Then, the BSKT algorithm obtains its K-Truss graph by decomposing the TextRank word graph and obtains the truss level feature of the word. Finally, by combining the word IDF and truss level features, the BSKT algorithm scores the words to extract keywords. Experimental results show that the BSKT algorithm achieves better performance than the latest keyword extraction algorithm SCTR in the task of extracting 1–10 keywords. Furthermore, the increment in F1 increased by 11.2% when the BSKT algorithm was used to extract three keywords from the Sensor dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3188861",
            "Date of Publication": "06 July 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wenming Guo",
                "labs": [
                    "School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China",
                    "Key Laboratory of Trustworthy Distributed Computing and Service (BUPT), Ministry of Education, Beijing, China",
                    "Xinjiang Institute of Engineering, Ürümqi, China"
                ]
            },
            {
                "name": "Zihao Wang",
                "labs": [
                    "School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China",
                    "Key Laboratory of Trustworthy Distributed Computing and Service (BUPT), Ministry of Education, Beijing, China"
                ]
            },
            {
                "name": "Fang Han",
                "labs": [
                    "Xinjiang Institute of Engineering, Ürümqi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Semantics",
                "Dictionaries",
                "Bit error rate",
                "Task analysis",
                "Data mining",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Keyword extraction",
                "BERT word vector",
                "K-Truss graph",
                "TextRank",
                "semantics"
            ]
        }
    },
    {
        "Title": "Incorporating Label Co-Occurrence Into Neural Network-Based Models for Multi-Label Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/8936450/",
        "Abstract": "Multi-label text classification (MLTC) addresses a fundamental problem in natural language processing, which assigns multiple relevant labels to each document. In recent years, Neural Network-based models (NN models) for MLTC have attracted much attention. In addition, NN models achieve favorable performances because they can exploit label correlations in the penultimate layer. To further capture and explore label correlations, we propose a novel initialization to incorporate label co-occurrence into NN models. First, we represent each class as a column vector of the weight matrix in the penultimate layer, which we name the class embedding matrix. Second, we deduce an equation for correlating the class embedding matrix with the label co-occurrence matrix, ensuring that relevant classes are denoted by vectors with large correlations. Finally, we provide a theoretical analysis of the equation, and propose an algorithm to calculate the initial values of the class embedding matrix from the label co-occurrence matrix. We evaluate our approach with various text extractors, such as Recurrent Neural Network (RNN), Convolutional Neural Network (CNN) and Transformer on four public datasets. The experimental results demonstrate that our approach markedly improves the performance of existing NN models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2960626",
            "Date of Publication": "18 December 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiaqi Yao",
                "labs": [
                    "National Key Laboratory of Science and Technology on Blind Signal Processing, Chengdu, China"
                ]
            },
            {
                "name": "Keren Wang",
                "labs": [
                    "National Key Laboratory of Science and Technology on Blind Signal Processing, Chengdu, China"
                ]
            },
            {
                "name": "Jikun Yan",
                "labs": [
                    "National Key Laboratory of Science and Technology on Blind Signal Processing, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Mathematical model",
                "Artificial neural networks",
                "Adaptation models",
                "Correlation",
                "Matrix decomposition",
                "Recurrent neural networks"
            ],
            "Author Keywords": [
                "Multi-label text classification",
                "label co-occurrence",
                "initialization",
                "neural network",
                "class embedding"
            ]
        }
    },
    {
        "Title": "Detect Sarcasm and Humor Jointly by Neural Multi-Task Learning",
        "Link": "https://ieeexplore.ieee.org/document/10445419/",
        "Abstract": "Sarcasm is a sophisticated speech act that is intended to express contempt or ridicule on social communities such as Twitter. In recent years, the prevalence of sarcasm on the social media has become highly disruptive to sentiment analysis systems due to not only its tendency of polarity flipping but also usage of figurative language. It is observed that sarcastic texts often convey a humorous effect. Thus, determining the humor in texts can be pertinent to the successful detection of sarcasm, and vice versa. However, current works always regard sarcasm detection and humor identification as separate tasks. In this paper, we argue that these tasks should be treated as a joint, collaborative, effort, considering the semantic connections between sarcasm and humor expressed in texts. Enlightened by the multi-task learning strategy, we present a joint architecture that settles two highly pertinent tasks, sarcasm detection and humor identification. As the basic of deep neural networks, we learn both tasks jointly exploring weight sharing to capture the task-specific features for each task and task-cross features between the two tasks. Extensive experiments on real-world datasets demonstrate that our presented model consistently enhances both sarcasm detection and humor identification tasks consistently with the help of the strong semantic relationships, achieving much better performance than state-of-the-art baselines.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3370858",
            "Date of Publication": "26 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yufeng Diao",
                "labs": [
                    "School of Computer Science and Technology, Inner Mongolia Minzu University, Tongliao, China"
                ]
            },
            {
                "name": "Liang Yang",
                "labs": [
                    "Department of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Shiqi Li",
                "labs": [
                    "School of Computer Science and Technology, Inner Mongolia Minzu University, Tongliao, China"
                ]
            },
            {
                "name": "Zhang Hao",
                "labs": [
                    "School of Computer Science and Technology, Inner Mongolia Minzu University, Tongliao, China"
                ]
            },
            {
                "name": "Xiaochao Fan",
                "labs": [
                    "School of Computer Science and Technology, Xinjiang Normal University, Xinjiang, China"
                ]
            },
            {
                "name": "Hongfei Lin",
                "labs": [
                    "Department of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Multitasking",
                "Feature extraction",
                "Context modeling",
                "Social networking (online)",
                "Semantics",
                "Logic gates",
                "Detection algorithms",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Sarcasm detection",
                "humor identification",
                "multi-task learning",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Common Sense-Based Reasoning Using External Knowledge for Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/9298744/",
        "Abstract": "Much research has been conducted recently on machines with human-level reasoning ability. Unlike domain knowledge, common sense is an extensive knowledge of the real world, and is included in human reasoning ability in many cases. However, it is difficult for machines to learn common sense because of the lack of well-written data. ComonsenseQA is a dataset in the form of multiple-choice questions and answers created for training and evaluating common sense in machines. RoBERTa, a pre-trained language model that performs well in natural language processing tasks, also performs well in ComonsenseQA. However, its performance is still inadequate compared to human performance. In this paper, we propose a model for predicting the correct answer by searching for information called evidence necessary to answer questions from external knowledge and by using the evidence as a context. The proposed model is comprised of three stages: An external knowledge finder to explore the required information from external knowledge; a triple-to-sentence converter, which converts triple-shaped in-formation such as (table, AtLocation, rug) into sentence form based on the configured evidence; and a reasoning module that predicts the correct answer. The performance of our proposed model showed a performance of 80.84% on the CommonsenseQA validation data and 76.14% on the test data. The latter is an improvement of 4.04% over the baseline model RoBERTa.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3045762",
            "Date of Publication": "18 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yunyeong Yang",
                "labs": [
                    "NAVER Corporation, Seongnam, South Korea"
                ]
            },
            {
                "name": "Sangwoo Kang",
                "labs": [
                    "School of Computing, Gachon University, Seongnam, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Cognition",
                "Bit error rate",
                "Predictive models",
                "Context modeling",
                "Knowledge discovery",
                "Training"
            ],
            "Author Keywords": [
                "Computational and artificial intelligence",
                "natural language processing",
                "neural networks",
                "machine reading comprehension"
            ]
        }
    },
    {
        "Title": "Controllable and Editable Neural Story Plot Generation via Control-and-Edit Transformer",
        "Link": "https://ieeexplore.ieee.org/document/9471847/",
        "Abstract": "Language-modeling-based methods for story plot generation aim to generate a plot with a language model (LM). LM methods have limitations of user-assist plot generation of goal control, refinement for editing, causing the generated plots not clear sense for specific goal, lack coherence, and edit flexible. We present a control-and-edit transformer technique which uses controlled imitation learning of editing distance from dynamic programming to support deleting policy, inserting policy, a weighting-reward with prepossess of corpus statistic, and measures continues reward for the controlled goal. Automated evaluation and Haman judgement show our method is promising in comparison with the baselines.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3094263",
            "Date of Publication": "02 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jin Chen",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Guangyi Xiao",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Xu Han",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Hao Chen",
                "labs": [
                    "College of Computer Science and Electronic Engineering, Hunan University, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generators",
                "Task analysis",
                "Training",
                "Reinforcement learning",
                "Decoding",
                "Coherence"
            ],
            "Author Keywords": [
                "Neural story plot generation",
                "controllable",
                "editable",
                "edit distance"
            ]
        }
    },
    {
        "Title": "Leveraging Structured Information from a Passage to Generate Questions",
        "Link": "https://ieeexplore.ieee.org/document/9983985/",
        "Abstract": "Question Generation (QG) is the task of utilizing Artificial Intelligence (Al) technology to generate questions that can be answered by a span of text within a given passage. Existing research on QG in the educational field struggles with two challenges: the mainstream QG models based on seq-to-seq fail to utilize the structured information from the passage; the other is the lack of specialized educational QG datasets. To address the challenges, a specialized QG dataset, reading comprehension dataset from examinations for QG (named RACE4QG), is reconstructed by applying a new answer tagging approach and a data-filtering strategy to the RACE dataset. Further, an end-to-end QG model, which can exploit the intra- and inter-sentence information to generate better questions, is proposed. In our model, the encoder utilizes a Gated Recurrent Units (GRU) network, which takes the concatenation of word embedding, answer tagging, and Graph Attention neTworks(GAT) embedding as input. The hidden states of the GRU are operated with a gated self-attention to obtain the final passage-answer representation, which will be fed to the decoder. Results show that our model outperforms baselines on automatic metrics and human evaluation. Consequently, the model improves the baseline by 0.44, 1.32, and 1.34 on BLEU-4, ROUGE-L, and METEOR metrics, respectively, indicating the effectivity and reliability of our model. Its gap with human expectations also reflects the research potential.",
        "Details": {
            "DOI": "10.26599/TST.2022.9010034",
            "Date of Publication": "13 December 2022",
            "Publisher": "TUP",
            "Published In": "Tsinghua Science and Technology"
        },
        "issn_info": {
            "Electronic ISSN": "1007-0214"
        },
        "authors_data": [
            {
                "name": "Jian Xu",
                "labs": [
                    "Key Laboratory of Educational Informatization for Nationalities, Yunnan Normal University, Kunming, China",
                    "School of Information Engineering, Qujing Normal University, Qujing, China"
                ]
            },
            {
                "name": "Yu Sun",
                "labs": [
                    "School of Information Science and Technology, Yunnan Normal University, Kunming, China"
                ]
            },
            {
                "name": "Jianhou Gan",
                "labs": [
                    "Yunnan Key Laboratory of Smart Education, Yunnan Normal University, Kunming, China"
                ]
            },
            {
                "name": "Mingtao Zhou",
                "labs": [
                    "School of Information Science and Technology, Yunnan Normal University, Kunming, China"
                ]
            },
            {
                "name": "Di Wu",
                "labs": [
                    "Key Laboratory of Educational Informatization for Nationalities, Yunnan Normal University, Kunming, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Pain",
                "Education",
                "Logic gates",
                "Tagging",
                "Decoding",
                "Reliability"
            ],
            "Author Keywords": [
                "automatic Question Generation (QG)",
                "RACE4QG dataset",
                "Answer-Oriented GAT (AO-GAT)",
                "attention mechanism",
                "structured information"
            ]
        }
    },
    {
        "Title": "An Attention-Based Neural Network Using Human Semantic Knowledge and Its Application to Clickbait Detection",
        "Link": "https://ieeexplore.ieee.org/document/9917322/",
        "Abstract": "Clickbait is a commonly used social engineering technique to carry out phishing attacks, illegitimate marketing, and dissemination of disinformation. As a result, clickbait detection has become a popular research topic in recent years due to the prevalence of clickbait on the web and social media. In this article, we propose a novel attention-based neural network for the task of clickbait detection. To the best of our knowledge, our work is the first that incorporates human semantic knowledge into an artificial neural network, and uses linguistic knowledge graphs to guide attention mechanisms for the clickbait detection task. Extensive experimental results show that the proposed model outperforms existing state-of-the-art clickbait classifiers, even when training data is limited. The proposed model also performs better or comparably to powerful pretrained models, namely, BERT, RoBERTa, and XLNet, while being much more lightweight. Furthermore, we conducted experiments to demonstrate that the use of human semantic knowledge can significantly enhance the performance of pretrained models in the semisupervised domain such as BERT, RoBERTa, and XLNet.",
        "Details": {
            "DOI": "10.1109/OJCS.2022.3213791",
            "Date of Publication": "12 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Feng Wei",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada"
                ]
            },
            {
                "name": "Uyen Trang Nguyen",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Knowledge engineering",
                "Fake news",
                "Correlation",
                "Biological neural networks",
                "Task analysis",
                "Linguistics"
            ],
            "Author Keywords": [
                "Clickbait detection",
                "fake news",
                "human semantic knowledge",
                "knowledge base",
                "neural networks"
            ]
        }
    },
    {
        "Title": "Automated Matchmaking of Researcher Biosketches and Funder Requests for Proposals Using Deep Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/10597426/",
        "Abstract": "This study developed an automated matchmaking system using deep neural networks to enhance the efficiency of pairing researcher biosketches with funders’ requests for proposals (RFPs). In thus U.S., with over 900 federal grant programs and 86,000+ foundations, researchers often spend up to 200 hours on each application due to low success rates, forcing them to apply multiple times a year. Our approach improves on existing systems by fixing issues like unreliable keyword searches, and one-size-fits-all recommendations. We analyzed 12,991 biosketches from a research institution and 2,234 RFPs from the National Institutes of Health, spanning 2014 to 2019. Employing four advanced deep-learning models, utilizing cross and Siamese encoding strategies, we benchmarked their performance against conventional predictive models such as logistic regression and support vector machines. The most effective model integrated BERT with cross-encoding, a post-BERT BiLSTM layer, and back translation (BC2BT), achieving an F1-score of 71.15%. These results demonstrate the potential of sophisticated natural language processing techniques to automate complex matchmaking tasks in the research funding sector. This approach not only improves the precision of matching researchers to suitable funding opportunities but also sets a promising foundation for future advancements in automated funding mechanisms.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3427631",
            "Date of Publication": "15 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sifei Han",
                "labs": [
                    "Department of Biomedical and Health Informatics, Tsui Laboratory, Children’s Hospital of Philadelphia, Philadelphia, PA, USA"
                ]
            },
            {
                "name": "Russell Richie",
                "labs": [
                    "Department of Biomedical and Health Informatics, Tsui Laboratory, Children’s Hospital of Philadelphia, Philadelphia, PA, USA",
                    "Cognitive Science and MindCORE, University of Pennsylvania, Philadelphia, PA, USA"
                ]
            },
            {
                "name": "Lingyun Shi",
                "labs": [
                    "Department of Biomedical and Health Informatics, Tsui Laboratory, Children’s Hospital of Philadelphia, Philadelphia, PA, USA"
                ]
            },
            {
                "name": "Fuchiang Tsui",
                "labs": [
                    "Department of Biomedical and Health Informatics, Tsui Laboratory, Children’s Hospital of Philadelphia, Philadelphia, PA, USA",
                    "Department of Anesthesiology and Critical Care, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA",
                    "Department of Biostatistics, Epidemiology, and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Bidirectional control",
                "Biological system modeling",
                "Proposals",
                "Long short term memory",
                "Task analysis",
                "Convolutional neural networks",
                "Artificial neural networks",
                "Data augmentation"
            ],
            "Author Keywords": [
                "Document similarity",
                "deep neural networks",
                "data augmentation"
            ]
        }
    },
    {
        "Title": "Chinese Short Text Entity Disambiguation Based on the Dual-Channel Hybrid Network",
        "Link": "https://ieeexplore.ieee.org/document/9256270/",
        "Abstract": "Entity disambiguation refers to the accurate inference of the real mention of an entity with the same name according to the context. Most existing studies focused on long texts, for short texts, the performance has been unsatisfactory due to sparsity. In this paper, we treat the entity disambiguation task as a classification problem. we propose a novel neural network-based capsule network and convolutional neural network for entity disambiguation, leveraging full semantic information of short text data. In particular, a self-attention mechanism is utilized to further filter the semantic information extracted from the capsule network. On the other hand, a convolutional neural network with combined pooling is established to capture semantics from another channel. In the end, the semantic features obtained by the above models are combined through a fully connected layer to complete the task of entity disambiguation. The experimental results on the CCKS 2019 entity linking dataset showed that the dual-channel hybrid network proposed in this paper achieved an F1-score of 88.04%, which is superior to that of the existing mainstream deep learning model, thereby verifying the effectiveness of the model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3037333",
            "Date of Publication": "11 November 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Liting Jiang",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China",
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China",
                    "National Language Resource Monitoring and Research Center on Minority Languages, Ürümqi, China"
                ]
            },
            {
                "name": "Gulila Altenbek",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Di Wu",
                "labs": [
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Yajing Ma",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China",
                    "Xinjiang Laboratory of Multi-Language Information Technology, Xinjiang University, Ürümqi, China",
                    "National Language Resource Monitoring and Research Center on Minority Languages, Ürümqi, China"
                ]
            },
            {
                "name": "Hayinaer Aierzhati",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Feature extraction",
                "Task analysis",
                "Routing",
                "Bit error rate",
                "Heuristic algorithms",
                "Data mining"
            ],
            "Author Keywords": [
                "Entity disambiguation",
                "short text",
                "convolutional neural networks",
                "capsule networks"
            ]
        }
    },
    {
        "Title": "Tasneef: A Fast and Effective Hybrid Representation Approach for Arabic Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10654296/",
        "Abstract": "The Arabic language role in actual global affairs entails sophisticated natural language processing techniques, especially in text classification. This paper presents Tasneef as a novel hybrid approach to tackle computational challenges by reducing memory usage and runtime overhead for actual Arabic text classification (ATC). Tasneef integrates distance-based meta-features (DBMFs) representation with word embeddings. This integration is useful because using a single text representation technique can be limiting in capturing the essential range of features necessary for effective classification, especially in complex languages like Arabic. By addressing the intricacies arising from the high dimensionality and sparsity inherent in Term Frequency-Inverse Document Frequency (TF-IDF) representation, the utilization of DBMFs is shown to offer a promising solution. The DBMFs rely on document labels and statistical features to establish meaningful distance relationships between documents, thereby facilitating effective reduction. Furthermore, word embeddings encapsulate semantic attributes. Empirical assessments reveal a significant reduction of two orders of magnitude in both memory usage and runtime. This reduction translates to memory savings ranging from 158x to 361x and runtime reductions from 120x to 524x across three popular datasets; maintaining comparable MicroF1 and MacroF1 values, while notably reducing learning time. Moreover, Tasneef outperforms ten state-of-the-art deep learning models and seven dimension reduction methods in accuracy, with enhancements ranging from 0.3% to 39.6%; and F-Measure, with improvements from 4.6% to 26.8%, across four additional datasets. These findings highlight Tasneef as a promising solution for diverse ATC applications in real-world scenarios, offering concise and rapid classification with reduced computational learning costs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3450507",
            "Date of Publication": "28 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maroua Louail",
                "labs": [
                    "Computer Science Department, LRSD Laboratory, Ferhat Abbas University Setif 1, Setif, Algeria"
                ]
            },
            {
                "name": "Chafia Kara-Mohamed Hamdi-Cherif",
                "labs": [
                    "Computer Science Department, LRSD Laboratory, Ferhat Abbas University Setif 1, Setif, Algeria"
                ]
            },
            {
                "name": "Aboubekeur Hamdi-Cherif",
                "labs": [
                    "Computer Science Department, Ferhat Abbas University Setif 1, Setif, Algeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Accuracy",
                "Runtime",
                "Linguistics",
                "Semantics",
                "Feature extraction",
                "Natural language processing",
                "Text processing"
            ],
            "Author Keywords": [
                "Arabic natural language processing",
                "Arabic text classification",
                "Arabic text representation",
                "feature extraction",
                "meta-features",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "BERT-Based Dual-Channel Power Equipment Defect Text Assessment Model",
        "Link": "https://ieeexplore.ieee.org/document/10638086/",
        "Abstract": "Accumulating a substantial amount of textual data on power equipment defects during maintenance and inspection stages presents a valuable problem of assessing and grading these text-based information. This paper proposes a dual-channel text feature extraction model based on the pre-trained BERT model, applied to the evaluation of power equipment defect levels in textual data. Firstly, a dataset of power equipment defect levels is established, followed by data augmentation and preprocessing. Then, a neural network model is constructed, utilizing the pre-trained BERT model for initial semantic information extraction from the text, further extracting features through two modules, Bi-LSTM and CNN, on top of BERT’s output. Finally, the obtained feature vectors are concatenated to generate the output. Comparative experiments with other algorithms demonstrate that the proposed method out-performs others in multiple metrics, achieving an F1 score of 96%. The research findings can serve as a reference for achieving intelligent processing of power textual information.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3444852",
            "Date of Publication": "16 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhenan Zhou",
                "labs": [
                    "School of Information Engineering, China University of Geosciences (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Chuyan Zhang",
                "labs": [
                    "School of Information Engineering, China University of Geosciences (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Xinyi Liang",
                "labs": [
                    "School of Information Engineering, China University of Geosciences (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Huifang Liu",
                "labs": [
                    "School of Information Engineering, China University of Geosciences (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Mingguang Diao",
                "labs": [
                    "School of Information Engineering, China University of Geosciences (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Yu Deng",
                "labs": [
                    "Tibet Yangbajing High Altitude Electrical Safety and Electromagnetic Environment National Observation and Research Station, China Electric Power Research Institute, Yangbajain, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Encoding",
                "Bidirectional control",
                "Hidden Markov models",
                "Training",
                "Natural language processing",
                "Deep learning",
                "Maintenance engineering",
                "Inspection",
                "Defect detection",
                "Electronic equipment testing"
            ],
            "Author Keywords": [
                "Power defect text",
                "natural language processing",
                "deep learning",
                "BERT",
                "dual channel model"
            ]
        }
    },
    {
        "Title": "Predictability and Causality in Spanish and English Natural Language Generation",
        "Link": "https://ieeexplore.ieee.org/document/10577102/",
        "Abstract": "In recent years, the field of Natural Language Generation (NLG) has been boosted by the recent advances in deep learning technologies. Nonetheless, these new data-intensive methods introduce language-dependent disparities in NLG as the main training data sets are in English. Also, most neural NLG systems use decoder-only (causal) transformer language models, which work well for English, but were not designed with other languages in mind. In this work we depart from the hypothesis that they may introduce generation bias in target languages with less rigid word ordering, subject omission, or different attachment preferences for relative clauses, so that for these target languages other language generation strategies may be more desirable. This paper first compares causal and non-causal language modeling for English and Spanish, two languages with different grammatical structures and over 1.5 billion and 0.5 billion speakers, respectively. For this purpose, we define a novel metric of average causal and non-causal context-conditioned entropy of the grammatical category distribution for both languages as an information-theoretic a priori approach. The evaluation of natural text sources (such as training data) in both languages reveals lower average non-causal conditional entropy in Spanish and lower causal conditional entropy in English. According to this experiment, Spanish is more predictable than English given a non-causal context. Then, by applying a conditional relative entropy metric to text generation experiments, we obtain as insights that the best performance is respectively achieved with causal NLG in English, and with non-causal NLG in Spanish. These insights support further research in NLG in Spanish using bidirectional transformer language models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3420710",
            "Date of Publication": "28 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Andrea Busto-Castiñeira",
                "labs": [
                    "Information Technologies Group, atlanTTic Research Center for Telecommunication Technologies, Telecommunication Engineering School, University of Vigo, Vigo, Spain"
                ]
            },
            {
                "name": "Francisco Javier González-Castaño",
                "labs": [
                    "Information Technologies Group, atlanTTic Research Center for Telecommunication Technologies, Telecommunication Engineering School, University of Vigo, Vigo, Spain"
                ]
            },
            {
                "name": "Silvia García-Méndez",
                "labs": [
                    "Information Technologies Group, atlanTTic Research Center for Telecommunication Technologies, Telecommunication Engineering School, University of Vigo, Vigo, Spain"
                ]
            },
            {
                "name": "Francisco de Arriba-Pérez",
                "labs": [
                    "Information Technologies Group, atlanTTic Research Center for Telecommunication Technologies, Telecommunication Engineering School, University of Vigo, Vigo, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Context modeling",
                "Entropy",
                "Cause effect analysis",
                "Predictive models",
                "Task analysis",
                "Measurement",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Language predictability",
                "natural language generation",
                "non-causal language modeling",
                "Spanish language",
                "transformer language models"
            ]
        }
    },
    {
        "Title": "Leveraging Large Language Model for Enhanced Text-to-SQL Parsing",
        "Link": "https://ieeexplore.ieee.org/document/10878990/",
        "Abstract": "Text-to-SQL conversion, the process of generating SQL queries from natural language input, has gained significant attention due to its potential to simplify database interaction. Although benchmarks in this task have driven advancements in the field, the challenges posed by complex join logic and the rich diversity of natural language expressions remain significant obstacles. These complexities underscore the ongoing difficulty of accurately bridging the gap between natural language and structured query representations, particularly in cross-domain and real-world scenarios. Recent research, including intermediate representations, relation-aware transformers, and large language models such as T5 and LLaMA, has improved performance by addressing the semantic gap between natural language and SQL. In this work, we propose SLENet, a novel approach that uses state-of-the-art large language models (LLMs) to enhance semantic understanding and SQL generation. Our method integrates three core innovations: (1) the use of advanced LLMs for context-aware representations, (2) syntax-constrained SQL decoder to ensure grammatical correctness, and (3) search-based prompt optimization utilizing external knowledge sources like WikiSQL. These innovations collectively address schema comprehension and SQL generation complexities. Evaluations on the Spider benchmark demonstrate that SLENet significantly outperforms existing methods, achieving higher exact matching accuracy and effectively handling complex SQL components. Our contributions highlight the importance of combining LLMs with syntax constraints and external data for advancing cross-domain semantic parsing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3540072",
            "Date of Publication": "10 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zecheng Zhan",
                "labs": [
                    "Bytedance Inc, Beijing, China"
                ]
            },
            {
                "name": "E. Haihong",
                "labs": [
                    "School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Meina Song",
                "labs": [
                    "School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Structured Query Language",
                "Decoding",
                "Semantics",
                "Natural languages",
                "Databases",
                "Syntactics",
                "Benchmark testing",
                "Large language models",
                "Technological innovation",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Semantic parsing",
                "SQL generation",
                "deep learning",
                "LLM",
                "deep learning"
            ]
        }
    },
    {
        "Title": "SkelETT—Skeleton-to-Emotion Transfer Transformer",
        "Link": "https://ieeexplore.ieee.org/document/10852297/",
        "Abstract": "Emotion recognition plays an essential role in human-computer interaction, spanning diverse domains from human-robot communication and virtual reality to mental health assessment and affective computing. Traditionally, this field has heavily relied on visual and auditory cues, such as facial expressions and speech analysis. However, these modalities alone may not comprehensively capture the full spectrum of human emotion and suffer limitations due to noise or occlusion. Human skeletons, derived from depth sensors or pose estimation algorithms, offer an alternative for facial expression, including valuable spatial and temporal cues. In this paper, we introduce a novel approach to emotion recognition by pre-training a transformer model on a large dataset of unsupervised human skeleton representations and subsequently fine-tuning it for emotion classification. By exposing the model to an extensive corpus of unlabeled human skeleton data, we can effectively learn to represent complex spatial and temporal dependencies inherent in body movements. Following this foundational knowledge acquisition, the model undergoes fine-tuning on a smaller, labeled dataset tailored for emotion classification tasks. We introduce SkelETT, an encoder-only transformer architecture for body emotion recognition. Comprising a series of encoder layers, SkelETT patches 2D body pose representations, it also includes multi-head self-attention mechanisms and position-wise feed-forward networks, providing a powerful framework for extracting hierarchical features from sequential body pose data. We propose and evaluate the impact of different fine-tuning strategies on pose data using the MPOSE action recognition dataset as a pre-training source. Transfer performance is measured on the BoLD body emotion recognition dataset. Compared to the state-of-the-art, we report significant gains in accuracy (\n≈ 34\n% higher), training time (\n≈ 50\n% less), and model complexity reduction (\n≈ 80\n% less trainable parameters).\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3534145",
            "Date of Publication": "24 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pedro Victor Vieira Paiva",
                "labs": [
                    "School of Technology, University of Campinas, Limeira, Brazil",
                    "Department of Computer Science, University of Calgary, Calgary, AB, Canada"
                ]
            },
            {
                "name": "Josué Junior Guimarães Ramos",
                "labs": [
                    "Renato Archer IT Center, Campinas, Brazil"
                ]
            },
            {
                "name": "Marina Gavrilova",
                "labs": [
                    "Department of Computer Science, University of Calgary, Calgary, AB, Canada"
                ]
            },
            {
                "name": "Marco Antônio Garcia de Carvalho",
                "labs": [
                    "School of Technology, University of Campinas, Limeira, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Transformers",
                "Skeleton",
                "Adaptation models",
                "Accuracy",
                "Computational modeling",
                "Transfer learning",
                "Training",
                "Solid modeling",
                "Data models"
            ],
            "Author Keywords": [
                "Attention-based design",
                "body emotion recognition",
                "gait analysis",
                "masked autoencoder",
                "affective computing"
            ]
        }
    },
    {
        "Title": "A Systematic Review of Pretrained Models in Automated Essay Scoring",
        "Link": "https://ieeexplore.ieee.org/document/11062635/",
        "Abstract": "Automated essay scoring (AES) uses artificial intelligence and machine learning methods to grade student essays and produce human-like scores. AES research has witnessed significant advancements over time by adopting diverse machine learning models. This evolution started with traditional techniques like regression and classification, and later advanced to deep learning models that leverage neural networks for enhancing scoring performance. This review focuses on the utilization of Transformer architectures, a sophisticated form of neural networks employing attention mechanisms, with an emphasis on pretrained models like BERT in AES research. The aim is to enhance the understanding of their applicability in advancing the AES research landscape. Additionally, this study selected and analyzed relevant papers from Scopus and Web of Science databases in the past five years, by adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. An intensive screening process was followed to shortlist studies within the defined scope, focusing on AES applications that employed pretrained models. From the comprehensive analysis of 354 studies, this review shortlisted 22 key papers and identified five distinct focus areas within the current AES research landscape: holistic scoring, trait scoring, cross-domain and generalization, model fairness, and robustness. The results highlight the potential of transformer-based pretrained models in improving AES systems’ accuracy. However, pretrained models face several limitations, such as high computational costs, long input text length, and explainability. Tackling these challenges and integrating emerging technologies, such as large language models (GPT4), is expected to foster the development of accurate, robust, and transparent AES systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3584784",
            "Date of Publication": "01 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ahmed M. Elmassry",
                "labs": [
                    "College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Nazar Zaki",
                "labs": [
                    "College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Negmeldin Alsheikh",
                "labs": [
                    "College of Education, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Mohammed Mediani",
                "labs": [
                    "College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Systematic literature review",
                "Mathematical models",
                "Computer architecture",
                "Accuracy",
                "Decoding",
                "Information technology",
                "Guidelines",
                "Focusing",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Automated essay scoring",
                "PRISMA",
                "trait",
                "transformers",
                "pretrained",
                "BERT"
            ]
        }
    },
    {
        "Title": "Misinformation Features Detection in Weibo: Unsupervised Learning, Latent Dirichlet Allocation, and Network Structure",
        "Link": "https://ieeexplore.ieee.org/document/10747342/",
        "Abstract": "This study employs an unsupervised learning technique to identify features of misinformation on Weibo, a popular social media platform in China. By utilizing BERT (Bidirectional Encoder Representations from Transformers) for sequence classification, we were able to detect a dataset with a mix of true and false information, achieving a perfect recall rate for false information detection. However, the precision for true information was low, with a 3% precision, 6% recall, and an F1 score of 6%, indicating a high rate of misclassification. To address this, we conducted a Latent Dirichlet Allocation (LDA) analysis on the misclassified true information, identifying specific features that led to incorrect classification. Additionally, social network analysis revealed the presence of structural holes within the information network. This study contributes to the understanding of misinformation detection mechanisms and provides insights into the social dynamics of information spread.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3494015",
            "Date of Publication": "08 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yiping Li",
                "labs": [
                    "Department of Humanities and Arts, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Xuanfeng Li",
                "labs": [
                    "Institute of Systems Engineering, Macau University of Science and Technology, Macau, China",
                    "Faculty of Innovation Engineering, Macau University of Science and Technology, Taipa, Macau SAR, China"
                ]
            },
            {
                "name": "Yuejing Zhai",
                "labs": [
                    "Macao Polytechnic University, Macau, China"
                ]
            },
            {
                "name": "Di Wang",
                "labs": [
                    "Department of Humanities and Arts, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Chitin Hon",
                "labs": [
                    "Institute of Systems Engineering, Macau University of Science and Technology, Macau, China",
                    "Faculty of Innovation Engineering, Macau University of Science and Technology, Taipa, Macau SAR, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Training",
                "Data models",
                "Blogs",
                "Accuracy",
                "Resource management",
                "Encoding",
                "Analytical models",
                "Transformers",
                "Unsupervised learning"
            ],
            "Author Keywords": [
                "Misinformation detection",
                "unsupervised learning",
                "BERT",
                "latent dirichlet allocation (LDA)",
                "social network analysis"
            ]
        }
    },
    {
        "Title": "Injecting Linguistic Knowledge Into BERT for Dialogue State Tracking",
        "Link": "https://ieeexplore.ieee.org/document/10584540/",
        "Abstract": "Dialogue State Tracking (DST) models often employ intricate neural network architectures, necessitating substantial training data, and their inference process lacks transparency. This paper proposes a method that extracts linguistic knowledge via an unsupervised framework and subsequently utilizes this knowledge to augment BERT’s performance and interpretability in DST tasks. The knowledge extraction procedure is computationally economical and does not require annotations or additional training data. The injection of the extracted knowledge can be achieved by the addition of simple neural modules. We employ the Convex Polytopic Model (CPM) as a feature extraction tool for DST tasks and illustrate that the acquired features correlate with syntactic and semantic patterns in the dialogues. This correlation facilitates a comprehensive understanding of the linguistic features influencing the DST model’s decision-making process. We benchmark this framework on various DST tasks and observe a notable improvement in accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3423452",
            "Date of Publication": "04 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiaohan Feng",
                "labs": [
                    "Department of System Engineering and Engineering Management, The Chinese University of Hong Kong, Shatin, Hong Kong"
                ]
            },
            {
                "name": "Xixin Wu",
                "labs": [
                    "Department of System Engineering and Engineering Management, The Chinese University of Hong Kong, Shatin, Hong Kong"
                ]
            },
            {
                "name": "Helen Meng",
                "labs": [
                    "Department of System Engineering and Engineering Management, The Chinese University of Hong Kong, Shatin, Hong Kong"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Feature extraction",
                "Task analysis",
                "Computational modeling",
                "Training",
                "Biological system modeling",
                "Encoding",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Dialogue state tracking",
                "convex polytopic model",
                "knowledge extraction",
                "interpretable AI"
            ]
        }
    },
    {
        "Title": "Low-Resource Noisy Transliteration Normalization Using Large-Scale Language Model",
        "Link": "https://ieeexplore.ieee.org/document/11017577/",
        "Abstract": "Transliteration normalization is a crucial task for low-resource languages, particularly for Mongolian, where noisy text from social media presents significant challenges. The frequent use of non-standard transliteration can contribute to the gradual erosion of linguistic knowledge, particularly among young users, making it harder to maintain proficiency in their native language. Therefore, developing robust methods for normalizing such text is essential. In this paper, we propose a novel approach leveraging large-scale neural models, specifically GPT-2, to normalize noisy transliterated Mongolian text. Our study explores a data-driven approach, including word pairs, sentence pairs, and synthetic data, to enhance model performance. To further improve accuracy, we introduce a post-processing module that integrates Edit Distance-based corrections with a context-aware ranking mechanism using the Mongolian BERT model. Experimental results demonstrate that our approach (M10: 16.42%) improves overall accuracy by approximately 4.91%, while achieving a 10.44% increase in out-of-vocabulary (OOV) word normalization compared to baseline models. Our proposed approach demonstrates effectiveness in normalizing noisy transliterated text under low-resource conditions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574933",
            "Date of Publication": "29 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zolzaya Byambadorj",
                "labs": [
                    "Department of Information Technology, Mongolian University of Science and Technology, Ulaanbaatar, Mongolia"
                ]
            },
            {
                "name": "Ulziibayar Sonom-Ochir",
                "labs": [
                    "Department of Information Technology, Mongolian University of Science and Technology, Ulaanbaatar, Mongolia"
                ]
            },
            {
                "name": "Munkhsukh Enkhbayar",
                "labs": [
                    "Department of Information Technology, Mongolian University of Science and Technology, Ulaanbaatar, Mongolia"
                ]
            },
            {
                "name": "Hyun-Chul Kim",
                "labs": [
                    "Department of Software, Sangmyung University, Cheonan, South Korea"
                ]
            },
            {
                "name": "Altangerel Ayush",
                "labs": [
                    "Department of Information Technology, Mongolian University of Science and Technology, Ulaanbaatar, Mongolia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Noise measurement",
                "Standards",
                "Social networking (online)",
                "Accuracy",
                "Long short term memory",
                "Data models",
                "Transformers",
                "Convolutional neural networks",
                "Writing",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Data-driven method",
                "GPT2 model",
                "noisy text",
                "seq2seq model",
                "text normalization",
                "token",
                "transliterated text"
            ]
        }
    },
    {
        "Title": "Contrastive Learning Algorithm for Low-Resource Cryptographic Attack Event Detection",
        "Link": "https://ieeexplore.ieee.org/document/11045891/",
        "Abstract": "The widespread use of the internet has led to frequent cryptographic attack event incidents, which pose various risks, including the leakage of personal information, privacy data, identity theft, and potential legal liabilities. However, conventional event detection models depend on expert-annotated trigger words, which are costly to obtain and constrain the applicability of detection methods in cryptographic security. Detecting cryptographic attack events faces two challenges: 1) Semantic complexity: terminology and abbreviations are diverse, and the same event is described using different vocabulary, sentence structures, and contexts, making it difficult for models to accurately identify specific events; 2) Lack of annotated features: This field relies on manually annotated data for feature learning, but there is a lack of publicly available datasets, and related research is scarce. Thus, we propose a method CLAD: Contrastive Learning Algorithm for Detecting Low-resource Cryptographic Attack Event. By comparing similarities and differences between samples, richer feature representations can be extracted. Additionally, assigning appropriate weights to keywords of different event types and employing clustering methods for effective classification reduce reliance on manually labeled data, thereby facilitating the training of an efficient cryptographic attack event detection model. To evaluate the effectiveness of the proposed method, we analyzed 916 cryptographic attack events collected from news blogs. The evaluation results show that the proposed method achieved an F1 score of 82.05% in detecting cryptographic attack events in low-resource scenarios, significantly outperforming state-of-the-art solutions. It reduces reliance on manual annotation and effectively handles semantic complexity using contrastive learning and clustering techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3581984",
            "Date of Publication": "20 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Peng Luo",
                "labs": [
                    "College of Computer Science and Technology, Qinghai Normal University, Xining, Qinghai, China",
                    "State Key Laboratory of Tibetan Intelligent Information Processing and Application, Xining, Qinghai, China"
                ]
            },
            {
                "name": "Rangjia Cai",
                "labs": [
                    "College of Computer Science and Technology, Qinghai Normal University, Xining, Qinghai, China",
                    "State Key Laboratory of Tibetan Intelligent Information Processing and Application, Xining, Qinghai, China"
                ]
            },
            {
                "name": "Yuanbo Guo",
                "labs": [
                    "School of Cyberspace Security (School of Cryptology), Hainan University, Haikou, Hainan, China",
                    "National Key Laboratory of Security Communication, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cryptography",
                "Event detection",
                "Contrastive learning",
                "Data models",
                "Semantics",
                "Security",
                "Accuracy",
                "Clustering algorithms",
                "Feature extraction",
                "Clustering methods"
            ],
            "Author Keywords": [
                "Cryptographic attack event detection",
                "semantic similarity",
                "contrastive learning",
                "low-resource scenarios"
            ]
        }
    },
    {
        "Title": "An Approach for Buyer Name Normalization in Pharmacy Sales Data",
        "Link": "https://ieeexplore.ieee.org/document/9466847/",
        "Abstract": "It is fundamental for pharmaceutical enterprises to make statistics and analyses on the massive sales data that are submitted by distributors at different levels when making market plans and other decisions. However, buyer names in sales data may have various forms due to aliases, abbreviations, typos, and other reasons, which severely affect the subsequent mining performance. To tackle this problem, in this paper, we propose a novel approach called BuyerNorm which can identify different expression forms for a given buyer name. The proposed model takes pairs of variable length buyer names as input and combines Bidirectional Encoder Representations from Transformers (BERT) and Bi-directional Long Short-Term Memory (BiLSTM) to obtain string representations and calculate the similarity between the two names, which indicates whether they represent the same buyer. For this task, we first build a data set including more than 80,000 pairs of buyer names. Then, extensive experiments on the data set show that BuyerNorm performs better than the state-of-the-art baseline and can obtain an average AUC of 99.84%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3093028",
            "Date of Publication": "28 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiajing Li",
                "labs": [
                    "Department of Computer Science and Technology, China University of Mining & Technology (Beijing), Beijing, China",
                    "Wangganzhicha Information Technology Inc, Nanjing, China"
                ]
            },
            {
                "name": "Wang Jia",
                "labs": [
                    "Department of Computer Science and Technology, China University of Mining & Technology (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Fuhui Nie",
                "labs": [
                    "Department of Computer Science and Technology, China University of Mining & Technology (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Hongyan You",
                "labs": [
                    "Department of Computer Science and Technology, China University of Mining & Technology (Beijing), Beijing, China"
                ]
            },
            {
                "name": "Yaxin Hao",
                "labs": [
                    "Department of Computer Science and Technology, China University of Mining & Technology (Beijing), Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Semantics",
                "Hospitals",
                "Data mining",
                "Drugs",
                "Context modeling"
            ],
            "Author Keywords": [
                "Semantic similarity evaluation",
                "named entities normalization",
                "sentence classification",
                "representation learning",
                "BERT",
                "BiLSTM"
            ]
        }
    },
    {
        "Title": "RoBERTa-Based Multi-Feature Integrated BiLSTM and CNN Model for Ceramic Review Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11031473/",
        "Abstract": "To address the limitation that the Robustly Optimized BERT Pretraining Approach (RoBERTa) may not effectively capture local dependencies and salient features within the text, we propose a feature fusion framework based on RoBERTa’s multi-output architecture. By feeding different outputs of RoBERTa into Convolutional Neural Networks (CNN) and Bidirectional Long Short-Term Memory (BiLSTM) networks, the model effectively captures both local static patterns and global contextual dependencies, thereby enhancing its capability to handle complex textual inputs. Additionally, an attention mechanism highlights semantically important features, further improving feature representation and classification performance. To evaluate the effectiveness of the proposed model, we conducted comparative experiments on the Amazon, IMDB, SST-2, and Ceramic datasets. The F1 scores achieved were 94.25%, 92.52%, 91.51%, and 81.32%, respectively, substantially outperforming existing models, particularly in handling domain-specific and nuanced texts. These results demonstrate that the proposed multi-feature fusion model significantly enhances sentiment classification performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3579022",
            "Date of Publication": "12 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "LiHua Yang",
                "labs": [
                    "School of Information Engineering, Jingdezhen Ceramic University, Jingdezhen, Jiangxi, China",
                    "School of Mechanical and Electronic Engineering, Jingdezhen Ceramic University, Jingdezhen, Jiangxi, China"
                ]
            },
            {
                "name": "Jun Wang",
                "labs": [
                    "School of Information Engineering, Jingdezhen Ceramic University, Jingdezhen, Jiangxi, China"
                ]
            },
            {
                "name": "WangRen Qiu",
                "labs": [
                    "School of Information Engineering, Jingdezhen Ceramic University, Jingdezhen, Jiangxi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Attention mechanisms",
                "Semantics",
                "Reviews",
                "Vectors",
                "Context modeling",
                "Training",
                "Text categorization",
                "Bidirectional long short term memory"
            ],
            "Author Keywords": [
                "RoBERTa",
                "feature extraction",
                "deep learning",
                "attention mechanism",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Efficient Task Grouping Through Sample-Wise Optimisation Landscape Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11078907/",
        "Abstract": "Shared training approaches, such as multi-task learning (MTL) and gradient-based meta-learning, are widely used in various machine learning applications, but they often suffer from negative transfer, leading to performance degradation in specific tasks. While several optimisation techniques have been developed to mitigate this issue for pre-selected task cohorts, identifying optimal task combinations for joint learning—known as task grouping—remains underexplored and computationally challenging due to the exponential growth in task combinations and the need for extensive training and evaluation cycles. This paper introduces an efficient task grouping framework designed to reduce these overwhelming computational demands of the existing methods. The proposed framework infers pairwise task similarities through a sample-wise optimisation landscape analysis, eliminating the need for the shared model training required to infer task similarities in existing methods. With task similarities acquired, a graph-based clustering algorithm is employed to pinpoint near-optimal task groups, providing an approximate yet efficient and effective solution to the originally NP-hard problem. Empirical assessments conducted on 9 different datasets highlight the effectiveness of the proposed framework, revealing a five-fold speed enhancement compared to previous state-of-the-art methods. Moreover, the framework consistently demonstrates comparable performance, confirming its remarkable efficiency and effectiveness in task grouping.",
        "Details": {
            "DOI": "10.1109/TPAMI.2025.3588685",
            "Date of Publication": "14 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
        },
        "issn_info": {
            "Print ISSN": "0162-8828",
            "Electronic ISSN": "1939-3539"
        },
        "authors_data": [
            {
                "name": "Anshul Thakur",
                "labs": [
                    "Department of Engineering Science, University of Oxford, Oxford, U.K."
                ]
            },
            {
                "name": "Yichen Huang",
                "labs": [
                    "Harvard John A. Paulson School of Engineering and Applied Sciences, Boston, MA, USA"
                ]
            },
            {
                "name": "Soheila Molaei",
                "labs": [
                    "Department of Engineering Science, University of Oxford, Oxford, U.K."
                ]
            },
            {
                "name": "Yujiang Wang",
                "labs": [
                    "Oxford Suzhou Centre for Advanced Research, University of Oxford, Suzhou, Jiangsu, China"
                ]
            },
            {
                "name": "David A. Clifton",
                "labs": [
                    "Department of Engineering Science, University of Oxford, Oxford, U.K.",
                    "Oxford Suzhou Centre for Advanced Research, University of Oxford, Suzhou, Jiangsu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Multitasking",
                "Training",
                "Optimization",
                "Computational modeling",
                "Metalearning",
                "Analytical models",
                "Computational efficiency",
                "Physiology",
                "Electronic healthcare",
                "Predictive models"
            ],
            "Author Keywords": [
                "Task groupings",
                "multi-tasking",
                "sample-wise convergence",
                "gradient-based meta-learning"
            ]
        }
    },
    {
        "Title": "Ranking Assisted Unsupervised Morphological Disambiguation of Turkish",
        "Link": "https://ieeexplore.ieee.org/document/10908819/",
        "Abstract": "In comparison to English, Turkish is an agglutinative language with fewer resources. The agglutinative properties of words result in a significant number of morphological analyses, creating uncertainty in morphological disambiguation and syntactic parsing. Traditional approaches typically rely on supervised learning models based on the correct morphological analysis of a given phrase. In this study, we propose a ranking method to limit and filter out irrelevant morphological tags from all possible combinations of morphological analyses of a given sentence without supervision. The suggested method selects less ambiguous analyses for statistical aggregation and applies inference through the PageRank algorithm on a densely connected graph. Subsequently, this graph is utilized to develop a voting schema for each test word based on the connections in the test sentence. Experimental evaluations of the proposed methods on three independently and manually annotated test datasets indicate a token accuracy of approximately 80% and an accuracy of around 61% for ambiguous tokens. In all ranking evaluations, the best scores from the PageRank variations significantly outperform those of Self-Attention LSTM and ELMO deep learning models. The training process of PageRank is notably straightforward and efficient, requiring\nO(\nn\n2\n)\nparameter adjustments, which is considerably fewer than those required by the backpropagation method used in neural network training. Furthermore, to reduce ambiguity in sentences from different genres with scarce samples, the proposed method is easily adaptable.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3547303",
            "Date of Publication": "03 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hayri Volkan Agun",
                "labs": [
                    "Department of Computer Engineering, Bursa Technical University, Bursa, Türkiye"
                ]
            },
            {
                "name": "Özkan Aslan",
                "labs": [
                    "Department of Computer Engineering, Afyon Kocatepe University, Afyon, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Training",
                "Analytical models",
                "Long short term memory",
                "Tuning",
                "Training data",
                "Surface morphology",
                "Supervised learning",
                "Natural language processing",
                "Indexes"
            ],
            "Author Keywords": [
                "Morphological disambiguation",
                "deep neural networks",
                "feature engineering",
                "unsupervised learning"
            ]
        }
    },
    {
        "Title": "Enhancing Zero-Shot Word Sense Disambiguation via Clustered Sense Vectors",
        "Link": "https://ieeexplore.ieee.org/document/11126102/",
        "Abstract": "Recent approaches to Word Sense Disambiguation (WSD) often rely on the use of either clustered sense labels or sense vectors. The former reduces the output label space and helps handle untrained senses while maintaining fine-grained sense distinctions. The latter leverages latent representations to capture contextual information. In this study, we propose Clustered Sense Vectors, a method that integrates both strategies to enhance fine-grained WSD performance. In order to create clustered sense vectors, we convert clustered sense labels into clustered sense vectors. For this, we propose Sense-aware Clustering (SaC), a method for clustering sense labels more effectively. Then, for a WSD system, we present CluBE, a bi-encoder model that utilizes these clustered sense vectors by converting clustered sense labels into representative vectors through cluster vector normalization. The experimental results show that SaC improves clustering quality, and that CluBE not only achieves 1.6%p higher F1 scores but also reduces memory usage by 82% compared to a baseline bi-encoder model, while significantly enhancing zero-shot learning capability by effectively handling untrained word senses through clustered representations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599179",
            "Date of Publication": "15 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jeongyeon Park",
                "labs": [
                    "Department of Computer Science, Chungbuk National University, Cheongju-si, Republic of Korea"
                ]
            },
            {
                "name": "Hyeong Jin Shin",
                "labs": [
                    "Department of Computer Science, Chungbuk National University, Cheongju-si, Republic of Korea"
                ]
            },
            {
                "name": "Donghyeok Lee",
                "labs": [
                    "Department of Computer Science, Chungbuk National University, Cheongju-si, Republic of Korea"
                ]
            },
            {
                "name": "Jae Sung Lee",
                "labs": [
                    "Department of Computer Science, Chungbuk National University, Cheongju-si, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Training",
                "Context modeling",
                "Computational modeling",
                "Clustering algorithms",
                "Semantics",
                "Zero shot learning",
                "Predictive models",
                "Dictionaries",
                "Accuracy"
            ],
            "Author Keywords": [
                "Word sense disambiguation",
                "zero-shot learning",
                "clustering",
                "sense vectors",
                "cluster-based bi-encoder"
            ]
        }
    },
    {
        "Title": "A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?",
        "Link": "https://ieeexplore.ieee.org/document/10380590/",
        "Abstract": "Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3349952",
            "Date of Publication": "04 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "John Fields",
                "labs": [
                    "Business Analytics, Concordia University Wisconsin-Ann Arbor, Mequon, WI, USA",
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Kevin Chovanec",
                "labs": [
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Praveen Madiraju",
                "labs": [
                    "Department of Computer Science, Marquette University, Milwaukee, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Transformers",
                "Surveys",
                "Task analysis",
                "Taxonomy",
                "Data models",
                "Chatbots"
            ],
            "Author Keywords": [
                "NLP",
                "text classification",
                "transformers",
                "survey"
            ]
        }
    },
    {
        "Title": "Bangla-BERT: Transformer-Based Efficient Model for Transfer Learning and Language Understanding",
        "Link": "https://ieeexplore.ieee.org/document/9852438/",
        "Abstract": "The advent of pre-trained language models has directed a new era of Natural Language Processing (NLP), enabling us to create powerful language models. Among these models, Transformer-based models like BERT have grown in popularity due to their cutting-edge effectiveness. However, these models heavily rely on resource-intensive languages, forcing other languages into multilingual models(mBERT). The two fundamental challenges with mBERT become significantly more challenging in a resource-constrained language like Bangla. It was trained on a limited and organized dataset and contained weights for all other languages. Besides, current research on other languages suggests that a language-specific BERT model will exceed multilingual ones. This paper introduces Bangla-BERT,a a monolingual BERT model for the Bangla language. Despite the limited data available for NLP tasks in Bangla, we perform pre-training on the largest Bangla language model dataset, BanglaLM, which we constructed using 40 GB of text data. Bangla-BERT achieves the highest results in all datasets and vastly improves the state-of-the-art performance in binary linguistic classification, multilabel extraction, and named entity recognition, outperforming multilingual BERT and other previous research. The pre-trained model is assessed against several non-contextual models such as Bangla fasttext and word2vec the downstream tasks. Finally, this model is evaluated by transfer learning based on hybrid deep learning models such as LSTM, CNN, and CRF in NER, and it is observed that Bangla-BERT outperforms state-of-the-art methods. The proposed Bangla-BERT model is assessed by using benchmark datasets, including Banfakenews, Sentiment Analysis on Bengali News Comments, and Cross-lingual Sentiment Analysis in Bengali. Finally, it is concluded that Bangla-BERT surpasses all prior state-of-the-art results by 3.52%, 2.2%, and 5.3%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3197662",
            "Date of Publication": "08 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. Kowsher",
                "labs": [
                    "Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Abdullah As Sami",
                "labs": [
                    "Department of Computer Science and Engineering, Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Nusrat Jahan Prottasha",
                "labs": [
                    "Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Mohammad Shamsul Arefin",
                "labs": [
                    "Department of Computer Science and Engineering, Daffodil International University, Dhaka, Bangladesh",
                    "Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Pranab Kumar Dhar",
                "labs": [
                    "Chittagong University of Engineering and Technology, Chattogram, Bangladesh"
                ]
            },
            {
                "name": "Takeshi Koshiba",
                "labs": [
                    "Waseda University, Tokyo, Shinjuku-ku, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Learning systems",
                "Transformers",
                "Data models",
                "Computational modeling",
                "Internet",
                "Transfer learning"
            ],
            "Author Keywords": [
                "Bangla NLP",
                "BERT-base",
                "large corpus",
                "transformer"
            ]
        }
    },
    {
        "Title": "Application of Quantum Natural Language Processing for Language Translation",
        "Link": "https://ieeexplore.ieee.org/document/9525075/",
        "Abstract": "In this paper, we develop compositional vector-based semantics of positive transitive sentences using quantum natural language processing (Q-NLP) to compare the parametrized quantum circuits of two synonymous simple sentences in English and Persian. We propose a protocol based on quantum long short-term memory (Q-LSTM) for Q-NLP to perform various tasks in general but specifically for translating a sentence from English to Persian. Then, we generalize our method to use quantum circuits of sentences as an input for the Q-LSTM cell. This enables us to translate sentences in different languages. Our work paves the way toward representing quantum neural machine translation, which may demonstrate quadratic speedup and converge faster or reaches a better accuracy over classical methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3108768",
            "Date of Publication": "30 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mina Abbaszade",
                "labs": [
                    "Department of Physics, Isfahan University of Technology, Isfahan, Iran"
                ]
            },
            {
                "name": "Vahid Salari",
                "labs": [
                    "Basque Center for Applied Mathematics (BCAM), Bilbao, Spain",
                    "Department of Physical Chemistry, University of the Basque Country UPV/EHU, Bilbao, Spain",
                    "Quantum Biology Laboratory, Howard University, Washington, DC, USA"
                ]
            },
            {
                "name": "Seyed Shahin Mousavi",
                "labs": [
                    "Department of Pure Mathematics, Shahid Bahonar University of Kerman, Kerman, Iran"
                ]
            },
            {
                "name": "Mariam Zomorodi",
                "labs": [
                    "Department of Computer Engineering, Ferdowsi University of Mashhad, Mashhad, Iran",
                    "Department of Computer Science, Faculty of Computer Science and Telecommunications, Cracow University of Technology, Krakow, Poland"
                ]
            },
            {
                "name": "Xujuan Zhou",
                "labs": [
                    "School of Business, University of Southern Queensland, Springfield Campus, Springfield Central, QLD, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Quantum circuit",
                "Tensors",
                "Machine translation",
                "Computational modeling",
                "Decoding",
                "Mathematical model"
            ],
            "Author Keywords": [
                "Q-NLP",
                "DisCoCat diagrams",
                "ZX-calculus",
                "quantum circuits",
                "Q-LSTM"
            ]
        }
    },
    {
        "Title": "Graph-Based Text Representation and Matching: A Review of the State of the Art and Future Challenges",
        "Link": "https://ieeexplore.ieee.org/document/9088989/",
        "Abstract": "Graph-based text representation is one of the important preprocessing steps in data and text mining, Natural Language Processing (NLP), and information retrieval approaches. The graph-based methods focus on how to represent text documents in the shape of a graph to exploit the best features of their characteristics. This study reviews and lists the advantages and disadvantages of such methods employed or developed in graph-based text representations. The literature shows that some of the proposed graph-based methods suffer from a lack of representing texts in certain situations. Currently, several techniques are commonly used in graph-based text representation. However, there are still some weaknesses and shortages in these techniques and tools that significantly affect the success of graph representation and graph matching. In this review, we conduct an inclusive survey of the state of the art in graph-based text representation and learning. We provide a formal description of the problem of graph-based text representation and introduce some basic concepts. More significantly, this study proposes a new taxonomy of graph-based text representation, categorizing the existing studies based on representation characteristics and scheme techniques. In terms of the representation scheme taxonomy, we introduce four main types of conceptual graph schemes and summarize the challenges faced in each scheme. The main issues of graph representation, such as research topics and the sub-taxonomy of graph models for web documents, are introduced and categorized. This research also covers some tasks of understanding natural language processing (NLP) that depend on different types of graph structures. In addition, the graph matching taxonomy implements three main categories based on the matching approach, including structural-, semantic-, and similarity-based approaches. Moreover, a deep comparison of these approaches is discussed and reported in terms of methods and tools, the concepts of matching and locality, and the application domains that use these tools. Finally, the paper recommends seven promising future study directions in the graph-based text representation field. These recommendation points are summarized and highlighted as open problems and challenges of graph-based text representation and learning to facilitate and fill the research gaps for scientific researchers in this field.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2993191",
            "Date of Publication": "07 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ahmed Hamza Osman",
                "labs": [
                    "Department of Information System, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Omar Mohammed Barukub",
                "labs": [
                    "Department of Information System, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Numerical models",
                "Text mining",
                "Semantics",
                "Labeling",
                "Tools",
                "Taxonomy"
            ],
            "Author Keywords": [
                "Graph representation",
                "NLP",
                "graph",
                "graph matching",
                "representation scheme",
                "text mining"
            ]
        }
    },
    {
        "Title": "A Novel Approach for Linguistic Steganography Evaluation Based on Artificial Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/9523860/",
        "Abstract": "Increasing prevalence and simplicity of using Artificial Intelligence (AI) techniques, Steganography is shifting from conventional model building to AI model building. AI enables computers to learn from their mistakes, adapt to emerging inputs, and carry out human-like activities. Traditional Linguistic Steganographic approaches lack automation, analysis of Cover text and hidden text volume and accuracy. A formal methodology is used in only a few Steganographic approaches. In the vast majority of situations, traditional approaches fail to survive third-party vulnerability. This study looks at evaluation of an AI-based statistical language model for text Steganography. Since the advent of Natural Language Processing (NLP) into the research field, linguistic Steganography has superseded other types of Steganography. This paper proposes the positive aspects of NLP-based Markov chain model for an auto-generative cover text. The embedding rate, volume, and other attributes of Recurrent Neural Networks (RNN) Steganographic schemes are contrasted in this article between RNN-Stega and RNN-generated Lyrics, two RNN methods. Here the RNN model follows Long Short Term Memory (LSTM) neural network. The paper also includes a case study on Artificial Intelligence and Information Security, which discusses history, applications, AI challenges, and how AI can help with security threats and vulnerabilities. The final portion is dedicated to the study’s shortcomings, which may be the subject of future research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3108183",
            "Date of Publication": "26 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "R. Gurunath",
                "labs": [
                    "Department of Computer Science, CHRIST (Deemed to be University), Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Ahmed H. Alahmadi",
                "labs": [
                    "Department of Computer Science and Information, Taibah University, Medina, Saudi Arabia"
                ]
            },
            {
                "name": "Debabrata Samanta",
                "labs": [
                    "Department of Computer Science, CHRIST (Deemed to be University), Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Mohammad Zubair Khan",
                "labs": [
                    "Department of Computer Science and Information, Taibah University, Medina, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulrahman Alahmadi",
                "labs": [
                    "Department of Computer Science and Information, Taibah University, Medina, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Markov processes",
                "Linguistics",
                "Recurrent neural networks",
                "Natural language processing",
                "Social networking (online)",
                "Artificial intelligence",
                "Data models"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "steganography",
                "linguistic steganography",
                "statistical language model",
                "natural language processing",
                "NLP",
                "Markov chain model",
                "recurrent neural networks",
                "RNN",
                "LSTM"
            ]
        }
    },
    {
        "Title": "An Analytical Analysis of Text Stemming Methodologies in Information Retrieval and Natural Language Processing Systems",
        "Link": "https://ieeexplore.ieee.org/document/10318122/",
        "Abstract": "The exponential increase in textual unstructured digital data creates significant demand for advanced and smart stemming systems. As a preprocessing stage, stemming is applied in various research fields such as information retrieval (IR), domain vocabulary analysis, and feature reduction in many natural language processing (NLP). Text stemming (TS), an important step, can significantly improve performance in such systems. Text-stemming methods developed till now could be better in their results and can produce errors of different types leading to degraded performance of the applications in which these are used. This work presents a systematic study with an in-depth review of selected stemming works published from 1968 to 2023. The work presents a multidimensional review of studied stemming algorithms i.e., methodology, data source, performance, and evaluation methods. For this study, we have chosen different stemmers, which can be categorized as 1) linguistic knowledge-based, 2) statistical, 3) corpus-based, 4) context-sensitive, and 5) hybrid stemmers. The study shows that linguistic knowledge-based stemming techniques were widely used for highly inflected languages (such as Arabic, Hindi, and Urdu) and have reported higher accuracy than other techniques. We compare and analyze the performance of various state-of-the-art TS approaches, including their issues and challenges, which are summarized as research gaps. This work also analyzes different NLP applications utilizing stemming methods. At the end, we list the future work directions for interested researchers.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3332710",
            "Date of Publication": "14 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdul Jabbar",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Main Campus, Tarlai Kalan, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Sajid Iqbal",
                "labs": [
                    "Department of Information Systems, College of Computer Science and Information Technology, King Faisal University, Al Hofuf, Saudi Arabia"
                ]
            },
            {
                "name": "Manzoor Ilahi Tamimy",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Main Campus, Tarlai Kalan, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Amjad Rehman",
                "labs": [
                    "Artificial Intelligence & Data Analytics Laboratory (AIDA), CCIS, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Saeed Ali Bahaj",
                "labs": [
                    "MIS Department, College of Business Administration, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia",
                    "Department of Computer Engineering, College of Engineering and Petroleum, Hadhramout University, Mukalla, Hadhramout, Yemen"
                ]
            },
            {
                "name": "Tanzila Saba",
                "labs": [
                    "Artificial Intelligence & Data Analytics Laboratory (AIDA), CCIS, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Vocabulary",
                "Information retrieval",
                "Linguistics",
                "Text categorization",
                "Sentiment analysis",
                "Tokenization"
            ],
            "Author Keywords": [
                "Text stemming",
                "information retrieval (IR) systems",
                "text classification",
                "stemmer evaluation",
                "technological development",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Compilation, Analysis and Application of a Comprehensive Bangla Corpus KUMono",
        "Link": "https://ieeexplore.ieee.org/document/9845427/",
        "Abstract": "Research in Natural Language Processing (NLP) and computational linguistics highly depends on a good quality representative corpus of any specific language. Bangla is one of the most spoken languages in the world but Bangla NLP research is in its early stage of development due to the lack of quality public corpus. This article describes the detailed compilation methodology of a comprehensive monolingual Bangla corpus, KUMono (Khulna University Monolingual corpus). The newly developed corpus consists of more than 350 million word tokens and more than one million unique tokens from 18 major text categories of online Bangla websites. We have conducted several word-level and character-level linguistic phenomenon analyses based on empirical studies of the developed corpus. The corpus follows Zipf’s curve and hapax legomena rule. The quality of the corpus is also assessed by analyzing and comparing the inherent sparseness of the corpus with existing Bangla corpora, by analyzing the distribution of function words of the corpus and vocabulary growth rate. We have developed a Bangla article categorization application based on the KUMono corpus and received compelling results by comparing to the state-of-the-art models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3195236",
            "Date of Publication": "01 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aysha Akther",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Md. Shymon Islam",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Hafsa Sultana",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "A. K. Z. Rasel Rahman",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Sujana Saha",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Kazi Masudul Alam",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Rameswar Debnath",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Linguistics",
                "Buildings",
                "Natural language processing",
                "Annotations",
                "Tagging",
                "Statistical analysis",
                "Standards"
            ],
            "Author Keywords": [
                "NLP",
                "Bangla corpus",
                "N-gram",
                "Zipf’s law",
                "article categorization"
            ]
        }
    },
    {
        "Title": "Advances in Pruning and Quantization for Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10685352/",
        "Abstract": "With ongoing advancements in natural language processing (NLP) and deep learning methods, the demand for computational and memory resources has considerably increased, which signifies the determination of efficient and compact models in resource-constrained environments. A comprehensive overview of the most recent advancements in pruning and quantization methods for deep neural networks is provided in this paper. Numerous cutting-edge techniques that harness the complementary advantages of pruning and quantization have been analyzed, highlighting their effectiveness in reducing model size, enhancing computational efficiency, and minimizing memory usage. These techniques include Quantization and Sparsity Aware Fine Tuning, Compression Learning by In-Parallel Pruning-Quantization, GroupReduce, Quantization-Pruned Attention, Structured Pruning, Normalized Linear Quantization (Prune and NLQ), Quantization and Pruning for Sentiment Analysis, an Automatic mixed-precision Quantization approach for BERT compression (AQ-BERT), Mixed Precision Quantization, Unstructured Pruning, and Quantization, and Magnitude Pruning. The datasets utilized, models employed, and outcomes achieved are taken into account within this research. The utilization of pruning and quantization techniques across diverse deep-learning tasks, NLP, and sentiment analysis are also discussed. Moreover, issues such as compatibility with hardware configurations, optimization complexities, accuracy degradation, and other constraints have been analysed. Several challenges and limitations of weight or unit pruning that are utilized for optimizing memory and quantization techniques to enhance precision are explored. The in-depth analysis of these state-of-the-art techniques and experiments provides a broad understanding. Furthermore, strategies to effectively reduce the computational and memory demands of neural networks without compromising their performance are also analysed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3465631",
            "Date of Publication": "23 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ummara Bibi",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan",
                    "Next-Generation Communications Research Group, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Mahrukh Mazhar",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Dilshad Sabir",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Fasih Uddin Butt",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan",
                    "Next-Generation Communications Research Group, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Ali Hassan",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Mustansar Ali Ghazanfar",
                "labs": [
                    "Department of Computer Science and Digital Technologies, School of Architecture, Computing and Engineering, University of East London, London, U.K."
                ]
            },
            {
                "name": "Arshad Ali Khan",
                "labs": [
                    "5Here East, Queen Elizabeth Olympic Park, Plexal, London, U.K."
                ]
            },
            {
                "name": "Wadood Abdul",
                "labs": [
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Computational modeling",
                "Measurement",
                "Neurons",
                "Natural language processing",
                "Memory management",
                "Convolutional neural networks",
                "Deep learning"
            ],
            "Author Keywords": [
                "Convolutional neural network",
                "natural language processing",
                "quantization",
                "NLP models",
                "compression",
                "pruning",
                "pruning and quantization"
            ]
        }
    },
    {
        "Title": "A VAN-Based Multi-Scale Cross-Attention Mechanism for Skin Lesion Segmentation Network",
        "Link": "https://ieeexplore.ieee.org/document/10194499/",
        "Abstract": "With the rise of deep learning technology, the field of medical image segmentation has undergone rapid development. In recent years, convolutional neural networks (CNNs) have brought many achievements and become the consensus in medical image segmentation tasks. Although many neural networks based on U-shaped structures and methods, such as skip connections have achieved excellent results in medical image segmentation tasks, the properties of convolutional operations limit their ability to effectively learn local and global features. To address this problem, the Transformer from the field of natural language processing (NLP) was introduced to the image segmentation field. Various Transformer-based networks have shown significant performance advantages over mainstream neural networks in different visual tasks, demonstrating the huge potential of Transformers in the field of image segmentation. However, Transformers were originally designed for NLP and ignore the multidimensional nature of images. In the process of operation, they may destroy the 2D structure of the image and cannot effectively capture low-level features. Therefore, we propose a new multi-scale cross-attention method called M-VAN Unet, which is designed based on the Visual Attention Network (VAN) and can effectively learn local and global features. We propose two attention mechanisms, namely MSC-Attention and LKA-Cross-Attention, for capturing low-level features and promoting global information interaction. MSC-Attention is designed for multi-scale channel attention, while LKA-Cross-Attention is a cross-attention mechanism based on the large kernel attention (LKA). Extensive experiments show that our method outperforms current mainstream methods in evaluation metrics such as Dice coefficient and Hausdorff 95 coefficient.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3298826",
            "Date of Publication": "25 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shuang Liu",
                "labs": [
                    "School of Computer Science and Engineering, Dalian Minzu University, Liaoning, Dalian, China"
                ]
            },
            {
                "name": "Zeng Zhuang",
                "labs": [
                    "School of Computer Science and Engineering, Dalian Minzu University, Liaoning, Dalian, China"
                ]
            },
            {
                "name": "Yanfeng Zheng",
                "labs": [
                    "School of Computer Science and Engineering, Dalian Minzu University, Liaoning, Dalian, China"
                ]
            },
            {
                "name": "Simon Kolmaniè",
                "labs": [
                    "Faculty of Electrical Engineering and Computer Science, University of Maribor, Maribor, Slovenia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Image segmentation",
                "Transformers",
                "Feature extraction",
                "Melanoma",
                "Decoding",
                "Convolutional neural networks",
                "Visualization",
                "Deep learning",
                "Biomedical image processing",
                "Semantic segmentation"
            ],
            "Author Keywords": [
                "CNNs",
                "deep learning",
                "medical image processing",
                "NLP",
                "semantic segmentation"
            ]
        }
    },
    {
        "Title": "Performance Improvement on Traditional Chinese Task-Oriented Dialogue Systems With Reinforcement Learning and Regularized Dropout Technique",
        "Link": "https://ieeexplore.ieee.org/document/10052671/",
        "Abstract": "The development of conversational voice assistant applications has been in full swing around the world. This paper aims to develop traditional Chinese multi-domain task-oriented dialogue (TOD) systems. It is typically implemented using pipeline approach, where submodules are optimized independently, resulting in inconsistencies with each other. Instead, this paper implements end-to-end multi-domain TOD models using pre-trained deep neural networks (DNNs). This allows us to integrate all the submodules into one single DNN model to solve the inconsistencies. Data shortages are common in conversational natural language processing (NLP) tasks using DNN models. In this regard, dropout regularization has been widely used to improve overfitting caused by insufficient training dataset. However, the randomness it introduces leads to non-negligible discrepancies between training and inference. On the other hand, pre-trained language models have successfully provided effective regularization for NLP tasks. An inherent disadvantage is that fine-tuning the pre-trained language model suffers from exposure bias and loss-evaluation mismatch. To this end, we propose a reinforcement learning (RL) approach to address both issues. Furthermore, we adopt a method called regularized dropout (R-Drop) to improve the inconsistency in dropout layers of DNNs. Experimental results show that both our proposed RL approach and the R-Drop technique can significantly improve the joint target accuracy (JGA) score and combined score of traditional Chinese TOD system in tasks of dialogue state tracking (DST) and end-to-end sentence prediction, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3248796",
            "Date of Publication": "24 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jeng-Shin Sheu",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Yunlin, Taiwan"
                ]
            },
            {
                "name": "Siang-Ru Wu",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Yunlin, Taiwan"
                ]
            },
            {
                "name": "Wen-Hung Wu",
                "labs": [
                    "Ponddy Education Taiwan Ltd., New Taipei City, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": []
        }
    },
    {
        "Title": "Integrating Natural Language Processing With Vision Transformer for Landscape Character Identification",
        "Link": "https://ieeexplore.ieee.org/document/10870433/",
        "Abstract": "Landscape character identification (LCI) has traditionally relied on manual methods to integrate and visually interpret multiple layers of natural and cultural data across regions. While effective, these methods are constrained by subjectivity in manual categorization and face challenges in scalability and consistency when applied to larger regions. In this article, we propose a novel deep learning-based LCI method that leverages natural language processing (NLP) to enable greater flexibility in identifying landscape types through natural language guidance. Focusing on the Western Sichuan Plains, our approach integrates nine geographic information system-derived landscape elements with natural language descriptions that specify desired styles of landscape characteristics. The model features three key components: a transformer-based module for extracting natural language features, a vision transformer (ViT) for spatial feature extraction, and a feature pyramid network for decision-making. Through multimodal information fusion across the feature extraction and decision-making stages, natural language inputs effectively guide the prioritization of landscape attributes and control the granularity of the generated landscape character maps. Visualization experiments demonstrate the model's capability to produce accurate and detailed landscape character maps, with a particular emphasis on identifying agricultural landscapes in the Western Sichuan Plains. This study validates the potential of integrating NLP into LCI, offering a significant advancement in precision and adaptability for landscape characterization.",
        "Details": {
            "DOI": "10.1109/JSTARS.2025.3538174",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing"
        },
        "issn_info": {
            "Print ISSN": "1939-1404",
            "Electronic ISSN": "2151-1535"
        },
        "authors_data": [
            {
                "name": "Tingting Huang",
                "labs": [
                    "School of Landscape Architecture, Beijing Forestry University, Beijing, China",
                    "School of Agriculture, Policy and Development, University of Reading, Reading, U.K."
                ]
            },
            {
                "name": "Haiyue Zhao",
                "labs": [
                    "School of Landscape Architecture, Beijing Forestry University, Beijing, China"
                ]
            },
            {
                "name": "Bo Huang",
                "labs": [
                    "College of Optoelectronic Engineering, Chongqing University, Chongqing, China",
                    "Key Laboratory of Optoelectronic Technology and Systems of the Education Ministry of China, Chongqing University, Chongqing, China"
                ]
            },
            {
                "name": "Sha Li",
                "labs": [
                    "School of Architecture and Design, China University of Mining and Technology, Xuzhou, China"
                ]
            },
            {
                "name": "Jianning Zhu",
                "labs": [
                    "School of Landscape Architecture, Beijing Forestry University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Feature extraction",
                "Natural language processing",
                "Biological system modeling",
                "Natural languages",
                "Computer vision",
                "Planning",
                "Adaptation models",
                "Manuals",
                "Focusing"
            ],
            "Author Keywords": [
                "Deep learning",
                "landscape character identification (LCI)",
                "multimodal information fusion",
                "natural language processing (NLP)",
                "vision transformer (ViT)"
            ]
        }
    },
    {
        "Title": "TOPSIS-Based Nonlinear Programming Method in Cubic p, q–Quasirung Orthopair Fuzzy Environment: Application in Green Supplier Selection",
        "Link": "https://ieeexplore.ieee.org/document/10637340/",
        "Abstract": "The aim of this study is to explore innovative non-linear programming (NLP) models utilizing the Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) method, tailored for resolving decision-making challenges within the framework of cubic\np,q−\nquasirung orthopair fuzzy sets\n(\nC\n(p,q)\nQOFSs)\n. In prior research, data pertaining to an element has typically been gathered in the form of either interval-valued\np,q−\nquasirung orthopair fuzzy sets\n(\nIV\n(p,q)\nQOFSs)\nor\np,q−\nquasi orthopair fuzzy sets (\np,q−\nQOFSs) information. As an alternative approach,\nC\n(p,q)\nQOFSs\nemerges as an extension of these sets, wherein information is compiled by simultaneously considering both\nIV\n(p,q)\nQOFSs\nand\np,q−\nQOFSs. Driven by this motivation, we constructed the NLP models incorporating interval weights and integrating the relative closeness coefficient concept alongside weighted distance measures. Furthermore, we scrutinized some notable characteristics (RCC) of these models. Additionally, we introduce an innovative multicriteria decision-making (MCDM) technique and illustrate its application with a real-world case study related to green supplier selection. A comparative analysis is also performed to validate the effectiveness and rationality of the method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3444605",
            "Date of Publication": "16 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bin You",
                "labs": [
                    "College of General Education, Chongqing Vocational and Technical University of Mechatronics, Chongqing, China"
                ]
            },
            {
                "name": "Muhammad Rahim",
                "labs": [
                    "Department of Mathematics and Statistics, Hazara University Mansehra, Mansehra, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Fazli Amin",
                "labs": [
                    "Department of Mathematics and Statistics, Hazara University Mansehra, Mansehra, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Sadique Ahmad",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Asim",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",
                    "School of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fuzzy sets",
                "Decision making",
                "MCDM",
                "Uncertainty",
                "Weight measurement",
                "Programming profession",
                "Green products"
            ],
            "Author Keywords": [
                "Cubic p,q-quasirung orthopair fuzzy set",
                "NLP model",
                "TOPSIS method",
                "multi criteria group decision making"
            ]
        }
    },
    {
        "Title": "Trajectory Optimization Method of Interceptor for High-Speed Gliding Target via Hp-Adaptive Radau Pseudo-Spectral Method",
        "Link": "https://ieeexplore.ieee.org/document/10639498/",
        "Abstract": "The high speed gliding aircraft has fast flight speed, posing high interception difficulty. This paper proposes a multi-stage interception scheme and presents a trajectory optimization method based on the hp adaptive Radau pseudospectral method (hp-ARPM) for interceptors. This method can effectively meet various constraints such as heat flux density and dynamic pressure, effectively solving the trajectory optimization problem of interceptors. Firstly, the flight process of interceptors is divided into initial boost stage, midcourse guidance stage, and terminal guidance stage to meet the requirements for long range interception of high-speed gliding aircraft. Taking into account that the initial boost stage is strongly affected by aerodynamic forces while the midcourse guidance stage is weakly affected, separated motion models are established for the initial boost stage and the midcourse guidance stage to more precisely describe the flight behavior of interceptors. Secondly, a multi-stage, multi-constraint nonlinear trajectory optimization model for interceptors is constructed, with connection constraints, process constraints, and optimization performance indicators established for different flight stages. Then, by using the hp-ARPM to transform the optimal control problem into a nonlinear programming problem (NLP), the optimal control solutions for the boost stage and midcourse guidance stage of interceptors are directly obtained by solving the NLP problem. The hp-ARPM method can adaptively adjust the number of nodes, improving optimization accuracy and computational efficiency. Simulation comparison experiments demonstrate that the multi-stage interception scheme proposed in this paper is feasible, and the hp-ARPM shows superior performance indicators compared to the Gauss pseudo-spectral method (GPM).",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3443395",
            "Date of Publication": "19 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ning Li",
                "labs": [
                    "Graduate College, Air Force Engineering University, Xi’an, China",
                    "Air and Missile Defense College, Air Force Engineering University, Xi’an, China"
                ]
            },
            {
                "name": "Tao Zhang",
                "labs": [
                    "Air and Missile Defense College, Air Force Engineering University, Xi’an, China"
                ]
            },
            {
                "name": "Wenyu Chen",
                "labs": [
                    "Graduate College, Air Force Engineering University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory optimization",
                "Optimal control",
                "Aircraft",
                "Accuracy",
                "Engines",
                "Missiles"
            ],
            "Author Keywords": [
                "Hp adaptive",
                "Radau pseudospectral method",
                "interceptor",
                "trajectory optimization",
                "NLP"
            ]
        }
    },
    {
        "Title": "A Novel Semantic Cohesion Approach for Chinese Airworthiness Regulations: Theory and Application",
        "Link": "https://ieeexplore.ieee.org/document/9301303/",
        "Abstract": "Airworthiness regulation documents are critical, which contain massive safe constraints for system design and airworthiness certification. The textual information of airworthiness regulations is organized and stored in a hierarchical and scattered form due to the unique provision structure. The linguistic form of legal provision brings the problems of incompleteness semantic information and syntactic structure to each legal clause, which limits the application of Natural Language Processing (NLP) technology in the field of airworthiness safety. In this article, a novel theory of semantic cohesion is proposed for Chinese airworthiness regulations, in which four critical elements are contained, including definition, model, theorem and rules. The definition of attributive directed graph model is proposed to achieve the graphical representation of airworthiness regulation texts. Moreover, the graphical issue of regulation texts is proved in accordance with the characteristic of hierarchical provision structure based on graph theory, and the rules of edge structure construction are provided. Based on the theory, a new node content link algorithm is proposed to achieve the tasks of semantic cohesion and structure conversion for Chinese airworthiness regulation texts. According to the hierarchical structure characteristic of regulation texts, the algorithm can convert the provision structure to the general narrative linguistic form by constructing edges with semantic cohesion relation. As a result, provision sentences with complete semantic information and syntactic structure can be generated. The algorithm has been deployed on the current 119 airworthiness regulation texts to verify the validity and feasibility. The experimental results show that the algorithm achieves efficient performance in the tasks of structure conversion and semantic cohesion, and the algorithm performs reliably with an accuracy rate of 100%. The problem of application limitation for NLP technology to Chinese airworthiness regulation texts has been resolved, which promotes the intelligent and automatic development of airworthiness safety.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3046294",
            "Date of Publication": "21 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Haotian Niu",
                "labs": [
                    "School of Civil Aviation, Northwestern Polytechnical University, Xi’an, China"
                ]
            },
            {
                "name": "Cunbao Ma",
                "labs": [
                    "School of Civil Aviation, Northwestern Polytechnical University, Xi’an, China"
                ]
            },
            {
                "name": "Pei Han",
                "labs": [
                    "Communication Division, 20th Institute, China Electronics Technology Group Corporation, Xi’an, China"
                ]
            },
            {
                "name": "Siyuan Li",
                "labs": [
                    "School of Civil Aviation, Northwestern Polytechnical University, Xi’an, China"
                ]
            },
            {
                "name": "Qi Ma",
                "labs": [
                    "School of Civil Aviation, Northwestern Polytechnical University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Regulation",
                "Semantics",
                "Task analysis",
                "Syntactics",
                "Safety",
                "Atmospheric modeling",
                "Linguistics"
            ],
            "Author Keywords": [
                "Airworthiness safety",
                "attributive directed graph",
                "Chinese airworthiness regulations",
                "general linguistic form",
                "hierarchical provision structure",
                "NLP",
                "node content link algorithm",
                "semantic cohesion theory"
            ]
        }
    },
    {
        "Title": "Optimizing Non-Intersecting Synthetic Vascular Trees in Nonconvex Organs",
        "Link": "https://ieeexplore.ieee.org/document/10944261/",
        "Abstract": "Objective: The understanding of the mechanisms driving vascular development is still limited. Techniques to generate vascular trees synthetically have been developed to tackle this problem. However, most algorithms are limited to single trees inside convex perfusion volumes. We introduce a new framework for generating multiple trees inside general nonconvex perfusion volumes. Methods: Our framework combines topology optimization and global geometry optimization into a single algorithmic approach. Our first contribution is defining a baseline problem based on Murray's original formulation, which accommodates efficient solution algorithms. The problem of finding the global minimum is cast into a nonlinear optimization problem (NLP) with merely super-linear solution effort. Our second contribution extends the NLP to constrain multiple vascular trees inside any nonconvex boundary while avoiding intersections. We test our framework against a benchmark of an anatomic region of brain tissue and a vasculature of the human liver. Results: In all cases, the total tree energy is improved significantly compared to local approaches. Conclusion: By avoiding intersections globally, we can reproduce key physiological features such as parallel running inflow vessels and tortuous vessels. Significance: The ability to generate non-intersecting vascular trees inside nonconvex organs can improve the functional assessment of organs.",
        "Details": {
            "DOI": "10.1109/TBME.2025.3554339",
            "Date of Publication": "27 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Biomedical Engineering"
        },
        "issn_info": {
            "Print ISSN": "0018-9294",
            "Electronic ISSN": "1558-2531"
        },
        "authors_data": [
            {
                "name": "Etienne Jessen",
                "labs": [
                    "Institute for Mechanics, Computational Mechanics Group, Technical University of Darmstadt, Darmstadt, Germany"
                ]
            },
            {
                "name": "Marc C. Steinbach",
                "labs": [
                    "Institute of Applied Mathematics, Algorithmic Optimization Group, Leibniz University Hannover, Germany"
                ]
            },
            {
                "name": "Dominik Schillinger",
                "labs": [
                    "Institute for Mechanics, Computational Mechanics Group, Technical University of Darmstadt, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Geometry",
                "Blood",
                "Topology",
                "Indexes",
                "Liver",
                "Mathematical models",
                "Viscosity",
                "Vectors",
                "Upper bound"
            ],
            "Author Keywords": [
                "Brain",
                "liver",
                "NLP",
                "nonconvex organs",
                "synthetic vascular trees"
            ]
        }
    },
    {
        "Title": "TextFocus: Assessing the Faithfulness of Feature Attribution Methods Explanations in Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10543008/",
        "Abstract": "Among the existing eXplainable AI (XAI) approaches, Feature Attribution methods are a popular option due to their interpretable nature. However, each method leads to a different solution, thus introducing uncertainty regarding their reliability and coherence with respect to the underlying model. This work introduces TextFocus, a metric for evaluating the faithfulness of Feature Attribution methods for Natural Language Processing (NLP) tasks involving classification. To address the absence of ground truth explanations for such methods, we introduce the concept of textual mosaics. A mosaic is composed of a combination of sentences belonging to different classes, which provides an implicit ground truth for attribution. The accuracy of explanations can be then evaluated by comparing feature attribution scores with the known class labels in the mosaic. The performance of six feature attribution methods is systematically compared on three sentence classification tasks by using TextFocus, with Integrated Gradients being the best overall method in terms of faithfulness and computational requirements. The proposed methodology fills a gap in NLP evaluation, by providing an objective way to assess Feature Attribution methods while finding their optimal parameters.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3408062",
            "Date of Publication": "31 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ettore Mariotti",
                "labs": [
                    "Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Santiago de Compostela, Spain"
                ]
            },
            {
                "name": "Anna Arias-Duart",
                "labs": [
                    "Barcelona Supercomputing Center (BSC), Barcelona, Spain",
                    "Universitat Politècnica de Catalunya (UPC)–BarcelonaTech, Les Corts, Barcelona, Spain"
                ]
            },
            {
                "name": "Michele Cafagna",
                "labs": [
                    "University of Malta, Msida, MSD, Malta"
                ]
            },
            {
                "name": "Albert Gatt",
                "labs": [
                    "Utrecht University, Utrecht, CS, The Netherlands"
                ]
            },
            {
                "name": "Dario Garcia-Gasulla",
                "labs": [
                    "Barcelona Supercomputing Center (BSC), Barcelona, Spain",
                    "Universitat Politècnica de Catalunya (UPC)–BarcelonaTech, Les Corts, Barcelona, Spain"
                ]
            },
            {
                "name": "Jose Maria Alonso-Moral",
                "labs": [
                    "Centro Singular de Investigación en Tecnoloxías Intelixentes (CiTIUS), Santiago de Compostela, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Predictive models",
                "Measurement",
                "Explainable AI",
                "Data models",
                "Computational modeling",
                "Artificial intelligence",
                "Feature detection"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "explainable AI (XAI)",
                "trustworthy AI",
                "explanation faithfulness",
                "feature attribution",
                "feature importance",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "AI-Powered Adaptive English Language Learning Systems: Leveraging Deep Learning Algorithms and Natural Language Processing for Personalized Teaching Approaches",
        "Link": "https://ieeexplore.ieee.org/document/11143192/",
        "Abstract": "This study explores the development of AI-powered adaptive systems for English language learning, focusing on leveraging Recurrent Neural Networks (RNNs) and Natural Language Processing (NLP) to create personalized learning experiences. The goal is to address the challenges of traditional, one-size-fits-all teaching methods by using AI to tailor content to individual learner needs, improving engagement and proficiency. Through RNNs, the system is able to model sequential language data, such as grammar and speech patterns, while NLP techniques process and interpret text and spoken input, allowing for real-time error detection and feedback. The key findings indicate that learners using the AI-powered system show significantly higher improvements in language proficiency—particularly in grammar accuracy and speech clarity—compared to those using traditional methods. The system’s ability to adapt content based on performance leads to greater user engagement, demonstrating the effectiveness of personalized learning paths. This study highlights the potential of AI to revolutionize language education, offering scalable solutions that cater to diverse learning styles and proficiency levels. The findings suggest that such systems could play a crucial role in enhancing global language education, particularly for non-native English learners, by offering a more flexible and individualized approach to learning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3603602",
            "Date of Publication": "28 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ying Ma",
                "labs": [
                    "Foreign Language Teaching Department, Nanjing University of Chinese Medicine, Nanjing, Jiangsu, China"
                ]
            },
            {
                "name": "Xiao-Jian Tang",
                "labs": [
                    "Architects and Engineers Company Ltd., Southeast University, Nanjing, Jiangsu, China"
                ]
            },
            {
                "name": "Xin Huang",
                "labs": [
                    "State Key Laboratory of Natural Medicines, China Pharmaceutical University, Nanjing, Jiangsu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Mathematical models",
                "Education",
                "Natural language processing",
                "Adaptation models",
                "Learning systems",
                "Adaptive systems",
                "Training",
                "Signal to noise ratio",
                "Market research",
                "Deep learning"
            ],
            "Author Keywords": [
                "AI-powered learning",
                "adaptive language learning",
                "recurrent neural networks (RNNs)",
                "natural language processing (NLP)",
                "personalized education"
            ]
        }
    },
    {
        "Title": "Prompt Tuning Techniques for Chinese Idiom Recommendation",
        "Link": "https://ieeexplore.ieee.org/document/10965689/",
        "Abstract": "Chinese idioms pose significant challenges in natural language processing (NLP) due to their complex, non-compositional nature and frequent embedded cultural and historical meanings. This study investigates prompt tuning techniques for Chinese idiom recommendation, exploring multiple-choice (MC) prompts, binary classification (BC) prompts, and prompt ensembling strategies. We also introduce an innovative dynamic candidate sampling strategy (DCSS) technique designed to mitigate the overfitting issues commonly encountered with prompt tuning methods on Chinese idiom datasets. Our experimental results demonstrate that prompt tuning combined with ensembling methods significantly improves model performance across multiple datasets. The proposed methods outperform the state-of-the-art (SOTA) methods while maintaining training and inference efficiency. Moreover, we show that prompt tuning can effectively be generalized for other NLP tasks, such as sentiment analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3561188",
            "Date of Publication": "15 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shun-Ming Wang",
                "labs": [
                    "Department of Industrial Engineering and Management, National Kaohsiung University of Science and Technology, Kaohsiung City, Sanmin, Taiwan"
                ]
            },
            {
                "name": "I-Fang Su",
                "labs": [
                    "Department of Computer Science and Information Engineering, National University of Tainan, Tainan City, West Central District, Taiwan"
                ]
            },
            {
                "name": "Yu-Chi Chung",
                "labs": [
                    "Department of Industrial Engineering and Management, National Kaohsiung University of Science and Technology, Kaohsiung City, Sanmin, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tuning",
                "Encoding",
                "Bidirectional control",
                "Training",
                "Motion pictures",
                "Adaptation models",
                "Urban areas",
                "Training data",
                "Sentiment analysis",
                "Semantics"
            ],
            "Author Keywords": [
                "Chinese idiom recommendation",
                "deep learning",
                "prompt engineering/tuning",
                "pre-trained language model",
                "NLP"
            ]
        }
    },
    {
        "Title": "Developing a Multi-Layer Ontology Construction Framework for Arabic Language Processing: Focus on Figurative Language Potential",
        "Link": "https://ieeexplore.ieee.org/document/11112775/",
        "Abstract": "Figurative language, encompassing metaphor, hyperbole, and metonymy, is deeply embedded in Arabic discourse and presents considerable challenges related to Arabic’s rich morphology, dialectal diversity, and complex syntax. In response to these challenges, this study introduces a novel multi-layered ontology construction framework aimed at systematically capturing and formalizing linguistic features essential for the annotation of figurative language in Arabic texts. The proposed framework comprises four interrelated layers–Lexical, Grammatical, Inflectional, and Categorical–and integrates external lexical resources, such as Wiktionary, dependency parsing, and morphological analysis to model syntactic, morphological, and semantic relationships. The ontology supports key NLP applications, including word sense disambiguation, semantic search, and text summarization. Experimental evaluation demonstrates the scalability and effectiveness of the framework, resulting in the structured representation of over 41,000 Arabic lexical entries and approximately 830,000 morphological inflections. Theoretically, this work advances the formal modeling of figurative language in morphologically rich languages, while practically, it enables the development of more linguistically grounded and semantically aware Arabic NLP systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3596130",
            "Date of Publication": "05 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zouheir Banou",
                "labs": [
                    "Laboratory of Artificial Intelligence and Systems, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Sanaa El Filali",
                "labs": [
                    "Laboratory of Artificial Intelligence and Systems, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "El Habib Benlahmar",
                "labs": [
                    "Laboratory of Artificial Intelligence and Systems, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Laila Eljiani",
                "labs": [
                    "Laboratory of Artificial Intelligence and Systems, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Fatima-Zahra Alaoui",
                "labs": [
                    "Laboratory of Artificial Intelligence and Systems, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ontologies",
                "Semantics",
                "Law",
                "Resource description framework",
                "Multilingual",
                "Annotations",
                "Accuracy",
                "Unified modeling language",
                "Manuals",
                "Text summarization"
            ],
            "Author Keywords": [
                "Arabic ontology",
                "figurative language annotation",
                "lexical relationships",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "A Hybrid Frequency Based, Syntax, and Conditional Random Field Method for Implicit and Explicit Aspect Extraction",
        "Link": "https://ieeexplore.ieee.org/document/10535189/",
        "Abstract": "Aspect extraction is the most important factor influencing the quality of Aspect-Based Sentiment Analysis (ABSA). Aspect extractions are divided into three approaches: supervised, unsupervised, and hybrid methods. Most previous aspect extraction algorithms focus on the explicit aspect, which lacks meaningful ABSA. Thus, considering the implicit aspect has become significant as most customer reviews consist of these by about 30%. Hybrid approaches have attempted to solve both aspects by integrating the frequency-based approaches (FB) with syntax, hybrid Conditional Random Field (CRF) with syntax, and hybrid FB with CRF, but the performance is still low. Extracting the implicit and compound noun aspects is challenging due to their hidden nature and special syntax needs. The implicit aspect needs FB, syntax dependency, and specialized tagging with feature embedding using natural language processing (NLP) solution, while the compound noun aspect needs FB, syntax dependency-based NLP solving. Therefore, this paper proposes a noble hybrid method combining frequency-based, syntax-based dependency, and CRF algorithms using tagging and labeling to extract both implicit and explicit aspects. It also provides a mechanism for extracting and calculating implicit and explicit aspects and a method for accurately identifying compound noun aspects. Experiments with the benchmark SemEval and Amazon review dataset validate the suggested hybrid model’s effectiveness. The proposed method produced remarkable improvement in extracting explicit and implicit aspects and improved overall results with precision-recall and accuracy between 5-15 percent. Moreover, this study has shown the number and the list of explicit and implicit aspects. The proposed method has obtained (2269, 368), (523, 60), (322, 55) number of explicit versus implicit aspects for SemEval 16, Amazon (Canon), and Amazon (Nokia) datasets, respectively. Hybrid with frequency-based, CRF’s superiority tagging and syntax help solve implicit and explicit aspects, including compound nouns.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3403479",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Mashrekul Kabir",
                "labs": [
                    "Centre for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Zulaiha Ali Othman",
                "labs": [
                    "Centre for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Mohd Ridzwan Yaakub",
                "labs": [
                    "Centre for Artificial Intelligence Technology (CAIT), Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Syntactics",
                "Reviews",
                "Conditional random fields",
                "Compounds",
                "Tagging",
                "Semantics",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Aspect extraction",
                "aspects",
                "implicit aspect",
                "customer reviews",
                "ABSA",
                "sentiment analysis",
                "CRF",
                "NLP",
                "hybrid method"
            ]
        }
    },
    {
        "Title": "Examining the Factors Influencing the Mobile Learning Usage During COVID-19 Pandemic: An Integrated SEM-ANN Method",
        "Link": "https://ieeexplore.ieee.org/document/9488198/",
        "Abstract": "The way in which the emotion of fear affects the technology adoption of students and teachers amid the COVID-19 pandemic is examined in this study. Mobile Learning (ML) has been used in the study as an educational social platform at both public and private higher-education institutes. The key hypotheses of this study are based on how COVID-19 has influenced the incorporation of mobile learning (ML) as the pandemic brings about an increase in different kinds of fear. The major kinds of fear that students and teachers/instructors are facing at this time include: fear because of complete lockdown, fear of experiencing education collapse and fear of having to give up social relationships. The proposed model was evaluated by developing a questionnaire survey which was distributed among 280 students at Zayed University, on the Abu Dhabi Campus, in the United Arab Emirates (UAE) with the purpose of collecting data from them. This study uses a new hybrid analysis approach that combines SEM and deep learning-based artificial neural networks (ANN). The importance-performance map analysis is also used in this study to determine the significance and performance of every factor. Both ANN and IPMA research showed that Attitude (ATD) are the most important predictor of intention to use mobile learning. According to the empirical findings, perceived ease of use, perceived usefulness, satisfaction, attitude, perceived behavioral control, and subjective norm played a strongly significant role justified the continuous Mobile Learning usage. It was found that perceived fear and expectation confirmation were significant factors in predicting intention to use mobile learning. Our study showed that the use of mobile learning (ML) in the field of education, amid the coronavirus pandemic, offered a potential outcome for teaching and learning; however, this impact may be reduced by the fear of losing friends, a stressful family environment and fear of future results in school. Therefore, during the pandemic, it is important to examine students appropriately so as to enable them to handle the situation emotionally. The proposed model has theoretically given enough details as to what influences the intention to use ML from the viewpoint of internet service variables on an individual basis. In practice, the findings would allow higher education decision formers and experts to decide which factors should be prioritized over others and plan their policies appropriately. This study examines the competence of the deep ANN model in deciding non-linear relationships among the variables in the theoretical model, methodologically.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3097753",
            "Date of Publication": "16 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Khadija Alhumaid",
                "labs": [
                    "College of Education, Zayed University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Mohammed Habes",
                "labs": [
                    "Department of Radio and Television, Faculty of Mass Communication, Yarmouk University, Irbid, Jordan"
                ]
            },
            {
                "name": "Said A. Salloum",
                "labs": [
                    "School of Science, Engineering, Environment, University of Salford, Manchester, U.K",
                    "Machine Learning and NLP Research Group, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Mathematical model",
                "Artificial neural networks",
                "Technology acceptance model",
                "Education",
                "COVID-19",
                "Uncertainty",
                "Pandemics"
            ],
            "Author Keywords": [
                "Artificial Neural Network Architecture",
                "hybrid-model",
                "mobile learning",
                "Structural Equation Modeling",
                "subjective norm"
            ]
        }
    },
    {
        "Title": "Korean-Vietnamese Neural Machine Translation System With Korean Morphological Analysis and Word Sense Disambiguation",
        "Link": "https://ieeexplore.ieee.org/document/8660625/",
        "Abstract": "Although deep neural networks have recently led to great achievements in machine translation (MT), various challenges are still encountered during the development of Korean-Vietnamese MT systems. Because Korean is a morphologically rich language and Vietnamese is an analytic language, neither have clear word boundaries. The high rate of homographs in Korean causes word ambiguities, which causes problems in neural MT (NMT). In addition, as a low-resource language pair, there is no freely available, adequate Korean-Vietnamese parallel corpus that can be used to train translation models. In this paper, we manually established a lexical semantic network for the special characteristics of Korean as a knowledge base that was used for developing our Korean morphological analysis and word-sense disambiguation system: UTagger. We also constructed a large Korean-Vietnamese parallel corpus, in which we applied the state-of-the-art Vietnamese word segmentation method RDRsegmenter to Vietnamese texts and UTagger to Korean texts. Finally, we built a bi-directional Korean-Vietnamese NMT system based on the attention-based encoder-decoder architecture. The experimental results indicated that UTagger and RDRsegmenter could significantly improve the performance of the Korean-Vietnamese NMT system, achieving remarkable results by 27.79 BLEU points and 58.77 TER points in Korean-to-Vietnamese direction and 25.44 BLEU points and 58.72 TER points in the reverse direction.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2902270",
            "Date of Publication": "05 March 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Quang-Phuoc Nguyen",
                "labs": [
                    "Department of IT Convergence, University of Ulsan, Ulsan, South Korea"
                ]
            },
            {
                "name": "Anh-Dung Vo",
                "labs": [
                    "Department of IT Convergence, University of Ulsan, Ulsan, South Korea"
                ]
            },
            {
                "name": "Joon-Choul Shin",
                "labs": [
                    "Department of IT Convergence, University of Ulsan, Ulsan, South Korea"
                ]
            },
            {
                "name": "Phuoc Tran",
                "labs": [
                    "NLP-KD Lab, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Cheol-Young Ock",
                "labs": [
                    "Department of IT Convergence, University of Ulsan, Ulsan, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Buildings",
                "Feeds",
                "Training",
                "Dictionaries",
                "Vocabulary",
                "Neural networks"
            ],
            "Author Keywords": [
                "Korean-Vietnamese machine translation",
                "korean-Vietnamese parallel corpus",
                "lexical semantic network",
                "morphological analysis",
                "neural machine translation",
                "word sense disambiguation"
            ]
        }
    },
    {
        "Title": "Path Planning Algorithm Using the Hybridization of the Rapidly-Exploring Random Tree and Ant Colony Systems",
        "Link": "https://ieeexplore.ieee.org/document/9612162/",
        "Abstract": "This paper proposes a path planning algorithm using the hybridization of the rapidly-exploring random tree (RRT) and ant colony system (ACS) algorithms. The RRT algorithm can quickly generate paths. However, the resulting path is suboptimal. Meanwhile, the ACS algorithm can generate the optimal path from the suboptimal previous path information. Then, the proposed algorithm will combine the advantages of RRT with the ACS algorithm. Therefore, it can reach the optimal value with a good convergence speed. We call this proposed algorithm the RRT-ACS algorithm. This study developed a new method for hybridizing the RRT and ACS algorithms for path planning problems. This hybridization process is carried out using one of the ACS principles: the pseudorandom proportional rule. The performance of the proposed algorithm with the RRT*, informed RRT*, RRT*-connect, and informed RRT*-connect algorithms is tested with several benchmark cases. The test results from benchmark case tests with known optimal values indicate that the proposed algorithm has succeeded in achieving those optimal values. Furthermore, statistical tests have also been carried out to verify whether there is a significant difference in performance between the RRT-ACS algorithm and the existing algorithms. The test and statistical analysis results show that the RRT-ACS algorithm has good performance and convergence speed. We also discuss the stability, robustness, convergence, and rapidity of the RRT-ACS algorithm. The results indicates that the RRT-ACS algorithm may be used in applications that require fast and optimal path planning algorithms such as robots and autonomous vehicles.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3127635",
            "Date of Publication": "11 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Aria Rajasa Pohan",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Sigit Puji Santosa",
                "labs": [
                    "Faculty of Mechanical and Aerospace Engineering, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Arief Syaichu Rohman",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Path planning",
                "Convergence",
                "Search methods",
                "Benchmark testing",
                "Statistical analysis",
                "Mathematical models",
                "Robustness"
            ],
            "Author Keywords": [
                "Path planning",
                "rapidly-exploring random tree",
                "ant colony system",
                "convergence speed"
            ]
        }
    },
    {
        "Title": "Context-Similarity Collaborative Filtering Recommendation",
        "Link": "https://ieeexplore.ieee.org/document/8998219/",
        "Abstract": "This article proposes a new method to overcome the sparse data problem of the collaborative filtering models (CF models) by considering the homologous relationship between users or items calculated on contextual attributes when we build the CF models. In the traditional CF models, the results are built only based on data from the user's ratings for items. The results of the proposed models are calculated on two factors: (1) the similar factors based on rating values; (2) the similar factors based on contextual attributes. The findings from the experimentation on two datasets DePaulMovie and InCarMusic, show that the proposed models have higher accuracy than the traditional CF models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2973755",
            "Date of Publication": "13 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hiep Xuan Huynh",
                "labs": [
                    "College of Information and Communication Technology, Can Tho University, Can Tho, Vietnam"
                ]
            },
            {
                "name": "Nghia Quoc Phan",
                "labs": [
                    "Assessment Office, Tra Vinh University, Tra Vinh, Vietnam"
                ]
            },
            {
                "name": "Nghi Mong Pham",
                "labs": [
                    "Thapmuoi Vocational School, Cao Lãnh, Vietnam"
                ]
            },
            {
                "name": "Van-Huy Pham",
                "labs": [
                    "NLP-KD Lab, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Le Hoang Son",
                "labs": [
                    "VNU Information Technology Institute, Vietnam National University, Hanoi, Vietnam"
                ]
            },
            {
                "name": "Mohamed Abdel-Basset",
                "labs": [
                    "Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            },
            {
                "name": "Mahmoud Ismail",
                "labs": [
                    "Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Collaboration",
                "Data models",
                "Motion pictures",
                "Predictive models",
                "Recommender systems"
            ],
            "Author Keywords": [
                "CIBCF models",
                "contextual attributes",
                "context-similarity matrix",
                "CUBCF models"
            ]
        }
    },
    {
        "Title": "Path Planning Using Combined Informed Rapidly- Exploring Random Tree Star and Particle Swarm Optimization Algorithms",
        "Link": "https://ieeexplore.ieee.org/document/10500393/",
        "Abstract": "This study proposes a path planning algorithm that combines an informed rapidly-exploring random tree (RRT*) and particle swarm optimization (PSO) algorithms. The informed RRT* algorithm can build optimal pathways quickly. However, in some cases, the informed RRT* strategy cannot help increase the convergence rate. Meanwhile, the PSO algorithm can be combined with other algorithms to improve algorithm performance. The proposed algorithm will combine the advantages of informed RRT* and PSO algorithms. The proposed algorithm is called the RRT-PSO algorithm. The RRT-PSO algorithm’s performance was compared to the informed RRT*, RRT*, RRT-ACS, and informed RRT*-connect algorithms using eight benchmark scenarios. The test results on benchmark scenarios with known optimal values demonstrate that the RRT-PSO algorithm achieves those optimal values. The statistical analysis shows that the RRT-PSO algorithm has a fast convergence rate compared to other comparison algorithms. The test results also demonstrate the RRT-PSO algorithm’s stability and robustness compared to other comparison algorithms. Our test results also show the RRT-PSO algorithm’s advantages over other PSO-based and traditional path planning algorithms. The results show that the RRT-PSO algorithm is suitable for applications requiring a fast and optimal path planning algorithm, such as self-driving cars and unmanned aerial vehicles (UAV).",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3389152",
            "Date of Publication": "15 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Aria Rajasa Pohan",
                "labs": [
                    "Doctoral Program of Electrical Engineering and Informatics, School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Bandung, Indonesia"
                ]
            },
            {
                "name": "Sigit Puji Santosa",
                "labs": [
                    "Faculty of Mechanical and Aerospace Engineering, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Arief Syaichu Rohman",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Heuristic algorithms",
                "Optimization",
                "Convergence",
                "Classification algorithms",
                "Genetic algorithms",
                "Path planning",
                "Particle swarm optimization"
            ],
            "Author Keywords": [
                "Path planning",
                "convergence rate",
                "optimal path",
                "informed rapidly-exploring random tree",
                "particle swarm optimization"
            ]
        }
    },
    {
        "Title": "Object Detection in Dense and Mixed Traffic for Autonomous Vehicles With Modified Yolo",
        "Link": "https://ieeexplore.ieee.org/document/10325498/",
        "Abstract": "Autonomous vehicles rely on the accurate detection and recognition of objects in their surroundings, a critical requirement for safe operation, especially in congested traffic with diverse vehicle types. This study presents a novel dataset collected in various road conditions in Indonesia, and it focuses on the detection and classification of visual objects around autonomous vehicles. Object recognition is achieved through the use of YOLOv7-based deep learning, adapted to identify small, faint, and partially concealed objects. Key enhancements include the integration of a deformable layer and the transition from Non-Maximum Suppression (NMS) to Soft Non-Maximum Suppression (softNMS). The dataset comprises eight predefined custom classes commonly encountered in Indonesian traffic. We collected video data recordings of heavy traffic scenarios featuring a wide range of vehicle types as training and testing data. The object detection model is fine-tuned through transfer learning, with multiple learning configurations explored for comparison. Experimental results demonstrate that deep learning models trained with transfer learning outperform those trained from scratch. Specifically, the modified YOLOv7, referred to as YOLOv7-MOD, incorporates a deformable convolution layer for up-sampling, leading to a remarkable performance of 94.68% in Recall, 96.87% in Precision, and 95.76% in F1-score. The modification resulted in an additional performance increase of 1.05% on average compared to the original model. The findings indicate that YOLOv7-MOD enhances the precision of object detection and recognition compared to the original YOLOv7, making it a promising solution for autonomous vehicle perception systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3335826",
            "Date of Publication": "21 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ari Wibowo",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Bandung, Indonesia"
                ]
            },
            {
                "name": "Egi Muhammad Idris Hidayat",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Rinaldi Munir",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Autonomous vehicles",
                "Deep learning",
                "Proposals",
                "Convolutional neural networks",
                "Real-time systems",
                "Object recognition",
                "Deformable models"
            ],
            "Author Keywords": [
                "Object detection",
                "deformable convolution",
                "autonomous vehicle",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A Novel Single Valued Neutrosophic Hesitant Fuzzy Time Series Model: Applications in Indonesian and Argentinian Stock Index Forecasting",
        "Link": "https://ieeexplore.ieee.org/document/9044863/",
        "Abstract": "This paper proposed a novel first-order single-valued neutrosophic hesitant fuzzy time series (SVNHFTS) forecasting model. Our aim is to improve the previously proposed neutrosophic time series (NTS) model by incorporating the degree of the hesitancy using single-valued neutrosophic hesitant fuzzy set (SVNHFS) model instead of single-valued neutrosophic set (SVNS). Our paper's novelty is that we incorporate an algorithm that automatically converts the crisp dataset into the neutrosophic set that eliminates the need for experts' input or opinions in determining the membership in each of the partitioned neutrosophic set. We also incorporate Markov Chain algorithm in the de-neutrosophication process to include the weightage of the repeating neutrosophic logical relationships (NLRs). Our paper's significant contribution is to add to the existing body of knowledge related to fuzzy time series (FTS) by developing a new FTS model based on SVNHFS, one of the improved version of fuzzy sets, since this area of research is still relatively underdeveloped. To determine our proposed model's capability, we apply our proposed SVNHFTS model to three real datasets while also comparing the result to the other FTS models based on improved versions of fuzzy sets. Our datasets include benchmark enrollment data of University of Alabama, IDX Composite (Indonesian composite stock index), and MERVAL index (Argentinian composite stock index). The result shows that our proposed SVNHFTS model outperforms most of the other FTS models in terms of AFE and RMSE, especially the previously proposed NTS model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2982825",
            "Date of Publication": "23 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Billy Tanuwijaya",
                "labs": [
                    "Department of Actuarial Science and Applied Statistics, Faculty of Business and Information Science, UCSI University, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Ganeshsree Selvachandran",
                "labs": [
                    "Department of Actuarial Science and Applied Statistics, Faculty of Business and Information Science, UCSI University, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Le Hoang Son",
                "labs": [
                    "VNU Information Technology Institute, Vietnam National University, Hanoi, Vietnam",
                    "College of Electronics and Information Engineering, Sejong University, Seoul, South Korea"
                ]
            },
            {
                "name": "Mohamed Abdel-Basset",
                "labs": [
                    "Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            },
            {
                "name": "Hiep Xuan Huynh",
                "labs": [
                    "College of Information and Communication Technology, Can Tho University, Can Tho, Vietnam"
                ]
            },
            {
                "name": "Van-Huy Pham",
                "labs": [
                    "NLP-KD Lab, Faculty of Information Technology, Ton Duc Thang University, Chi Minh, Vietnam"
                ]
            },
            {
                "name": "Mahmoud Ismail",
                "labs": [
                    "Faculty of Computers and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Fuzzy sets",
                "Forecasting",
                "Predictive models",
                "Fuzzy set theory",
                "Indexes",
                "Hafnium"
            ],
            "Author Keywords": [
                "Single-valued neutrosophic hesitant fuzzy set (SVNHFS)",
                "single-valued neutrosophic hesitant fuzzy time series (SVNHFTS)",
                "neutrosophic time series (NTS)",
                "fuzzy time series (FTS)"
            ]
        }
    },
    {
        "Title": "Resource Mention Extraction for MOOC Discussion Forums",
        "Link": "https://ieeexplore.ieee.org/document/8743365/",
        "Abstract": "In discussions hosted on discussion forums for massive online open courses (MOOCs), references to online learning resources are often of central importance. They contextualize the discussion, anchoring the discussion participants' presentation of the issues and their understanding. However, they are usually mentioned in free text, without appropriate hyperlinking to their associated resource. Automated learning resource mention hyperlinking and categorization will facilitate discussion and searching within the MOOC forums and also benefit the contextualization of such resources across disparate views. We propose the novel problem of learning resource mention identification in MOOC forums, i.e., to identify resource mentions in discussions and classify them into pre-defined resource types. As this is a novel task with no publicly available data, we first contribute a large-scale labeled dataset-dubbed the forum resource mention (FoRM) dataset-to facilitate our current research and future research on this task. The FoRM contains over 10 000 real-world forum threads in collaboration with Coursera, with more than 23 000 manually labeled resource mentions. We then formulate this task as a sequence tagging problem and investigate solution architectures to address the problem. Importantly, we identify two major challenges that hinder the applications of sequence tagging models to the task: (1) the diversity of resource mention expression and (2) long-range contextual dependencies. We address these challenges by incorporating character-level and thread context information into an LSTM-CRF model. First, we incorporate a character encoder to address the out-of-vocabulary problem caused by the diversity of mention expressions. Second, to address the context dependency challenge, we encode thread contexts using an RNN-based context encoder and apply the attention mechanism to selectively leverage useful context information during sequence tagging. The experiments on FoRM show that the proposed method improves the baseline deep sequence tagging models notably, significantly bettering performance on instances that exemplify two challenges.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2924250",
            "Date of Publication": "21 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ya-Hui An",
                "labs": [
                    "Web IR/NLP Group, National University of Singapore, Singapore"
                ]
            },
            {
                "name": "Liangming Pan",
                "labs": [
                    "NUS Graduate School for Integrative Sciences and Engineering, National University of Singapore, Singapore"
                ]
            },
            {
                "name": "Min-Yen Kan",
                "labs": [
                    "NUS Institute for Application of Learning Science and Educational Technology, National University of Singapore, Singapore"
                ]
            },
            {
                "name": "Qiang Dong",
                "labs": [
                    "CompleX Lab, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            },
            {
                "name": "Yan Fu",
                "labs": [
                    "CompleX Lab, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context",
                "Task analysis",
                "Tagging",
                "Message systems",
                "Discussion forums",
                "Context modeling",
                "Semantics"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "deep learning",
                "hyperlinking",
                "learning resources",
                "MOOC discussion forums",
                "name entity recognition"
            ]
        }
    },
    {
        "Title": "Distributed Framework for Automating Opinion Discretization From Text Corpora on Facebook",
        "Link": "https://ieeexplore.ieee.org/document/8735698/",
        "Abstract": "Nowadays, the consecutive increase of the volume of text corpora datasets and the countless research directions in general classification have created a great opportunity and an unprecedented demand for a comprehensive evaluation of the current achievement in the research of natural language processing. There are unfortunately few studies that have applied the combination of convolutional neural networks (CNN) and Apache Spark to the task of automating opinion discretization. In this paper, the authors propose a new distributed structure for solving an opinion classification problem in text mining by utilizing CNN models and big data technologies on Vietnamese text sources. The proposed framework consists of implementation concepts that are needed by a researcher to perform experiments on text discretization problems. It covers all the steps and components that are usually part of a completely practical text mining pipeline: acquiring input data, processing, tokenizing it into a vectorial representation, applying machine learning algorithms, performing the trained models to unseen data, and evaluating their accuracy. The development of the framework started with a specific focus on binary text discretization, but soon expanded toward many other text-categorization-based problems, distributed language modeling and quantification. Several intensive assessments have been investigated to prove the robustness and efficiency of the proposed framework. Resulting in high accuracy (72.99% ± 3.64) from the experiments, one can conclude that it is feasible to perform our proposed distributed framework to the task of opinion discretization on Facebook.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2922427",
            "Date of Publication": "12 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hiep Xuan Huynh",
                "labs": [
                    "College of Information and Communications Technology, Can Tho University, Can Tho, Vietnam"
                ]
            },
            {
                "name": "Vu Tuan Nguyen",
                "labs": [
                    "College of Information and Communications Technology, Can Tho University, Can Tho, Vietnam"
                ]
            },
            {
                "name": "Nghia Duong-Trung",
                "labs": [
                    "Department of Computer Science, Can Tho University of Technology, Can Tho University, Can Tho, Vietnam"
                ]
            },
            {
                "name": "Van-Huy Pham",
                "labs": [
                    "NLP-KD Lab, Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh, Vietnam"
                ]
            },
            {
                "name": "Cang Thuong Phan",
                "labs": [
                    "College of Information and Communications Technology, Can Tho University, Can Tho, Vietnam"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sparks",
                "Facebook",
                "Machine learning",
                "Cluster computing",
                "Data mining",
                "Task analysis"
            ],
            "Author Keywords": [
                "Apache spark",
                "classification",
                "convolutional neural networks",
                "deep learning",
                "opinion mining",
                "TensorFlow"
            ]
        }
    },
    {
        "Title": "Design of DDPG-Based Extended Look-Ahead for Longitudinal and Lateral Control of Vehicle Platoon",
        "Link": "https://ieeexplore.ieee.org/document/10239154/",
        "Abstract": "This paper presents a novel Deep Deterministic Policy Gradient (DDPG) algorithm with extended look-ahead approach for longitudinal and lateral control of vehicle platooning. The DDPG algorithm is adapted due to its ability to fit nonlinear system and to handle continuous control environment. Moreover, the dynamic input inversion is introduced to reduce domain of the action space from DDPG output. The existing look-ahead approach is considered as a cost-effective approach since it uses the available information from on-board sensors and is effective against the loss of lane markings. However, the approach is known to suffer from cutting-corner phenomenon. To address cutting-corners, we introduce the extended look-ahead approach and derive the true-local error states using the already available information from lidar and V2V communication. The robustness and performance of DDPG-based extended look-ahead controller is investigated by means of simulations and validated through experiments on a Donkey Car platform. The simulations and experiments with Donkey Car show that the DDPG-based extended look-ahead algorithm can provide an efficient control strategy for longitudinal and lateral maneuvers without the requirement of path information.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3311850",
            "Date of Publication": "04 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anggera Bayuwindra",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Leon Wonohito",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang R. Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Bandung Institute of Technology, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Heuristic algorithms",
                "Vehicle dynamics",
                "Nonlinear dynamical systems",
                "Kinematics",
                "Dynamics",
                "Vehicular ad hoc networks",
                "Mathematical models",
                "Reinforcement learning"
            ],
            "Author Keywords": [
                "Deep deterministic policy gradient (DDPG)",
                "reinforcement learning control",
                "longitudinal and lateral control",
                "vehicle platooning",
                "vehicle following"
            ]
        }
    },
    {
        "Title": "Machine Reading Comprehension Framework Based on Self-Training for Domain Adaptation",
        "Link": "https://ieeexplore.ieee.org/document/9336622/",
        "Abstract": "Machine reading comprehension (MRC) is a type of question answering mechanism in which a computer reads documents and answers related questions. The accuracies of recent MRC systems surpass those of humans. However, most MRC systems exhibit significant performance deteriorations when domains are changed. Hence, we propose a self-training framework for MRC. The proposed framework is composed of a pseudo-answer extractor, a pseudo-question generator, and an MRC system. In the source domain, components are pretrained using an MRC training dataset. In the target domain, the performances of the pseudo-question generator and MRC system is improved through a mutual self-training scheme. During the mutual self-training, the pseudo-question generator provides new training data to the MRC system and obtains rewards from the MRC system for reinforcement learning. In experiments with a Wikipedia domain (source domain) and civil affair domain (target domain), an MRC system based on the proposed self-training scheme demonstrates better performances than that based on automatic data augmentation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3054912",
            "Date of Publication": "27 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyeon-Gu Lee",
                "labs": [
                    "Search & NLP Laboratory, NAVER Corporation, Seongnam, Republic of Korea"
                ]
            },
            {
                "name": "Youngjin Jang",
                "labs": [
                    "Division of Computer Science and Engineering, Konkuk University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Harksoo Kim",
                "labs": [
                    "Division of Computer Science and Engineering, Konkuk University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generators",
                "Training",
                "Adaptation models",
                "Decoding",
                "Training data",
                "Data models",
                "Internet"
            ],
            "Author Keywords": [
                "Machine reading comprehension",
                "self-training",
                "pseudo-answer extractor",
                "pseudo-question generator"
            ]
        }
    },
    {
        "Title": "Enhancing the Dynamic Performance of Hybrid Photovoltaic-Battery DC Microgrid Through Piece-Wise Affine Model-Based Controller With Mode Transition Function",
        "Link": "https://ieeexplore.ieee.org/document/10711205/",
        "Abstract": "Solar energy utilization, in conjunction with battery systems, within stand-alone DC microgrid systems represents a significant trend. In such isolated network configurations, the voltage of the Direct Current (DC) bus experiences fluctuations: it increases when the islanded DC microgrid receives excess energy and decreases during periods of energy scarcity. Ensuring the appropriate operational mode for photovoltaic (PV) panels is crucial for maintaining the DC bus voltage within specified operational limits, guaranteeing high electrical quality, whether the power is supplied directly or converted to AC form. Furthermore, achieving balanced power sharing between the PV and the energy storage system enhances the efficiency of the energy storage workload. This study proposes a transition function to facilitate seamless switching of the PV panel’s operational mode between Maximum Power Point Tracking (MPPT) and voltage-controlled modes. This transition function is applied to the PV side converter, which adjusts the duty cycle value of both MPPT and droop mode outputs based on the microgrid’s energy adequacy condition, as determined by the DC bus voltage readings. Moreover, this study introduces a Duty Cycle Range Divider (DCRD) algorithm to derive the converter’s Piece-wise Affine (PWA) model. Subsequently, a linear quadratic regulator (LQR) controller, designed based on the PWA model, is employed alongside the transition function to enhance the DC microgrid’s dynamic performance. A similar LQR controller is applied to the battery-side converter with a battery State of Charge (SoC)-based droop control to balance the power-sharing. The proposed control strategy stabilizes the DC bus voltage and ensures a seamless response during transitions in the PV system’s operating mode. The efficacy of this strategy is validated through MATLAB Simulink simulations and laboratory-scale experiments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3476624",
            "Date of Publication": "09 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wakhyu Dwiono",
                "labs": [
                    "Doctoral Program of Electrical Engineering and Informatics, School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",
                    "Department of Electrical Engineering, Universitas Muhammadiyah Purwokerto, Purwokerto, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "University Center of Excellence—Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Bandung, Indonesia",
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Tri Desmana Rachmildha",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Arwindra Rizqiawan",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Microgrids",
                "Voltage control",
                "Control systems",
                "Batteries",
                "Energy storage",
                "Renewable energy sources",
                "Communication channels",
                "Artificial neural networks",
                "Switches",
                "Photovoltaic systems",
                "DC power transmission"
            ],
            "Author Keywords": [
                "DC microgrid",
                "MPPT-voltage controlled transition",
                "piecewise affine",
                "duty cycle range divider algorithm"
            ]
        }
    },
    {
        "Title": "Architecture and Decision-Making for Autonomous Tram Development",
        "Link": "https://ieeexplore.ieee.org/document/10177167/",
        "Abstract": "A decision-making system is an essential component of an autonomous tram. The decision-making system uses information on the surrounding area to recognize the traffic situation and determine appropriate actions to maintain safety and passenger comfort. However, guaranteeing reliable performance and safety remains challenging in all driving situations. The development of autonomous trams involves iterative engineering-related tasks. Therefore, proper architecture to facilitate the flexibility of engineering development is required. This paper proposes a modular architecture for a decision-making system for autonomous trams. The decision-making system can serve as a high-level controller for autonomous trams. The architecture consists of risk assessment and decision & planning modules. It also integrates several key functions, such as trajectory prediction, safety assessment, adaptive cruise control (ACC), collision avoidance (CA), and emergency braking system (EBS). In the decision and planning module, a finite-state machine is devised as part of the decision-making system. This module provides a speed reference for low-level speed controllers. In addition, the decision-making system architecture was implemented and its implementation was validated using a Carla simulator. Under a mixed-traffic scenario, simulation results showed that the decision-making system has a high percentage of mission successes. Out of 50 simulations in mixed-traffic scenarios, the tram reached its destination with an 80% success rate in which the success rates of ACC, CA, and EBS executions to avoid collisions were 96.94%, 100%, and 100%, respectively. In addition, the system works well in real-time to recognize the surrounding environment and determine actions. Although beyond the scope of the decision-making system, the simulation results also indicate that an improving performance of the tram’s low-level speed controller may provide more reliable performance of the decision-making system.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3293659",
            "Date of Publication": "10 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Khansa Salsabila Suhaimi",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Abdurraafi’ Syauqy",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Mohammad Salman Subki",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia",
                    "University Center of Excellence of Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Arief Syaichu Rohman",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Yulyan Wahyu Hadi",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Handoko Supeno",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Dhimas Bintang Kusumawardhana",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, Indonesia"
                ]
            },
            {
                "name": "Dewi Nala Husna",
                "labs": [
                    "PT Industri Kereta Api (INKA), Madiun, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decision making",
                "Planning",
                "Risk management",
                "Safety",
                "Road traffic",
                "Autonomous vehicles",
                "Trajectory",
                "Autonomous vehicles"
            ],
            "Author Keywords": [
                "Autonomous tram",
                "Carla simulator",
                "collision avoidance",
                "decision-making system"
            ]
        }
    },
    {
        "Title": "Collaborative Coverage Strategy Using Multiple UAVs-UGVs in CRN Mapping",
        "Link": "https://ieeexplore.ieee.org/document/10980321/",
        "Abstract": "Chemical, Radiological, and Nuclear (CRN) contamination poses a significant threat, potentially leading to mass casualties and long-term environmental repercussions. This paper presents a collaborative framework utilizing a heterogeneous coverage control approach to measure and generate an estimated density distribution map of a designated area. Multiple Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) are deployed strategically within partitioned regions, determined through weighted Voronoi tessellation. This method integrates both the robots’ internal parameters and environmental factors. The distinct operational domains of UAVs and UGVs facilitate region decomposition by accounting for variations in CRN dispersion, obstacle representation, and environmental conditions. The resulting cross-partitioned regions are systematically merged to enhance robot distribution efficiency. Each robot autonomously measures within its allocated region, updates contamination data, and generates a dispersion map. The proposed strategy enables an adaptive robot distribution, eliminating uncontaminated grids and improving mapping accuracy. Compared to existing methods, including homogeneous schemes, our approach reduces data variance in CRN-contaminated regions while maintaining mapping efficiency.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3565779",
            "Date of Publication": "30 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Agung Nugroho Jati",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, West Java, Indonesia",
                    "University Center of Excellence for Intelligent Sensing-IoT, Telkom University, Bandung, Jawa Barat, Indonesia"
                ]
            },
            {
                "name": "Bambang Riyanto Trilaksono",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, West Java, Indonesia",
                    "University Center of Excellent in Artificial Intelligence on Vision, NLP and Big Data Analytics (U-CoE AI-VLB), Institut Teknologi Bandung, Bandung, West Java, Indonesia"
                ]
            },
            {
                "name": "Egi Muhammad Idris Hidayat",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, West Java, Indonesia"
                ]
            },
            {
                "name": "Widyawardana Adiprawita",
                "labs": [
                    "School of Electrical Engineering and Informatics, Institut Teknologi Bandung, Bandung, West Java, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Robot sensing systems",
                "Sensors",
                "Contamination",
                "Robot kinematics",
                "Estimation",
                "Collaboration",
                "Pollution measurement",
                "Accuracy",
                "Autonomous aerial vehicles"
            ],
            "Author Keywords": [
                "Collaborative robots",
                "CRN mapping",
                "coverage control"
            ]
        }
    },
    {
        "Title": "A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10433480/",
        "Abstract": "Large Language Models (LLMs) recently demonstrated extraordinary capability in various natural language processing (NLP) tasks including language translation, text generation, question answering, etc. Moreover, LLMs are new and essential part of computerized language processing, having the ability to understand complex verbal patterns and generate coherent and appropriate replies in a given context. Though this success of LLMs has prompted a substantial increase in research contributions, rapid growth has made it difficult to understand the overall impact of these improvements. Since a plethora of research on LLMs have been appeared within a short time, it is quite impossible to track all of these and get an overview of the current state of research in this area. Consequently, the research community would benefit from a short but thorough review of the recent changes in this area. This article thoroughly overviews LLMs, including their history, architectures, transformers, resources, training methods, applications, impacts, challenges, etc. This paper begins by discussing the fundamental concepts of LLMs with its traditional pipeline of the LLMs training phase. Then the paper provides an overview of the existing works, the history of LLMs, their evolution over time, the architecture of transformers in LLMs, the different resources of LLMs, and the different training methods that have been used to train them. The paper also demonstrates the datasets utilized in the studies. After that, the paper discusses the wide range of applications of LLMs, including biomedical and healthcare, education, social, business, and agriculture. The study also illustrates how LLMs create an impact on society and shape the future of AI and how they can be used to solve real-world problems. Finally, the paper also explores open issues and challenges to deploy LLMs in real-world scenario. Our review paper aims to help practitioners, researchers, and experts thoroughly understand the evolution of LLMs, pre-trained architectures, applications, challenges, and future goals.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3365742",
            "Date of Publication": "13 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohaimenul Azam Khan Raiaan",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Saddam Hossain Mukta",
                "labs": [
                    "LUT School of Engineering Sciences, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland"
                ]
            },
            {
                "name": "Kaniz Fatema",
                "labs": [
                    "Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia"
                ]
            },
            {
                "name": "Nur Mohammad Fahad",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sadman Sakib",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Most Marufatul Jannat Mim",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Jubaer Ahmad",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Mohammed Eunus Ali",
                "labs": [
                    "Department of CSE, Bangladesh University of Engineering and Technology (BUET), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sami Azam",
                "labs": [
                    "Faculty of Science and Technology, Charles Darwin University, Casuarina, NT, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Artificial intelligence",
                "Transformers",
                "Training",
                "Taxonomy",
                "Task analysis",
                "Surveys",
                "Natural language processing",
                "Question answering (information retrieval)",
                "Information analysis",
                "Linguistics"
            ],
            "Author Keywords": [
                "Large language models (LLM)",
                "natural language processing (NLP)",
                "artificial intelligence",
                "transformer",
                "pre-trained models",
                "taxonomy",
                "application"
            ]
        }
    },
    {
        "Title": "Application of Machine Learning and Word Embeddings in the Classification of Cancer Diagnosis Using Patient Anamnesis",
        "Link": "https://ieeexplore.ieee.org/document/9108225/",
        "Abstract": "Currently, one of the main challenges for information systems in healthcare is focused on support for health professionals regarding disease classifications. This work presents an innovative method for a recommendation system for the diagnosis of breast cancer using patient medical histories. In this proposal, techniques of natural language processing (NLP) were implemented on real datasets: one comprised 160, 560 medical histories of anonymous patients from a hospital in Chile for the following categories: breast cancer, cysts and nodules, other cancer, breast cancer surgeries and other diagnoses; and the other dataset was obtained from the MIMIC III dataset. With the application of word-embedding techniques, such as word2vec's skip-gram and BERT, and machine learning techniques, a recommendation system as a tool to support the physician's decision-making was implemented. The obtained results demonstrate that using word embeddings can define a good-quality recommendation system. The results of 20 experiments with 5-fold cross-validation for anamnesis written in Spanish yielded an F1 of 0.980 ± 0.0014 on the classification of `cancer' versus `not cancer' and 0.986 ± 0.0014 for `breast cancer' versus `other cancer'. Similar results were obtained with the MIMIC III dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3000075",
            "Date of Publication": "04 June 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Andrés Alejandro Ramos Magna",
                "labs": [
                    "Escuela de Ingeniería en Informática, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Héctor Allende-Cid",
                "labs": [
                    "Escuela de Ingeniería en Informática, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Carla Taramasco",
                "labs": [
                    "Escuela de Ingeniería Civil en Informática, Universidad de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Carlos Becerra",
                "labs": [
                    "Escuela de Ingeniería Civil en Informática, Universidad de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Rosa L. Figueroa",
                "labs": [
                    "Departamento de Ingeniería Eléctrica, Universidad de Concepción, Concepción, Chile"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "History",
                "Medical diagnostic imaging",
                "Breast cancer",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "machine learning",
                "deep learning",
                "recommendation system",
                "anamnesis"
            ]
        }
    },
    {
        "Title": "A Survey on Deep Active Learning: Recent Advances and New Frontiers",
        "Link": "https://ieeexplore.ieee.org/document/10537213/",
        "Abstract": "Active learning seeks to achieve strong performance with fewer training samples. It does this by iteratively asking an oracle to label newly selected samples in a human-in-the-loop manner. This technique has gained increasing popularity due to its broad applicability, yet its survey papers, especially for deep active learning (DAL), remain scarce. Therefore, we conduct an advanced and comprehensive survey on DAL. We first introduce reviewed paper collection and filtering. Second, we formally define the DAL task and summarize the most influential baselines and widely used datasets. Third, we systematically provide a taxonomy of DAL methods from five perspectives, including annotation types, query strategies, deep model architectures, learning paradigms, and training processes, and objectively analyze their strengths and weaknesses. Then, we comprehensively summarize the main applications of DAL in natural language processing (NLP), computer vision (CV), data mining (DM), and so on. Finally, we discuss challenges and perspectives after a detailed analysis of current studies. This work aims to serve as a useful and quick guide for researchers in overcoming difficulties in DAL. We hope that this survey will spur further progress in this burgeoning field.",
        "Details": {
            "DOI": "10.1109/TNNLS.2024.3396463",
            "Date of Publication": "23 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Neural Networks and Learning Systems"
        },
        "issn_info": {
            "Print ISSN": "2162-237X",
            "Electronic ISSN": "2162-2388"
        },
        "authors_data": [
            {
                "name": "Dongyuan Li",
                "labs": [
                    "School of Information and Communication Engineering, Institute of Innovative Research, Tokyo Institute of Technology, Tokyo, Japan"
                ]
            },
            {
                "name": "Zhen Wang",
                "labs": [
                    "School of Information and Communication Engineering, Institute of Innovative Research, Tokyo Institute of Technology, Tokyo, Japan"
                ]
            },
            {
                "name": "Yankai Chen",
                "labs": [
                    "School of Computer Science and Engineering, The Chinese University of Hong Kong, shatin, Hong Kong"
                ]
            },
            {
                "name": "Renhe Jiang",
                "labs": [
                    "Center for Spatial Information Science, The University of Tokyo, Tokyo, Japan"
                ]
            },
            {
                "name": "Weiping Ding",
                "labs": [
                    "School of Information Science and Technology, Nantong University, Nantong, China"
                ]
            },
            {
                "name": "Manabu Okumura",
                "labs": [
                    "School of Information and Communication Engineering, Institute of Innovative Research, Tokyo Institute of Technology, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Training",
                "Surveys",
                "Annotations",
                "Taxonomy",
                "Electronic mail",
                "Deep learning"
            ],
            "Author Keywords": [
                "Active learning",
                "adaptive sampling",
                "computer vision (CV)",
                "deep learning",
                "natural language processing (NLP)",
                "sequential optimal design",
                "uncertainty quantification"
            ]
        }
    },
    {
        "Title": "An Intelligent Disease Prediction and Drug Recommendation Prototype by Using Multiple Approaches of Machine Learning Algorithms",
        "Link": "https://ieeexplore.ieee.org/document/10247046/",
        "Abstract": "Large blocks of data must be analyzed and explored by utilizing the data mining procedures in order to uncover significant patterns and trends. Medical databases are one area where the data mining procedures can be utilized. Many people all over the world are struggling with their health and medical diagnoses. Massive amounts of data are produced by hospital information systems (HIS), yet it might be difficult to extract knowledge from diagnosis case data. By just giving the symptoms they are experiencing, patients can quickly learn about the sickness they are experiencing and the medication that can assist, treat it using the approaches utilized in this paper. In this paper, we give drug recommendations relied on ratings and conditions to customers. Four distinct prototypes are utilized to predict the diseases. The Vader tool and sentiment analysis relied on NLP are utilized to analyze the reviews. And finally, probabilistic and weighted average methodologies are utilized to recommend the medications. Each model and strategy utilized in this paper is described in detail. The experimental findings presented in this work can be utilized in future studies and for a variety of different medicinal applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3314332",
            "Date of Publication": "11 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Suvendu Kumar Nayak",
                "labs": [
                    "Department of Computer Science and Engineering, Centurion University of Technology and Management, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Mamata Garanayak",
                "labs": [
                    "Department of Computer Science, Kalinga Institute of Social Sciences, Deemed to be University, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Sangram Keshari Swain",
                "labs": [
                    "Department of Computer Science and Engineering, Centurion University of Technology and Management, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Sandeep Kumar Panda",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Faculty of Science and Technology (IcfaiTech), ICFAI Foundation for Higher Education, Hyderabad, Telangana, India"
                ]
            },
            {
                "name": "Deepthi Godavarthi",
                "labs": [
                    "School of Computer Science & Engineering (SCOPE), VIT-AP University, Amaravati, Andhra Pradesh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Medical diagnostic imaging",
                "Recommender systems",
                "Medical services",
                "Diseases",
                "Drugs",
                "Machine learning"
            ],
            "Author Keywords": [
                "Data mining",
                "drug recommendation system",
                "NLP",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "A Systematic Review of Chatbots: Classification, Development, and Their Impact on Tourism",
        "Link": "https://ieeexplore.ieee.org/document/10542991/",
        "Abstract": "Recently, we have observed a noticeable evolution and growing use and incorporation of chatbots on websites, mobile and social networking apps. A chatbot is a computer program that exhibits a capacity to converse quite naturally with users in a way that resembles a human dialogue. Examples of chatbots can be found in several areas, including education, commerce, and tourism. The use of Artificial Intelligence (AI) and its sub-fields, such as Machine Learning, Deep Learning, and Natural Language Processing (NLP), is increasing across all business sectors. One of the most advanced applications of this technology is the chatbot, which is particularly beneficial due to the quick response times and its simplicity. Nevertheless, although studies on chatbots exist in tourism, academic research covering their adoption, technological evolution, and impact on this sector is still relatively sparse. Therefore, this study aims to provide a comprehensive overview of chatbots and their effect on tourism. First, we provide a new classification of chatbots based on specific criteria. Second, we explore the conceptual architecture of chatbots and their key components. Third, this study aims to assess and contrast the main existing tools for developing chatbots, classifying them and highlighting their key advantages and disadvantages. Fourth, this study aims to examine the integration of chatbots in the tourism sector by identifying their key applications in the industry over the past decade. Additionally, it seeks to analyze the impact of chatbots on the various functionalities outlined in the 6A framework for tourism. To achieve this, a thorough search will be conducted using five prominent databases - Scopus, ACM, IEEE Xplore, Springer Link, and Web of Science - covering the period from 2013 to 2023. For this study, 1155 academic publications were reviewed after applying a systematic review protocol including purpose, research questions, keywords, digital libraries, search strings, and inclusion and exclusion criteria. Only 31 were identified to be primary studies.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3408108",
            "Date of Publication": "31 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lamya Benaddi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Charaf Ouaddi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Abdeslam Jakimi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Brahim Ouchao",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Reviews",
                "Artificial intelligence",
                "Systematics",
                "Oral communication",
                "Virtual assistants",
                "Task analysis",
                "Natural language processing",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Chatbot",
                "conversational agent",
                "tourism",
                "history of chatbots",
                "classification",
                "architecture",
                "artificial intelligence",
                "NLP"
            ]
        }
    },
    {
        "Title": "Boosting Arabic Named-Entity Recognition With Multi-Attention Layer",
        "Link": "https://ieeexplore.ieee.org/document/8685084/",
        "Abstract": "Sequence labeling models with recurrent neural network variants, such as long short-term memory (LSTM) and gated recurrent unit (GRU), show promising performance on several natural language processing (NLP) problems, including named-entity recognition (NER). Most existing models utilize word embeddings for capturing similarities between words. However, they lag when handling previously unobserved or infrequent words. Moreover, the attention mechanism has been used to improve sequence labeling tasks. In this paper, we propose an efficient multi-attention layer system for the Arabic named-entity recognition (ANER) task. In addition to word-level embeddings, we adopt character-level embeddings and combine them via an embedding-level attention mechanism. The output is fed into an encoder unit with bidirectional-LSTM, followed by another self-attention layer that is used to boost the system performance. Our model achieves approximately matched F1 score of 91% on the “ANERCorpus.” The overall experimental results demonstrate that our method is superior to other systems. Our approach using multi-layer attention mechanism yields a new state-of-the-art result for the ANER.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2909641",
            "Date of Publication": "11 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Nadher Abdo Ali",
                "labs": [
                    "School of Information Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Guanzheng Tan",
                "labs": [
                    "School of Information Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Aamir Hussain",
                "labs": [
                    "Department of Computer Science, Muhammad Nawaz Shareef University of Agriculture Multan, Multan, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Natural language processing",
                "Labeling",
                "Boosting",
                "Recurrent neural networks",
                "Logic gates"
            ],
            "Author Keywords": [
                "ANER",
                "self-attention",
                "LSTM",
                "NLP",
                "word embedding",
                "character embedding"
            ]
        }
    },
    {
        "Title": "Banner: A Cost-Sensitive Contextualized Model for Bangla Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/9044317/",
        "Abstract": "Named Entity Recognition (NER) is a task in Natural Language Processing (NLP) that aims to classify words into a predetermined list of Named Entities (NE). Many architectures have produced good results on high resourced languages like English and Chinese. However, the NER task has not yet achieved much progress for Bangla, a low resource Language. In this paper, we perform the NER task on Bangla Language using Word2Vec and contextual Bidirectional Encoder Representations from Transformers (BERT) embeddings. We propose multiple BERT-based deep learning models that use the contextualized embedding from BERT as inputs and a simple statistical approach for class weight cost sensitive learning. The modified cost-sensitive loss function was used to address the class imbalance of the data. In our modified cost-sensitive loss function, we penalize the dominant classes by taking the ratio concerning the maximum sample in a class instead of the whole dataset. This penalty is made so that the learner learns slowly for the dominant class. In addition, we experiment by adding a Conditional Random Field (CRF) layer and incorporating Focal Loss to the training process. We found the best F1 Macro score to be 65.96%, F1 Micro score of 90.64%, and F1 Message Understanding Coreference (MUC) score of 72.04%, which were calculated at Named Entity level. Our experimental results demonstrate that one of the proposed models, which jointly optimizes for the CRF loss and class weighted cost-sensitive loss according to our proposed statistical approach, achieve an improvement of over 8% F1 MUC score on a recently introduced Bangla NER dataset when compared to previously published work.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2982427",
            "Date of Publication": "23 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Imranul Ashrafi",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Muntasir Mohammad",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Arani Shawkat Mauree",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Galib Md. Azraf Nijhum",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Redwanul Karim",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Nabeel Mohammed",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sifat Momen",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Task analysis",
                "Hidden Markov models",
                "Context modeling",
                "Computational modeling",
                "Computer architecture",
                "Vocabulary"
            ],
            "Author Keywords": [
                "Bangla NER",
                "Bengali NER",
                "BERT",
                "CRF",
                "NLP",
                "focal loss",
                "cost-sensitive learning",
                "contextual embeddings"
            ]
        }
    },
    {
        "Title": "Leveraging DistilBERT for Summarizing Arabic Text: An Extractive Dual-Stage Approach",
        "Link": "https://ieeexplore.ieee.org/document/9539169/",
        "Abstract": "Towards tackling the phenomenon of textual information overload that is exponentially pumping with redundancy over the Internet, this paper investigates a solution depending on the Automatic Text Summarization (ATS) method. The idea of ATS is to assist, e.g., online readers, in getting a simplified version of texts for preserving their time/effort required to skim a given large body of text. However, ATS is deemed as one of the most complex NLP applications, particularly for the Arabic language that has not been intelligently developed like the other Indo-European languages. Thus, we present an extractive-based summarizer (ArDBertSum) for text written in Arabic, relying on the DistilBERT model. Besides, we propose a domain-specific sentence-clauses segmentater (SCSAR) to support our ArDBertSum in further shortening long/complex sentences. The results of our experiments illustrate that our ArDBertSum yields the best performance, compared with non-heuristic Arabic summarizers, in producing an acceptable quality of candidate summaries. These experiments have been conducted on EASC-dataset (along with our proposed dataset) to report on (1) a statistical evaluation utilizing ROUGE metrics and (2) a specific human-based evaluation. The human evaluation results revealed promising perceptions; however, further works are needed to ameliorate the coherence and punctuation of the automatic summaries.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3113256",
            "Date of Publication": "15 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdullah Alshanqiti",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Abdallah Namoun",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Aeshah Alsughayyir",
                "labs": [
                    "College of Computer Science and Engineering, Taibah University, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Aisha Mousa Mashraqi",
                "labs": [
                    "College of Computer Science, Najran University (NU), Najran, Saudi Arabia"
                ]
            },
            {
                "name": "Abdul Rehman Gilal",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Sami Saad Albouq",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Learning (artificial intelligence)",
                "Internet",
                "Bit error rate",
                "Redundancy"
            ],
            "Author Keywords": [
                "NLP",
                "natural language understanding",
                "automatic text summarization",
                "machine learning",
                "transfer learning",
                "pre-trained model",
                "BERT",
                "sentence segmentation",
                "clause-based segmentation",
                "sentence reduction"
            ]
        }
    },
    {
        "Title": "Enhancing User Experience on Q&A Platforms: Measuring Text Similarity Based on Hybrid CNN-LSTM Model for Efficient Duplicate Question Detection",
        "Link": "https://ieeexplore.ieee.org/document/10414059/",
        "Abstract": "This research introduces an innovative approach for identifying duplicate questions within the Stack Overflow community, a challenging task in NLP. Leveraging deep learning techniques, our proposed methodology combines Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks to capture both local and long-term dependencies in textual data. We employ word embeddings, specifically Google’s Word2Vec and GloVe, to enhance text representation. Extensive experiments on the Stack Overflow dataset demonstrate the effectiveness of our approach, achieving an impressive accuracy of 87.09% and a recall rate of 87.%. The integration of CNN and LSTM models significantly streamlines preprocessing, making it a valuable tool for detecting duplicate questions. Future directions include extending the model to multiple languages and exploring alternative word embedding techniques. Our approach presents promising applications beyond Stack Overflow, offering solutions for identifying similar questions on various QA platforms.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3358422",
            "Date of Publication": "25 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Faseeh",
                "labs": [
                    "Department of Electronics Engineering, Jeju National University, Jeju-si, Republic of Korea"
                ]
            },
            {
                "name": "Murad Ali Khan",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Republic of Korea"
                ]
            },
            {
                "name": "Naeem Iqbal",
                "labs": [
                    "School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K."
                ]
            },
            {
                "name": "Faiza Qayyum",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Republic of Korea"
                ]
            },
            {
                "name": "Asif Mehmood",
                "labs": [
                    "Department of Biomedical Engineering, College of IT Convergence, Gachon University, Sujeong-gu, Seongnam-si, Republic of Korea"
                ]
            },
            {
                "name": "Jungsuk Kim",
                "labs": [
                    "Department of Biomedical Engineering, College of IT Convergence, Gachon University, Sujeong-gu, Seongnam-si, Republic of Korea",
                    "Cellico Research and Development Laboratory, Sungnam-si, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Semantics",
                "Brain modeling",
                "Task analysis",
                "Feature extraction",
                "Convolutional neural networks",
                "Syntactics",
                "Natural language processing",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "Duplicate question identification",
                "stack overflow",
                "deep learning (DL)",
                "word embeddings",
                "natural language processing (NLP)",
                "question-and-answer (QA) platforms"
            ]
        }
    },
    {
        "Title": "Harnessing the Power of LLMs for Service Quality Assessment From User-Generated Content",
        "Link": "https://ieeexplore.ieee.org/document/10599371/",
        "Abstract": "Adopting Large Language Models (LLMs) creates opportunities for organizations to increase efficiency, particularly in sentiment analysis and information extraction tasks. This study explores the efficiency of LLMs in real-world applications, focusing on sentiment analysis and service quality dimension extraction from user-generated content (UGC). For this purpose, we compare the performance of two LLMs (ChatGPT 3.5 and Claude 3) and three traditional NLP methods using two datasets of customer reviews (one in English and one in Persian). The results indicate that LLMs can achieve notable accuracy in information extraction (76% accuracy for ChatGPT and 68% for Claude 3) and sentiment analysis (substantial agreement with human raters for ChatGPT and moderate agreement with human raters for Claude 3), demonstrating an improvement compared to other AI models. However, challenges persist, including discrepancies between model predictions and human judgments and limitations in extracting specific dimensions from unstructured text. Whereas LLMs can streamline the SQ assessment process, human supervision remains essential to ensure reliability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3429290",
            "Date of Publication": "16 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Taha Falatouri",
                "labs": [
                    "Faculty of Management and Economics, Tomas Bata University in Zlín, Zlín, Czech Republic",
                    "Department for Logistics, University of Applied Sciences Upper Austria, Steyr, Austria",
                    "Josef Ressel-Centre for Predictive Value Network Intelligence, Steyr, Austria"
                ]
            },
            {
                "name": "Denisa Hrušecká",
                "labs": [
                    "Faculty of Management and Economics, Tomas Bata University in Zlín, Zlín, Czech Republic"
                ]
            },
            {
                "name": "Thomas Fischer",
                "labs": [
                    "Department for Logistics, University of Applied Sciences Upper Austria, Steyr, Austria",
                    "Josef Ressel-Centre for Predictive Value Network Intelligence, Steyr, Austria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Task analysis",
                "Analytical models",
                "Sentiment analysis",
                "Companies",
                "Chatbots",
                "Large language models",
                "Quality assessment"
            ],
            "Author Keywords": [
                "ChatGPT",
                "cloud 3",
                "large language models (LLMs)",
                "natural language processing (NLP)",
                "sentiment analysis",
                "service quality assessment"
            ]
        }
    },
    {
        "Title": "A Heuristic Grafting Strategy for Manufacturing Knowledge Graph Extending and Completion Based on Nature Language Processing: KnowTree",
        "Link": "https://ieeexplore.ieee.org/document/9464315/",
        "Abstract": "Applied to search, question answering, and semantic web of close-or-open domain, knowledge graph (KG) is known for its incompleteness subject to the rapid knowledge growing pace. Inspired by the agricultural grafting technology to fruit variety, this paper proposes a heuristic knowledge grafting strategy (HGS) for manufacturing knowledge graph (MKG) named KnowTree extending and completion with natural language processing (NLP) mining engineering cases document. Based on similarity analysis, firstly the grafting related definitions and mechanisms (completeness, relatedness, connectivity and reutilization) are defined. Then, focused on the four mechanisms, HGS takes a pair same engineering documents as input. KnowWords is built as a collection of KnowScion, and each scion is mined from engineering documents based on the SAO structure network, whose importance is evaluated by SAORank counting the in-out degree of centrality. On another hand, the KnowRoot system is designed based on the extended P & S ontology model to characterize the structure of abstract document into four sub-space of knowledge: know-what (problem), know-why (context), know-how (solution) and know-with (result), where a pre-trained language representation model K-BERT is used to classify the KnowScion candidates into the designed KnowRoot system with a fine-tuning classification task. In the knowledge grafting process, the connection unit is constructed based on the extracted domain knowledge triples of the K-BERT model, where the head element of a triple is from the KnowScion candidate set KnowWords satisfying the threshold value, the tail element is from the domain MKG to be extended, and a connection factor is used to evaluate the relationship of union combination. To the goal of knowledge reuse, the path based reasoning rules are designed for KnowTree reutilization. Finally, take the latest engineering case abstract (ECA) in whitegoods domain as resources, a case study is conducted to validate the proposed HGS strategy.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3092019",
            "Date of Publication": "24 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Longlong He",
                "labs": [
                    "State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Bo Dong",
                "labs": [
                    "Department of Computer Science, The University of Texas at Dallas, Richardson, TX, USA"
                ]
            },
            {
                "name": "Pingyu Jiang",
                "labs": [
                    "State Key Laboratory for Manufacturing Systems Engineering, Xi’an Jiaotong University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge engineering",
                "Manufacturing",
                "Ontologies",
                "Cognition",
                "Semantics",
                "Data mining",
                "Biomimetics"
            ],
            "Author Keywords": [
                "Knowledge graph extending and completion",
                "heuristic grafting strategy (HGS)",
                "NLP"
            ]
        }
    },
    {
        "Title": "Transformers: A Security Perspective",
        "Link": "https://ieeexplore.ieee.org/document/10771766/",
        "Abstract": "The Transformers architecture has recently emerged as a revolutionary paradigm in the field of deep learning, particularly excelling in Natural Language Processing (NLP) and Computer Vision (CV) applications. Despite its success, the security implications of Transformers have not been comprehensively explored, encompassing a broad spectrum of both hardware and software vulnerabilities. This paper aims to address this critical gap by conducting an extensive exploration of security challenges confronting Transformers from both software and hardware perspectives. While software-related concerns like adversarial attacks, private inference, and watermarking have been studied, the paper sheds light on previously underexplored hardware vulnerabilities such as trojans and side-channel attacks. By unraveling the intricacies of these hardware threats, the study aims to contribute to a comprehensive understanding of Transformer security. It presents an in-depth analysis of recent advancements in the security of Transformers. Additionally, it outlines existing challenges and forecasts future research trends, offering insights for researchers and practitioners aiming for the secure and resilient design and deployment of Transformers. The survey categorizes different attacks and defenses related to Transformers, helping researchers identify gaps and opportunities in this area. Furthermore, it defines a roadmap for a unified security framework, serving as a foundational starting point for developers seeking to implement robust security measures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3509372",
            "Date of Publication": "29 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Banafsheh Saber Latibari",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Najmeh Nazari",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Muhtasim Alam Chowdhury",
                "labs": [
                    "Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA"
                ]
            },
            {
                "name": "Kevin Immanuel Gubbi",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Chongzhou Fang",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Sujan Ghimire",
                "labs": [
                    "Department of System and Industrial Engineering, The University of Arizona, Tucson, AZ, USA"
                ]
            },
            {
                "name": "Elahe Hosseini",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Hossein Sayadi",
                "labs": [
                    "California State University at Long Beach, Long Beach, CA, USA"
                ]
            },
            {
                "name": "Houman Homayoun",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            },
            {
                "name": "Soheil Salehi",
                "labs": [
                    "Department of Electrical and Computer Engineering, The University of Arizona, Tucson, AZ, USA"
                ]
            },
            {
                "name": "Avesta Sasan",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at Davis, Davis, CA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Security",
                "Computer architecture",
                "Computational modeling",
                "Computer vision",
                "Software",
                "Analytical models",
                "Hardware security",
                "Deep learning",
                "Attention mechanisms"
            ],
            "Author Keywords": [
                "Deep learning security",
                "hardware security",
                "NLP",
                "transformers",
                "vision"
            ]
        }
    },
    {
        "Title": "Analyzing Trends and Patterns Across the Educational Technology Communities Using Fontana Framework",
        "Link": "https://ieeexplore.ieee.org/document/9745089/",
        "Abstract": "Nowadays, the use of technology in continuously increasing, making a significant impact in almost every area, including education. New areas have gained much popularity in the last years in educational technology (EdTech), such as Massive Open Online Courses (MOOCs) or computer-supported collaborative learning. In addition, research and interest in this area have also been growing over the years. The quantity of research and scientific publications in EdTech is constantly increasing, and trying to analyze and extract information from a set of research papers is often a very time-consuming task. To make this process easier and solve these limitations, we present Fontana, a framework that can quickly perform trend and social network analysis using any corpus of documents and its metadata. Specifically, the framework can: 1) Discover the latest trends given any corpus of documents, using Natural Language Processing (NLP) analysis and keywords (bibliometric approach); 2) Discover the evolution of the trends previously identified over the years; 3) Discover the primary authors and papers, along with hidden relationships between existing communities. To test its functionality, we evaluated the framework using a corpus of papers from the EdTech research field. We also followed an open science methodology making the entire framework available in Open Science Framework (OSF) easy to access and use. The case study successfully proved the capabilities of the framework, revealing some of the most frequent topics in the area, such as “EDM,” “learning analytics,” or “collaborative learning.” We expect our work to help identifying trends and patterns in the EdTech area, using natural language processing and social network analysis to objectively process large amounts of research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3163253",
            "Date of Publication": "30 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Manuel J. Gomez",
                "labs": [
                    "Faculty of Computer Science, University of Murcia, Murcia, Spain"
                ]
            },
            {
                "name": "José A. Ruipérez-Valiente",
                "labs": [
                    "Faculty of Computer Science, University of Murcia, Murcia, Spain"
                ]
            },
            {
                "name": "Félix J. García Clemente",
                "labs": [
                    "Faculty of Computer Science, University of Murcia, Murcia, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bibliometrics",
                "Market research",
                "Task analysis",
                "Metadata",
                "Social networking (online)",
                "Databases",
                "Network analyzers"
            ],
            "Author Keywords": [
                "EdTech",
                "data mining",
                "bibliometrics",
                "NLP",
                "network analysis",
                "topic modeling"
            ]
        }
    },
    {
        "Title": "Topic Modeling and Sentiment Analysis of Arabic News Headlines for a Societal Well-Being Scoring and Monitoring System: Moroccan Use Case",
        "Link": "https://ieeexplore.ieee.org/document/10872924/",
        "Abstract": "In today’s information-rich society, the rapid dissemination of news content across digital platforms plays a pivotal role in shaping public perception and discourse, yet they remain underutilized for sentiment analysis compared to other social media data. This study addresses this gap by using advanced Natural Language Processing (NLP) techniques to analyze Modern Standard Arabic (MSA) news content, categorizing headlines into themes like politics, business, education, weather, and sport, and applying sentiment analysis to classify them as positive or negative. These models form the foundation of our Societal Wellbeing Scoring and Monitoring System, which quantifies and monitors societal sentiment across key Quality of Life (QoL) aspects in Moroccan news. Our approach utilizes an LDA topic modeling approach in the preprocessing stage on the Moroccan News Arabic Dataset (MNAD) to enhance the quality of selected data sample before building classification models. Following this, we compare deep learning models with AraBERT and asafaya/bert-base-arabic (ASAFAYA) word embeddings to traditional machine learning algorithms using term frequency-inverse document frequency (TF-IDF). Notably, the GRU model with ASAFAYA embeddings excelled in the topic modeling task, achieving a 94.74% accuracy. We further analyzed public sentiment using data from Hibapress, a Moroccan news website, by scraping titles, likes, and dislikes to assign positive and negative sentiment scores. Leveraging a Bi-GRU model with ASAFAYA embeddings, we achieved an accuracy of 90.23%. We propose the Societal Wellbeing Scoring and Monitoring System, an aspect-based sentiment analysis framework designed to assign a wellbeing score over a specified sample or time period. Our findings highlight the effectiveness of combining topic modeling with deep learning-driven sentiment analysis to derive actionable insights from Arabic news, thereby enhancing the understanding of societal dynamics in Morocco.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3538888",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ayoub Jannani",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Soukaina Bouhsissin",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Nawal Sael",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Faouzia Benabbou",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Accuracy",
                "Data models",
                "Support vector machines",
                "Social networking (online)",
                "Monitoring",
                "Media",
                "Real-time systems",
                "Text categorization"
            ],
            "Author Keywords": [
                "Text classification",
                "sentiment analysis",
                "news headlines",
                "modern standard Arabic",
                "deep learning",
                "NLP",
                "GRU",
                "Bi-GRU",
                "ASAFAYA",
                "AraBert",
                "wellbeing",
                "quality of life"
            ]
        }
    },
    {
        "Title": "Driving the Technology Value Stream by Analyzing App Reviews",
        "Link": "https://ieeexplore.ieee.org/document/10109144/",
        "Abstract": "An emerging feature of mobile application software is the need to quickly produce new versions to solve problems that emerged in previous versions. This helps adapt to changing user needs and preferences. In a continuous software development process, the user reviews collected by the apps themselves can play a crucial role to detect which components need to be reworked. This paper proposes a novel framework that enables software companies to drive their technology value stream based on the feedback (or reviews) provided by the end-users of an application. The proposed end-to-end framework exploits different Natural Language Processing (NLP) tasks to best understand the needs and goals of the end users. We also provide a thorough and in-depth analysis of the framework, the performance of each of the modules, and the overall contribution in driving the technology value stream. An analysis of reviews with sixteen popular Android Play Store applications from various genres over a long period of time provides encouraging evidence of the effectiveness of the proposed approach.",
        "Details": {
            "DOI": "10.1109/TSE.2023.3270708",
            "Date of Publication": "26 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Software Engineering"
        },
        "issn_info": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "authors_data": [
            {
                "name": "Souvick Das",
                "labs": [
                    "DAIS Department, Ca’ Foscari University, Venice, Italy"
                ]
            },
            {
                "name": "Novarun Deb",
                "labs": [
                    "Indian Institute of Information Technology (IIIT), Vadodara, Gujarat, India"
                ]
            },
            {
                "name": "Nabendu Chaki",
                "labs": [
                    "Department of Computer Science and Engineering, University of Calcutta, Kolkata, West Bengal, India"
                ]
            },
            {
                "name": "Agostino Cortesi",
                "labs": [
                    "DAIS Department, Ca’ Foscari University, Venice, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Task analysis",
                "Training",
                "Computer bugs",
                "Visualization",
                "Text categorization"
            ],
            "Author Keywords": [
                "Continuous software development",
                "technology value stream",
                "NLP",
                "app reviews"
            ]
        }
    },
    {
        "Title": "Breaking Away From AI: The Ontological and Ethical Evolution of Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/10933972/",
        "Abstract": "Machine Learning (ML) has historically been associated with Artificial Intelligence (AI) but has developed into an independent discipline. This paper argues for the ontological independence of ML, driven by its unique methodologies, applications, and ethical considerations. A bibliometric analysis reveals that ML research output (494,572 publications from 2017–2023) surpasses AI (283,762 publications) by 74%, reflecting its rapid growth and specialization. Unlike AI’s pursuit of general intelligence and symbolic reasoning, ML focuses on data-driven performance optimization, with impactful applications in computer vision, natural language processing (NLP), and autonomous systems. The study highlights ethical challenges—such as addressing algorithmic bias (50 occurrences), fairness (2,778 publications), and environmental sustainability (283 related works)—which emphasize the need for dedicated ethical frameworks tailored to ML. These findings propose a conceptual and practical separation between ML and AI to enable targeted research, interdisciplinary collaboration, and solutions to challenges like explainability, transparency, and sustainability. The paper underscores the importance of recognizing ML’s independence in advancing both fields.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3553032",
            "Date of Publication": "19 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Enrico Barbierato",
                "labs": [
                    "Faculty of Mathematical, Physical and Natural Sciences, Catholic University of the Sacred Heart, Brescia, Italy"
                ]
            },
            {
                "name": "Alice Gatti",
                "labs": [
                    "Faculty of Mathematical, Physical and Natural Sciences, Catholic University of the Sacred Heart, Brescia, Italy"
                ]
            },
            {
                "name": "Alessandro Incremona",
                "labs": [
                    "Faculty of Mathematical, Physical and Natural Sciences, Catholic University of the Sacred Heart, Brescia, Italy"
                ]
            },
            {
                "name": "Andrea Pozzi",
                "labs": [
                    "Faculty of Mathematical, Physical and Natural Sciences, Catholic University of the Sacred Heart, Brescia, Italy"
                ]
            },
            {
                "name": "Daniele Toti",
                "labs": [
                    "Faculty of Mathematical, Physical and Natural Sciences, Catholic University of the Sacred Heart, Brescia, Italy",
                    "Department of Sciences, Roma Tre University, Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Ethics",
                "Machine learning",
                "Natural language processing",
                "Physics",
                "Cognition",
                "Bibliometrics",
                "Astronomy",
                "Problem-solving",
                "Pattern recognition"
            ],
            "Author Keywords": [
                "Machine learning (ML)",
                "artificial intelligence (AI)",
                "deep learning (DL)",
                "fairness",
                "bias",
                "epistemology",
                "ethical artificial intelligence",
                "explainability",
                "bibliometric analysis",
                "sustainability",
                "natural language processing (NLP)",
                "computer vision"
            ]
        }
    },
    {
        "Title": "Enhancing Cybersecurity With P-Code Analysis and XGBoost: A Novel Approach for Malicious VBA Macro Detection in Office Documents",
        "Link": "https://ieeexplore.ieee.org/document/10534288/",
        "Abstract": "In the evolving landscape of cybersecurity, the prevalence of malicious Visual Basic for Applications (VBA) macros embedded in Office documents presents a formidable challenge. These macros, while integral to automation, have become potent vehicles for cyber-attacks, necessitating advanced detection techniques. This study introduces a comprehensive framework employing P-Code Analysis and XGBoost, a leading-edge machine learning algorithm, to address this issue. The proposed solution synergizes static analysis of VBA source code with dynamic P-Code structural analysis, enhanced by Natural Language Processing (NLP) techniques for effective feature extraction. By integrating these methodologies, our model adeptly distinguishes between benign and malicious macros, achieving an unprecedented detection accuracy of 98.70% and an F1-score of 98.81% in rigorous testing environments. The core contribution of this research lies in its innovative approach to malicious macro detection, offering a robust framework that significantly improves upon existing methods. Additionally, the utilization of XGBoost for machine learning analysis introduces a novel application in cybersecurity defenses against macro-based threats. The results underscore the efficacy of combining P-Code analysis with machine learning for cybersecurity, marking a significant stride in the detection of sophisticated cyber threats. This study not only advances the domain of cybersecurity but also lays the groundwork for future research, advocating for the exploration of further optimizations and the adaptation of our model to combat evolving attack vectors. Recommended terms: Cybersecurity, Malicious VBA Macro Detection, P-Code Analysis, XGBoost, Machine Learning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3402956",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Candra Ahmadi",
                "labs": [
                    "Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan"
                ]
            },
            {
                "name": "Jiann-Liang Chen",
                "labs": [
                    "Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan"
                ]
            },
            {
                "name": "Yi-Cheng Lai",
                "labs": [
                    "Department of Electrical Engineering, National Taiwan University of Science and Technology, Taipei, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer security",
                "Codes",
                "XML",
                "Natural language processing",
                "Feature extraction",
                "Vectors",
                "Static analysis"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "malicious code detection",
                "natural language processing (NLP)",
                "office documents security",
                "P-code analysis",
                "visual basic for applications (VBA)",
                "XGBoost algorithm"
            ]
        }
    },
    {
        "Title": "Person Entity Attribute Extraction Based on Siamese Network",
        "Link": "https://ieeexplore.ieee.org/document/8716664/",
        "Abstract": "Entity attribute extraction, which converts chaotic text data to structured knowledge, plays an important role in natural language processing (NLP). Many previous studies proved that the representation of text has a significant impact on the results of attribute extraction. In this paper, we propose a novel model to obtain the discriminative representation of sentences by applying the Siamese architecture. Specifically, we simultaneously input two variable-length sentences in the training stage of our model, namely, the main sentence and its similar or dissimilar partner. This scheme of pair is beneficial for entity attribute extraction. First, the entity attribute extraction community suffers the insufficient but expensive labeled data, the two input sets produce much more samples for the representation learning and can be treated as a useful data augmentation method. More importantly, the co-learning by the Siamese architecture achieves more interesting embedding than the separate way, since the informative relation between the focused sentence and its partner help the representation learning to explore more essential semantics and keep stable to the variation of wording and syntax of a sentence. The experiments on the Wikipedia data show that our model takes advantage of the Siamese architecture for sentence embedding and achieves significant improvements on attribute extraction as compared with baselines. To the best of our knowledge, we are the first to introduce the Siamese network into the person entity attribute extraction, which we proved to achieve the state of the art.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2917302",
            "Date of Publication": "16 May 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yangchen Huang",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Aiping Li",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Bin Zhou",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Jiuming Huang",
                "labs": [
                    "Hunan Xingyunshuzi Intelligent Data Technology Co., Ltd, Changsha, China"
                ]
            },
            {
                "name": "Long Lan",
                "labs": [
                    "State Key Laboratory of High Performance Computing, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Xiaoyao Yin",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Yan Jia",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Feature extraction",
                "Task analysis",
                "Training",
                "Semantics",
                "Natural language processing",
                "Data models"
            ],
            "Author Keywords": [
                "Attribute extraction",
                "natural language processing (NLP)",
                "long short-term memory (LSTM) network",
                "Siamese network"
            ]
        }
    },
    {
        "Title": "Enhanced Transformer-BLSTM Model for Classifying Sentiment of User Comments on Movies and Books",
        "Link": "https://ieeexplore.ieee.org/document/10562280/",
        "Abstract": "Classifying the sentiment of user comments on a website is a crucial task within Natural Language Processing (NLP). Conducting sentiment analysis can aid businesses in gaining a more profound comprehension and examination of users’ emotional inclinations towards products or services. This study introduces a sentiment classification model that combines the Transformer and BLSTM architectures to analyze the sentiment of user comments on movie and book websites. By incorporating the strengths of both Transformer and BLSTM, the proposed model mitigates the issue of vanishing gradient by scrutinizing inputs within a long-term context using BLSTM. It employs the multi-head attention mechanism of the Transformer to extract features and capture significant semantic details within the comments. Furthermore, the joint model combines the TF-IDF weights with the vector space, which improves the embedding process. The proposed model’s effectiveness was evaluated by categorizing the sentiment of user comments on publicly available datasets containing more than 20,000 movie and book comments. The results indicate that the proposed model is superior to LSTM and CNN in sentiment classification tasks. Moreover, the proposed approach has demonstrated significant improvements, particularly in the training set, achieving an accuracy of 93.81%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3416755",
            "Date of Publication": "19 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yun Lin",
                "labs": [
                    "School of Information Science and Technology, Tan Kah Kee College, Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Tundong Liu",
                "labs": [
                    "Pen-Tung Sah Institute of Micro-Nano Science and Technology, Xiamen University, Xiamen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Feature extraction",
                "Task analysis",
                "Analytical models",
                "Accuracy",
                "Computational modeling",
                "Training",
                "Sentiment analysis",
                "Long short term memory",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "NLP",
                "sentiment analysis",
                "transformer",
                "BLSTM",
                "TF-IDF"
            ]
        }
    },
    {
        "Title": "UEF-HOCUrdu: Unified Embeddings Ensemble Framework for Hate and Offensive Text Classification in Urdu",
        "Link": "https://ieeexplore.ieee.org/document/10849516/",
        "Abstract": "Hate speech and other forms of hostile communication on social media have several implications such as; fostering violence, promoting social divide, and negative psychological effects. Since such toxic language is becoming more and more common, it is imperative to have a proper way of identifying it, especially in low resource language like Urdu. To meet this challenge, this research proposed a new ensemble based multi-classification model and generated new dataset of 36,000 Urdu tweets categorized as ‘Hate’, ‘Offensive’ and ‘Neither’. This study sought to create a model that not only achieves a high classification accuracy but also overcome key challenges inherent in natural language processing, namely, high dimensionality, sparsity, overfitting, OOV words and dialectal variations. For this purpose, an extensive comparison of different learning algorithms were conducted. As a result, the most efficient models, namely FastText, XLM-RoBERTa, ULMFiT, and XGBoost were incorporated in the proposed ensemble approach to achieve the best results in both classification and mitigation of NLP issues. To further enhance the confidence in proposed model, a stratified 5-fold cross-validation technique has been utilized. The ensemble model performed the best and achieved macro F1 score of 0.94, complemented by comprehensive labeled dataset focusing on hate and offensive speech in Urdu. By addressing key research gaps, this research provides a valuable foundation for future work and benchmarking in Urdu hate speech multi-classification tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3532611",
            "Date of Publication": "22 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kifayat Ullah",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Aslam",
                "labs": [
                    "Department of Computer Science, University of Engineering and Technology Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Usman Ghani Khan",
                "labs": [
                    "National Center of Artificial Intelligence, Al-Khawarizmi Institute of Computer Science, UET Lahore, Lahore, Pakistan",
                    "Artificial Intelligence & Data Analytics Laboratory (AIDA), CCIS, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Faten S. Alamri",
                "labs": [
                    "Department of Mathematical Sciences, College of Science, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Amjad Rehman Khan",
                "labs": [
                    "Artificial Intelligence & Data Analytics Laboratory (AIDA), CCIS, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hate speech",
                "Text categorization",
                "Machine learning",
                "Deep learning",
                "Context modeling",
                "Transfer learning",
                "Multilingual",
                "Data models",
                "Cyberbullying",
                "Cultural differences"
            ],
            "Author Keywords": [
                "Urdu hate speech detection",
                "Urdu multi-class classification",
                "machine learning",
                "deep learning",
                "transfer learning",
                "ensemble learning model",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "From Transformers to ChatGPT: An Analysis of Large Language Models Research",
        "Link": "https://ieeexplore.ieee.org/document/11131119/",
        "Abstract": "In recent years, the development and rapid adoption of the Large Language Models (LLMs) has revolutionized the Natural Language Processing (NLP) and Artificial Intelligence (AI) fields, influencing various research areas, as well as the everyday life of people, thanks to their wide use in a variety of areas, including decision and policy making. In this context, the present study focuses on the LLMs field from a bibliometric perspective, having the aim to discuss the global trends, applications and challenges associated with this type of language models. Starting from Transformer architecture – which serves as the foundation for the state-of-the-art models – and ending with ChatGPT, the paper analyzes the articles in the field of LLMs included in the Clarivate Analytics’ Web of Science Core Collection in terms of the most prolific authors, the dominant scientific outlets, the most prominent universities and countries based on the number of publications and characterizes the collaborative trends and interdisciplinary linkages. The exponential growth in the interest of the scientific community for LLMs is further highlighted through various indicators, such as an annual growth rate for the scientific production of 220.74%, which underscores the rapid development of this research domain. In order to complete the analysis, most cited papers are discussed in depth. Further, an n-gram analysis is conducted, accompanied by a trend and a factorial analysis, highlighting the most prominent themes, as well as key research areas of innovation and ongoing challenges. The insights derived from this study could provide valuable information for the interested parties and unlock potential future research directions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3600739",
            "Date of Publication": "20 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Liviu-Adrian Cotfas",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Andra Sandu",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Camelia Delcea",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Paul Diaconu",
                "labs": [
                    "Department of Accounting and Audit, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Corina Frăsineanu",
                "labs": [
                    "Department of Management, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Aurelia Stănescu",
                "labs": [
                    "Department of Management, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bibliometrics",
                "Databases",
                "Chatbots",
                "Education",
                "Medical diagnostic imaging",
                "Economics",
                "Collaboration",
                "Transformers",
                "Production",
                "Large language models"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "bibliometric analysis",
                "biblioshiny",
                "ChatGPT",
                "large language models (LLMs)",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Multi-Modal Emotion Detection and Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10935793/",
        "Abstract": "In the digital era, the proliferation of online reviews through videos has been meteoric and driven by recent technological advancements. The sentiments expressed in these videos drive consumer reliance, decision-making and may shape perception building of general public. The sentiment classification of videos is emerging as a vital area of research in Natural Language Processing (NLP) and is challenging due to complexity of emotions and temporal aspects of modalities. These challenges become more complex for low-resourced languages such as Urdu. Addressing the need for a comprehensive study in this realm, we introduce a generic framework, Urdu Multi-modal Sentiment Analysis (UMSA), for emotion detection and sentiment classification of videos.UMSA highlights that incorporating additional modalities and cross-modal interactions significantly enhances the analysis. Our research culminates in the creation of the Urdu Sentiments Dataset (USD), a comprehensive collection of Urdu video reviews. In this study, we classify videos using a two-phase approach that incorporates early fusion and ensembling. After fusion, we perform ensembling of two models for each modality: audio, text, and frames. We utilize Long Short-Term Memory (LSTM) networks and Random Forest Classifier for audio. Text-based analysis is conducted using Logistic Regression and the Bidirectional Encoder Representations from Transformers (BERT) model. For frames, we employ Random Forest and Convolutional Neural Networks (CNN). Afterwards, we implement model ensembling across the three modalities. This multi-modal integration proves essential in providing a clearer and more comprehensive understanding of the sentiments conveyed and achieved more than 80% accuracy. The validation of UMSA is reinforced through a comprehensive case study approach. This independent validation highlights its robustness and adaptability to real-world scenarios.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3552475",
            "Date of Publication": "20 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shoaib Sikunder Malik",
                "labs": [
                    "Department of CS, University of Sargodha, Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Muhammad Ilyas",
                "labs": [
                    "Department of CS, University of Sargodha, Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Yasin Ul Haq",
                "labs": [
                    "Department of Computer Science and Engineering, University of Engineering and Technology Lahore, Narowal Campus, Narowal, Pakistan"
                ]
            },
            {
                "name": "Rabia Sana",
                "labs": [
                    "Department of Computer Science and Engineering, University of Engineering and Technology Lahore, Narowal Campus, Narowal, Pakistan"
                ]
            },
            {
                "name": "Muhamamd Saad Razzaq",
                "labs": [
                    "Department of CS, University of Sargodha, Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Fahad Maqbool",
                "labs": [
                    "Department of CS, University of Sargodha, Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Muhammad Salman Pathan",
                "labs": [
                    "School of Computing, Dublin City University, Dublin 9, Ireland",
                    "ADAPT SFI Research Centre, Dublin 2, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Videos",
                "Visualization",
                "Linguistics",
                "Analytical models",
                "Accuracy",
                "Electronic mail",
                "Taxonomy",
                "Market research",
                "Emotion recognition"
            ],
            "Author Keywords": [
                "Emotion detection",
                "multi-modal sentiment analysis",
                "NLP",
                "UMSA",
                "USD"
            ]
        }
    },
    {
        "Title": "Automated Microservices Identification Through Business Process Analysis: A Semantic-Driven Clustering Approach",
        "Link": "https://ieeexplore.ieee.org/document/11007623/",
        "Abstract": "The rise of microservice architectures has further evolved software development practices, building upon the foundation established by web services in breaking down monolithic systems, while offering more finely detailed, coherent, and loosely interconnected services. Despite the transformative potential of microservices, the challenge of effectively pinpointing microservices that meet an organization’s specific requirements remains a difficult task. This paper presents an extended approach for automating microservices identification by leveraging business processes (BPs). Addressing limitations in existing microservices identification techniques, this approach utilizes advanced Natural Language Processing (NLP) techniques—such as Named Entity Recognition (NER) and semantic analysis—to capture dependencies and align boundaries with business logic. This methodology applies unsupervised clustering algorithms, including K-means, K-medoids, and DBSCAN, to generate well-defined microservices by analyzing semantic similarity across BP activities. Evaluation on real-world case studies, such as the Bicing bicycle rental system, Cargo Tracking, and JPetStore, demonstrates its effectiveness, yielding high cohesion, low coupling, and superior granularity in microservices decomposition compared to traditional methods. Metrics such as the Silhouette Index, Afferent Coupling, and Instability further validate its performance. By automating microservices identification with a BP-centered framework, this approach aligns technical architecture with organizational goals, advancing both agility and scalability in software systems. This work marks a step forward in optimizing system modularity and provides a foundation for future scalability improvements.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571809",
            "Date of Publication": "20 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Idris Oumoussa",
                "labs": [
                    "SI2M Laboratory, National Institute of Statistics and Applied Economics (INSEA), Rabat, Morocco"
                ]
            },
            {
                "name": "Rajaa Saidi",
                "labs": [
                    "SI2M Laboratory, National Institute of Statistics and Applied Economics (INSEA), Rabat, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Microservice architectures",
                "Couplings",
                "Semantics",
                "Business",
                "Faces",
                "Clustering algorithms",
                "Unified modeling language",
                "Source coding",
                "Measurement",
                "Indexes"
            ],
            "Author Keywords": [
                "Microservices",
                "micro-services granularity",
                "business processes",
                "NLP",
                "clustering",
                "semantic similarity",
                "micro-services decompositions",
                "software architecture"
            ]
        }
    },
    {
        "Title": "The Impact of LoRA Adapters on LLMs for Clinical Text Classification Under Computational and Data Constraints",
        "Link": "https://ieeexplore.ieee.org/document/11048527/",
        "Abstract": "Fine-tuning Large Language Models (LLMs) for clinical Natural Language Processing (NLP) poses significant challenges due to domain gap, limited data, and stringent hardware constraints. In this study, we evaluate four adapter techniques—Adapter, Lightweight, TinyAttention, and Gated Residual Network (GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note classification under real-world, resource-constrained conditions. All experiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512 CUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to\n≤8\nsequences and maximum sequence length to 256 tokens. Our clinical corpus comprises only 580 000 tokens, several orders of magnitude smaller than standard LLM pre-training datasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio, AliBERT, DrBERT) and two lightweight Transformer models trained from scratch. Results show that 1) adapter structures provide no consistent gains when fine-tuning biomedical LLMs under these constraints, and 2) simpler Transformers, with minimal parameter counts and training times under six hours, outperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among adapters, GRN achieved the best metrics (accuracy, precision, recall, F1 = 0.88). These findings demonstrate that, in low-resource clinical settings with limited data and compute, lightweight Transformers trained from scratch offer a more practical and efficient solution than large LLMs, while GRN remains a viable adapter choice when minimal adaptation is needed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3582037",
            "Date of Publication": "24 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thanh-Dung Le",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, Montreal, QC, Canada",
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Ti Ti Nguyen",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Vu Nguyen Ha",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Symeon Chatzinotas",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Philippe Jouvet",
                "labs": [
                    "CHU Sainte-Justine Research Center, CHU Sainte-Justine Hospital, University of Montreal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Rita Noumeir",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, Montreal, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Text categorization",
                "Natural language processing",
                "Adaptation models",
                "Acute respiratory distress syndrome",
                "Graphics processing units",
                "Biological system modeling",
                "Accuracy",
                "Tuning",
                "Training"
            ],
            "Author Keywords": [
                "Low-rank adaptation (LoRA)",
                "adapters",
                "LLM",
                "clinical NLP",
                "cardiac failure",
                "text classification"
            ]
        }
    },
    {
        "Title": "Extracting Place Functionality From Crowdsourced Textual Data Using Semantic Space Modeling",
        "Link": "https://ieeexplore.ieee.org/document/10318117/",
        "Abstract": "Place has gained significant attention in geographic information science. Places are described by users that make a huge amount of user-generated textual contents. This research introduces a novel approach to extract place functionality using crowdsourcing textual data, which are shared in the form of online reviews. To achieve this goal, salient features are modeled as directions in a domain-specific semantic space. We propose an unsupervised method that only requires a Bag-of-Words (BoW) of place reviews and utilizes Natural Language Processing (NLP) methods. Finally, a probabilistic multi-label functionality for each place is predicted using the semantic space constructed based on the salient feature directions, and the maximum probability is defined as the main functionality of place. The functionality of ‘Hotels’ is determined with an average accuracy of 88.52%, while the efficiency of extracting ‘Attractions’, ‘FoodPlaces’, and ‘Shoppings’ functionalities is 65.66%, 64.99%, and 12.70%, respectively. The proposed method can help users to find places that afford a specific functionality and can improve decisions in urban planning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3332854",
            "Date of Publication": "14 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mina Karimi",
                "labs": [
                    "Department of Geospatial Information Systems, K. N. Toosi University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Mohammad Saadi Mesgari",
                "labs": [
                    "Department of Geography, University of Zürich, Zürich, Switzerland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Semantics",
                "Data mining",
                "Data models",
                "Urban planning",
                "Web services",
                "Social networking (online)",
                "Geographic information systems",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Functionality",
                "geographic information extraction",
                "natural language processing (NLP)",
                "place",
                "semantic space"
            ]
        }
    },
    {
        "Title": "Annotators’ Selection Impact on the Creation of a Sentiment Corpus for the Cryptocurrency Financial Domain",
        "Link": "https://ieeexplore.ieee.org/document/10322757/",
        "Abstract": "Well labeled natural language corpus data is essential for most natural language processing techniques, especially in specialized fields. However, cohort biases remain a significant challenge in machine learning. The narrow origin of data sampling or human annotators in cohorts is a prevalent issue for machine learning researchers due to its potential to induce bias in the final product. During the development of the CryptoLin corpus for another research project, the authors became concerned about the potential influence of cohort bias on the selection of annotators. Therefore, this paper addresses the question of whether cohort diversity improves the labeling result through the implementation of a repeated annotator process, involving two annotator cohorts and a statistically robust comparison methodology. The utilization of statistical tests, such as the Chi-Square Independence test for absolute frequency tables, and the construction of confidence intervals for Kappa point estimates, facilitates a rigorous analysis of the differences between Kappa estimates. Furthermore, the application of a two-proportion z-test to compare the accuracy scores of UTAD and IE annotators for various pre-trained models, including Vader Sentiment Analysis, TextBlob Sentiment Analysis, Flair NLP library, and FinBERT Financial Sentiment Analysis with BERT, contributes to the advancement of knowledge in this field. The paper utilizes Cryptocurrency Linguo (CryptoLin), a corpus containing 2683 cryptocurrency-related news articles spanning more than three years, and compares two different selection criteria for the annotators. CryptoLin was annotated twice with discrete values representing negative, neutral, and positive news respectively. The first annotation was done by twenty-seven annotators from the same cohort. Each news title was randomly assigned and blindly annotated by three human annotators. The second annotation was carried out by eighty-three annotators from three cohorts. Each news title was randomly assigned and blindly annotated by three human annotators, one in each different cohort. In both annotations, a consensus mechanism using simple voting was applied. The first annotation used the same cohort with students from the same nationality and background. The second used three cohorts with students from a very diverse set of nationalities and educational backgrounds. The results demonstrate that manual labeling done by both groups was acceptable according to inter-rater reliability coefficients Fleiss’s Kappa, Krippendorff’s Alpha, and Gwet’s AC1. Preliminary analysis utilizing Vader, Textblob, Flair, and FinBERT confirmed the utility of the data set labeling for further refinement of sentiment analysis algorithms. Our results also highlight that the more diverse annotator pool performed better in all measured aspects.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3334260",
            "Date of Publication": "17 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Manoel Fernando Alonso Gadi",
                "labs": [
                    "Department of Computer Science, University of Alcalá de Henares, Alcalá de Henares, Spain"
                ]
            },
            {
                "name": "Miguel Ángel Sicilia",
                "labs": [
                    "Department of Computer Science, University of Alcalá de Henares, Alcalá de Henares, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Cryptocurrency",
                "Machine learning",
                "Labeling",
                "Finance",
                "Sentiment analysis",
                "Task analysis",
                "Finance",
                "Bit error rate"
            ],
            "Author Keywords": [
                "Annotation",
                "annotator selection criteria",
                "cryptocurrency",
                "news event",
                "labeled data set",
                "NLP",
                "news sentiment corpus"
            ]
        }
    },
    {
        "Title": "A Comprehensive Survey on AI in Counter-Terrorism and Cybersecurity: Challenges and Ethical Dimensions",
        "Link": "https://ieeexplore.ieee.org/document/11008653/",
        "Abstract": "The advanced capabilities in threat detection and mitigation brought about by the rapid development of Artificial Intelligence (AI) significantly impact the fight against terrorism and cybersecurity threats. However, critical concerns such as algorithmic bias, data quality limitations, and governance challenges introduce significant obstacles to their deployment. This paper provides a comprehensive overview of AI methodologies, such as predictive analytics, Natural Language Processing (NLP), and machine learning architectures (e.g., Support Vector Machines – SVM and Long Short-Term Memory – LSTM), and optimization algorithms (e.g., Particle Swarm Optimization – PSO), assessing their effectiveness in security applications. Additionally, AI-based approaches to surveillance, misinformation management, and anomaly detection are explored, focusing on their impacts on national security. Beyond the technical aspects, the paper highlights ethical concerns and policy issues, putting forward frameworks such as Explainable Artificial Intelligence (XAI) and crowdsourced intelligence (Crosint) to ensure the responsible and transparent deployment of AI. The integration of the technical, ethical, and operational perspectives addressed in this research contributes to a holistic understanding of the potential of AI in cybersecurity, while also ensuring adherence to AI governance standards.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3572348",
            "Date of Publication": "21 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ioannis Syllaidopoulos",
                "labs": [
                    "Department of Business Administration, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Klimis S. Ntalianis",
                "labs": [
                    "Department of Business Administration, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Ioannis Salmon",
                "labs": [
                    "Department of Business Administration, University of West Attica, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Computer security",
                "Natural language processing",
                "Machine learning",
                "Ethics",
                "Threat assessment",
                "Fake news",
                "Deep learning",
                "Biological system modeling",
                "Surveys"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "counter-terrorism",
                "cybersecurity",
                "machine learning",
                "explainable artificial intelligence (XAI)",
                "misinformation management",
                "natural language processing (NLP)",
                "threat detection"
            ]
        }
    },
    {
        "Title": "Empowering Sentiment Analysis in African Low-Resource Languages Through Transformer Models and Strategic Language Selection",
        "Link": "https://ieeexplore.ieee.org/document/11127074/",
        "Abstract": "This research addresses the significant challenges of sentiment analysis in low-resource African languages by utilizing advanced transformer-based models to bridge gaps in natural language processing (NLP) for underrepresented linguistic communities. Covering 12 diverse languages: Hausa, Yoruba, Igbo, Nigerian Pidgin, Amharic, Algerian Arabic, Moroccan Arabic Darija, Swahili, Kinyarwanda, Twi, Mozambican Portuguese, and Xitsonga. Our work includes pre-trained language models (PLMs) such as XLM-R, AfroXLMR, AfriBERTa, and mDeBERTaV3, fine-tuning them for the specific task of sentiment classification. In particular, using datasets from the AfriSenti SemEval 2023 Shared Task 12, this process involves tailoring multilingual transformer models to low-resource African languages, enabling them to capture complex linguistic nuances and sentiment polarities effectively. The results demonstrate significant improvements across key metrics, including accuracy, precision, recall, and weighted F1 score. Notably, our work using AfroXLMR achieves the top 1 rank, with a weighted F1 score of 75.8%, outperforming all other submissions. In addition to multilingual transformer models, we evaluated traditional machine learning models, including CNN, Naïve Bayes, and SVM, to compare their performance. The evaluation focused on zero-shot sentiment classification for Tigrinya, a low-resource African language not seen during model training. The results indicate that while traditional models produced meaningful results, multilingual transformer models achieved higher performance in the zero-shot setting. This highlights both the challenges and potential of multilingual transfer approaches for sentiment analysis in African low-resource languages. Moreover, this research highlights the transformative role of Artificial Intelligence (AI) in addressing linguistic diversity, fostering digital inclusion, and enabling reliable sentiment analysis. Furthermore, it lays the groundwork for future advancements in processing low-resource languages and emphasizes the importance of promoting cultural inclusivity through AI technologies.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599480",
            "Date of Publication": "18 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nilanjana Raychawdhary",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Sutanu Bhattacharya",
                "labs": [
                    "Auburn University at Montgomery, Montgomery, AL, USA"
                ]
            },
            {
                "name": "Cheryl Seals",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Gerry V. Dozier",
                "labs": [
                    "Auburn University, Auburn, AL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Multilingual",
                "Transformers",
                "Natural language processing",
                "Adaptation models",
                "Hidden Markov models",
                "Market research",
                "Cultural differences",
                "Syntactics",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Adaptive pretraining",
                "African low-resource languages",
                "cross-lingual transfer learning",
                "multilingual sentiment classification",
                "natural language processing (NLP)",
                "transformer models"
            ]
        }
    },
    {
        "Title": "Smart Agile Prioritization and Clustering: An AI-Driven Approach for Requirements Prioritization",
        "Link": "https://ieeexplore.ieee.org/document/11082164/",
        "Abstract": "In Agile software development, requirements prioritization plays a crucial role in ensuring that critical functionalities are delivered efficiently. Traditional prioritization methods often suffer from scalability limitations, lack of automation, and difficulty in handling dependencies. This paper proposes Smart Agile Prioritization and Clustering (SAPC), an AI-driven approach that enhances requirements prioritization by leveraging Natural Language Processing (NLP), BERT embeddings, graph-based dependency modeling, and optimization techniques. The proposed model extracts and processes textual requirements, constructs a dependency graph to model interrelations, and applies PageRank to compute requirement importance. Feature fusion and dimensionality reduction using Uniform Manifold Approximation and Projection (UMAP) facilitate clustering, while Particle Swarm Optimization (PSO) determines the optimal number of clusters for efficient backlog prioritization. The effectiveness of SAPC is evaluated using functional requirements extracted from Software Requirement Specifications (SRS), product backlogs, and customer requests, along with a benchmark dataset for validation. Various machine learning algorithms are tested, with KNN and Random Forest demonstrating the highest accuracy and lowest Mean Squared Error (MSE), outperforming traditional prioritization techniques. The results highlight the potential of AI-based methods in automating and optimizing backlog management within Agile methodologies, offering a scalable and data-driven approach to enhanced requirements prioritization.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3589959",
            "Date of Publication": "16 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aya M. Radwan",
                "labs": [
                    "Department of Information Systems, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt"
                ]
            },
            {
                "name": "Manal A. Abdel-Fattah",
                "labs": [
                    "Department of Information Systems, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt"
                ]
            },
            {
                "name": "Wael Mohamed",
                "labs": [
                    "Department of Information Systems, Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Stakeholders",
                "Natural language processing",
                "Machine learning",
                "Artificial intelligence",
                "Accuracy",
                "Collaboration",
                "Agile software development",
                "Feature extraction",
                "Decision making",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Agile prioritization",
                "requirements clustering",
                "BERT embeddings",
                "PageRank",
                "particle swarm optimization (PSO)",
                "NLP",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Automatic Scene Generation: State-of-the-Art Techniques, Models, Datasets, Challenges, and Future Prospects",
        "Link": "https://ieeexplore.ieee.org/document/11016674/",
        "Abstract": "Automatic scene generation is an essential area of research with applications in robotics, recreation, visual representation, training and simulation, education, and more. This survey provides a comprehensive review of the current state-of-the-arts in automatic scene generation, focusing on techniques that leverage machine learning, deep learning, embedded systems, and natural language processing (NLP). We categorize the models into four main types: Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Transformers, and Diffusion Models. Each category is explored in detail, discussing various sub-models and their contributions to the field. We also review the most commonly used datasets, such as COCO-Stuff, Visual Genome, and MS-COCO, which are critical for training and evaluating these models. Methodologies for scene generation are examined, including image-to-3D conversion, text-to-3D generation, graph-based methods, and interactive scene generation. Evaluation metrics such as Fréchet Inception Distance (FID), Kullback-Leibler (KL) Divergence, Inception Score (IS), Intersection over Union (IoU), and Mean Average Precision (mAP) are discussed in the context of their use in assessing model performance. The survey identifies key challenges and limitations in the field, such as maintaining realism, handling complex scenes with multiple objects, and ensuring consistency in object relationships and spatial arrangements. By summarizing recent advances and pinpointing areas for improvement, this survey aims to provide a valuable resource for researchers and practitioners working on automatic scene generation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574298",
            "Date of Publication": "28 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Awal Ahmed Fime",
                "labs": [
                    "School of Computing, Southern Illinois University, Carbondale, IL, USA"
                ]
            },
            {
                "name": "Saifuddin Mahmud",
                "labs": [
                    "Department of Computer Science and Information Systems, Bradley University, Peoria, IL, USA"
                ]
            },
            {
                "name": "Arpita Das",
                "labs": [
                    "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA"
                ]
            },
            {
                "name": "Md. Sunzidul Islam",
                "labs": [
                    "Department of Computer Science and Engineering, Khulna University of Engineering and Technology, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Jong-Hoon Kim",
                "labs": [
                    "Department of Computer Science, Advanced Telerobotics Research Laboratory, Kent State University, Kent, OH, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autoencoders",
                "Image reconstruction",
                "Transformers",
                "Training",
                "Three-dimensional displays",
                "Diffusion models",
                "Visualization",
                "Surveys",
                "Image synthesis",
                "Decoding"
            ],
            "Author Keywords": [
                "Automatic scene generation",
                "variational autoencoders",
                "generative adversarial networks",
                "transformers",
                "diffusion models",
                "machine learning",
                "deep learning",
                "NLP",
                "3D scene generation",
                "2D image generation",
                "evaluation metrics",
                "COCO-stuff",
                "visual genome",
                "MS-COCO"
            ]
        }
    },
    {
        "Title": "Enhancement of Implicit Emotion Recognition in Arabic Text: Annotated Dataset and Baseline Models",
        "Link": "https://ieeexplore.ieee.org/document/11168475/",
        "Abstract": "Emotion recognition in textual data has emerged as a rapidly advancing task within the field of Natural Language Processing (NLP). Implicit Emotion Recognition (IER), which aims to identify emotions primarily through contextual cues rather than overt or explicit emotional expressions, remains in its early stages. Despite the significant progress in emotion recognition tasks, current research has largely ignored IER, particularly for low-resource languages such as Arabic. This study aims to comprehensively address this task for the Arabic language, including dataset construction, annotation, modeling, and evaluation. Specifically, the study 1) introduces the first annotated dataset for Arabic Implicit Emotion Recognition (AIER); 2) annotates the dataset with emotions, cues, and causes using a semi-automatic annotation tool validated by four native Arabic speakers and linguists; 3) investigates the potential of two categories of transformer-based models: masked language models, exemplified by pre-trained Bidirectional Encoder Representations from Transformers (BERT)-based architectures through a series of fine-tuning experiments, and causal-based models, such as generative Large Language Models (LLMs), through a zero-shot prompting approach; and 4) evaluates the performance of four distinct algorithmic approaches on the proposed dataset, namely classical Machine Learning (ML), Deep Learning (DL), BERT-based models, and generative LLMs. The experimental results indicate that BERT-based models outperform ML, DL, and generative LLMs. In particular, the fine-tuned MARBERTv2 model achieved the best performance among all pre-trained models, obtaining an F1-score of 79.83% on the AIER dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611337",
            "Date of Publication": "17 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hanane Boutouta",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria",
                    "Artificial Intelligence Laboratory (AI-Lab), Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Abdelaziz Lakhfif",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria",
                    "Artificial Intelligence Laboratory (AI-Lab), Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Ferial Senator",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria",
                    "Artificial Intelligence Laboratory (AI-Lab), Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria"
                ]
            },
            {
                "name": "Chahrazed Mediani",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria",
                    "Artificial Intelligence Laboratory (AI-Lab), Faculty of Sciences, Setif 1 University—Ferhat ABBAS, Setif, Algeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Natural language processing",
                "Encoding",
                "Context modeling",
                "Blogs",
                "Bidirectional control",
                "Annotations",
                "Linguistics",
                "Transformers",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "BERT",
                "deep learning",
                "implicit emotion recognition",
                "generative LLMs",
                "machine learning",
                "masked language modeling"
            ]
        }
    },
    {
        "Title": "Enhancing Essay Scoring: An Analytical and Holistic Approach With Few-Shot Transformer-Based Models",
        "Link": "https://ieeexplore.ieee.org/document/10843186/",
        "Abstract": "In the field of automated essay scoring (AES), the task of evaluating written compositions has been a persistent challenge. Despite the impressive capabilities of generalized transformer models in various natural language processing (NLP) domains, their application to essay scoring has often fallen short of expectations. In response to this ongoing challenge, this research delves into the intricate nuances of holistic and analytical essay assessment. This work presents an innovative approach centered on Few-Shot transformer-based models, capitalizing on the strengths of pretrained language models while enabling fine-tuning with limited essay-specific data, often called ‘Few-Shot.’ The outcomes of this study are highly promising, with significant improvements in essay scoring accuracy that surpass the performance benchmarks established by conventional methods. The proposed methodology demonstrates remarkable enhancements in the Quadratic Weighted Kappa (QWK) score, indicating its potential. This represents a significant stride towards automating sophisticated essay evaluation, addressing a long-standing issue in the field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3530272",
            "Date of Publication": "15 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tahira Amin",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Zahoor-Ur-Rehman Tanoli",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Farhan Aadil",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan",
                    "Department of Computer Engineering, Sivas University of Science and Technology, Sivas, Türkiye"
                ]
            },
            {
                "name": "Khalid Mahmood Awan",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, Pakistan"
                ]
            },
            {
                "name": "Sangsoon Lim",
                "labs": [
                    "Department of Computer Engineering, Sungkyul University, Anyang, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Analytical models",
                "Few shot learning",
                "Coherence",
                "Predictive models",
                "Feature extraction",
                "Data models",
                "Solid modeling",
                "Linguistics",
                "Encoding"
            ],
            "Author Keywords": [
                "AES",
                "NLP",
                "transfer learning",
                "BERT",
                "few-shot learning",
                "holistic scoring",
                "analytical scoring"
            ]
        }
    },
    {
        "Title": "Multidimensional Readiness Evaluation of Smart Tourism Destinations: A Natural Language Processing and Thematic Analysis Approach",
        "Link": "https://ieeexplore.ieee.org/document/11045893/",
        "Abstract": "The rapid expansion of the tourism sector, driven by technological progress, has led to smart tourism, improving visitor experiences and streamlining destination administration. In underdeveloped nations, such as Indonesia, destinations often are not adequately prepared to use smart technology, resulting in inefficiencies and unsuccessful projects. Existing models for evaluating tourism progress typically concentrate on specific regions or isolated dimensions, lacking a comprehensive assessment of governance, socio-economic conditions, and information technology (IT) awareness. This research addresses this gap by introducing a multidimensional framework for evaluating smart tourism readiness based on the Technology-Organization-Environment (TOE) paradigm. The study starts with a thorough review of existing literature using the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) method to find key factors for readiness, and it uses a combination of both qualitative and quantitative research methods. We conducted a quantitative examination using natural language processing (NLP) to cluster the dimensions of the existing evaluation models. In the qualitative phase, two validation processes were conducted. The first process involved expert interviews with stakeholders to validate the dimensions identified in the previous step. In the second validation process, we simplified the information by matching the proposed dimensions with IT governance components from well-known frameworks like COBIT and ITIL 4. This mapping ensures the proposed dimensions are aligned with IT governance components, supporting the effective management of smart technology in smart tourism destinations. The study identifies seven critical readiness dimensions as a key finding: governance, sustainability, online tourism services, smart technology, accessibility, innovation, and socioeconomic conditions. The findings contribute to a holistic readiness evaluation framework, offering actionable insights for policymakers and tourism stakeholders to inform strategic planning and policy development. This comprehensive model supports the successful implementation of smart tourism initiatives, addressing the unique challenges of developing countries and fostering long-term sustainability.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3581962",
            "Date of Publication": "20 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dhiani Tresna Absari",
                "labs": [
                    "Department of Information Systems, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia",
                    "Department of Information Systems, Universitas Surabaya, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Arif Djunaidy",
                "labs": [
                    "Department of Information Systems, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Tony Dwi Susanto",
                "labs": [
                    "Department of Information Systems, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Stakeholders",
                "Natural language processing",
                "Evaluation models",
                "Information systems",
                "Weather forecasting",
                "Technological innovation",
                "Sustainable development",
                "Current measurement",
                "Socioeconomics",
                "Smart cities"
            ],
            "Author Keywords": [
                "Multidimensional evaluation",
                "natural language processing (NLP)",
                "smart tourism",
                "technology-organization-environment (TOE) theory",
                "thematic analysis",
                "tourism readiness"
            ]
        }
    },
    {
        "Title": "Abstractive Text Summarization in Arabic-Like Script Using Multi-Encoder Architecture and Semantic Extraction Techniques",
        "Link": "https://ieeexplore.ieee.org/document/11020615/",
        "Abstract": "In the field of Natural Language Processing (NLP), the task of text summarization plays a vital role in understanding textual content and producing concise summaries. Text summarization approaches can be categorized as either extractive or abstractive, with the latter largely unexplored in the Arabic script languages. Previous research on abstractive summarization for the Urdu language has made progress in creating logical and succinct summaries. Still, it has failed to preserve the underlying semantics, often resulting in inconsistent and ambiguous outputs. This study focuses on designing and implementing an abstractive text summarization model for the Urdu language, aiming to capture the semantic meaning of the original text. The proposed model improves readability and comprehension by generating concise and meaningful overviews of original content while introducing new words and expressions. The study implements a multi-layer transformer encoder as part of the mBART (Multilingual BART) model. The encoder consists of multiple stacked transformer layers. It utilizes self-attention mechanisms to process and understand the input sequences effectively, achieving a BERTScore of 90%, a BLEU score of 43%, and ROUGE scores of 80.3% for ROUGE-1, 74.3% for ROUGE-2, and 80.3% for ROUGE-L. These results demonstrate the efficacy of the model in producing coherent and high-quality abstractive summaries for the Urdu language.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3575610",
            "Date of Publication": "02 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wajiha Fatima",
                "labs": [
                    "Department of Computer Science, Capital University of Science and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Syed Saqib Raza Rizvi",
                "labs": [
                    "Department of Computer Science, Capital University of Science and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Taher M. Ghazal",
                "labs": [
                    "Department of Networks and Cybersecurity, Hourani Center for Applied Scientific Research, Al-Ahliyya Amman University, Amman, Jordan"
                ]
            },
            {
                "name": "Qasem M. Kharma",
                "labs": [
                    "Software Engineering Department, Hourani Center for Applied Scientific Research, Al-Ahliyya Amman University, Amman, Jordan"
                ]
            },
            {
                "name": "Munir Ahmad",
                "labs": [
                    "Department of Computer Science, National College of Business Administration and Economics, Lahore, Pakistan",
                    "University College, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Sagheer Abbas",
                "labs": [
                    "Computer Science Department, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Furqan",
                "labs": [
                    "Department of Software Engineering, Capital University of Science and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Khan Muhammad Adnan",
                "labs": [
                    "Department of Software, Faculty of Artificial Intelligence and Software, Gachon University, Seongnam-si, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text summarization",
                "Semantics",
                "Data models",
                "Natural language processing",
                "Transformers",
                "Multilingual",
                "Social networking (online)",
                "Data mining",
                "Coherence",
                "Translation"
            ],
            "Author Keywords": [
                "Abstractive text summarization (ATS)",
                "natural language processing (NLP)",
                "semantic meaning",
                "text generation",
                "text summarization (TS)"
            ]
        }
    },
    {
        "Title": "Predicting Suspicious Arabic X Accounts Using Stylometric Features",
        "Link": "https://ieeexplore.ieee.org/document/11146657/",
        "Abstract": "Some users use the X platform to spread negativity, violence, and hatred. These users may initially conceal their true beliefs in order to gain users’ trust, making traditional content-based detection methods not helpful in identifying these accounts as suspicious (i.e., indicate whether an X account belongs to a terrorist). Stylometric features, which analyze writing styles, can reveal behavioral traits and hidden thoughts. In this paper, we propose a novel model that predicts whether an Arabic X account is suspicious (owned by a terrorist) using 85 stylometric features extracted from 1,500 accounts (750 suspicious, 750 non-suspicious). We utilized a variety of AI techniques, such as machine learning and deep learning, to evaluate our approach. We also used NLP techniques for preprocessing and feature extraction. Our results showed that the Random Forest (RF) model achieved the highest accuracy, reaching 98%. This approach can aid cybersecurity efforts by detecting suspicious accounts without relying on content analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605126",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Taghreed Bagies",
                "labs": [
                    "Department of Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Rahaf Alsuhaimi",
                "labs": [
                    "Department of Information Systems, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Miada Almasre",
                "labs": [
                    "Department of Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Alaa Bafail",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Accuracy",
                "Terrorism",
                "Radio frequency",
                "Nearest neighbor methods",
                "Writing",
                "Social networking (online)",
                "Machine learning algorithms",
                "Deep learning",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Arabic suspicious X account",
                "stylometric features",
                "machine learning",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis of Online Reviews: A Machine Learning Based Approach with TF-IDF Vectorization",
        "Link": "https://ieeexplore.ieee.org/document/10976588/",
        "Abstract": "Nowadays, online reviews wield considerable influence over consumer decision-making processes. Surveys show 84% of people compare their trust-worthiness to recommendations from personal connections in these online reviews. Online reviews of services or destinations can significantly benefit the tourism industry. Therefore, our primary intent of this study is to leverage Machine Learning (ML) and Natural Language Processing (NLP) for sentiment analysis of hotel reviews in Jordan in order to assist both hotel owners and tourists. In this study, we proposed a ML-based approach using Support Vector Machine (SVM) and TF-IDF to perform sentiment analysis of hotel reviews into positive or negative. In addition, our experiments were performed using our real dataset, “JOHotelRating”, which was gathered in the Jordanian context. In the feature extraction stage, we utilized the Term Frequency-Inverse Document Frequency (TF-IDF) method. In the machine learning (ML) classification phase, we utilized various algorithms such as Support Vector Machine (SVM), Multinomial Naïve Bayes (MNB), Bernoulli's Naïve Bayes (BNB), Decision Tree (DT), and Random Forest (RF). SVM with TF-IDF for feature extraction, emerged as the standout performer, achieving an impressive 97% accuracy in sentiment classification. Our proposed approach offers the hotel owners a time-saving method to identify positive and negative reviews, allow them to understand trends, and enhance the overall customer experience. On the tourist side, the study attempts to tackle the challenge of comprehending numerous reviews by providing sentiment analysis, ultimately aiding them in making better-informed decisions when selecting a hotel in Jordan.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.2055",
            "Date of Publication": "September 2024",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Khalid Alemerien",
                "labs": [
                    "Information Technology Department, Tafila Technical University Tafila, Jordan"
                ]
            },
            {
                "name": "Aram Al-Ghareeb",
                "labs": [
                    "Deanship of Scientific Research and Graduate Studies, Tafila Technical University, Tafila, Jordan"
                ]
            },
            {
                "name": "Malek Zakarya Alksasbeh",
                "labs": [
                    "Faculty of Information Technology, Al-Hussein Bin Talal University, Jordan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Surveys",
                "Sentiment analysis",
                "Accuracy",
                "Reviews",
                "Tourism industry",
                "Streaming media",
                "Feature extraction",
                "Bayes methods",
                "Videos"
            ],
            "Author Keywords": [
                "Machine learning (ML)",
                "natural language processing (NLP)",
                "sentiment analysis",
                "online review",
                "tourism",
                "support vector machine (SVM)"
            ]
        }
    },
    {
        "Title": "Noor: A Pipeline Framework for Classical Arabic Parsing",
        "Link": "https://ieeexplore.ieee.org/document/11153936/",
        "Abstract": "Classical Arabic (CA) presents unique and significant challenges for computational syntactic analysis, primarily due to its complex morphosyntax, pervasive ellipsis, flexible word order, and the critical scarcity of comprehensive annotated resources. This paper introduces Noor, a novel multi-stage pipeline framework specifically engineered for robust, high-performance syntactic parsing of CA. The Noor framework integrates several key innovations: (1) a dedicated pre-parsing module (TAQDIR) employing a hybrid rule-based and heuristic approach for explicit ellipsis resolution; (2) parallel dependency (ARC-IIRAB) and constituency (ARC-MAHAL) parsers utilizing Bidirectional Long Short-Term Memory (BiLSTM)-based representations and tailored transition systems; and (3) a synthesis mechanism generating enriched hybrid syntactic representations. A primary contribution of this work is the creation and public release of the Quranic Treebank—the first complete, validated, and fully machine-readable hybrid syntactic resource for the CA, reconstructed and augmented using the Noor framework. Empirical evaluation demonstrates that Noor achieves state-of-the-art (SOTA) performance on CA parsing, with the hybrid parser significantly outperforming previous benchmarks by over 4.6 F1 points on the Extended Labeled Attachment Score (ELAS). The framework is complemented by IIRAB Vis, a novel visualization tool designed to render complex hybrid structures in alignment with traditional Arabic grammatical principles (I’rāb). By providing both a validated SOTA methodology and a foundational public dataset, this research substantially advances the computational analysis capabilities for CA across Natural Language Processing (NLP), digital humanities, and linguistic studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3607915",
            "Date of Publication": "09 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wadee A. Nashir",
                "labs": [
                    "Digital Dhad Experts, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulqader M. Mohsen",
                "labs": [
                    "The Arab Academy for Management, Banking and Financial Sciences, Amman, Jordan"
                ]
            },
            {
                "name": "Asma A. Al-Shargabi",
                "labs": [
                    "Department of Information Technology, College of Computer, Qassim University, Buraydah, Saudi Arabia"
                ]
            },
            {
                "name": "Mohamed K. Nour",
                "labs": [
                    "Department of Computer Sciences, College of Computing and Information Systems, Umm Al-Qura University, Makkah, Saudi Arabia"
                ]
            },
            {
                "name": "Badriyya B. Al-Onazi",
                "labs": [
                    "Department of Language Preparation, Arabic Language Teaching Institute, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Syntactics",
                "Linguistics",
                "Annotations",
                "Grammar",
                "Pipelines",
                "Cultural differences",
                "Computational linguistics",
                "Complexity theory",
                "Adaptation models",
                "Visualization"
            ],
            "Author Keywords": [
                "Classical Arabic",
                "syntactic parsing",
                "hybrid parsing",
                "ellipsis resolution",
                "Arabic treebank",
                "natural language processing",
                "Arabic NLP",
                "computational linguistics"
            ]
        }
    },
    {
        "Title": "Enhancing Immoral Post Detection on Social Networks Using Knowledge Graph and Attention-Based BiLSTM Framework",
        "Link": "https://ieeexplore.ieee.org/document/10759662/",
        "Abstract": "Preserving a secure and morally safe online environment on social media is a challenging task. It is essential to find immoral or unsuitable information in user-generated postings to safeguard users and enforce community standards. Various Natural Language Processing (NLP) approaches are being employed to detect subtle immoral posts; however, there remains a research gap due to the semantic and contextual complexity of natural language. To bridge this gap, this work proposes the use of a Knowledge Graph (KG) for entity recognition and the extraction of semantic relationships in Social Network (SN) posts. By doing so, the KG helps provide a deeper contextual understanding, enabling the detection of negative interactions between entities that are often present in immoral content. KG allows us to extract these associations from the text, enabling the model to recognize language that leads to immoral behavior. By utilizing a KG, the model can more easily identify connections between entities, verify statements made in postings, and classify material more precisely. GloVe (Global Vector) word embedding is used to transform the enriched text data into numerical representations. An attention-based Bidirectional Long Short-Term Memory (BiLSTM) network performs the classification task. The BiLSTM concurrently analyses the input sequence in both directions, enabling the network to recognize not only the context that is present at the moment but also the context in which each word in the sequence comes before and after. To validate the model performance, we used benchmark datasets Self-Annotated Reddit Corpus (SARC), and Hate Evaluation (HatEval) dataset. We achieved a higher F1-score of 82.79% and 84.06% on both datasets and outperformed state-of-the-art works.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3504258",
            "Date of Publication": "21 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bibi Saqia",
                "labs": [
                    "Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan"
                ]
            },
            {
                "name": "Khairullah Khan",
                "labs": [
                    "Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan"
                ]
            },
            {
                "name": "Atta Ur Rahman",
                "labs": [
                    "Riphah Institute of Systems Engineering (RISE), Riphah International University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Sajid Ullah Khan",
                "labs": [
                    "Department of Information Systems, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammed Alkhowaiter",
                "labs": [
                    "Department of Computer Engineering, College of Computer Engineering and Sciences, Prince Sattam bin Abdulaziz University, Alkharj, Saudi Arabia"
                ]
            },
            {
                "name": "Wahab Khan",
                "labs": [
                    "Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan"
                ]
            },
            {
                "name": "Ashraf Ullah",
                "labs": [
                    "Department of Computer Science, University of Science and Technology Bannu, Bannu, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Ethics",
                "Feature extraction",
                "Accuracy",
                "Standards",
                "Media",
                "Manuals",
                "Hate speech",
                "Long short term memory",
                "Law"
            ],
            "Author Keywords": [
                "Immoral posts",
                "post detection",
                "NLP",
                "social media",
                "knowledge graph",
                "BiLSTM network"
            ]
        }
    },
    {
        "Title": "Comparative Analysis of GPT-4 and LLaMA 3.2 Integration With Speech Processing Models for Enhancing Human–Robot Interaction and Motion Control in Real-World Applications",
        "Link": "https://ieeexplore.ieee.org/document/11084769/",
        "Abstract": "Human-Robot Interaction (HRI) in robots finds wide applications today such as personal assistant robots, autonomous vehicles, healthcare support robots, industrial robots and many more, which receive interpreted commands to perform functions ranging from home automation to real-time assembly line operations. This paper provides a comparative study of different Natural Language Processing (NLP) models that are created by combining advanced Large Language Models (LLMs) with speech processing technologies to create a more intuitive, adaptable, and accurate system for robots. By assessing performance metrics including accuracy, response time and robustness, this paper identifies the best generalized model for the real-world application in robotics. In fact, this framework enables natural language understanding and speech generation to be combined effectively, which can help robots respond quickly to spoken requests, even in dynamic environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3590592",
            "Date of Publication": "18 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sheeba Uruj",
                "labs": [
                    "Department of Computer Science, Birla Institute of Technology and Science, Pilani, Dubai Campus, Dubai International Academic City, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Riddhi Goswami",
                "labs": [
                    "Department of Computer Science, Birla Institute of Technology and Science, Pilani, Dubai Campus, Dubai International Academic City, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Sujala D. Shetty",
                "labs": [
                    "Department of Computer Science, Birla Institute of Technology and Science, Pilani, Dubai Campus, Dubai International Academic City, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Kalaichelvi Venkatesan",
                "labs": [
                    "Department of Electrical and Electronics Engineering, Birla Institute of Technology and Science, Pilani, Dubai Campus, Dubai International Academic City, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Karthikeyan Ramanujam",
                "labs": [
                    "Department of Mechanical Engineering, Birla Institute of Technology and Science, Pilani, Dubai Campus, Dubai International Academic City, Dubai, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robots",
                "Navigation",
                "Human-robot interaction",
                "Service robots",
                "Natural languages",
                "Vehicle dynamics",
                "Natural language processing",
                "Computational modeling",
                "Urban areas",
                "Real-time systems"
            ],
            "Author Keywords": [
                "HRI",
                "robot operating system (ROS)",
                "NLP",
                "LLMs",
                "speech-to-text (STT)",
                "text-to-speech (TTS)"
            ]
        }
    },
    {
        "Title": "Survey and Evaluation of Converging Architecture in LLMs Based on Footsteps of Operations",
        "Link": "https://ieeexplore.ieee.org/document/11072851/",
        "Abstract": "Large language models (LLMs), which have emerged from advances in natural language processing (NLP), enable chatbots, virtual assistants, and numerous domain-specific applications. These models, often comprising billions of parameters, leverage the Transformer architecture and Attention mechanisms to process context effectively and address long-term dependencies more efficiently than earlier approaches, such as recurrent neural networks (RNNs). Notably, since the introduction of Llama, the architectural development of LLMs has significantly converged, predominantly settling on a Transformer-based decoder-only architecture. The evolution of LLMs has been driven by advances in high-bandwidth memory, specialized accelerators, and optimized architectures, enabling models to scale to billions of parameters. However, it also introduces new challenges: meeting compute and memory efficiency requirements across diverse deployment targets, ranging from data center servers to resource-constrained edge devices. To address these challenges, we survey the evolution of LLMs at two complementary levels: architectural trends and their underlying operational mechanisms. Furthermore, we quantify how hyperparameter settings influence inference latency by profiling kernel-level execution on a modern GPU architecture. Our findings reveal that identical models can exhibit varying performance based on hyperparameter configurations and deployment contexts, emphasizing the need for scalable and efficient solutions. The insights distilled from this analysis guide the optimization of performance and efficiency within these converged LLM architectures, thereby extending their applicability across a broader range of environments.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3587005",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Seongho Kim",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jihyun Moon",
                "labs": [
                    "Department of Systems Semiconductor Engineering, Yonsei University, Seoul, South Korea",
                    "BK21 Graduate Program in Intelligent Semiconductor Technology, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Juntaek Oh",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Insu Choi",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Joon-Sung Yang",
                "labs": [
                    "Department of Electrical and Electronic Engineering, Yonsei University, Seoul, South Korea",
                    "Department of Systems Semiconductor Engineering, Yonsei University, Seoul, South Korea",
                    "BK21 Graduate Program in Intelligent Semiconductor Technology, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer architecture",
                "Computational modeling",
                "Transformers",
                "Training",
                "Neural networks",
                "Context modeling",
                "Artificial intelligence",
                "Encoding",
                "Surveys",
                "Optimization"
            ],
            "Author Keywords": [
                "Edge computing",
                "LLM",
                "NLP",
                "transformer architecture",
                "and server deployment"
            ]
        }
    },
    {
        "Title": "Deep Learning-Driven Labor Education and Skill Assessment: A Big Data Approach for Optimizing Workforce Development and Industrial Relations",
        "Link": "https://ieeexplore.ieee.org/document/11052269/",
        "Abstract": "The automation of resume screening is a critical component of modern recruitment processes, particularly in large organizations. Automated systems for resume screening typically involve various NLP tasks to streamline candidate evaluation. This paper investigates the application of LLM models in automating labor education and skill assessment, focusing on optimizing workforce development through advanced language models. We propose a comprehensive framework for automating resume screening and grading, utilizing SOTA LLM models to enhance recruitment processes. The proposed system integrates information extraction and summarization tasks, leveraging LLMs for decision-making throughout the hiring process. Our experiments, conducted on a publicly available resume dataset, demonstrate significant improvements in efficiency and accuracy. The LLaMA2-13B model, achieves a ROUGE-1 score of 37.31, ROUGE-2 of 15.04, ROUGE-L of 36.99, and BLEU score of 13.82, significantly outperforming the baseline models such as FLAN-T5 and GPT-NeoX. These results highlight the potential of LLM-based systems in automating labor-related assessments, with the fine-tuned LLaMA2-13B model delivering up to 27% better performance than zero-shot models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583324",
            "Date of Publication": "26 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dan Peng",
                "labs": [
                    "School of Marxism, China University of Mining and Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Resumes",
                "Decision making",
                "Recruitment",
                "Hidden Markov models",
                "Pipelines",
                "Accuracy",
                "Manuals",
                "Large language models",
                "Data models",
                "Unsupervised learning"
            ],
            "Author Keywords": [
                "Skill assessment",
                "hiring optimization",
                "large language models",
                "knowledge graph",
                "NLP"
            ]
        }
    },
    {
        "Title": "UAV Path Optimization for WSN in Smart Agriculture",
        "Link": "https://ieeexplore.ieee.org/document/11003879/",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) play a crucial role in Wireless Sensor Network (WSN) applications, particularly in smart agriculture, enabling efficient data collection from large-scale sensor deployments. A key challenge in this field is optimizing the UAV’s flight path while considering real-world constraints such as UAV dynamics, sensor heterogeneity, communication ranges, hovering requirements, overlapping cluster heads, altitude variation, and UAV limitations. Many existing studies oversimplify this problem by considering some of these constraints while neglecting others, leading to suboptimal solutions. In this work, we propose a novel UAV path optimization algorithm, “OptiFly”, designed for WSN-based agricultural systems, incorporating all these constraints in a single framework. The optimization problem is formulated as a Nonlinear Programming (NLP) model and solved using an appropriate solver. Unlike existing approaches, OptiFly integrates UAV kinematics, dynamics, and aerodynamics into the optimization process while accounting for heterogeneous sensors, as commonly observed in real-world agricultural implementations. The algorithm ensures that the UAV hovers at an optimal position within each sensor’s coverage area, minimizing unnecessary movements. Additionally, we consider overlapping cluster heads, allowing the UAV to hover over their intersection regions and collect data from both at the same point, thereby minimizing travel distance. For sensors with small communication ranges, the UAV dynamically adjusts its altitude to maintain connectivity while conserving energy. Furthermore, OptiFly enables the UAV to be self-aware of its endurance, terminating the mission before exceeding its maximum flight time. Power consumption is also considered based on the UAV’s dynamics. Simulation results demonstrate that OptiFly significantly reduces both travel distance and energy consumption compared to unoptimized and optimized approaches. Additionally, the proposed algorithm proves to have low computational complexity in various scenarios. The achieved improvements validate the effectiveness of our method, making it a promising solution for UAV-WSN applications in smart agriculture and beyond.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3569642",
            "Date of Publication": "14 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Katia Karam",
                "labs": [
                    "LabSTICC, UMR 6285 CNRS, ENSTA, Institut Polytechnique de Paris, Brest, France",
                    "Department of Electrical Engineering, Faculty of Engineering, University of Balamand, Tripoli, Lebanon"
                ]
            },
            {
                "name": "Ali Mansour",
                "labs": [
                    "LabSTICC, UMR 6285 CNRS, ENSTA, Institut Polytechnique de Paris, Brest, France"
                ]
            },
            {
                "name": "Mohamad Khaldi",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering, University of Balamand, Tripoli, Lebanon"
                ]
            },
            {
                "name": "Benoit Clement",
                "labs": [
                    "LabSTICC, UMR 6285 CNRS, ENSTA, Institut Polytechnique de Paris, Brest, France"
                ]
            },
            {
                "name": "Mohammad Ammad-Uddin",
                "labs": [
                    "LabSTICC, UMR 6285 CNRS, ENSTA, Institut Polytechnique de Paris, Brest, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Optimization",
                "Wireless sensor networks",
                "Energy consumption",
                "Heuristic algorithms",
                "Smart agriculture",
                "Clustering algorithms",
                "Trajectory",
                "Data collection",
                "Aerodynamics"
            ],
            "Author Keywords": [
                "Nearest neighbor (NN) algorithm",
                "nonlinear programming (NLP)",
                "path optimization",
                "quadcopter",
                "smart agriculture",
                "travelling salesman problem (TSP)",
                "wireless sensor network (WSN)"
            ]
        }
    },
    {
        "Title": "Aspect Based Feature Extraction in Sentiment Analysis Using Bi-GRU-LSTM Model",
        "Link": "https://ieeexplore.ieee.org/document/10977815/",
        "Abstract": "In Natural Language Processing (NLP), Sentiment Analysis (SA) is a fundamental process which predicts the sentiment expressed in sentences. In contrast to conventional sentiment analysis, Aspect-Based Sentiment Analysis (ABSA) employs a more nuanced approach to assess the sentiment of individual aspects or components within a document or sentence. Its objective is to identify the sentiment polarity, such as positive, neutral, or negative, associated with particular elements disclosed within a sentence. This research introduces a novel sentiment analysis technique that proves to be more efficient in sentiment analysis compared to current methods. The suggested sentiment analysis method undergoes three key phases: 1. Pre-processing 2. Extraction of aspect sentiment and 3. Sentiment analysis classification. The input text data undergoes pre-processing through the implementation of four typical text normalization techniques, which include stemming, stop word elimination, lemmatization, and tokenization. By employing these methods, the provided text data is prepared and fed into the aspect sentiment extraction phase. During the aspect sentiment extraction phase, features are obtained through a series of steps, including enhanced ATE (Aspect Term Extraction), assessment of word length, and determination of cosine similarity. By following these steps, the relevant features are extracted on the basis of aspects and sentiments involved in the text data. Further, a hybrid classification model is proposed to classify sentiments. In this work, two of the Deep Learning (DL) classifiers, Bi-directional Gated Recurrent Unit (Bi-GRU) and Long Short-Term memory (LSTM) are used in proposing a hybrid classification model which classifies the sentiments effectively and provides accurate final predicted results. Moreover, the performance of proposed sentiment analysis technique is analyzed experimentally to show its efficacy over other models.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.2048",
            "Date of Publication": "July 2024",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Shilpi Gupta",
                "labs": [
                    "Shobhit Institute of Engineering & Technology (Deemed to-be University), Meerut, India"
                ]
            },
            {
                "name": "Niraj Singhal",
                "labs": [
                    "Sir Chhotu Ram Institute of Engineering & Technology, Chaudhary Charan Singh University, Meerut, India"
                ]
            },
            {
                "name": "Sheela Hundekari",
                "labs": [
                    "School of Engineering and Technology, Pimpri Chinchwad University, Maval Talegaon, Pune, India"
                ]
            },
            {
                "name": "Kamal Upreti",
                "labs": [
                    "CHRIST University, Delhi NCR Campus, Ghaziabad, India"
                ]
            },
            {
                "name": "Anjali Gautam",
                "labs": [
                    "Manav Rachna International Institute of Research & Studies, Faridabad, Haryana"
                ]
            },
            {
                "name": "Pradeep Kumar",
                "labs": [
                    "JSS Academy of Technical Education, Noida, India"
                ]
            },
            {
                "name": "Rajesh Verma",
                "labs": [
                    "CHRIST University, Delhi NCR Campus, Ghaziabad, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Sentiment analysis",
                "Analytical models",
                "Computational modeling",
                "Feature extraction",
                "Tokenization",
                "Data models",
                "Data mining",
                "Long short term memory",
                "Text processing"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "NLP",
                "text processing",
                "aspect sentiment extraction",
                "dl based sentiment classification"
            ]
        }
    },
    {
        "Title": "Attention in Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/9194070/",
        "Abstract": "Attention is an increasingly popular mechanism used in a wide range of neural architectures. The mechanism itself has been realized in a variety of formats. However, because of the fast-paced advances in this domain, a systematic overview of attention is still missing. In this article, we define a unified model for attention architectures in natural language processing, with a focus on those designed to work with vector representations of the textual data. We propose a taxonomy of attention models according to four dimensions: the representation of the input, the compatibility function, the distribution function, and the multiplicity of the input and/or output. We present the examples of how prior information can be exploited in attention models and discuss ongoing research efforts and open challenges in the area, providing the first extensive categorization of the vast body of literature in this exciting domain.",
        "Details": {
            "DOI": "10.1109/TNNLS.2020.3019893",
            "Date of Publication": "10 September 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Neural Networks and Learning Systems"
        },
        "issn_info": {
            "Print ISSN": "2162-237X",
            "Electronic ISSN": "2162-2388"
        },
        "authors_data": [
            {
                "name": "Andrea Galassi",
                "labs": [
                    "Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy"
                ]
            },
            {
                "name": "Marco Lippi",
                "labs": [
                    "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Modena, Italy"
                ]
            },
            {
                "name": "Paolo Torroni",
                "labs": [
                    "Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Computer architecture",
                "Visualization",
                "Neural networks",
                "Natural language processing",
                "Taxonomy",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "neural attention",
                "neural networks",
                "review",
                "survey"
            ]
        }
    },
    {
        "Title": "Detecting White Supremacist Hate Speech Using Domain Specific Word Embedding With Deep Learning and BERT",
        "Link": "https://ieeexplore.ieee.org/document/9497095/",
        "Abstract": "White supremacist hate speech is one of the most recently observed harmful content on social media. The critical influence of these radical groups is no longer limited to social media and can negatively affect society by promoting racial hatred and violence. Traditional channels of reporting hate speech have proved inadequate due to the tremendous explosion of information and the implicit nature of hate speech. Therefore, it is necessary to detect such speech automatically and in a timely manner. This research investigates the feasibility of automatically detecting white supremacist hate speech on Twitter using deep learning and natural language processing techniques. Two deep learning models are investigated in this research. The first approach utilizes a bidirectional Long Short-Term Memory (BiLSTM) model along with domain-specific word embeddings extracted from white supremacist corpus to capture the semantic of white supremacist slangs and coded words. The second approach utilizes one of the most recent language models, which is Bidirectional Encoder Representations from Transformers (BERT). The BiLSTM model achieved 0.75 F1-score and BERT reached a 0.80 F1-score. Both models are tested on a balanced dataset combined from Twitter and a Stormfront dataset compiled from white supremacist forum.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3100435",
            "Date of Publication": "26 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hind S. Alatawi",
                "labs": [
                    "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Areej M. Alhothali",
                "labs": [
                    "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Kawthar M. Moria",
                "labs": [
                    "Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Deep learning",
                "Blogs",
                "Bit error rate",
                "Support vector machines",
                "Semantics",
                "Media"
            ],
            "Author Keywords": [
                "BERT",
                "deep learning",
                "NLP",
                "white supremacist",
                "hate speech",
                "Twitter"
            ]
        }
    },
    {
        "Title": "Bloom’s Learning Outcomes’ Automatic Classification Using LSTM and Pretrained Word Embeddings",
        "Link": "https://ieeexplore.ieee.org/document/9519690/",
        "Abstract": "Bloom’s taxonomy is a popular model to classify educational learning objectives into different learning levels for three domains including cognitive, affective and psycho motor. Each domain is further detailed into different levels. The cognitive domain includes knowledge, comprehension, application, analysis, synthesis and evaluation levels. In educational institutions, designing course learning outcomes (CLOs) as per different levels of Bloom and mapping of assessment items on designed CLOs is an important task — every semester, faculty and administrators read thousands of statements to complete the tedious task of such mapping of CLOs and assessment items into Bloom’s levels for an improved student learning. This paper proposes LSTM based deep learning model to perform classification of CLOs and assessment items in different levels of Bloom in cognitive domain. Although, there has been some attempts in the literature to automatically assign Bloom’s taxonomy category using keywords-based approach but it suffers from the problem of low accuracy and overlapping of keywords. Initially, when we performed keywords-based approach on our datasets we achieved an overall accuracy of 55% for classification of CLOs and assessment items into Bloom’s taxonomy. The proposed model predicts Bloom’s level for CLO and assessment question item, respectively. The proposed model is simple in terms of the architecture as compared to other deep learning models reported in literature and achieves classification accuracy of 87% and 74% on CLOs and assessment question items, respectively. The proposed model obtained 3% increase in overall accuracy comparing to an existing study for the same task. To the best of our knowledge, this is first attempt towards applying deep learning on classifying educational objectives in Bloom’s levels.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3106443",
            "Date of Publication": "20 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sarang Shaikh",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan",
                    "Department of Information Security and Communication Technology (IIK), Norwegian University of Science and Technology (NTNU), Gjøvik, Norway"
                ]
            },
            {
                "name": "Sher Muhammad Daudpotta",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Ali Shariq Imran",
                "labs": [
                    "Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Taxonomy",
                "Deep learning",
                "Training",
                "Task analysis",
                "Accreditation",
                "Quality assessment"
            ],
            "Author Keywords": [
                "Bloom’s taxonomy",
                "learning objectives",
                "text classification",
                "natural language processing (NLP)",
                "deep learning",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Matching Real-World Facilities to Building Information Modeling Data Using Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/8811494/",
        "Abstract": "Building Information Modeling (BIM) is a promising technology for building informatics. Currently, an increasing number of applications adopt BIM to improve the building operations and facility management. In these applications, matching real-world facilities to the corresponding BIM items is a fundamental yet challenging task. This study addresses this issue using Natural Language Processing. Firstly, a novel BIM hierarchy tree (HiTree) is proposed to model the original spatial structure relationships of a BIM. Then, the locations of facilities are extracted from natural language through processes of word segmentation, keyword extraction, and semantic disambiguation. Thirdly, an algorithm that matches real-world facilities to the BIM data is developed using the HiTree and the extracted locations. Finally, a concrete case for a 35,000 m2 library is presented to verify the effectiveness of the proposed solution. BIM has become a common paradigm in the construction industry, and our scheme can facilitate more applications of BIM in building operations and facility management. One of the most representative applications is integrating the BIM data and information within IoT (Internet of Things) system intelligently by matching the BIM data to real-world facilities.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2937219",
            "Date of Publication": "23 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qingsheng Xie",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing University of Civil Engineering and Architecture, Beijing, China"
                ]
            },
            {
                "name": "Xiaoping Zhou",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing University of Civil Engineering and Architecture, Beijing, China"
                ]
            },
            {
                "name": "Jia Wang",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing University of Civil Engineering and Architecture, Beijing, China"
                ]
            },
            {
                "name": "Xinao Gao",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Processing for Building Big Data, Beijing University of Civil Engineering and Architecture, Beijing, China"
                ]
            },
            {
                "name": "Xi Chen",
                "labs": [
                    "School of Humanity and Law, Beijing University of Civil Engineering and Architecture, Beijing, China"
                ]
            },
            {
                "name": "Chun Liu",
                "labs": [
                    "Hunan Vocational Institute of Safety Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Facilities management",
                "Natural language processing",
                "Semantics",
                "Data mining",
                "Architecture"
            ],
            "Author Keywords": [
                "Building information modeling (BIM)",
                "facility",
                "natural language processing (NLP)",
                "facility management"
            ]
        }
    },
    {
        "Title": "Assessing the Impact of Contextual Information in Hate Speech Detection",
        "Link": "https://ieeexplore.ieee.org/document/10076443/",
        "Abstract": "Social networks and other digital media deal with huge amounts of user-generated contents where hate speech has become a problematic more and more relevant. A great effort has been made to develop automatic tools for its analysis and moderation, at least in its most threatening forms, such as in violent acts against people and groups protected by law. One limitation of current approaches to automatic hate speech detection is the lack of context. The spotlight on isolated messages, without considering any type of conversational context or even the topic being discussed, severely restricts the available information to determine whether a post on a social network should be tagged as hateful or not. In this work, we assess the impact of adding contextual information to the hate speech detection task. We specifically study a subdomain of Twitter data consisting of replies to digital newspapers posts, which provides a natural environment for contextualized hate speech detection. We built a new corpus in Spanish (Rioplatense variant) focused on hate speech associated to the COVID-19 pandemic, annotated using guidelines carefully designed by our interdisciplinary team. Our classification experiments using state-of-the-art transformer-based machine learning techniques show evidence that adding contextual information improves the performance of hate speech detection for two proposed tasks: binary and multi-label prediction, increasing their Macro F1 by 4.2 and 5.5 points, respectively. These results highlight the importance of using contextual information in hate speech detection. Our code, models, and corpus has been made available for further research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3258973",
            "Date of Publication": "20 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Juan Manuel Pérez",
                "labs": [
                    "Instituto de Ciencias de la Computación, CONICET, Universidad de Buenos Aires (UBA), Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Franco M. Luque",
                "labs": [
                    "Facultad de Astronomía, Matemática y Física, Universidad Nacional de Córdoba, Córdoba, Argentina",
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Demian Zayat",
                "labs": [
                    "Facultad de Derecho, Universidad de Buenos Aires, Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Martín Kondratzky",
                "labs": [
                    "Facultad de Filosofía y Letras, Universidad de Buenos Aires, Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Agustín Moro",
                "labs": [
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina",
                    "Universidad Nacional del Centro de la Provincia de Buenos Aires, Tandil, Argentina"
                ]
            },
            {
                "name": "Pablo Santiago Serrati",
                "labs": [
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina",
                    "Instituto de Investigaciones Gino Germani, Facultad de Ciencias Sociales, Universidad de Buenos Aires, Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Joaquín Zajac",
                "labs": [
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina",
                    "Escuela Interdisciplinaria de Altos Estudios Sociales, Universidad de San Martín, San Martín, Argentina"
                ]
            },
            {
                "name": "Paula Miguel",
                "labs": [
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina",
                    "Instituto de Investigaciones Gino Germani, Facultad de Ciencias Sociales, Universidad de Buenos Aires, Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Natalia Debandi",
                "labs": [
                    "Universidad Nacional de Río Negro, Rio Negro, Argentina"
                ]
            },
            {
                "name": "Agustín Gravano",
                "labs": [
                    "Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET), Buenos Aires, Argentina",
                    "Escuela de Negocios, Universidad Torcuato Di Tella, Buenos Aires, Argentina",
                    "Laboratorio de Inteligencia Artificial, Universidad Torcuato Di Tella, Buenos Aires, Argentina"
                ]
            },
            {
                "name": "Viviana Cotik",
                "labs": [
                    "Instituto de Ciencias de la Computación, CONICET, Universidad de Buenos Aires (UBA), Buenos Aires, Argentina",
                    "Departamento de Computación, Facultad de Ciencias Exactas y Naturales, Universidad de Buenos Aires, Buenos Aires, Argentina"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hate speech",
                "Task analysis",
                "Social networking (online)",
                "Fake news",
                "Media",
                "Context awareness"
            ],
            "Author Keywords": [
                "NLP",
                "text classification",
                "hate speech detection",
                "contextual information",
                "Spanish corpus",
                "COVID-19 hate speech"
            ]
        }
    },
    {
        "Title": "Enhancements of Attention-Based Bidirectional LSTM for Hybrid Automatic Text Summarization",
        "Link": "https://ieeexplore.ieee.org/document/9528391/",
        "Abstract": "The automatic generation of a text summary is a task of generating a short summary for a relatively long text document by capturing its key information. In the past, supervised statistical machine learning was widely used for the Automatic Text Summarization (ATS) task, but due to its high dependence on the quality of text features, the generated summaries lack accuracy and coherence, while the computational power involved, and performance achieved, could not easily meet the current needs. This paper proposes four novel ATS models with a Sequence-to-Sequence (Seq2Seq) structure, utilizing an attention-based bidirectional Long Short-Term Memory (LSTM), with added enhancements for increasing the correlation between the generated text summary and the source text, and solving the problem of out-of-vocabulary (OOV) words, suppressing the repeated words, and preventing the spread of cumulative errors in generated text summaries. Experiments conducted on two public datasets confirmed that the proposed ATS models achieve indeed better performance than the baselines and some of the state-of-the-art models considered.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3110143",
            "Date of Publication": "03 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiawen Jiang",
                "labs": [
                    "Department of Computer Science, College of Artificial Intelligence, North China University of Science and Technology, Tangshan, China"
                ]
            },
            {
                "name": "Haiyang Zhang",
                "labs": [
                    "Department of Computer Science, The University of Sheffield, Sheffield, U.K."
                ]
            },
            {
                "name": "Chenxu Dai",
                "labs": [
                    "Department of Computer Science, College of Artificial Intelligence, North China University of Science and Technology, Tangshan, China"
                ]
            },
            {
                "name": "Qingjuan Zhao",
                "labs": [
                    "Department of Computer Science and Engineering, Beihang University, Beijing, China"
                ]
            },
            {
                "name": "Hao Feng",
                "labs": [
                    "Department of Computer Science, College of Artificial Intelligence, North China University of Science and Technology, Tangshan, China"
                ]
            },
            {
                "name": "Zhanlin Ji",
                "labs": [
                    "Department of Computer Science, College of Artificial Intelligence, North China University of Science and Technology, Tangshan, China",
                    "Telecommunications Research Centre (TRC), University of Limerick, Limerick, Ireland"
                ]
            },
            {
                "name": "Ivan Ganchev",
                "labs": [
                    "Telecommunications Research Centre (TRC), University of Limerick, Limerick, Ireland",
                    "Department of Computer Systems, Plovdiv University “Paisii Hilendarski”, Plovdiv, Bulgaria",
                    "Bulgarian Academy of Sciences (BAS), Institute of Mathematics and Informatics (IMI), Sofia, Bulgaria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Natural language processing",
                "Data models",
                "Computational modeling",
                "Task analysis",
                "Semantics",
                "Encoding"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "automatic text summarization (ATS)",
                "sequenceto-sequence (Seq2Seq) model",
                "attention mechanism",
                "bidirectional LSTM (Bi-LSTM)",
                "pointer network",
                "coverage mechanism",
                "mixed learning objective (MLO) function"
            ]
        }
    },
    {
        "Title": "Robust Ensemble Machine Learning Model for Filtering Phishing URLs: Expandable Random Gradient Stacked Voting Classifier (ERG-SVC)",
        "Link": "https://ieeexplore.ieee.org/document/9597532/",
        "Abstract": "As cyber-attacks grow fast and complicated, the cybersecurity industry faces challenges to utilize state-of-the-art technology and strategies to battle the consistently present malicious threats. Phishing is a sort of social engineering attack produced technically and classified as identity theft and complicated attack vectors to steal information of internet users. In this perspective, our main objective of this study is to propose a unique, robust ensemble machine learning model architecture that provides the highest prediction accuracy with a low error rate while proposing few other robust machine learning models. Both supervised and unsupervised techniques were used for the detection process. For our experiments, seven classification algorithms, one clustering algorithm, two ensemble techniques, and two large standard legitimate datasets with 73,575 URLs and 100,000 URLs were used. Two test modes (percentage split, K-Fold cross-validation) were utilized for conducting experiments and final predictions. Mechanisms were developed to (I) identify the best\nN\n, which is the optimal heuristic-based threshold value for splitting words into subwords for each classifier, (II) tune hyperparameters for each classifier to specify the best parameter combination, (III) select prominent features using various feature selection techniques, (IV) propose a robust ensemble model (classifier) called the Expandable Random Gradient Stacked Voting Classifier (ERG-SVC) utilizing a voting classifier along with a model architecture, (V) analyze possible clusters of the dataset using k-means clustering, (VI) thoroughly analyze the gradient boost classifier (GB) with respect to utilizing the “criterion” parameter with the Mean Absolute Error (MAE), Mean Squared Error (MSE), and Friendman_MSE, and(VII) propose a lightweight preprocessor to reduce computational cost and preprocessing time. Initial experiments were carried out with 46 features; the number of features was reduced to 22 after the experiments. The results show that the GB classifier outperformed with the least number of NLP based features by achieving a 98.118% prediction accuracy. Furthermore, our stacking ensemble model and proposed voting ensemble model (ERG-SVC) outperformed other tested approaches and yielded reliable prediction accuracy results in detecting malicious URLs at rates of 98.23% and 98.27%, respectively.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3124628",
            "Date of Publication": "01 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pubudu L. Indrasiri",
                "labs": [
                    "School of Computing and Mathematics, Charles Sturt University, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Malka N. Halgamuge",
                "labs": [
                    "Department of Electrical and Electronic Engineering, The University of Melbourne, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Azeem Mohammad",
                "labs": [
                    "School of Computing and Mathematics, Charles Sturt University, Melbourne, VIC, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Feature extraction",
                "Machine learning",
                "Computational modeling",
                "Support vector machines",
                "Uniform resource locators",
                "Radio frequency"
            ],
            "Author Keywords": [
                "Phishing URLs",
                "cybersecurity",
                "machine learning",
                "NLP",
                "supervised",
                "unsupervised"
            ]
        }
    },
    {
        "Title": "PAC-GPT: A Novel Approach to Generating Synthetic Network Traffic With GPT-3",
        "Link": "https://ieeexplore.ieee.org/document/10287342/",
        "Abstract": "The application of machine learning models, particularly in cybersecurity, has surged significantly in the past few years. However, the effectiveness of these models is predominantly tethered to the quality and breadth of the training data they ingest. The scarcity of realistic datasets within the cybersecurity field constitutes a considerable challenge to the development of industry-grade tools intended for real-world application scenarios. Specifically, current datasets are either significantly outdated or fall short on both qualitative and quantitative fronts, primarily because many organizations exhibit reluctance in data sharing, stemming from privacy concerns or the potential threat to trade secrets. To address this challenge, the paper introduces PAC-GPT, a novel framework to generate reliable synthetic data for machine learning methods based on Open AI’s Generative Pre-trained Transformer 3 (GPT-3). The core components of this framework are two modules, namely a Flow Generator, which is responsible for capturing and regenerating patterns in a series of network packets, and Packet Generator, which can generate individual network packets given the network flow. We also propose a packet generator based on LLM chaining and then proceed to assess, compare, and evaluate its performance using metrics such as loss, accuracy and success rate, concluding that transformers are a suitable approach for synthetic packet generation with minimal fine-tuning performed. Lastly, a streamlined command line interface (CLI) tool has been devised to facilitate the seamless access of this innovative data generation strategy by professionals from various disciplines.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3325727",
            "Date of Publication": "18 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Danial Khosh Kholgh",
                "labs": [
                    "Center for Ubiquitous Computing, University of Oulu, Oulu, Finland"
                ]
            },
            {
                "name": "Panos Kostakos",
                "labs": [
                    "Center for Ubiquitous Computing, University of Oulu, Oulu, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generators",
                "Telecommunication traffic",
                "Computer security",
                "Transformers",
                "Task analysis",
                "Protocols",
                "Machine learning",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "cybersecurity",
                "generative pre-trained transformer",
                "GPT-3",
                "machine learning",
                "NLP",
                "transformer",
                "LLMs"
            ]
        }
    },
    {
        "Title": "A Comprehensive Survey on Arabic Sarcasm Detection: Approaches, Challenges and Future Trends",
        "Link": "https://ieeexplore.ieee.org/document/10049545/",
        "Abstract": "On social media platforms, it is essential to express one’s thoughts, opinions, and reviews. One of the most widely used linguistic forms to criticize or express a person’s ideas with ridicule is sarcasm, where the written text has both intended and unintended meanings. The sarcastic text frequently reverses the polarity of the sentiment. Therefore, detecting sarcasm in the text has a positive impact on the sentiment analysis task and ensures more accurate results. Although Arabic is one of the most frequently used languages for web content sharing, the sarcasm detection of Arabic content is restricted and yet still naive due to several challenges, including the morphological structure of the Arabic language, the variety of dialects, and the lack of adequate data sources. Despite that, researchers started investigating this area by introducing the first Arabic dataset and experiment for irony detection in 2017. Thus, our review focuses on studies published between 2017 and 2022 on Arabic sarcasm detection. We provide a thorough literature review of Artificial Intelligence (AI) techniques and benchmarks used for Arabic sarcasm detection. In addition, the challenges of Arabic sarcasm detection are investigated, along with future directions, focusing on the challenge of publicly available Arabic sarcasm datasets.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3247427",
            "Date of Publication": "22 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alaa Rahma",
                "labs": [
                    "Department of Computer Science, Faculty of Graduate Studies for Statistical Research (FGSSR), Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Shahira Shaaban Azab",
                "labs": [
                    "Department of Computer Science, Faculty of Graduate Studies for Statistical Research (FGSSR), Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Ammar Mohammed",
                "labs": [
                    "Department of Computer Science, Faculty of Graduate Studies for Statistical Research (FGSSR), Cairo University, Giza, Egypt",
                    "Faculty of Computer Science, Modern Science and Arts University, 6th of October City, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Sentiment analysis",
                "Social networking (online)",
                "Feature extraction",
                "Linguistics",
                "Market research",
                "Machine learning",
                "Natural language processing",
                "Deep learning"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "Arabic sarcasm detection",
                "deep learning (DL)",
                "machine learning (ML)",
                "natural language processing (NLP)",
                "sentiment analysis (SA)"
            ]
        }
    },
    {
        "Title": "Context-Aware Deep Learning Model for Detection of Roman Urdu Hate Speech on Social Media Platform",
        "Link": "https://ieeexplore.ieee.org/document/9926094/",
        "Abstract": "Over the last two decades, social media platforms have grown dramatically. Twitter and Facebook are the two most popular social media platforms, with millions of active users posting billions of messages daily. These platforms allow users to have freedom of expression. However, some users exploit this facility by disseminating hate speeches. Manual detection and censorship of such hate speeches are impractical; thus, an automatic detection mechanism is required to detect and counter hate speeches in a real-time environment. Most research in hate speech detection has been carried out in the English language. Still, minimal work has been explored in other languages, mainly Urdu written in Roman Urdu script. A few research have attempted machine learning, and deep learning models for Roman Urdu hate speech detection; however, due to a scarcity of Roman Urdu resources, and a large corpus with defined annotation rules, a robust hate speech detection model is still required. With this motivation, this study contributes in the following manner: we developed annotation guidelines for Roman Urdu Hate Speech. Second, we constructed a new Roman Urdu Hate Speech Dataset (RU-HSD-30K) that was annotated by a team of experts using the annotation rules. To the best of our knowledge, the Bi-LSTM model with an attention layer for Roman-Urdu Hate Speech Detection has not been explored. Therefore, we developed a context-aware Roman Urdu Hate Speech detection model based on Bi-LSTM with an attention layer and used custom word2vec for word embeddings. Finally, we examined the effect of lexical normalization of Roman Urdu words on the performance of the proposed model. Different traditional as well as deep learning models, including LSTM and CNN models, were used as baseline models. The performance of the models was assessed in terms of evaluation metrics like accuracy, precision, recall, and F1-score. The generalization of each model is also evaluated on a cross-domain dataset. Experimental results revealed that Bi-LSTM with attention outperformed the traditional machine learning models and other deep learning models with an accuracy score of 0.875 and an F-Score of 0.885. In addition, the results demonstrated that our suggested model (Bi-LSTM with Attention Layer) is more general than previous models when applied to unseen data. The results confirmed that lexical normalization of Roman Urdu words enhanced the performance of the suggested model.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3216375",
            "Date of Publication": "21 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Bilal",
                "labs": [
                    "Department of Computer Science, Islamia College University Peshawar, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Atif Khan",
                "labs": [
                    "Department of Computer Science, Islamia College University Peshawar, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Salman Jan",
                "labs": [
                    "Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",
                    "Department of Computer Science, Bacha Khan University Charsadda, Charsadda, Pakistan"
                ]
            },
            {
                "name": "Shahrulniza Musa",
                "labs": [
                    "Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",
                    "UniKL–LR University Joint ICT Laboratory (KLR-JIL), Universiti Kuala Lumpur–La Rochelle University, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hate speech",
                "Social networking (online)",
                "Deep learning",
                "Annotations",
                "Feature extraction",
                "Support vector machines",
                "Guidelines",
                "Natural language processing",
                "Social factors",
                "Context awareness"
            ],
            "Author Keywords": [
                "Bi-LSTM",
                "CNN",
                "deep learning",
                "hate speech",
                "LSTM",
                "natural language processing (NLP)",
                "Roman Urdu",
                "social media"
            ]
        }
    },
    {
        "Title": "ChatGPT’s Security Risks and Benefits: Offensive and Defensive Use-Cases, Mitigation Measures, and Future Implications",
        "Link": "https://ieeexplore.ieee.org/document/10443401/",
        "Abstract": "ChatGPT has been acknowledged as a powerful tool that can radically boost productivity across a wide range of industries. It reveals potential in cybersecurity-related tasks such as social engineering. Nevertheless, this possibility raises important concerns regarding the thin line separating moral use of this technology from its harmful usage. It is imperative to address the challenges of distinguishing between legitimate and malevolent use of ChatGPT. This research paper investigates the many concerns of ChatGPT in cybersecurity, privacy and enterprise settings. It covers harmful attacker uses such as injecting malicious prompts, testing brute force attacks, preparing and developing ransomware attacks, etc. Defenders’ proactive activities are also addressed, highlighting ChatGPT’s significance in security operations and threat intelligence. These defensive operations are classified based on the National Institute of Standards and Technology cybersecurity framework. They involve analyzing configuration files, inquiring about authoritative server, improving security in various systems, etc. Moreover, secure enterprise practices and mitigations spread through five classes are proposed, with an emphasis on clear usage standards and guidelines establishment, personally identifiable information protection, adversarial attack prevention, watermarking generated content, etc. An integrated discussion digs into the interaction of offensive and defensive applications, covering ethical and practical concerns. Future attacks are also discussed, along with potential solutions such as content filtering and collaboration. Finally, a comparative analysis with recent research on ChatGPT security concerns is directed. The paper provides a thorough framework to comprehend the range of implications associated with ChatGPT, enabling the navigation of cybersecurity and privacy challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3367792",
            "Date of Publication": "21 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maha Charfeddine",
                "labs": [
                    "REsearch Groups in Intelligent Machines (REGIM-Lab), National Engineering School of Sfax, University of Sfax, Sfax, Tunisia"
                ]
            },
            {
                "name": "Habib M. Kammoun",
                "labs": [
                    "REsearch Groups in Intelligent Machines (REGIM-Lab), National Engineering School of Sfax, University of Sfax, Sfax, Tunisia"
                ]
            },
            {
                "name": "Bechir Hamdaoui",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA"
                ]
            },
            {
                "name": "Mohsen Guizani",
                "labs": [
                    "Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Security",
                "Artificial intelligence",
                "Computer security",
                "Ethics",
                "Guidelines",
                "Privacy",
                "Cyberattack",
                "NIST Standards",
                "Watermarking"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "ChatGPT",
                "computer crime",
                "cyberattack",
                "cyberethics",
                "cybersecurity",
                "defense industry",
                "NLP",
                "privacy"
            ]
        }
    },
    {
        "Title": "A Review of Methodologies for Fake News Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10182240/",
        "Abstract": "Nowadays, with the proliferation of different news sources, fake news detection is becoming a crucial topic to research. Millions of articles are published daily in the press, on social media, and in electronic media, and many of them may be fake. It is common for scammers to spread fake news to mislead people for malicious purposes. For researchers to be able to evaluate fake news, it is necessary to understand its diversity, how to study it, how to detect it, and its limitations. A descriptive literature review has been conducted in this paper to identify more appropriate methodologies for analysing fake news. The review found two broad classifications in the fake news research methodologies: fake news study perspectives and fake news detection techniques. Based on our literature review, we suggest four perspectives to study fake news and two major approaches to detecting it. Fake news can be studied in terms of knowledge, style, propagation and source. In order to detect fake news, there are two major approaches: manually and automatically. There are two types of manual fact-checks: expert-based and crowd-sourced. Automatic techniques are based mainly on data science methods, specifically deep learning and machine learning. A machine learning-based method was found to be more appealing when we evaluated all the automatic methods. Further research will focus on investigating the efficacy of using Bayesian methods for detecting fake news statistically because it is a flexible approach that allows for rapid updating of models in response to new data and has been successfully applied to a wide range of problems across different domains.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3294989",
            "Date of Publication": "13 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mehedi Tajrian",
                "labs": [
                    "School of Computing, Mathematics and Engineering, Charles Sturt University, Wagga Wagga, NSW, Australia"
                ]
            },
            {
                "name": "Azizur Rahman",
                "labs": [
                    "School of Computing, Mathematics and Engineering, Charles Sturt University, Wagga Wagga, NSW, Australia"
                ]
            },
            {
                "name": "Muhammad Ashad Kabir",
                "labs": [
                    "School of Computing, Mathematics and Engineering, Charles Sturt University, Wagga Wagga, NSW, Australia"
                ]
            },
            {
                "name": "Md. Rafiqul Islam",
                "labs": [
                    "School of Computing, Mathematics and Engineering, Charles Sturt University, Wagga Wagga, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Deep learning",
                "Manuals",
                "Knowledge based systems",
                "Chatbots",
                "Bayes methods",
                "Machine learning",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Bayesian modelling",
                "classification",
                "deep learning",
                "fake news detection",
                "machine learning",
                "NLP"
            ]
        }
    },
    {
        "Title": "Finding the Number of Latent Topics With Semantic Non-Negative Matrix Factorization",
        "Link": "https://ieeexplore.ieee.org/document/9521777/",
        "Abstract": "Topic modeling, or identifying the set of topics that occur in a collection of articles, is one of the primary objectives of text mining. One of the big challenges in topic modeling is determining the correct number of topics: underestimating the number of topics results in a loss of information, i.e., omission of topics, underfitting, while overestimating leads to noisy and unexplainable topics and overfitting. In this paper, we consider a semantic-assisted non-negative matrix factorization (NMF) topics model, which we call SeNMFk, based on Kullback-Leibler(KL) divergence and integrated with a method for determining the number of latent topics. SeNMFk involves (i) creating a random ensemble of pairs of matrices whose mean is equal to the initial words-by-documents matrix representing the text corpus and the Shifted Positive Pointwise Mutual Information (SPPMI) matrix, which encodes the context information, respectively, and (ii) jointly factorizing each of these pairs with different number of topics to acquire sets of latent topics that are stable to noise. We demonstrate the performance of our method by identifying the number of topics in several benchmark text corpora, when compared to other state-of-the-art techniques. We also show that the number of document classes in the input text corpus may differ from the number of the extracted latent topics, but these classes can be retrieved by clustering the column-vectors of one of the factor matrices. Additionally, we introduce a software called pyDNMFk to estimate the number of topics. We demonstrate that our unsupervised method, SeNMFk, not only determines the correct number of topics, but also extracts topics with a high coherence and accurately classifies the documents of the corpus.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3106879",
            "Date of Publication": "24 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Raviteja Vangara",
                "labs": [
                    "Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            },
            {
                "name": "Manish Bhattarai",
                "labs": [
                    "Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            },
            {
                "name": "Erik Skau",
                "labs": [
                    "Computer, Computational and Statistical Sciences Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            },
            {
                "name": "Gopinath Chennupati",
                "labs": [
                    "Amazon Alexa, Sunnyvale, CA, USA"
                ]
            },
            {
                "name": "Hristo Djidjev",
                "labs": [
                    "Computer, Computational and Statistical Sciences Division, Los Alamos National Laboratory, Los Alamos, NM, USA",
                    "Bulgarian Academy of Sciences, Institute of Information and Communication Technologies, Sofia, Bulgaria"
                ]
            },
            {
                "name": "Tom Tierney",
                "labs": [
                    "Analytics, Intelligence and Technology Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            },
            {
                "name": "James P. Smith",
                "labs": [
                    "Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            },
            {
                "name": "Valentin G. Stanev",
                "labs": [
                    "Department of Materials Science and Engineering, University of Maryland, College Park, MD, USA"
                ]
            },
            {
                "name": "Boian S. Alexandrov",
                "labs": [
                    "Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Analytical models",
                "Probabilistic logic",
                "Stability analysis",
                "Data models",
                "Coherence",
                "Minimization"
            ],
            "Author Keywords": [
                "Machine learning",
                "NLP",
                "topic modeling",
                "semantic non-negative matrix factorization"
            ]
        }
    },
    {
        "Title": "Forecasting Crude Oil Price Using Event Extraction",
        "Link": "https://ieeexplore.ieee.org/document/9599721/",
        "Abstract": "Research on crude oil price forecasting has attracted tremendous attention from scholars and policymakers due to its significant effect on the global economy. Besides supply and demand, crude oil prices are largely influenced by various factors, such as economic development, financial markets, conflicts, wars, and political events. Most previous research treats crude oil price forecasting as a time series or econometric variable prediction problem. Although recently there have been researches considering the effects of real-time news events, most of these works mainly use raw news headlines or topic models to extract text features without profoundly exploring the event information. In this study, a novel crude oil price forecasting framework, AGESL, is proposed to deal with this problem. In our approach, an open domain event extraction algorithm is utilized to extract underlying related events, and a text sentiment analysis algorithm is used to extract sentiment from massive news. Then a deep neural network integrating the news event features, sentimental features, and historical price features is built to predict future crude oil prices. Empirical experiments are performed on West Texas Intermediate (WTI) crude oil price data, and the results show that our approach obtains superior performance compared with several benchmark methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3124802",
            "Date of Publication": "02 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiangwei Liu",
                "labs": [
                    "School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China"
                ]
            },
            {
                "name": "Xiaohong Huang",
                "labs": [
                    "School of Information Management and Engineering, Shanghai University of Finance and Economics, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Oils",
                "Forecasting",
                "Feature extraction",
                "Predictive models",
                "Biological system modeling",
                "Time series analysis",
                "Support vector machines"
            ],
            "Author Keywords": [
                "Bayesian inference",
                "crude oil price forecasting",
                "event extraction",
                "natural language processing (NLP)",
                "news sentiment"
            ]
        }
    },
    {
        "Title": "Investigating the Emotional Response to COVID-19 News on Twitter: A Topic Modeling and Emotion Classification Approach",
        "Link": "https://ieeexplore.ieee.org/document/9709267/",
        "Abstract": "Media has played an important role in public information on COVID-19. But distressing news, e.g., COVID-19 death tolls, may trigger negative emotions in public, discouraging them from following the news, which, in turn, can limit the effectiveness of the media. To understand people’s emotional response to the COVID-19 news, we have investigated the prevalence of basic human emotions in around 19 million user responses to 1.7 million COVID-19 news posts on Twitter from (English-speaking) media across 12 countries from January 2020 to April 2021. We have used Latent Dirichlet Allocation (LDA) to identify news themes on Twitter. Also, the Robustly Optimized BERT Pretraining Approach (RoBERTa) model was used to identify emotions in the tweets. Our analysis of the Twitter data revealed that anger was the most prevalent emotion in user responses to the news coverage of COVID-19. That was followed by sadness, optimism, and joy, steadily over the period of the study. The prevalence of anger (in user responses) was higher for the news about authorities and politics while optimism and joy were more prevalent for the news about vaccination and educational impacts of COVID-19 respectively. The prevalence of sadness in user responses, however, was the highest for the news about COVID-19 cases and deaths and the impacts on the families, mental health, jails, and nursing homes. We also observed a higher level of anger in the user responses to the (COVID-19) news posted by the USA media accounts (e.g., CNN Politics, Fox News, MSNBC). Optimism, on the other hand, was found to be the highest for Filipino media accounts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3150329",
            "Date of Publication": "09 February 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Francisco Bráulio Oliveira",
                "labs": [
                    "Department of Computer Engineering and Digital Systems, University of São Paulo, São Paulo, Brazil"
                ]
            },
            {
                "name": "Amanul Haque",
                "labs": [
                    "Department of Computer Science, North Carolina State University, Raleigh, NC, USA"
                ]
            },
            {
                "name": "Davoud Mougouei",
                "labs": [
                    "School of Mathematics, Physics and Computing, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Simon Evans",
                "labs": [
                    "School of Psychology, University of Surrey, Guildford, Surrey, U.K."
                ]
            },
            {
                "name": "Jaime Simão Sichman",
                "labs": [
                    "Department of Computer Engineering and Digital Systems, University of São Paulo, São Paulo, Brazil"
                ]
            },
            {
                "name": "Munindar P. Singh",
                "labs": [
                    "Department of Computer Science, North Carolina State University, Raleigh, NC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "COVID-19",
                "Media",
                "Social networking (online)",
                "Blogs",
                "Emotion recognition",
                "Emotional responses",
                "Pandemics"
            ],
            "Author Keywords": [
                "COVID-19",
                "media",
                "news",
                "emotion",
                "Twitter",
                "RoBERTa model",
                "topic modeling",
                "NLP"
            ]
        }
    },
    {
        "Title": "Automated Emerging Cyber Threat Identification and Profiling Based on Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10077593/",
        "Abstract": "The time window between the disclosure of a new cyber vulnerability and its use by cybercriminals has been getting smaller and smaller over time. Recent episodes, such as Log4j vulnerability, exemplifies this well. Within hours after the exploit being released, attackers started scanning the internet looking for vulnerable hosts to deploy threats like cryptocurrency miners and ransomware on vulnerable systems. Thus, it becomes imperative for the cybersecurity defense strategy to detect threats and their capabilities as early as possible to maximize the success of prevention actions. Although crucial, discovering new threats is a challenging activity for security analysts due to the immense volume of data and information sources to be analyzed for signs that a threat is emerging. In this sense, we present a framework for automatic identification and profiling of emerging threats using Twitter messages as a source of events and MITRE ATT&CK as a source of knowledge for threat characterization. The framework comprises three main parts: identification of cyber threats and their names; profiling the identified threat in terms of its intentions or goals by employing two machine learning layers to filter and classify tweets; and alarm generation based on the threat’s risk. The main contribution of our work is the approach to characterize or profile the identified threats in terms of their intentions or goals, providing additional context on the threat and avenues for mitigation. In our experiments, the profiling stage reached an F1 score of 77% in correctly profiling discovered threats.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3260020",
            "Date of Publication": "21 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Renato Marinho",
                "labs": [
                    "Graduate Program in Applied Informatics, University of Fortaleza, Fortaleza, Brazil",
                    "Morphus Labs, Fortaleza, Brazil"
                ]
            },
            {
                "name": "Raimir Holanda",
                "labs": [
                    "Graduate Program in Applied Informatics, University of Fortaleza, Fortaleza, Brazil",
                    "Morphus Labs, Fortaleza, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Security",
                "Knowledge based systems",
                "Cyber threat intelligence",
                "Behavioral sciences",
                "Ransomware"
            ],
            "Author Keywords": [
                "Cyber threat discovery",
                "cyber threat profiling",
                "emerging threats",
                "machine learning",
                "NLP",
                "OSINT"
            ]
        }
    },
    {
        "Title": "Exploring the Potential of Twitter to Understand Traffic Events and Their Locations in Greater Mumbai, India",
        "Link": "https://ieeexplore.ieee.org/document/8913679/",
        "Abstract": "Detecting traffic events and their locations is important for an effective transportation management system and better urban policy making. Traffic events are related to traffic accidents, congestion, parking issues, to name a few. Currently, traffic events are detected through static sensors e.g., CCTV camera, loop detectors. However they have limited spatial coverage and high maintenance cost, especially in developing regions. On the other hand, with Web 2.0 and ubiquitous mobile platforms, people can act as social sensors sharing different traffic events along with their locations. We investigated whether Twitter - a social media platform can be useful to understand urban traffic events from tweets in India. However, such tweets are informal and noisy and containing vernacular geographical information making the location retrieval task challenging. So far most authors have used geotagged tweets to identify traffic events which accounted for only 0.1%-3% or sometimes less than that. Recently Twitter has removed precise geotagging, further decreasing the utility of such approaches. To address these issues, this research explored how ungeotagged tweets could be used to understand traffic events in India. We developed a novel framework that does not only categorize traffic related tweets but also extracts the locations of the traffic events from the tweet content in Greater Mumbai. The results show that an SVM based model performs best detecting traffic related tweets. While extracting location information, a hybrid georeferencing model consists of a supervised learning algorithm and a number of spatial rules outperforms other models. The results suggest people in India, especially in Greater Mumbai often share traffic information along with location mentions, which can be used to complement existing physical transport infrastructure in a cost-effective manner to manage transport services in the urban environment.",
        "Details": {
            "DOI": "10.1109/TITS.2019.2950782",
            "Date of Publication": "26 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Intelligent Transportation Systems"
        },
        "issn_info": {
            "Print ISSN": "1524-9050",
            "Electronic ISSN": "1558-0016"
        },
        "authors_data": [
            {
                "name": "Rahul Deb Das",
                "labs": [
                    "Department of Geography, University of Zurich, Zürich, Switzerland",
                    "IBM Germany R&D, Böblingen, Germany"
                ]
            },
            {
                "name": "Ross S. Purves",
                "labs": [
                    "Department of Geography, University of Zurich, Zürich, Switzerland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Road traffic",
                "Sensors",
                "Task analysis",
                "Urban areas",
                "Accidents"
            ],
            "Author Keywords": [
                "Georeference",
                "jaccard distance",
                "placename",
                "toponym",
                "traffic",
                "tweet",
                "vernacular geography",
                "machine learning (ml)",
                "natural language processing (NLP)",
                "geographical information science (GIS)"
            ]
        }
    },
    {
        "Title": "Deep Entity Linking via Eliminating Semantic Ambiguity With BERT",
        "Link": "https://ieeexplore.ieee.org/document/8911323/",
        "Abstract": "Entity linking refers to the task of aligning mentions of entities in the text to their corresponding entries in a specific knowledge base, which is of great significance for many natural language process applications such as semantic text understanding and knowledge fusion. The pivotal of this problem is how to make effective use of contextual information to disambiguate mentions. Moreover, it has been observed that, in most cases, mention has similar or even identical strings to the entity it refers to. To prevent the model from linking mentions to entities with similar strings rather than the semantically similar ones, in this paper, we introduce the advanced language representation model called BERT (Bidirectional Encoder Representations from Transformers) and design a hard negative samples mining strategy to fine-tune it accordingly. Based on the learned features, we obtain the valid entity through computing the similarity between the textual clues of mentions and the entity candidates in the knowledge base. The proposed hard negative samples mining strategy benefits entity linking from the larger, more expressive pre-trained representations of BERT with limited training time and computing sources. To the best of our knowledge, we are the first to equip entity linking task with the powerful pre-trained general language model by deliberately tackling its potential shortcoming of learning literally, and the experiments on the standard benchmark datasets show that the proposed model yields state-of-the-art results.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2955498",
            "Date of Publication": "25 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiaoyao Yin",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Yangchen Huang",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Bin Zhou",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Aiping Li",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Long Lan",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China",
                    "State Key Laboratory of High Performance Computing, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Yan Jia",
                "labs": [
                    "College of Computer, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Knowledge based systems",
                "Semantics",
                "Joining processes",
                "Bit error rate",
                "Natural languages",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Entity linking",
                "natural language processing (NLP)",
                "bidirectional encoder representations from transformers (BERT)",
                "deep neural network (DNN)"
            ]
        }
    },
    {
        "Title": "The Study on the Text Classification for Financial News Based on Partial Information",
        "Link": "https://ieeexplore.ieee.org/document/9102263/",
        "Abstract": "The goal of this paper is to conduct the study on the text classification for financial news based on partial information. By a fact that an indispensable step for the efficient use of topic information embedded in financial news is the text classification, a new neural network called “All Dataset based on CharCNN (Character Convolutional Neural Networks) and GRU (Gated Recurrent Unit)” (in short, AD-CharCGNN) which extracts a part of the financial article and incorporates both time domain and spatial domain to classify financial texts is proposed. In the study of this paper, we first build a character level vocabulary by reading all characters of the financial dataset, part of each financial text which will be classified is mapped to a high-dimensional spatial vector based on the vocabulary. Then, the vectors are convoluted in the spatial domain to get the text local features, and next, the features are processed by the gated recurrent units to get the features contained time information. Finally, the features which contain spatial and time information will be classified through softmax function to get the text classification results. Our results on the experiments confirm that the network proposed in this paper works effectively with the accuracy of 96.45%, and it seems that the text classification algorithm with the feature by taking only partial text part is more suitable for the application of the practice. Meanwhile, for the input with character level vector, the network is not only suitable for Chinese but also for other languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2997969",
            "Date of Publication": "27 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wenjie Zhao",
                "labs": [
                    "School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China"
                ]
            },
            {
                "name": "Gaoyu Zhang",
                "labs": [
                    "School of Information Management, Shanghai Lixin University of Accounting and Finance, Shanghai, China"
                ]
            },
            {
                "name": "George Yuan",
                "labs": [
                    "Business School, Chengdu University, Chengdu, China",
                    "School of Finbtech, Shanghai Lixin University of Accounting and Finance, Shanghai, China"
                ]
            },
            {
                "name": "Jun Liu",
                "labs": [
                    "Shanghai Lixin University of Accounting and Finance, Shanghai, China"
                ]
            },
            {
                "name": "Hongtao Shan",
                "labs": [
                    "School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China"
                ]
            },
            {
                "name": "Shuyi Zhang",
                "labs": [
                    "Lixin Research Institute, Shanghai Lixin University of Accounting and Finance, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Logic gates",
                "Feature extraction",
                "Machine learning",
                "Neural networks",
                "Finance",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Financial news",
                "natural language processing (NLP)",
                "text processing"
            ]
        }
    },
    {
        "Title": "IT Infrastructure Anomaly Detection and Failure Handling: A Systematic Literature Review Focusing on Datasets, Log Preprocessing, Machine & Deep Learning Approaches and Automated Tool",
        "Link": "https://ieeexplore.ieee.org/document/9615039/",
        "Abstract": "Nowadays, reliability assurance is crucial in components of IT infrastructures. Unavailability of any element or connection results in downtime and triggers monetary and performance casualties. Thus, reliability engineering has been a topic of investigation recently. The system logs become obligatory in IT infrastructure monitoring for failure detection, root cause analysis, and troubleshooting. This Systematic Literature Review (SLR) focuses on detailed analysis based on the various qualitative and performance merits of datasets used, technical approaches utilized, and automated tools developed. The full-text review was directed by Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) methodology. 102 articles were extracted from Scopus, IEEE Explore, WoS, and ACM for a thorough examination. Also, a few more supplementary articles were studied by applying Snowballing technique. The study emphasizes the use of system logs for anomaly or failure detection and prediction. The survey encapsulates the automated tools under various quality merit criteria. This SLR ascertained that machine learning and deep learning-based classification approaches employed on selected features enable enhanced performance than traditional rule-based and method-based approaches. Additionally, the paper discusses research gaps in the existing literature and provides future research directions. The primary intent of this SLR is to perceive and inspect various tools and techniques proposed to mitigate IT infrastructure downtime in the existing literature. This survey will encourage prospective researchers to understand the pros and cons of current methods and pick an excellent approach to solve their identified problems in the field of IT infrastructure.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3128283",
            "Date of Publication": "15 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Deepali Arun Bhanage",
                "labs": [
                    "Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India"
                ]
            },
            {
                "name": "Ambika Vishal Pawar",
                "labs": [
                    "Symbiosis Institute of Technology, Symbiosis International (Deemed University), Pune, India"
                ]
            },
            {
                "name": "Ketan Kotecha",
                "labs": [
                    "Symbiosis Centre for Applied Artificial Intelligence, Symbiosis International (Deemed University), Pune, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tools",
                "Monitoring",
                "Systematics",
                "Deep learning",
                "Anomaly detection",
                "Bibliographies",
                "Machine learning"
            ],
            "Author Keywords": [
                "IT infrastructure monitoring",
                "log analysis",
                "failure detection",
                "failure prediction",
                "machine learning",
                "deep learning",
                "rule-based",
                "NLP",
                "semantic vectorization"
            ]
        }
    },
    {
        "Title": "Multimodal Arabic Rumors Detection",
        "Link": "https://ieeexplore.ieee.org/document/10026837/",
        "Abstract": "Recently, the use of social media platforms has increased with ease of use and fast accessibility, making such platforms a place of rumor proliferation owing to the lack of posting constraints and content authentication. Therefore, there is a need to leverage artificial intelligence techniques to detect rumors on social media platforms to prevent their adverse effects on society and individuals. Most existing works that detect rumors in Arabic target the textual features of the tweet content. Nevertheless, tweets contain different types of content, such as (text, images, videos, and URLs), and the visual features of tweets play an essential role in rumor diffusion. This study proposes an Arabic rumor detection model to detect rumors on Twitter using textual and visual image features through two types of multimodal fusion: early and late fusion. In addition, we leveraged the transfer learning of the pre-trained language and vision models. Different experiments were conducted to select the best textual and visual feature extractors for building a multimodal model. MARBERTv2 was used as a textual feature extractor, whereas the ensemble of VGG-19 and ResNet50 was used as a visual feature extractor to build the multimodal model. Subsequently, the language and vision models of the single models were used as a baseline to compare their results with those of multimodal models. Finally, the experimental results demonstrate the effectiveness of textual features in rumor detection tasks compared to multimodal models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3240373",
            "Date of Publication": "27 January 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rasha M. Albalawi",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Amani T. Jamal",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Alaa O. Khadidos",
                "labs": [
                    "Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Areej M. Alhothali",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Social networking (online)",
                "Visualization",
                "Fake news",
                "Blogs",
                "Videos",
                "Support vector machines",
                "Artificial intelligence",
                "Deep learning",
                "Transfer learning",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "artificial intelligence",
                "deep learning",
                "multimodal fusion",
                "rumor detection",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "Cognitive Dynamic Systems: A Review of Theory, Applications, and Recent Advances",
        "Link": "https://ieeexplore.ieee.org/document/10125578/",
        "Abstract": "The field of cognitive dynamic systems (CDSs) is an emerging area of research, whereby engineering learns from neuroscience. Under this framework, engineering systems are configured in a manner that mimics the human brain and improves the utility and performance of traditional systems. In essence, a CDS builds on Fuster’s paradigm of cognition and is fulfilled with the presence of five cognitive processes: the perception-action cycle, memory, attention, intelligence, and language. When augmented with these processes, a system can be classified as a CDS and is afforded the capabilities of processing information and learning from experience through continued interactions with the environment. Tremendous benefit from adopting the CDS framework has been observed in the literature, especially in the fields of cognitive radio and cognitive radar. More recently, the framework has been extended to other areas, such as control theory, risk control, and the Internet of Things; where the potential for drastic performance improvements has been evident in the literature. This comprehensive article presents a thorough background and exposition of the CDS framework and each field where it has been applied. In addition, we provide a comprehensive review of the recent advancements and related works in each domain by summarizing the key facts relating to the methodologies, findings, and limitations of the surveyed papers. Our novel contributions involve being the first source of centralized information on this topic and forming the foundation for future research efforts by presenting suggestions regarding worthwhile avenues for further investigation.",
        "Details": {
            "DOI": "10.1109/JPROC.2023.3272577",
            "Date of Publication": "16 May 2023",
            "Publisher": "IEEE",
            "Published In": "Proceedings of the IEEE"
        },
        "issn_info": {
            "Print ISSN": "0018-9219",
            "Electronic ISSN": "1558-2256"
        },
        "authors_data": [
            {
                "name": "Waleed Hilal",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, Canada"
                ]
            },
            {
                "name": "S. Andrew Gadsden",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, Canada"
                ]
            },
            {
                "name": "John Yawney",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Dynamical systems",
                "Cognitive radar",
                "Cognitive radio",
                "Neuroscience",
                "Internet of Things",
                "Computer architecture",
                "Internet of Things",
                "Natural language processing",
                "Reinforcement learning",
                "Machine learning"
            ],
            "Author Keywords": [
                "Cognitive control (CC)",
                "cognitive dynamic systems (CDSs)",
                "cognitive Internet of Things (CIoT)",
                "cognitive physical systems cognitive radar cognitive radio cognitive risk control (CRC)",
                "engineering stimation theory machine learning (ML)",
                "natural language processing (NLP)",
                "reinforcement learning (RL)"
            ]
        }
    },
    {
        "Title": "Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10720163/",
        "Abstract": "Large Language Models (LLMs) represent a class of deep learning models adept at understanding natural language and generating coherent responses to various prompts or queries. These models far exceed the complexity of conventional neural networks, often encompassing dozens of neural network layers and containing billions to trillions of parameters. They are typically trained on vast datasets, utilizing architectures based on transformer blocks. Present-day LLMs are multi-functional, capable of performing a range of tasks from text generation and language translation to question answering, as well as code generation and analysis. An advanced subset of these models, known as Multimodal Large Language Models (MLLMs), extends LLM capabilities to process and interpret multiple data modalities, including images, audio, and video. This enhancement empowers MLLMs with capabilities like video editing, image comprehension, and captioning for visual content. This survey provides a comprehensive overview of the recent advancements in LLMs. We begin by tracing the evolution of LLMs and subsequently delve into the advent and nuances of MLLMs. We analyze emerging state-of-the-art MLLMs, exploring their technical features, strengths, and limitations. Additionally, we present a comparative analysis of these models and discuss their challenges, potential limitations, and prospects for future development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482107",
            "Date of Publication": "16 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Minghao Shao",
                "labs": [
                    "New York University Tandon School of Engineering, New York University, New York, NY, USA"
                ]
            },
            {
                "name": "Abdul Basit",
                "labs": [
                    "Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Ramesh Karri",
                "labs": [
                    "New York University Tandon School of Engineering, New York University, New York, NY, USA"
                ]
            },
            {
                "name": "Muhammad Shafique",
                "labs": [
                    "Abu Dhabi Engineering Division, New York University Abu Dhabi, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Transformers",
                "Benchmark testing",
                "Encoding",
                "Large language models",
                "Adaptation models",
                "Market research",
                "Decoding",
                "Training",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "Transformer architecture",
                "generative models",
                "survey",
                "multimodal learning",
                "deep learning",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Abusive Language Detection in Urdu Text: Leveraging Deep Learning and Attention Mechanism",
        "Link": "https://ieeexplore.ieee.org/document/10445262/",
        "Abstract": "The widespread use of the Internet and the tremendous growth of social media have enabled people to connect with each other worldwide. Individuals are free to express themselves online, sharing their photos, videos, and text messages globally. However, such freedom sometimes leads to misuse, as some individuals exploit this platform by posting hateful and abusive comments on forums. The proliferation of abusive language on social media negatively impacts individuals and groups, leading to emotional distress and affecting mental health. It is crucial to automatically detect and filter such abusive content in order to effectively tackle this challenging issue. Detecting abusive language in text messages is challenging due to intentional word concealment and contextual complexity. To counter abusive speech on social media, we need to explore the potential of machine learning (ML) and deep learning (DL) models, particularly those equipped with attention mechanisms. In this study, we utilized popular ML and DL models integrated with attention mechanism to detect abusive language in Urdu text. Our methodology involved employing Count Vectorizer and Term Frequency-Inverse Document Frequency (TF/IDF) to extract n-grams at the word level: Unigrams (Uni), Bigrams (Bi), Trigrams (Tri), and their combination (Uni + Bi + Tri). Initially, we evaluated four traditional ML models—Logistic Regression (LR), Gaussian Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest (RF)—on both proposed and established datasets. The results highlighted that RF model outperformed other conventional models in terms of accuracy, precision, recall, and F1-measure on both datasets. In our implementation of deep learning models, we employed various models integrated with custom fastText and Word2Vec embeddings, each equipped with an attention layer, except for the Convolutional Neural Network (CNN). Our findings indicated that the Bidirectional Long Short-Term Memory (Bi-LSTM) + attention model, utilizing custom Word2Vec embeddings, exhibited improved performance in detecting abusive language on both datasets.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3370232",
            "Date of Publication": "26 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Atif Khan",
                "labs": [
                    "Department of Computer Science, Islamia College Peshawar, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Abrar Ahmed",
                "labs": [
                    "Department of Computer Science, Islamia College Peshawar, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Salman Jan",
                "labs": [
                    "Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",
                    "Department of Computer Science, Bacha Khan University Charsadda, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Muhammad Bilal",
                "labs": [
                    "Department of Computer Science, Islamia College Peshawar, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Megat F. Zuhairi",
                "labs": [
                    "Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hate speech",
                "Feature extraction",
                "Transformers",
                "Support vector machines",
                "Deep learning",
                "Context modeling",
                "Logistic regression",
                "Natural languages",
                "Human factors",
                "Long short term memory"
            ],
            "Author Keywords": [
                "Abusive language",
                "Bi-GRU",
                "Bi-LSTM",
                "deep learning models",
                "fastText",
                "GRU",
                "LSTM",
                "NLP",
                "TF/IDF",
                "Urdu",
                "Word2Vec"
            ]
        }
    },
    {
        "Title": "Application of Quantum Recurrent Neural Network in Low-Resource Language Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10461108/",
        "Abstract": "Text sentiment analysis is an important task in natural language processing and has always been a hot research topic. However, in low-resource regions such as South Asia, where languages like Bengali are widely used, the research interest is relatively low compared to high-resource regions due to limited computational resources, flexible word order, and high inflectional nature of the language. With the development of quantum technology, quantum machine learning models leverage the superposition property of qubits to enhance model expressiveness and achieve faster computation compared to classical systems. To promote the development of quantum machine learning in low-resource language domains, we propose a quantum–classical hybrid architecture. This architecture utilizes a pretrained multilingual bidirectional encoder representations from transformer (BERT) model to obtain vector representations of words and combines the proposed batch upload quantum recurrent neural network (BUQRNN) and parameter nonshared batch upload quantum recurrent neural network (PN-BUQRNN) as feature extraction models for sentiment analysis in Bengali. Our numerical results demonstrate that the proposed BUQRNN structure achieves a maximum accuracy improvement of 0.993% in Bengali text classification tasks while reducing average model complexity by 12%. The PN-BUQRNN structure surpasses the BUQRNN structure once again and outperforms classical architectures in certain tasks.",
        "Details": {
            "DOI": "10.1109/TQE.2024.3373903",
            "Date of Publication": "06 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Quantum Engineering"
        },
        "issn_info": {
            "Electronic ISSN": "2689-1808"
        },
        "authors_data": [
            {
                "name": "Wenbin Yu",
                "labs": [
                    "School of Software, Nanjing University of Information Science and Technology, Nanjing, China",
                    "Nanjing University of Information Science and Technology, Wuxi Institute of Technology, Wuxi, China",
                    "Jiangsu Collaborative Innovation Center of Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China"
                ]
            },
            {
                "name": "Lei Yin",
                "labs": [
                    "School of Software, Nanjing University of Information Science and Technology, Nanjing, China"
                ]
            },
            {
                "name": "Chengjun Zhang",
                "labs": [
                    "Nanjing University of Information Science and Technology, Wuxi Institute of Technology, Wuxi, China",
                    "School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China",
                    "Jiangsu Collaborative Innovation Center of Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China"
                ]
            },
            {
                "name": "Yadang Chen",
                "labs": [
                    "School of Computer Science, Nanjing University of Information Science and Technology, Nanjing, China"
                ]
            },
            {
                "name": "Alex X. Liu",
                "labs": [
                    "Shandong Provincial Key Laboratory of Computer Networks, Shandong Computer Science Center (National Supercomputer Center in Jinan), Qilu University of Technology (Shandong Academy of Sciences), Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Qubit",
                "Text categorization",
                "Integrated circuit modeling",
                "Feature extraction",
                "Computational modeling",
                "Natural language processing",
                "Machine learning",
                "Quantum computing",
                "Recurrent neural networks",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "quantum machine learning",
                "quantum recurrent neural network"
            ]
        }
    },
    {
        "Title": "Mapping Climate Themes From 2008-2021—An Analysis of Business News Using Topic Models",
        "Link": "https://ieeexplore.ieee.org/document/10068212/",
        "Abstract": "India and other developing economies are receiving more attention in the context of climate change due to their rapid rates of economic expansion and large populations. In terms of absolute emissions, India surpassed China and the U.S. in 2018 to become the third-largest emitter. Solving this wicked problem calls for climate action across the stakeholder spectrum involving governments, business communities, and citizens. While extant literature has focused significantly on the role of governments and individual perceptions, the business sector needs to be more represented. In this study, we consider business news media as a platform that reflects the industry engagement in climate change and as a source of information on climate change for business decision-makers. Hence, understanding the topic and themes in the nexus of climate and business is important to evaluate the business sector’s stance towards climate change and how it has evolved. This work explores business news related to climate change using natural language techniques. We first experiment with three topic-modeling techniques, such as LDA, NMF, and BERTopic, on the business news and two more benchmark news datasets. Our test data is derived from digital news archives of ’The Economic Times– India’s leading business news daily. We evaluate the performance based on quantitative metrics commonly used for topic models. We choose the algorithm that provides the highest precision for climate-specific information represented by the test dataset. We then apply the algorithm with the best performance, as evaluated by the experiment, to a large corpus of Indian climate news from E.T. spanning from 2008 -2021. We present how different themes, including industry engagement, evolved over the last two decades. The results suggest that climate cooperation has the highest contribution in the corpus, with other themes on resource management, energy and business gaining traction in recent years.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3256530",
            "Date of Publication": "13 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Swarnalakshmi Umamaheswaran",
                "labs": [
                    "Symbiosis Institute of Business Management, Symbiosis International (Deemed University), Bengaluru, India"
                ]
            },
            {
                "name": "Vandita Dar",
                "labs": [
                    "Symbiosis Institute of Business Management, Symbiosis International (Deemed University), Bengaluru, India"
                ]
            },
            {
                "name": "Eliza Sharma",
                "labs": [
                    "Symbiosis Institute of Business Management, Symbiosis International (Deemed University), Bengaluru, India"
                ]
            },
            {
                "name": "Jikku Susan Kurian",
                "labs": [
                    "Symbiosis Institute of Business Management, Symbiosis International (Deemed University), Bengaluru, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Meteorology",
                "Climate change",
                "Business",
                "Biological system modeling",
                "Analytical models",
                "Social sciences",
                "Matrix decomposition"
            ],
            "Author Keywords": [
                "Climate change",
                "media",
                "topic models",
                "NLP",
                "computational social sciences",
                "experiment"
            ]
        }
    },
    {
        "Title": "Toward Machine Learning Based Binary Sentiment Classification of Movie Reviews for Resource Restraint Language (RRL)—Hindi",
        "Link": "https://ieeexplore.ieee.org/document/10145436/",
        "Abstract": "Sentiment analysis has significantly progressed in English, whereas Hindi research is still nascent. Despite being the third most spoken language worldwide, Hindi remains an RRL. Movie reviews are a treasure trove of opinionated content fueled by people’s passionate engagement with film industry. The proliferation of great use of Hindi in writing reviews has catalyzed our endeavor to devise an approach for bipolar sentiment classification of movie reviews. We compiled and manually annotated a Hindi Language Movie Review (HLMR) dataset comprising 10K reviews for experiments, and challenges associated with Hindi have also been identified. In addition to HLMR, two publicly available IIT-P movie and product review datasets are used. Following dataset preprocessing, we explored TF-ISF with word-level N-gram features for text representation. Studies suggest that performance of machine learning approaches can be enhanced by hyperparameter tuning and ensemble learning. Several baseline classifiers were initially applied, and their parameters were hyper-tuned using Grid search. Subsequently, ensemble-based classifiers were applied individually. Lastly, we propose a simplistic yet powerful stacked ensemble-based architecture (SEBA), which effectively classifies Hindi reviews by leveraging the strengths of both approaches. Comprehensive experiments were conducted on all deployed datasets. Empirical results demonstrate that SEBA outperformed individual baselines and exhibited superior performance with unigrams and TF-ISF as features across deployed datasets. SEBA achieved an accuracy, precision, and recall of 0.808% and an F1-score of 0.807% on the HLMR dataset. These findings strongly advocate for the effectiveness of proposed solution and indicate its suitability for online deployment in binary review classification tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3283461",
            "Date of Publication": "07 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ankita Sharma",
                "labs": [
                    "University School of Information, Communication and Technology, Guru Gobind Singh Indraprastha University, New Delhi, India"
                ]
            },
            {
                "name": "Udayan Ghose",
                "labs": [
                    "University School of Information, Communication and Technology, Guru Gobind Singh Indraprastha University, New Delhi, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Motion pictures",
                "Machine learning",
                "Task analysis",
                "Sentiment analysis",
                "Ensemble learning",
                "Tuning",
                "Oral communication"
            ],
            "Author Keywords": [
                "Hindi",
                "machine learning",
                "movie reviews",
                "NLP",
                "opinion mining",
                "sentiment analysis",
                "stacking ensemble",
                "TF-ISF"
            ]
        }
    },
    {
        "Title": "PermPress: Machine Learning-Based Pipeline to Evaluate Permissions in App Privacy Policies",
        "Link": "https://ieeexplore.ieee.org/document/9861610/",
        "Abstract": "Privacy laws and app stores (e.g., Google Play Store) require mobile apps to have transparent privacy policies to disclose sensitive actions and data collection, such as accessing the phonebook, camera, storage, GPS, and microphone. However, many mobile apps do not accurately disclose their sensitive data access that requires sensitive (‘dangerous’) permissions. Thus, analyzing discrepancies between apps’ permissions and privacy policies facilitates the identification of compliance issues upon which privacy regulators and marketplace operators can act. In this paper, we propose PermPress – an automated machine-learning system to evaluate an Android app’s permission-completeness, i.e., whether its privacy policy matches its dangerous permissions. PermPress combines machine learning techniques with human annotation of privacy policies to establish whether app policies contain permission-relevant information. PermPress leverages MPP-270, an annotated policy corpus, for establishing a gold standard dataset of permission completeness. This corpus shows that only 31% of apps disclose all dangerous permissions in privacy policies. By leveraging the annotated dataset and machine learning techniques, PermPress achieves an AUC score of 0.92 in predicting the permission-completeness of apps. A large-scale evaluation of 164,156 Android apps shows that, on average, 7% of apps do not disclose more than half of their declared dangerous permissions in privacy policies, whereas 60% of apps omit to disclose at least one dangerous permission-related data collection in privacy policies. Our investigation uncovers the non-transparent state of app privacy policies and highlights the need to standardize app privacy policies’ compliance and completeness checking process.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3199882",
            "Date of Publication": "18 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Sajidur Rahman",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Pirouz Naghavi",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Blas Kojusner",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Sadia Afroz",
                "labs": [
                    "Avast Software, Emeryville, CA, USA"
                ]
            },
            {
                "name": "Byron Williams",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Sara Rampazzi",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            },
            {
                "name": "Vincent Bindschaedler",
                "labs": [
                    "Department of Computer and Information Science and Engineering, University of Florida, Gainesville, FL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Data privacy",
                "Smart phones",
                "Machine learning",
                "Data collection",
                "Predictive models",
                "Mobile applications",
                "Androids",
                "Computer applications",
                "Annotations"
            ],
            "Author Keywords": [
                "Privacy policy",
                "android apps",
                "data privacy",
                "NLP",
                "machine learning",
                "annotated dataset"
            ]
        }
    },
    {
        "Title": "RoBERTa-GCN: A Novel Approach for Combating Fake News in Bangla Using Advanced Language Processing and Graph Convolutional Networks",
        "Link": "https://ieeexplore.ieee.org/document/10677406/",
        "Abstract": "In this era of widespread information, combating fake news in less commonly represented languages like Bengali is a significant challenge. Fake news is a critical issue in Bangla, a language that a vast population uses but lacks adequate natural language processing tools. To address this, our research introduces RoBERTa-GCN, a cutting-edge model combining RoBERTa with a graph neural network (GCN) to accurately identify fake news in Bangladesh. The dataset we utilized comprises articles from 22 prominent Bangladeshi news portals covering diverse subjects such as politics, sports, economy, and entertainment. This comprehensive dataset enables the model to learn and adapt to the intricacies of the Bangla language and its news ecosystem, facilitating effective fake news detection across various content categories. Our approach integrates the RoBERTa model, adapted for Bangla, with GCN’s expertise in processing relational data, forming an effective means to differentiate between authentic and fake news. This study’s key achievement is the creation and application of the RoBERTa-GCN model to the Bangla language, an area not thoroughly explored in previous research. The findings show that RoBERTa-GCN surpasses existing methods, achieving impressive accuracy rates of 98.60%, highlighting its capability as a robust model for preserving news integrity in the digital era, especially for the Bangla-speaking population.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3457860",
            "Date of Publication": "11 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mejbah Ahammad",
                "labs": [
                    "Department of Computer Science and Engineering, American International University Bangladesh, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Al Sani",
                "labs": [
                    "Department of Industrial and Production Engineering, Jashore University of Science and Technology, Jashore, Bangladesh"
                ]
            },
            {
                "name": "Khalilur Rahman",
                "labs": [
                    "Department of Computer Science and Engineering, Sylhet Engineering College, Sylhet, Bangladesh"
                ]
            },
            {
                "name": "Md Tanvir Islam",
                "labs": [
                    "Department of Software, Sungkyunkwan University, Suwon, Gyeonggi, South Korea"
                ]
            },
            {
                "name": "Md Mostafizur Rahman Masud",
                "labs": [
                    "School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia"
                ]
            },
            {
                "name": "Md. Mehedi Hassan",
                "labs": [
                    "Computer Science and Engineering Discipline, Khulna University, Khulna, Bangladesh"
                ]
            },
            {
                "name": "Mohammad Abu Tareq Rony",
                "labs": [
                    "Department of Statistics, Noakhali Science and Technology University, Noakhali, Bangladesh"
                ]
            },
            {
                "name": "Shah Md Nazmul Alam",
                "labs": [
                    "Department of Computer Science and Engineering, Arizona State University, Tempe, AZ, USA"
                ]
            },
            {
                "name": "Md. Saddam Hossain Mukta",
                "labs": [
                    "LUT School of Engineering Science, LUT University, Lappeenranta, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Accuracy",
                "Data models",
                "Support vector machines",
                "Long short term memory",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Fake news detection",
                "graph neural network",
                "NLP",
                "Bangla language",
                "deep learning",
                "machine learning",
                "encoder"
            ]
        }
    },
    {
        "Title": "ChatGPT as a Text Annotation Tool to Evaluate Sentiment Analysis on South African Financial Institutions",
        "Link": "https://ieeexplore.ieee.org/document/10684700/",
        "Abstract": "Social media platforms play a significant role in analyzing customer perceptions of financial products and services in today’s culture. These platforms facilitate the immediate and in-depth sharing of thoughts and experiences, offering valuable insights into consumer behaviour. Any customer looking for such a service would surf the internet for reviews and ratings before making a decision, which usually influences their ultimate pick. Feedback and suggestions from friends, family, and coworkers improve customer experiences. Customer reviews play a crucial role in shaping the reputation and profitability of businesses and products offered by financial institutions, often serving as the final assessment of quality and satisfaction during decision-making. Therefore, it is paramount for decision-makers to carefully evaluate customer feedback and understand the sentiment expressed in a given piece of text, which could lead to equity trading, and credit market assessment, and offer invaluable insights that boost the financial performance of the institution. Previous research has used human-annotated text, such as lexicon-based methods, to train machine learning models for sentiment analysis, but the approach did not capture the full range of structure and semantic relationships in natural language. Therefore, our research aims to develop a more comprehensive and accurate sentiment analysis model using advanced natural language processing techniques that could answer questions on various subjects and tasks. To do this, we first crawled customer reviews on Hellopeter, a popular review site, and financial data on the top five financial institutions listed on the Johannesburg Stock Exchange (JSE) in South Africa. After that, we used OpenAI’s ChatGPT as a zero-short learning model to generate human-like annotation tools for different sentiment tasks. The OpenAI ChatGPT feature vector was subsequently fed into BERT, BiLSTM, and a SoftMax function to detect and identify the sentiment of a given sentence. Lastly, we use feature vectors with oversampling methods to address the imbalanced data dilemma and visualise the contribution features of the given piece of text for the customer reviewers. The experiments demonstrated that the method performed as well as or better than the latest and most effective methods on the tested datasets, yielding comparable results. When OpenAI’s ChatGPT was combined with pre-trained BERT and BiLSTM models, it did better overall, with an average score of 98.9%, an F1-measure of 97.7%, and an AUC of 91.90% when oversampling was used. The traditional lexicon-based model got an 86.68% score using SVM and logistic regression and an AUC of 91.90%. The study shows the exceptional performance of OpenAI ChatGPT in detecting the emotional tone or polarity of a given sentence in a customer review, which helps with annotation and understanding the sentiment analysis of an event and how it influences decisions and outcomes. In conclusion, these results underscore the significant advantages of incorporating customer sentiment analysis into financial analysis and decision-making processes as a valuable tool for understanding and prioritizing customer needs and preferences.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3464374",
            "Date of Publication": "20 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Miehleketo Mathebula",
                "labs": [
                    "Department of Computer Science, University of Pretoria, Pretoria, South Africa"
                ]
            },
            {
                "name": "Abiodun Modupe",
                "labs": [
                    "Department of Computer Science, University of Pretoria, Pretoria, South Africa"
                ]
            },
            {
                "name": "Vukosi Marivate",
                "labs": [
                    "Department of Computer Science, University of Pretoria, Pretoria, South Africa"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Social networking (online)",
                "Chatbots",
                "Business",
                "Sentiment analysis",
                "Feature extraction",
                "Vectors",
                "Media",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "Hellopeter",
                "online media",
                "SMOTE",
                "OpenAI ChatGPT",
                "BiLSTM",
                "BERT",
                "NLP"
            ]
        }
    },
    {
        "Title": "Understanding Climate Change and Air Quality Over the Last Decade: Evidence From News and Weather Data Processing",
        "Link": "https://ieeexplore.ieee.org/document/10368013/",
        "Abstract": "Climate change is a phenomenon that is sometimes denied or trivialized. However, in recent years, we have faced extreme phenomena such as fires, floods, excessive temperatures, etc. which affect our physical and mental condition and the environment, often leading to significant material damage. To understand these problems and highlight the meteorological and phenomenological changes encountered in the last decade, time series were web-scraped and analyzed from several open data sources: weather news broadcast in Romania, air quality, temperature, etc. The extraction and organization of data recorded between 2009 and 2023 are formulated as a framework that can be reproduced and replicated to continue the monitoring. The exploratory analysis of the categorical and numerical data highlights intricate patterns and correlations within meteorological conditions across regions and seasons. From temperature trends to air quality fluctuations, the study underscores the dynamic interplay of weather phenomena, paving the way for informed forecasting and deeper climate research. At the same time, data processing includes Latent Dirichlet Allocation, K-prototype clustering analysis, in addition to K-means clustering with dimensional reduction techniques, all of which are employed to further reveal the extreme phenomena in news and regions with higher occurrence. Therefore, in this paper, we propose a data processing framework for multiple datasets and analytics, extracting valuable information on climate change and identifying the exposed regions to extreme phenomena.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3345466",
            "Date of Publication": "21 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alin-Gabriel Văduva",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Mihai Munteanu",
                "labs": [
                    "Department of Statistics and Econometrics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Simona-Vasilica Oprea",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Adela Bâra",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Andreea-Mihaela Niculae",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania",
                    "Doctoral School of Economic Informatics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Climate change",
                "Data analysis",
                "Clustering methods",
                "Meteorology",
                "Data processing",
                "Data mining",
                "Air quality",
                "Time series analysis",
                "Temperature distribution",
                "Resource management"
            ],
            "Author Keywords": [
                "Climate change",
                "news",
                "web scraping",
                "NLP",
                "data analysis",
                "data clustering"
            ]
        }
    },
    {
        "Title": "Children’s Sentiment Analysis From Texts by Using Weight Updated Tuned With Random Forest Classification",
        "Link": "https://ieeexplore.ieee.org/document/10530269/",
        "Abstract": "Sentimental Analysis is considered a computational strategy that helps in identifying and assessing the emotions of people via text documents. Tools and different methods have been adopted for determining both positive and negative emotions in the form of text data analytics by using Machine and Deep Learning techniques. Experimentally, it has been shown that the accuracy of existing text classification models such as Bi-LSTM, Decision Tree, and Ensemble Classifiers is limited by poor quality data, inappropriate hyperparameter tuning, and model-specific bias levels. Additionally, these models are prone to overfitting, high computational overhead, and longer training time. To overcome these limitations, we proposed a hybrid binary classification framework by combining Deep sequential features with the Random Forest (RF) technique. The approach is implemented in four phases: Initially, data preprocessing is performed by employing a Vader sentiment package. In the second step, the deep Long Short Term Memory (LSTM) model was employed to extract deep sequential features corresponding to sad and happy emotions. In the third phase, a bi-orthogonalization algorithm with principal component Analysis (PCA) and Singular Value Decomposition (SVD) was employed to minimize the redundancy and maximize the relevance of extracted features. Finally, a five-fold cross-validation technique was implemented to discriminate sad and happy emotions using the Random Forest (RF) algorithm. Eventually, a grid search approach was implemented for hyperparameter tuning and results were compared with five baseline algorithms (Vanilla LSTM (VLSTM), Support Vector Machine (SVM), Gradient Boosting Machine (GBM), Naïve Bayes (NB), Ada Boost Algorithm (ABA). The experimental outcomes revealed that the proposed model achieved an accuracy rate of 99.631% on the 4000 stories dataset which was superior to all five state-of-the-art methods with a margin of 4.63%, 10.7%, 19.44%, 21%, and 56.5%, respectively. Interestingly, the proposed model realized improved results in terms of other conventional performance metrics also such as precision, recall, specificity, and time complexity. Overall, the proposed model has great potential in educational institutions, child psychology research, and child-friendly content moderation, generally helping in the understanding of the emotions and experiences of children in the digital realm.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3400992",
            "Date of Publication": "14 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Azhar Ahmed Bilal",
                "labs": [
                    "Department of Computer Engineering, Graduate School of Natural and Applied Sciences, Gazi University, Ankara, Turkey",
                    "College of Computer Science and Information Technology, Kirkuk University, Kirkuk, Iraq"
                ]
            },
            {
                "name": "O. Ayhan Erdem",
                "labs": [
                    "Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, Turkey"
                ]
            },
            {
                "name": "Sinan Toklu",
                "labs": [
                    "Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Long short term memory",
                "Feature extraction",
                "Semantics",
                "Support vector machines",
                "Bayes methods",
                "Training",
                "Random forests",
                "Deep learning",
                "Natural language processing",
                "Principal component analysis",
                "Sentiment analysis",
                "Singular value decomposition"
            ],
            "Author Keywords": [
                "Long short term memory (deep LSTM)",
                "natural language processing (NLP)",
                "principal component analysis (PCA)",
                "sentiment analysis (SA)",
                "singular value decomposition (SVD)"
            ]
        }
    },
    {
        "Title": "Fabricated Hadith Detection: A Novel Matn-Based Approach With Transformer Language Models",
        "Link": "https://ieeexplore.ieee.org/document/9931123/",
        "Abstract": "Muslims rely primarily on the Quran and the Hadiths in all their spiritual life and consider them as sacred sources. If the Quran is God’s word, then the Hadiths are God’s instructions in the words of the Prophet Muhammad. Since Hadiths are transmitted through multiple narrators, they have been extensively studied to ensure their authenticity. The purpose of this study is to detect fabricated Hadiths, or Mawdu, which is the type of Hadith most rejected by Muslim scholars. The study utilises the central text and content of Hadith, Matn, rather than solely focusing on Hadith chain of narrators, Sanad. In order to accomplish this, we create and release the first dataset dedicated to Mawdu Hadiths, called MAHADDAT. Furthermore, we set up a Mawdu Hadith (MH) detection system based on a transformer language model, BERT, achieving a 92.47%\nF\n1\nMH\nscore.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3217457",
            "Date of Publication": "26 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kamel Gaanoun",
                "labs": [
                    "Association for Business Intelligence (AMID), Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Mohammed Alsuhaibani",
                "labs": [
                    "Department of Computer Science, College of Computer, Qassim University, Buraydah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Authentication",
                "Transformers",
                "Time-varying systems",
                "Time-domain analysis",
                "Bit error rate",
                "Text categorization",
                "Classification algorithms",
                "Fabrication"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "BERT",
                "fabricated Hadiths",
                "Hadtih authentication",
                "Mawdu",
                "transformers"
            ]
        }
    },
    {
        "Title": "Text Classification Using Document-Relational Graph Convolutional Networks",
        "Link": "https://ieeexplore.ieee.org/document/9947069/",
        "Abstract": "Graph Convolutional Networks (GCNs) have received considerable attention in the field of artificial machine intelligence (AMI) and natural language processing research because they can build more sophisticated accompanying graph structures than traditional neural networks for feature engineering. Graph is used as feature in neural network because it is easy to find relations among nodes. In text classification applications, a GCN can create complex and rich relation-based adjacent matrix graphs as features to be trained. The existing methods, on the other hand, only generated adjacent matrix graphs in GCN at the word-document and word-word levels as features. In this paper, we propose a document-relational GCN to achieve superior accuracy in text classification by adding cumulative term frequency-inverse document frequency (TF-IDF) document-document relations as features. The performance of the proposed method is evaluated using five popular benchmark databases. In addition, different hidden nodes and proportions of document-document features are tested to achieve an advantageous outcome.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3221820",
            "Date of Publication": "14 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chongyi Liu",
                "labs": [
                    "School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Perth, WA, Australia"
                ]
            },
            {
                "name": "Xiangyu Wang",
                "labs": [
                    "School of Civil Engineering and Architecture, East China Jiaotong University, Nanchang, China",
                    "Australian Joint Research Centre for Building Information Modeling, Curtin University, Perth, WA, Australia"
                ]
            },
            {
                "name": "Honglei Xu",
                "labs": [
                    "School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Perth, WA, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Mathematical models",
                "Deep learning",
                "Social networking (online)",
                "Neural networks",
                "Convolutional neural networks",
                "Vocabulary",
                "Feature extraction",
                "Graph neural networks",
                "Text categorization",
                "Text mining",
                "Artificial neural networks",
                "Natural language processing"
            ],
            "Author Keywords": [
                "NLP",
                "document-document relation",
                "graph convolutional network",
                "text classification"
            ]
        }
    },
    {
        "Title": "Runtime and Design Time Completeness Checking of Dangerous Android App Permissions Against GDPR",
        "Link": "https://ieeexplore.ieee.org/document/10373786/",
        "Abstract": "Data and privacy laws, such as the GDPR, require mobile apps that collect and process the personal data of their citizens to have a legally-compliant policy. Since these mobile apps are hosted on app distribution platforms such as Google Play Store and App Store, the app publishers also require the app developers who wish to submit a new app or make changes to an existing app to be transparent about their app privacy practices regarding handling sensitive user data that requires sensitive permissions such as calendar, camera, microphone. To verify compliance with privacy regulators and app distribution platforms, the app privacy policies and permissions are investigated for consistency. However, little has been done to investigate GDPR completeness checking within the Android permission ecosystem. In this paper, we investigate the design and runtime approaches towards completeness checking of sensitive (‘dangerous’) Android permission policy declarations against GDPR. In this paper, we investigate the design and runtime approaches towards completeness checking of dangerous Android permission policy declarations against GDPR. Leveraging the MPP-270 annotated corpus that describes permission declarations in application privacy policies, six natural language processing and language modelling algorithms are developed to measure permission completeness during runtime while a proof of concept Class Unified Modeling Language Diagram (UML) tool is developed to generate GDPR-compliant permission policy declarations using UML diagrams during design time. This paper makes a significant contribution to the identification of appropriate permission policy declaration methodologies that a developer can use to target particular GDPR laws, increasing GDPR compliance by 12% in cases during runtime using BERT word embedding, measuring GDPR compliance in permission policy sentences, and a UML-driven tool to generate compliant permission declarations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3347194",
            "Date of Publication": "25 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ryan Mcconkey",
                "labs": [
                    "School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K."
                ]
            },
            {
                "name": "Oluwafemi Olukoya",
                "labs": [
                    "School of Electronics, Electrical Engineering and Computer Science, Queen’s University Belfast, Belfast, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Privacy",
                "Data privacy",
                "Unified modeling language",
                "General Data Protection Regulation",
                "Law",
                "Runtime",
                "Mobile applications",
                "Security",
                "Requirements engineering",
                "Conformance testing"
            ],
            "Author Keywords": [
                "Security and privacy protection",
                "requirement engineering",
                "regulatory compliance",
                "GDPR",
                "android permission",
                "unified modelling language",
                "privacy policy",
                "NLP",
                "data privacy",
                "mobile applications"
            ]
        }
    },
    {
        "Title": "Automatically Structuring on Chinese Ultrasound Report of Cerebrovascular Diseases via Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/8736947/",
        "Abstract": "The current ultrasound reports in Chinese hospitals are mostly written in free-text format. Important clinical information, such as stenosis rate and plaque location, is recorded in long sentences, especially for ultrasound reports of cerebrovascular diseases. They cannot be directly used for further automatic analysis due to the lack of structure and standardization. The goal of this paper is to assess the feasibility of applying natural language processing technology to automatically extract disease entities and relate information such as the stenosis rate and plaque location from free-text ultrasound reports of cerebrovascular diseases. A structured model using conditional random fields (CRFs) is first constructed. Then, the clause optimizing and segmentation process is performed on a word level to achieve data structuring. Seven categories of terms, including symptoms, plaque locations, diseases, and degree, in 1980 de-identified ultrasound reports were manually annotated as a training dataset. With this model, 7937 ultrasound reports were automatically processed to structure data within 40 min. The true positive rate of the model for each category of terms is 96%, 94%, 97%, 100%, 100%, 100%, and 97%, respectively. The CRF model can be used in Chinese natural language processing to provide support for unstructured data analysis. The standardized segmentation results can be obtained based on medical ontology libraries. However, real-time processing and scientific annotation remain a challenge if intelligent clinical decision making needs to be applied to a real-world clinical environment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2923221",
            "Date of Publication": "14 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pengyu Chen",
                "labs": [
                    "Information Center, Xuanwu Hospital, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Qiao Liu",
                "labs": [
                    "Department of Automation, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Lan Wei",
                "labs": [
                    "Information Center, Xuanwu Hospital, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Beier Zhao",
                "labs": [
                    "Beijing INFI-SAGACITY Technology Company, Ltd., Beijing, China"
                ]
            },
            {
                "name": "Yin Jia",
                "labs": [
                    "Beijing INFI-SAGACITY Technology Company, Ltd., Beijing, China"
                ]
            },
            {
                "name": "Hairong Lv",
                "labs": [
                    "Department of Automation, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Xiaolu Fei",
                "labs": [
                    "Information Center, Xuanwu Hospital, Capital Medical University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Carotid arteries",
                "Ultrasonic imaging",
                "Diseases",
                "Natural language processing",
                "Hidden Markov models",
                "Training",
                "Data models"
            ],
            "Author Keywords": [
                "Natural language processing (NLP)",
                "conditional random fields (CRF)",
                "ultrasound report"
            ]
        }
    },
    {
        "Title": "TBLC-rAttention: A Deep Neural Network Model for Recognizing the Emotional Tendency of Chinese Medical Comment",
        "Link": "https://ieeexplore.ieee.org/document/9097578/",
        "Abstract": "In the current paper, a hybrid depth neural network model, TBLC-rAttention, aiming at Chinese text emotion recognition, is proposed to identify the emotional tendency of the Chinese medical reviews. The model includes the following steps: acquiring and preprocessing the Chinese corpus; mapping the preprocessed text into the word vectors; using Bi-directional Long Short-Term Memory network (Bi-LSTM) with the attention mechanism to acquire the context semantic features of the text; using Convolutional Neural Network (CNN) to obtain local semantics features on the basis of the context semantic features; and inputting the final feature vectors into the classification layer to complete the task of emotion recognition and the classification of the Chinese medical reviews. In this experiment, the corpus data is the comments of 999 cold medicine on a large e-commerce platform. All corpus are divided into three types, including high praise, medium praise and bad review. Classical machine learning models (SVM, NB) and neural network models (CNN, LSTM, Bi-LSTM, BiLSTM-Attention and RCNN) are performed as the comparison benchmarks to assess the category performance of TBLC-rAttention model. All the results were obtained when the training accuracy and test accuracy were stable after 1000 cycles of repeated calculation. The results show that TBLC-rAttention can get better text feature than the reference models, and the text classification accuracy reaches to 99%. In conclusion, the TBLC-rAttention model can identify semantic feature information to the greatest extent. In addition, this study also completes the numerical quantification of the predicted results.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2994252",
            "Date of Publication": "21 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qibing Jin",
                "labs": [
                    "Institute of Automation, Beijing University of Chemical Technology, Beijing, China"
                ]
            },
            {
                "name": "Xingrong Xue",
                "labs": [
                    "Institute of Automation, Beijing University of Chemical Technology, Beijing, China"
                ]
            },
            {
                "name": "Wenjuan Peng",
                "labs": [
                    "Department of Epidemiology and Health Statistics, School of Public Health, Capital Medical University, Beijing, China",
                    "Beijing Municipal Key Laboratory of Clinical Epidemiology, Beijing, China"
                ]
            },
            {
                "name": "Wu Cai",
                "labs": [
                    "Institute of Automation, Beijing University of Chemical Technology, Beijing, China"
                ]
            },
            {
                "name": "Yuming Zhang",
                "labs": [
                    "Institute of Automation, Beijing University of Chemical Technology, Beijing, China"
                ]
            },
            {
                "name": "Ling Zhang",
                "labs": [
                    "Department of Epidemiology and Health Statistics, School of Public Health, Capital Medical University, Beijing, China",
                    "Beijing Municipal Key Laboratory of Clinical Epidemiology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Feature extraction",
                "Semantics",
                "Machine learning",
                "Neural networks",
                "Data models",
                "Data mining"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "bi-directional long short-term memory network (Bi-LSTM)",
                "Chinese medical comment",
                "Chinese text emotion recognition",
                "convolutional neural network (CNN)",
                "deep learning",
                "feature extraction",
                "hybrid neural network",
                "naive bayes (NB)",
                "natural language processing (NLP)",
                "support vector machine (SVM)"
            ]
        }
    },
    {
        "Title": "The World of Defacers: Looking Through the Lens of Their Activities on Twitter",
        "Link": "https://ieeexplore.ieee.org/document/9252879/",
        "Abstract": "Many web-based attacks have been studied to understand how web hackers behave, but web site defacement attacks (malicious content manipulations of victim web sites) and defacers' behaviors have received less attention from researchers. This paper fills this research gap via a computational data-driven analysis of a public database of defacers and defacement attacks and activities of 96 selected defacers who were active on Twitter. We conducted a comprehensive analysis of the data: an analysis of a friendship graph with 10,360 nodes, an analysis on how sentiments of defacers related to attack patterns, and a topical modelling based analysis to study what defacers discussed publicly on Twitter. Our analysis revealed a number of key findings: a modular and hierarchical clustering method can help discover interesting sub-communities of defacers; sentiment analysis can help categorize behaviors of defacers in terms of attack patterns; and topic modelling revealed some focus topics (politics, country-specific topics, and technical discussions) among defacers on Twitter and also geographic links of defacers sharing similar topics. We believe that these findings are useful for a better understanding of defacers' behaviors, which could help design and development of better solutions for detecting defacers and even preventing impeding defacement attacks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3037015",
            "Date of Publication": "09 November 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Çaǧri Burak Aslan",
                "labs": [
                    "STM Defense Technologies Engineering and Trade Inc., Ankara, Turkey",
                    "Computer Engineering Department, Ankara Yildirim Beyazit University, Ankara, Turkey"
                ]
            },
            {
                "name": "Shujun Li",
                "labs": [
                    "School of Computing, University of Kent, Canterbury, U.K.",
                    "Kent Interdisciplinary Research Centre in Cyber Security (KirCCS), University of Kent, Canterbury, U.K."
                ]
            },
            {
                "name": "Fatih V. ÇELEBI",
                "labs": [
                    "Computer Engineering Department, Ankara Yildirim Beyazit University, Ankara, Turkey"
                ]
            },
            {
                "name": "Hao Tian",
                "labs": [
                    "School of Cyber Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Web sites",
                "Computer hacking",
                "Cyberattack",
                "Lenses",
                "Clustering algorithms"
            ],
            "Author Keywords": [
                "Cyber attacks",
                "defacers",
                "defacement",
                "graph-based analysis",
                "hacking",
                "hackers",
                "online social networks",
                "natural language processing",
                "NLP",
                "OSN",
                "sentiment analysis",
                "social media",
                "topic modeling",
                "Twitter"
            ]
        }
    },
    {
        "Title": "AI-Integrated Traffic Information System: A Synergistic Approach of Physics Informed Neural Network and GPT-4 for Traffic Estimation and Real-Time Assistance",
        "Link": "https://ieeexplore.ieee.org/document/10526250/",
        "Abstract": "Traffic management systems have primarily relied on live traffic sensors for real-time traffic guidance. However, this dependence often results in uneven service delivery due to the limited scope of sensor coverage or potential sensor failures. This research introduces a novel approach to overcome this limitation by synergistically integrating a Physics-Informed Neural Network-based Traffic State Estimator (PINN-TSE) with a powerful Natural Language Processing model, GPT-4. The purpose of this integration is to provide a seamless and personalized user experience, while ensuring accurate traffic density prediction even in areas with limited data availability. The innovative PINN-TSE model was developed and tested, demonstrating a promising level of precision with a Mean Absolute Error of less than four vehicles per mile in traffic density estimation. This performance underlines the model’s ability to provide dependable traffic information, even in regions where conventional traffic sensors may be sparsely distributed or data communication is likely to be interrupted. Furthermore, the incorporation of GPT-4 enhances user interactions by understanding and responding to inquiries in a manner akin to human conversation. This not only provides precise traffic updates but also interprets user intentions for a tailored experience. The results of this research showcase an AI-integrated traffic guidance system that outperforms traditional methods in terms of traffic estimation, personalization, and reliability. While the study primarily focuses on a single road segment, the methodology shows promising potential for expansion to network-level traffic guidance, offering even greater accuracy and usability. This paves the way for a smarter and more efficient approach to traffic management in the future.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3399094",
            "Date of Publication": "08 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tewodros Syum Gebre",
                "labs": [
                    "Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Leila Beni",
                "labs": [
                    "Geomatics Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Eden Tsehaye Wasehun",
                "labs": [
                    "Applied Science and Technology Program, College of Science and Technology, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            },
            {
                "name": "Freda Elikem Dorbu",
                "labs": [
                    "Department of Computational Data Science and Engineering, North Carolina A&T State University, Greensboro, NC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sensors",
                "Biological neural networks",
                "Real-time systems",
                "Mathematical models",
                "Predictive models",
                "Information systems",
                "Sensor systems",
                "Traffic control",
                "Traffic congestion",
                "Intelligent transportation systems",
                "Mathematical models",
                "Information systems",
                "Artificial intelligence",
                "Natural language processing"
            ],
            "Author Keywords": [
                "AI-integrated traffic information system",
                "physics informed neural network (PINN)",
                "traffic state estimation (TSE)",
                "traffic data processing",
                "GPT-4",
                "prompt engineering",
                "natural language processing (NLP)",
                "large language models (LLM)",
                "foundation models"
            ]
        }
    },
    {
        "Title": "LLM-Based Text Prediction and Question Answer Models for Aphasia Speech",
        "Link": "https://ieeexplore.ieee.org/document/10636138/",
        "Abstract": "Aphasia, a brain injury-related linguistic problem, hinders communication. Current techniques generally struggle to handle aphasic speech’s intricacies. BERT, short for Bidirectional Encoder Representations from Transformers, is a pre-trained natural language model that utilizes contextual information from both preceding and succeeding words in a sentence to predict the target word. This study uses BERT models to predict and fill in sentences for people with aphasia, using the AphasiaBank dataset. The patients’ transcripts were thoroughly preprocessed, with nonverbal clues and redundant phrases removed. Because of the lack of control data, the accuracy of BERT in predicting masked tokens in aphasic speech was evaluated using a manual rating system with four raters. In addition, BERT was used for question-answering to increase context comprehension, underlining its ability to aid communication for those with aphasia. The preprocessing pipeline used advanced text-cleaning algorithms to ensure input data quality. The evaluation of BERT performance yielded satisfactory results with strong inter-rater reliability. The inter-rater correlation was remarkably strong, overall coefficients ranging from 0.61 to 0.74, suggesting a substantial level of agreement (Fleiss’ Kappa Score: 0.32). BERT’s predictions demonstrated a significant degree of contextual relevance and grammatical accuracy, as proven by ratings that were primarily above 3.0. The box plots also suggested a minimal number of outliers. The goal of this method is to improve the accuracy of speech prediction, which is beneficial for caregivers and speech therapists. BERT shows its nuanced capability in Aphasia sentence completion tests by exhibiting exceptional performance in terms of contextual appropriateness and grammatical correctness, as confirmed by manual evaluation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3443592",
            "Date of Publication": "14 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shamiha Binta Manir",
                "labs": [
                    "Department of EECE, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "K. M. Sajjadul Islam",
                "labs": [
                    "Department of CS, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Praveen Madiraju",
                "labs": [
                    "Department of CS, Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Priya Deshpande",
                "labs": [
                    "Department of EECE, Marquette University, Milwaukee, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Aphasia",
                "Speech recognition",
                "Predictive models",
                "Databases",
                "Speech enhancement",
                "Task analysis",
                "Encoding",
                "Text processing",
                "Brain injuries"
            ],
            "Author Keywords": [
                "Aphasia",
                "BERT models",
                "natural language processing (NLP)",
                "speech prediction",
                "sentence completion",
                "AphasiaBank",
                "transformer models",
                "patient-spoken transcripts",
                "communication aids",
                "speech therapy",
                "text preprocessing"
            ]
        }
    },
    {
        "Title": "A Feasible and Explainable Network Traffic Classifier Utilizing DistilBERT",
        "Link": "https://ieeexplore.ieee.org/document/10176140/",
        "Abstract": "While user-oriented service industries are rapidly growing, various network devices provide these services through different access paths. Accordingly, the network flow is also increasing explosively. As demand for management related to limited network resources increases, the network traffic classification grows to prominence. Usually, a quick classification task was possible with hundreds of data composed of dozens of features. Afterward, deep learning models have proliferated owing to an outstanding performance that overwhelms existing performance based on hundreds of thousands of features and data. However, the deep learning models showing one of the best performances cannot be free from two facts. One is a lot of time and resource consumption. The other is an uncertain explanation of the process. We solved these problems. Firstly, we used two methods to overcome resource constraints. We modified the DistilBERT applied with knowledge distillation for using a compressed model and securing a remarkable performance. We used a lightweight packet with a header and partial payload for feature reduction. Consequently, our XENTC can process four multi-attribute packets simultaneously and effectively by removing the superfluity of features. And it achieved 97.0~98.1% F1 scores. The required time to classify a packet using a trained model is 0.0093 seconds. Therefore, it can be one of the feasible solutions. Secondly, to approach human-understandable XAI, we analyzed the relationships between the features by associating them with the packet structure. At the specific point of the model’s finished training, it was revealed what the important features of the packet were by counting the Top-5 number of times among the attention values. In addition, we visualized the classification performance of the model using t-SNE to enable intuitive understanding.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3293105",
            "Date of Publication": "07 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chang-Yui Shin",
                "labs": [
                    "C4ISR System Development Quality Team, Defense Agency for Technology and Quality, Daejeon, South Korea"
                ]
            },
            {
                "name": "Jee-Tae Park",
                "labs": [
                    "Department of Computer Convergence Software, Major in Network Management, Korea University, Sejong, South Korea"
                ]
            },
            {
                "name": "Ui-Jun Baek",
                "labs": [
                    "Department of Computer Convergence Software, Major in Network Management, Korea University, Sejong, South Korea"
                ]
            },
            {
                "name": "Myung-Sup Kim",
                "labs": [
                    "Department of Computer Convergence Software, Major in Network Management, Korea University, Sejong, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Biological system modeling",
                "Data models",
                "Telecommunication traffic",
                "Payloads",
                "Cryptography",
                "Training"
            ],
            "Author Keywords": [
                "Encrypted network traffic classification",
                "deep learning",
                "NLP",
                "BERT",
                "knowledge distillation",
                "DistilBERT",
                "XAI"
            ]
        }
    },
    {
        "Title": "ArEmotive Bridging the Gap: Automatic Ontology Augmentation Using Zero-Shot Classification for Fine-Grained Sentiment Analysis of Arabic Text",
        "Link": "https://ieeexplore.ieee.org/document/10198434/",
        "Abstract": "Human-computer interaction remains one of the final frontiers to conquer while held in perspective with the rapid developments and technology growth over recent years. It is an arduous task to convey the true human intent to the machine in order to generate a computerized relevant decision in a certain field. In recent years, focus has shifted to cover fields of study that relate to Sentiment Analysis (SA) to improve and ease the tasks of our daily lives. We Propose ArEmotive (Arabic Emotive), a fine-grained sentiment analysis system that is human-independent which can automatically grow its source of information allowing for more precision and a greater dataset each time it is used through ontology augmentation and classification. Our proposed architecture relies on multiple data sources running through certain pipelines to generate a central online repository utilized by any mobile system to access this info-base. This system is important because many researchers in the field of automated ontology alignment and ontology mapping achieved a semi-automated approach to map new ontologies out of old ones or to extend already existing ontologies with data from new ones. ArEmotive identifies fine-grained emotions in text based on a dynamic ontology enriched through ontology alignment, mapping and machine learning assisted classification, resulting in a structure that contributes in: a centralized dataset ever growing to fit the need of the users, a sustainable structure able to allocate new data sources without the need to modify the system, ability to generate appropriate information even with the absence of “parent” sources.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3300737",
            "Date of Publication": "01 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amer Jaradeh",
                "labs": [
                    "Department of Web Sciences, Syrian Virtual University, Damascus, Syria"
                ]
            },
            {
                "name": "Mohamad-Bassam Kurdy",
                "labs": [
                    "Department of Web Sciences, Syrian Virtual University, Damascus, Syria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ontologies",
                "Task analysis",
                "Social networking (online)",
                "Sentiment analysis",
                "Bridges",
                "Blogs",
                "Soft sensors",
                "Emotion recognition"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "fine-grained emotions",
                "ontology augmentation"
            ]
        }
    },
    {
        "Title": "An Enhanced Fake News Detection System With Fuzzy Deep Learning",
        "Link": "https://ieeexplore.ieee.org/document/10568915/",
        "Abstract": "Addressing the intricate challenge of fake news detection, traditionally reliant on the expertise of professional fact-checkers due to the inherent uncertainty in fact-checking processes, this research leverages advancements in language models to propose a novel fuzzy logic-based network. The proposed model is specifically tailored to navigate the uncertainty inherent in the fake news detection task. The evaluation is conducted on the well-established LIAR dataset, a prominent benchmark for fake news detection research, yielding state-of-the-art results. Moreover, recognizing the limitations of the LIAR dataset, we introduce LIAR2 as a new benchmark, incorporating valuable insights from the academic community. Our study presents detailed comparisons and ablation experiments on both LIAR and LIAR2 datasets and establishes our results as the baseline for LIAR2. The proposed approach aims to enhance our understanding of dataset characteristics, contributing to refining and improving fake news detection methodologies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3418340",
            "Date of Publication": "24 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cheng Xu",
                "labs": [
                    "School of Computer Science, University College Dublin, Dublin 4, Ireland"
                ]
            },
            {
                "name": "M-Tahar Kechadi",
                "labs": [
                    "School of Computer Science, University College Dublin, Dublin 4, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Fuzzy logic",
                "Benchmark testing",
                "Social networking (online)",
                "Deep learning",
                "Task analysis",
                "Natural language processing",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Deep learning",
                "fuzzy deep learning",
                "fake news",
                "fake news detection",
                "fact-checking",
                "NLP",
                "classification systems",
                "benchmark"
            ]
        }
    },
    {
        "Title": "AraBig5: The Big Five Personality Traits Prediction Using Machine Learning Algorithm on Arabic Tweets",
        "Link": "https://ieeexplore.ieee.org/document/10189842/",
        "Abstract": "Personality trait prediction has attracted substantial academic interest in recent years as a consequence of its ability to characterize people’s distinctive personality features that distinguish them from others. These features help to anticipate how a person will interact with others in various situations and aid psychologists and therapists in building a profile of their clients. Personality traits are often measured through a traditional pencil-and-paper questionnaire. This questionnaire is considered expensive in terms of time and effort. Therefore, researchers have started using personality trait prediction that automatically analyzes users’ social media textual data by applying machine learning techniques. However, the majority of these studies have been predicted from English texts; only one study has predicted personality traits from Arabic (Egyptian dialect) texts. Furthermore, there is a significant gap between studies that predict personality from English and Arabic texts in terms of machine learning techniques and the dataset used. This study aims to reduce the gap by building a new Arabic dataset with Saudi dialect (AraBig5) and implementing different machine learning models on AraBig5 to predict Big Five personality traits. The results indicate that logistic regression and support vector machine yielded the best average F1 scores of 0.86 and 0.87, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3297981",
            "Date of Publication": "21 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sarah M. Alsubhi",
                "labs": [
                    "Computer Sciences Department, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Areej M. Alhothali",
                "labs": [
                    "Computer Sciences Department, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Amal A. AlMansour",
                "labs": [
                    "Computer Sciences Department, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Feature extraction",
                "Blogs",
                "Predictive models",
                "Metadata",
                "Support vector machines",
                "Psychology",
                "Machine learning",
                "Natural language processing",
                "Psychology",
                "Behavioral sciences",
                "Logistic regression"
            ],
            "Author Keywords": [
                "Arabic tweets",
                "personality traits",
                "big5",
                "machine learning",
                "NLP"
            ]
        }
    },
    {
        "Title": "Fine-Tuned Understanding: Enhancing Social Bot Detection With Transformer-Based Classification",
        "Link": "https://ieeexplore.ieee.org/document/10630818/",
        "Abstract": "In recent years, the proliferation of online communication platforms and social media has given rise to a new wave of challenges, including the rapid spread of malicious bots. These bots, often programmed to impersonate human users, can infiltrate online communities, disseminate misinformation, and engage in various activities detrimental to the integrity of digital discourse. It is becoming more and more difficult to discern a text produced by deep neural networks from that created by humans. Transformer-based Pre-trained Language Models (PLMs) have recently shown excellent results in challenges involving natural language understanding (NLU). The suggested method is to employ an approach to detect bots at the tweet level by utilizing content and fine-tuning PLMs, to reduce the current threat. Building on the recent developments of the BERT (Bidirectional Encoder Representations from Transformers) and GPT-3, the suggested model employs a text embedding approach. This method offers a high-quality representation that can enhance the efficacy of detection. In addition, a Feedforward Neural Network (FNN) was used on top of the PLMs for final classification. The model was experimentally evaluated using the Twitter bot dataset. The strategy was tested using test data that came from the same distribution as their training set. The methodology in this paper involves preprocessing Twitter data, generating contextual embeddings using PLMs, and designing a classification model that learns to differentiate between human users and bots. Experiments were carried out adopting advanced Language Models to construct an encoding of the tweet to create a potential input vector on top of BERT and their variants. By employing Transformer-based models, we achieve significant improvements in bot detection F1-score (93%) compared to traditional methods such as Word2Vec and Global Vectors for Word Representation (Glove). Accuracy improvements ranging from 3% to 24% compared to baselines were achieved. The capability of GPT-4, an advanced Large Language Model (LLM), in interpreting bot-generated content is examined in this research. Additionally, explainable artificial intelligence (XAI) was utilized alongside transformer-based models for detecting bots on social media, enhancing the transparency and reliability of these models.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3440657",
            "Date of Publication": "08 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amine Sallah",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Techniques, Moulay Ismail University of Meknes, Errachidia, Morocco"
                ]
            },
            {
                "name": "El Arbi Abdellaoui Alaoui",
                "labs": [
                    "Department of Sciences, Ecole Normale Supérieure, Moulay Ismail University of Meknes, Errachidia, Morocco"
                ]
            },
            {
                "name": "Said Agoujil",
                "labs": [
                    "École Nationale de Commerce et de Gestion, Moulay Ismail University of Meknes, El Hajeb, Morocco"
                ]
            },
            {
                "name": "Mudasir Ahmad Wani",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohamed Hammad",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Department of Information Technology, Faculty of Computers and Information, Menoufia University, Shibin El Kom, Egypt"
                ]
            },
            {
                "name": "Yassine Maleh",
                "labs": [
                    "Laboratory laSTI, ENSAK, Sultan Moulay Slimane University (USMS), Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Ahmed A. Abd El-Latif",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Center of Excellence in Quantum and Intelligent Computing, Prince Sultan University, Riyadh, Saudi Arabia",
                    "Department of Mathematics and Computer Science, Faculty of Science, Menoufia University, Shebin El-Koom, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Transformers",
                "Social networking (online)",
                "Blogs",
                "Encoding",
                "Bidirectional control",
                "Task analysis",
                "Large language models"
            ],
            "Author Keywords": [
                "BERT",
                "online social networks",
                "NLP",
                "transfer learning",
                "bot classification",
                "transformers",
                "pre-trained language models",
                "explainability",
                "LLM-based prompting"
            ]
        }
    },
    {
        "Title": "CQACD: A Concept Question-Answering System for Intelligent Tutoring Using a Domain Ontology With Rich Semantics",
        "Link": "https://ieeexplore.ieee.org/document/9802991/",
        "Abstract": "In this study, a Concept Question Answering system applied to the Computer Domain (CQACD) for intelligent tutoring is proposed. This system is a dialogue-based Intelligent Tutoring System (ITS) that allows the tutor and student with mixed-initiative and natural language to ask each other questions concerning the basic computer knowledge in the Computer Basics course. CQACD is based on constructivist principles and encourages the learner to construct knowledge rather than merely receiving knowledge, which has the following characteristics: (a) this system employs a domain ontology with rich semantic relationships to model the basic computer knowledge and build up a concept-centric knowledge model, (b) uses a limited number of 80 input templates with description logics to acquire the intention of questions posed by students, (c) a textual entailment algorithm with semantic technologies is proposed to match the input template and assess the student’s contribution to improve the flexibility of the system, and (d) an ontology-driven dialogue management mechanism is proposed, which can quickly form the conversational content and conversational sequence. The experimental results show that CQACD can replace the teachers’ tutoring in large classes and can promote the learning of poor students in large classes better than teachers can. The paper reveals that the domain ontology with rich semantic relationships plays an important role in the Concept Question Answer System (CQAS). It can model CQAS’s discipline knowledge, provide structured domain knowledge for student model, template design and matching, and provide basic architectural architecture for dialogue management.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3185400",
            "Date of Publication": "22 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yu Wen",
                "labs": [
                    "Student Work Department, Guilin Tourism University, Guilin, China"
                ]
            },
            {
                "name": "Xinhua Zhu",
                "labs": [
                    "School of Computer Science and Engineering, Guangxi Normal University, Guilin, China"
                ]
            },
            {
                "name": "Lanfang Zhang",
                "labs": [
                    "Faculty of Education, Guangxi Normal University, Guilin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ontologies",
                "Semantics",
                "Natural languages",
                "Libraries",
                "Cognition",
                "Motion pictures",
                "Knowledge engineering"
            ],
            "Author Keywords": [
                "Dialogue-based ITSs",
                "domain ontology",
                "question-answering system",
                "template logics",
                "ontology learning",
                "NLP",
                "answer reasoning",
                "dialogue management"
            ]
        }
    },
    {
        "Title": "An End-to-End Named Entity Recognition Platform for Vietnamese Real Estate Advertisement Posts and Analytical Applications",
        "Link": "https://ieeexplore.ieee.org/document/9846984/",
        "Abstract": "The volume and complexity of publicly available real estate data have been snowballing. As a result, information extraction and processing have become increasingly challenging and essential for many PropTech (Property Technology) companies worldwide. The challenges are even more pronounced with languages other than English, such as Vietnamese, where few studies in this field have taken place. This paper presents an end-to-end framework for automatically collecting real estate advertisement posts from different data sources, extracting useful information, and storing computed data into proper data warehouses and data marts for the Vietnamese advertisement posts in real estate. After that, one can serve aggregated data for other descriptive and predictive analytics. We combine two models for constructing the most appropriate extraction step: Noise Filtering and Named Entity Recognition (NER). These models can help process initial input data and extract all helpful information. The experiment results show that using\nPhoBERT\nlarge\ncan achieve the best performance compared to other approaches. Furthermore, we can obtain the corresponding F1 scores of the Noise filtering module and the NER module as 0.8697 and 0.8996, respectively. Finally, we utilize Superset for implementing analytic dashboards to visualize the predicted results and serve for further analysis and management processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3195496",
            "Date of Publication": "01 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Binh T. Nguyen",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Vietnam National University Ho Chi Minh City (VNUHCM)—University of Science, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Tung Tran Nguyen Doan",
                "labs": [
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Son Thanh Huynh",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Vietnam National University Ho Chi Minh City (VNUHCM)—University of Science, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Khanh Quoc Tran",
                "labs": [
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM)—University of Information Technology, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "An Trong Nguyen",
                "labs": [
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM)—University of Information Technology, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "An Tran-Hoai Le",
                "labs": [
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM)—University of Information Technology, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Anh Minh Tran",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Vietnam National University Ho Chi Minh City (VNUHCM)—University of Science, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Nhi Ho",
                "labs": [
                    "Hung Thinh Corporation, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Trung T. Nguyen",
                "labs": [
                    "Hung Thinh Corporation, Ho Chi Minh City, Vietnam"
                ]
            },
            {
                "name": "Dang T. Huynh",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Vietnam National University Ho Chi Minh City (VNUHCM)—University of Science, Ho Chi Minh City, Vietnam",
                    "Vietnam National University Ho Chi Minh City (VNUHCM), Ho Chi Minh City, Vietnam",
                    "AISIA Research Laboratory, Ho Chi Minh City, Vietnam"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Information retrieval",
                "Task analysis",
                "Soft sensors",
                "Noise measurement",
                "Urban areas",
                "Training"
            ],
            "Author Keywords": [
                "Information extraction",
                "information retrieval and text mining",
                "NLP applications"
            ]
        }
    },
    {
        "Title": "Lattice Reduction Aided Precoding Design in Downstream G.fast DSL Networks",
        "Link": "https://ieeexplore.ieee.org/document/8972443/",
        "Abstract": "As a non-linear precoding alternative to Tomlinson-Harashima precoding (THP), in this paper, so-called lattice reduction aided precoding (LRP) is considered as a crosstalk precompensation technique for downstream transmission in G.fast DSL networks. First, a practically achievable bit-rate expression for LRP is proposed in function of the precoder and integer matrix. The problem then consists of a joint precoder and integer matrix design in order to maximize the weighted sum-rate (WSR) under per-line power constraints. For a fixed integer matrix, zero-forcing (ZF) precoder matrix design simplifies to gain scaling optimization with complex gain scalars, for which a successive lower bound maximization method is presented. Additionally, it is established that the achievable ZF-LRP sum-rate is upper bounded by the achievable ZF-THP sum-rate at high SNR. For computing the optimal precoder matrix, on the other hand, an efficient method is developed by leveraging on the equivalence between the WSR maximization and the weighted sum of mean squared error (MSE) minimization, leading to a locally-optimal MMSE-LRP solution. Simulations with a measured G.fast cable binder are provided to compare the proposed LRP schemes with THP schemes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2967666",
            "Date of Publication": "28 January 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wouter Lanneer",
                "labs": [
                    "ESAT/STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium"
                ]
            },
            {
                "name": "Carl Nuzman",
                "labs": [
                    "Mathematics of Communication Department, Nokia Bell Labs, Murray Hill, USA"
                ]
            },
            {
                "name": "Yannick Lefevre",
                "labs": [
                    "Fixed Networks Department, Nokia Bell Labs, Antwerp, Belgium"
                ]
            },
            {
                "name": "Paschalis Tsiaflakis",
                "labs": [
                    "Fixed Networks Department, Nokia Bell Labs, Antwerp, Belgium"
                ]
            },
            {
                "name": "Werner Coomans",
                "labs": [
                    "Fixed Networks Department, Nokia Bell Labs, Antwerp, Belgium"
                ]
            },
            {
                "name": "Marc Moonen",
                "labs": [
                    "ESAT/STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven, Leuven, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Precoding",
                "DSL",
                "Lattices",
                "Optimization",
                "Signal to noise ratio",
                "Receivers",
                "Crosstalk"
            ],
            "Author Keywords": [
                "DSL",
                "Gfast",
                "dynamic spectrum management",
                "lattice reduction",
                "non-linear pre- coding (NLP)"
            ]
        }
    },
    {
        "Title": "Synthetic Data Generation Using Large Language Models: Advances in Text and Code",
        "Link": "https://ieeexplore.ieee.org/document/11080380/",
        "Abstract": "This survey reviews how large language models (LLMs) are transforming synthetic training data generation in both natural language and code domains. By producing artificial but task-relevant examples, these models can significantly augment or even substitute for real-world datasets, particularly in scenarios where labeled data is scarce, expensive, or sensitive. This paper surveys recent advances in leveraging LLMs to create synthetic text and code, highlighting key techniques such as prompt-based generation, retrieval-augmented pipelines, and iterative self-refinement. We examine how these methods can enrich low-resource tasks (e.g. classification, question answering) and facilitate code-centric applications (e.g. instruction tuning, code translation, bug repair) through automated verification of functional correctness. Alongside potential benefits—cost-effectiveness, broad coverage, and controllable diversity—we discuss the accompanying challenges, including factual inaccuracies in generated text, insufficient stylistic or distributional realism, and risks of bias amplification. Proposed mitigation strategies range from filtering and weighting synthetic outputs to reinforcement learning with execution feedback in code domains. We conclude by outlining open research directions, such as automated prompt engineering, cross-modal data synthesis, and robust evaluation frameworks, underscoring the growing importance of LLM-generated synthetic data in accelerating AI development while emphasizing ethical and quality safeguards.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3589503",
            "Date of Publication": "15 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mihai Nadǎş",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania"
                ]
            },
            {
                "name": "Laura Dioşan",
                "labs": [
                    "Department of Computer Science, Faculty of Mathematics and Computer Science, Babeş-Bolyai University, Cluj-Napoca, Romania"
                ]
            },
            {
                "name": "Andreea Tomescu",
                "labs": [
                    "KlusAI Laboratories, Cluj-Napoca, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Synthetic data",
                "Surveys",
                "Data models",
                "Translation",
                "Reviews",
                "Tuning",
                "Natural language processing",
                "Large language models",
                "Training"
            ],
            "Author Keywords": [
                "Synthetic data generation",
                "large language models (LLMs)",
                "text data augmentation",
                "code data synthesis",
                "prompt engineering",
                "instruction tuning",
                "machine learning training data",
                "natural language processing (NLP)",
                "code generation",
                "reinforcement learning for code",
                "automated data annotation",
                "bias and fairness in synthetic data",
                "retrieval-augmented generation (RAG)",
                "evaluation of synthetic data",
                "model collapse in LLMs"
            ]
        }
    },
    {
        "Title": "GapPredict – A Language Model for Resolving Gaps in Draft Genome Assemblies",
        "Link": "https://ieeexplore.ieee.org/document/9528958/",
        "Abstract": "Short-read DNA sequencing instruments can yield over 1012 bases per run, typically composed of reads 150 bases long. Despite this high throughput, de novo assembly algorithms have difficulty reconstructing contiguous genome sequences using short reads due to both repetitive and difficult-to-sequence regions in these genomes. Some of the short read assembly challenges are mitigated by scaffolding assembled sequences using paired-end reads. However, unresolved sequences in these scaffolds appear as “gaps”. Here, we introduce GapPredict – An implementation of a proof of concept that uses a character-level language model to predict unresolved nucleotides in scaffold gaps. We benchmarked GapPredict against the state-of-the-art gap-filling tool Sealer, and observed that the former can fill 65.6% of the sampled gaps that were left unfilled by the latter with high similarity to the reference genome, demonstrating the practical utility of deep learning approaches to the gap-filling problem in genome assembly.",
        "Details": {
            "DOI": "10.1109/TCBB.2021.3109557",
            "Date of Publication": "03 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Computational Biology and Bioinformatics"
        },
        "issn_info": {
            "Print ISSN": "1545-5963",
            "Electronic ISSN": "1557-9964"
        },
        "authors_data": [
            {
                "name": "Eric Chen",
                "labs": [
                    "Canada's Michael Smith Genome Sciences Centre, BC Cancer, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "Justin Chu",
                "labs": [
                    "Canada's Michael Smith Genome Sciences Centre, BC Cancer, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "Jessica Zhang",
                "labs": [
                    "Canada's Michael Smith Genome Sciences Centre, BC Cancer, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "René L. Warren",
                "labs": [
                    "Canada's Michael Smith Genome Sciences Centre, BC Cancer, Vancouver, BC, Canada"
                ]
            },
            {
                "name": "Inanc Birol",
                "labs": [
                    "Canada's Michael Smith Genome Sciences Centre, BC Cancer, Vancouver, BC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Genomics",
                "Bioinformatics",
                "Predictive models",
                "Training data",
                "Deep learning",
                "Neural networks",
                "Sequential analysis"
            ],
            "Author Keywords": [
                "Biology and genomics",
                "draft genome",
                "language models",
                "deep learning",
                "NLP",
                "neural networks"
            ]
        }
    },
    {
        "Title": "A Comparative Analysis of Word Embeddings Techniques for Italian News Categorization",
        "Link": "https://ieeexplore.ieee.org/document/10439164/",
        "Abstract": "Text categorization remains a formidable challenge in information retrieval, requiring effective strategies, especially when applied to low-resource languages such as Italian. This paper delves into the intricacies of categorizing Italian news articles, addressing the complexities arising from the language’s unique structure and writing style. The implemented methodology involves preprocessing the text, generating word embeddings, conducting feature engineering to extract meaningful representations, and training a classifier using the document vectors. The evaluation of the model’s performance is done on a partitioned dataset with a training set for model training and a test set for categorization, allowing assessment of its efficacy on unseen data. Within this paper, we assessed fifteen classifiers for the categorization of Italian news articles, scrutinizing eight models and three approaches for combining word embeddings to derive document vectors. We conducted a comparative analysis between established models such as Word2Vec and FastText and six novel Italian models pre-trained on native datasets. A significant highlight of our work is the introduction of an Italian GloVe model, previously absent for the Italian language. The datasets selected for testing the models’ performances are DICE, a dataset of 10,395 crime news articles extracted from an Italian newspaper, and RCV2-it, a collection of 28,405 Italian news stories released by the multinational media company Reuters Ltd. The tests conducted achieved as the best F-scores 84% and 93%. The results underscore the efficacy of the Support Vector Classification algorithm, while also revealing the inefficacy of Gaussian Naive Bayes, Bernoulli Naive Bayes, and Decision Tree models within the domain of text categorization. The comparison of the word embedding models revealed the better performance of Word2Vec and GloVe concerning FastText. The broader impact of this paper lies not only in advancing text categorization methodologies for Italian documents but also in enriching the linguistic landscape by releasing six novel Italian word embedding models.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3367246",
            "Date of Publication": "19 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Federica Rollo",
                "labs": [
                    "Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy"
                ]
            },
            {
                "name": "Giovanni Bonisoli",
                "labs": [
                    "Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy"
                ]
            },
            {
                "name": "Laura Po",
                "labs": [
                    "Department of Engineering “Enzo Ferrari,”, University of Modena and Reggio Emilia, Modena, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Training",
                "Analytical models",
                "Task analysis",
                "Feature extraction",
                "Writing",
                "Complexity theory",
                "Natural language processing",
                "Information retrieval",
                "Media"
            ],
            "Author Keywords": [
                "Text categorization",
                "text classification",
                "word embeddings",
                "natural language processing (NLP)",
                "Word2Vec",
                "FastText",
                "GloVe"
            ]
        }
    },
    {
        "Title": "Tasaheel: An Arabic Automative Textual Analysis Tool—All in One",
        "Link": "https://ieeexplore.ieee.org/document/10347219/",
        "Abstract": "This paper demonstrates Tasaheel, an automative Arabic textual analysis tool. It offers two types of textual analysis utilities: traditional natural language processing tasks; such as stemming, segmentation, normalization, name entity recognition, and part of speech tagging, by integrating open-sourced Arabic natural language processing packages. The second type of utility offers novel corpus analysis methods, including a detailed word use summary of part of speech, emotion, polarity, linguistics, and domain-specific word labeling. Tasaheel is the first Arabic tool that analyses affixes as a type of comprehensive textual analysis, along with options to search and handle data. We anticipate that Tasaheel will be a conducive tool for Arabic textual analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3340520",
            "Date of Publication": "07 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hanen T. Himdi",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Fatmah Y. Assiri",
                "labs": [
                    "Department of Software Engineering, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Task analysis",
                "Text analysis",
                "Tagging",
                "Speech recognition",
                "Morphology",
                "Writing"
            ],
            "Author Keywords": [
                "NLP",
                "text analysis",
                "tool",
                "development"
            ]
        }
    },
    {
        "Title": "Bridging Precision and Complexity: A Novel Machine Learning Approach for Ambiguity Detection in Software Requirements",
        "Link": "https://ieeexplore.ieee.org/document/10843220/",
        "Abstract": "Ambiguity in software requirements is a significant challenge as it often leads to misunderstandings, implementation errors, and costly project delays. This research proposes a hybrid framework that combines rule-based techniques with machine learning to identify ambiguity in software requirements with precision and efficiency. The framework begins with a rule-based model that systematically detects ambiguities using a carefully prepared list of ambiguous phrases. The analysis utilizes a dataset of 1,553 software requirements drawn from diverse project domains. To capture more intricate ambiguities that traditional rule-based systems might miss, the framework integrates TF-IDF vectorization and a Random Forest classifier, enhancing the precision and coverage of classification. In addition, clustering analysis identifies patterns to provide deeper insights into ambiguous requirements, while sentiment analysis explores the relationship between ambiguity and the emotional tone of requirements. Together, these analyses offer a broader understanding of ambiguity trends and stakeholder perceptions. The framework’s performance is validated using standard evaluation metrics, achieving an accuracy of 97%, precision of 97%, recall of 89%, and an F1-score of 92%, significantly surpassing traditional rule-based methodologies. This research advances automatic ambiguity detection by delivering a flexible and interpretable solution. The proposed approach enhances the clarity and quality of software requirements, strengthening requirements engineering practices and supporting more effective software development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3529943",
            "Date of Publication": "15 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahat Izhar",
                "labs": [
                    "Faculty of Engineering, Chiang Mai University (Presidential Scholarship), Chiang Mai, Thailand"
                ]
            },
            {
                "name": "Shahid N. Bhatti",
                "labs": [
                    "Department of Software Engineering, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Sultan A. Alharthi",
                "labs": [
                    "Department of Software Engineering, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Machine learning",
                "Accuracy",
                "Stakeholders",
                "Scalability",
                "Pragmatics",
                "Complexity theory",
                "Support vector machines",
                "Software engineering",
                "Requirements engineering"
            ],
            "Author Keywords": [
                "Software requirements engineering",
                "natural language processing (NLP)",
                "machine learning (ML)",
                "requirements ambiguity",
                "artificial intelligence (AI)",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Optimizing Question Answering Systems in Education: Addressing Domain-Specific Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10721435/",
        "Abstract": "Question Answering (QA) systems are increasingly essential in educational institutions, enhancing both learning and administrative processes by providing quick and accurate answers to user queries. However, existing systems often struggle with accurately classifying and responding to diverse and context-dependent questions, especially when dealing with large knowledge graphs. Predicting the domain of a question can significantly narrow down the search space within a vast knowledge graph, improving the system’s efficiency and accuracy. This study addresses this gap by developing and evaluating domain prediction models. We compare the performance of various deep learning architectures, including Bi-GRU, Bi-LSTM, GRU, and LSTM. Our results demonstrate that the 1-layer Bi-GRU model outperforms the others, achieving the highest test accuracy of 82.13%. Additionally, by employing an ensemble technique that combines models with highest performance measures from each architecture, we further enhance overall performance, achieving an accuracy of 87.14%, which demonstrates improved predictive capability. This work is significant as it provides a robust solution for improving the accuracy and relevance of QA systems in educational settings, thereby enhancing user satisfaction and operational efficiency.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3483224",
            "Date of Publication": "18 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "B. P. Swathi",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "M. Geetha",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Girija Attigeri",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "M. V. Suhas",
                "labs": [
                    "Department of Electronics and Communication Engineering, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Srinithya Halaharvi",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Academy of Higher Education, Manipal Institute of Technology, Manipal, Karnataka, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Question answering (information retrieval)",
                "Accuracy",
                "Predictive models",
                "Deep learning",
                "Knowledge graphs",
                "Data models",
                "Transportation",
                "Training",
                "Sports",
                "Ensemble learning",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Deep learning models",
                "educational institutions",
                "ensemble technique",
                "knowledge graphs",
                "natural language processing (NLP)",
                "natural language understanding (NLU)",
                "predictive models",
                "question answering systems (QAS)",
                "user queries"
            ]
        }
    },
    {
        "Title": "Extraction of Poetic and Non-Poetic Relations From of-Prepositions Using WordNet",
        "Link": "https://ieeexplore.ieee.org/document/9667368/",
        "Abstract": "The main goal of this paper is to extract the semantic relations underpinning the concepts of English prepositional of-constructions derived from poetic and non-poetic datasets, using Princeton WordNet. The problem is addressed by two different algorithms, which are evaluated for their ability to model the different types of resources from which the relations are derived, and for their ability to predict unseen relations. The first algorithm introduces the concept of subsumption hierarchy between relations in order to derive the most general relations associated to each type of data source and identify a set of relations specific to each dataset. The second algorithm investigates the use of a weighting scheme in order to establish the importance of each association extracted. Of particular importance are the notions of subsumption hierarchies between relations (expressed as synset pairs) and the Inverse Relation Frequency (IRF) measure, which is inspired by the Inverse Document Frequency measure used in Information Retrieval. The ontological prospects of using Princeton WordNet and the above algorithms for the creation of ontologies are also briefly discussed. Although the main interest of the proposed methods lies to the identification of conceptual relations particular to poetic resources, the methods followed can be applied and are evaluated on other domains too.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3140030",
            "Date of Publication": "31 December 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Christiana Panayiotou",
                "labs": [
                    "Cyprus University of Technology, Limassol, Cyprus"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Prediction algorithms",
                "Ontologies",
                "Semantics",
                "Task analysis",
                "Frequency measurement",
                "Data mining",
                "Psychology"
            ],
            "Author Keywords": [
                "Semantic relations extraction",
                "ontology learning",
                "NLP",
                "knowledge representation"
            ]
        }
    },
    {
        "Title": "Posts Quality Prediction for StackOverflow Website",
        "Link": "https://ieeexplore.ieee.org/document/10630800/",
        "Abstract": "The development of the computer industry is closely linked to various question-and-answer websites, whose primary function is to discover and solve problems encountered by users. This paper focuses on the quality prediction of question posts on the StackOverflow(SO) website, which can essentially be considered a text classification problem. Given the large number of users, manual moderation becomes inadequate when faced with a vast quantity of user questions. Reducing the occurrence of low-quality questions can effectively alleviate the operational pressure on the website. We preprocess and vectorize the posts to obtain vector representations of the training and testing sets. After training 5 different machine learning models, including decision trees, random forests, naive Bayes, support vector machines, logistic regression, and 2 deep learning models, Bi-LSTM and BERT, these models are compared through experiments by adjusting the values of different parameters. The results indicate that different parameters have a certain impact on the experimental results, and there are significant differences in the quality prediction performance of different models. The lowest accuracy rate only reaches 54%, while the highest accuracy is 92%. The comparison shows that quality assessment based on the attention mechanism model is effective and can be used to predict post-quality.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3440879",
            "Date of Publication": "08 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiawei Hu",
                "labs": [
                    "School of Information Science and Technology, Beijing Forestry University, Beijing, China"
                ]
            },
            {
                "name": "Bo Yang",
                "labs": [
                    "School of Information Science and Technology, Beijing Forestry University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Training",
                "Feature extraction",
                "Random forests",
                "Prediction algorithms",
                "Machine learning",
                "Quality assessment",
                "Deep learning",
                "Text categorization"
            ],
            "Author Keywords": [
                "Quality-analysis",
                "deep-learning",
                "machine-learning",
                "NLP",
                "text classification"
            ]
        }
    },
    {
        "Title": "Empowering Instructors With AI: Evaluating the Impact of an AI-Driven Feedback Tool in Learning Analytics",
        "Link": "https://ieeexplore.ieee.org/document/10970108/",
        "Abstract": "Providing timely and personalized feedback on open-ended student responses is a challenge in education due to the increased workloads and time constraints educators face. While existing research has explored how learning analytic approaches can support feedback provision, previous studies have not sufficiently investigated educators' perspectives of how these strategies affect the assessment process. This article reports on the findings of a study that aimed to evaluate the impact of an artificial intelligence (AI)-driven platform designed to assist educators in the assessment and feedback process. Leveraging large language models and learning analytics, the platform supports educators by offering tag-based recommendations and AI-generated feedback to enhance the quality and efficiency of open-response evaluations. A controlled experiment involving 65 higher education instructors assessed the platform's effectiveness in real-world environments. Using the technology acceptance model, this study investigated the platform's usefulness and relevance from the instructors' perspectives. Moreover, we collected data from the platform's usage to identify partners in instructors' behavior for different scenarios. Results indicate that AI-driven feedback significantly improved instructors' ability to provide detailed personalized feedback in less time. This study contributes to the growing research on AI applications in educational assessment and highlights key considerations for adopting AI-driven tools in instructional settings.",
        "Details": {
            "DOI": "10.1109/TLT.2025.3562379",
            "Date of Publication": "18 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Learning Technologies"
        },
        "issn_info": {
            "Electronic ISSN": "1939-1382"
        },
        "authors_data": [
            {
                "name": "Cleon Xavier",
                "labs": [
                    "Instituto Federal Goiano, Iporá, Brazil",
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Brazil"
                ]
            },
            {
                "name": "Luiz Rodrigues",
                "labs": [
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Brazil"
                ]
            },
            {
                "name": "Newarney Costa",
                "labs": [
                    "Instituto Federal Goiano, Iporá, Brazil",
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Brazil"
                ]
            },
            {
                "name": "Rodrigues Neto",
                "labs": [
                    "Universidade Federal Rural de Pernambuco, Recife, Brazil"
                ]
            },
            {
                "name": "Gabriel Alves",
                "labs": [
                    "Universidade Federal Rural de Pernambuco, Recife, Brazil"
                ]
            },
            {
                "name": "Taciana Pontual Falcão",
                "labs": [
                    "Universidade Federal Rural de Pernambuco, Recife, Brazil"
                ]
            },
            {
                "name": "Dragan Gašević",
                "labs": [
                    "Monash University, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Rafael Ferreira Mello",
                "labs": [
                    "Centro de Estudos e Sistemas Avançados do Recife, Recife, Brazil",
                    "Universidade Federal Rural de Pernambuco, Recife, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Education",
                "Training",
                "Time factors",
                "Technological innovation",
                "Real-time systems",
                "Natural language processing",
                "Large language models",
                "Usability",
                "Technology acceptance model"
            ],
            "Author Keywords": [
                "Educational feedback",
                "large language models (LLMs)",
                "natural language processing (NLP)",
                "open-response assessment",
                "recommendation system"
            ]
        }
    },
    {
        "Title": "A New Fuzzy Multiobjective Geometric Programming in Double Sampling in Presence of Non-Response",
        "Link": "https://ieeexplore.ieee.org/document/8998248/",
        "Abstract": "Non-linear programming problems can be solved efficiently by geometric programming in which non-linear expressions can be expressed by an exponential or power functions. In this paper, Double Sampling Stratification (DSS) strategy is used in multivariate stratified population with unidentified strata weights, for optimum sampling design (OSD) in the presence of non-response to estimate the unidentified population means. The double sampling problem in the presence of non-response is formulated as Fuzzy Multiobjective Convex Programming Problem (FMOCPP). Then, we convert FMOCPP into Fuzzy Single Objective Convex Problem (FSOCP) by using membership function. Dual solution is obtained using LINGO Software by solving FSOCP. The optimum allocations of sample sizes of respondents and non- respondents for both the phases are obtained by applying dual solutions and primal-dual relationship theorem. The given technique is illustrated by projecting a numerical problem.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2973935",
            "Date of Publication": "13 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shafiullah",
                "labs": [
                    "Department of Mathematics, F. H. (P. G.) College, Nidhauli Kalan, India"
                ]
            },
            {
                "name": "Mohd Tariq",
                "labs": [
                    "Department of Electrical Engineering, ZHCET, Aligarh Muslim University, Aligarh, India"
                ]
            },
            {
                "name": "Abdul Bari",
                "labs": [
                    "Department of Statistics and Operations Research, Aligarh Muslim University, Aligarh, India"
                ]
            },
            {
                "name": "Abdul R. Beig",
                "labs": [
                    "Department of Electrical and Computer Engineering, Advanced Power and Energy Center, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Programming",
                "Sociology",
                "Statistics",
                "Fuzzy set theory",
                "Resource management",
                "Software"
            ],
            "Author Keywords": [
                "Double sampling",
                "dual solutions (DS)",
                "fuzzy programming (FP)",
                "geometric programming (GP)",
                "non-linear programming (NLP)",
                "non-response",
                "non- respondents (NR)",
                "orthogonality condition (OC)",
                "respondents (R)"
            ]
        }
    },
    {
        "Title": "Context-Adaptive-Based Image Captioning by Bi-CARU",
        "Link": "https://ieeexplore.ieee.org/document/10210039/",
        "Abstract": "Image captions are abstract expressions of content representations using text sentences, helping readers to better understand and analyse information between different media. With the advantage of encoder-decoder neural networks, captions can provide a rational structure for tasks such as image coding and caption prediction. This work introduces a Convolutional Neural Network (CNN) to Bidirectional Content-Adaptive Recurrent Unit (Bi-CARU) (CNN-to-Bi-CARU) model that performs bidirectional structure to consider contextual features and captures major feature from image. The encoded feature coded form image is respectively passed into the forward and backward layer of CARU to refine the word prediction, providing contextual text output for captioning. An attention layer is also introduced to collect the feature produced by the context-adaptive gate in CARU, aiming to compute the weighting information for relationship extraction and determination. In experiments, the proposed CNN-to-Bi-CARU model outperforms other advanced models in the field, achieving better extraction of contextual information and detailed representation of image captions. The model obtains a score of 41.28 on BLEU@4, 31.23 on METEOR, 61.07 on ROUGE-L, and 133.20 on CIDEr-D, making it competitive in the image captioning of MSCOCO dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3302512",
            "Date of Publication": "07 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sio-Kei Im",
                "labs": [
                    "Faculty of Applied Sciences, Macao Polytechnic University, Macau, China",
                    "Engineering Research Centre of Applied Technology on Machine Translation and Artificial Intelligence of Ministry of Education, Macao Polytechnic University, Macau, China"
                ]
            },
            {
                "name": "Ka-Hou Chan",
                "labs": [
                    "Faculty of Applied Sciences, Macao Polytechnic University, Macau, China",
                    "Engineering Research Centre of Applied Technology on Machine Translation and Artificial Intelligence of Ministry of Education, Macao Polytechnic University, Macau, China",
                    "Faculty of Science, The Hong Kong Polytechnic University, Hong Kong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Decoding",
                "Logic gates",
                "Visualization",
                "Semantics",
                "Transformers",
                "Convolutional neural networks",
                "Context modeling",
                "Natural language processing",
                "Text categorization",
                "Text processing"
            ],
            "Author Keywords": [
                "CNN",
                "RNN",
                "NLP",
                "image captioning",
                "Bi-CARU",
                "context-adaptive",
                "attention mechanism"
            ]
        }
    },
    {
        "Title": "A Critical Analysis of Benchmarks, Techniques, and Models in Medical Visual Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/10323452/",
        "Abstract": "This paper comprehensively reviews medical VQA models, structures, and datasets, focusing on combining vision and language. Over 75 models and their statistical and SWOT (Strengths, Weaknesses, Opportunities, Threats) analyses were compared and analyzed. The study highlights whether the researchers in the general field influence those in the medical field. According to an analysis of text encoding techniques, LSTM is the approach that is utilized the most (42%), followed by non-text methods (14%) and BiLSTM (12%), whereas VGGNet (40%) and ResNet (22%) are the most often used vision methods, followed by Ensemble approaches (16%). Regarding fusion techniques, 14% of the models employed non-specific methods, while SAN (13%) and concatenation (10%) were frequently used. The study identifies LSTM-VGGNet and LSTM-ResNet combinations as the primary approaches in medical VQA, with 18% and 15% usage rates, respectively. The statistical analysis of medical VQA from 2018 to 2023 and individual yearly analyses reveals consistent preferences for LSTM and VGGNet, except in 2018 when ResNet was more commonly used. The SWOT analysis provides insights into the strengths and weaknesses of medical VQA research, highlighting areas for future exploration. These areas include addressing limited dataset sizes, enhancing question diversity, mitigating unimodal bias, exploring multi-modal datasets, leveraging external knowledge, incorporating multiple images, ensuring practical medical application integrity, improving model interpretation, and refining evaluation methods. This paper’s findings contribute to understanding medical VQA and offer valuable guidance for future researchers aiming to make advancements in this field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3335216",
            "Date of Publication": "20 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Suheer Al-Hadhrami",
                "labs": [
                    "Computer Science Department, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Engineering, Hadhramout University, Al Mukalla, Yemen"
                ]
            },
            {
                "name": "Mohamed El Bachir Menai",
                "labs": [
                    "Computer Science Department, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Saad Al-Ahmadi",
                "labs": [
                    "Computer Science Department, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed Alnafessah",
                "labs": [
                    "King Abdulaziz City for Science and Technology, Riyadh, Saudi Arabia",
                    "Massachusetts Institute of Technology, Cambridge, MA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biomedical imaging",
                "Surveys",
                "Visualization",
                "Question answering (information retrieval)",
                "Analytical models",
                "Statistical analysis",
                "Tumors",
                "Deep learning"
            ],
            "Author Keywords": [
                "Attention",
                "deep learning",
                "NLP",
                "QA",
                "question answering",
                "SWOT analysis",
                "vision",
                "vision and language",
                "visual",
                "VQA"
            ]
        }
    },
    {
        "Title": "Joint Topic-Emotion Modeling in Financial Texts: A Novel Approach to Investor Sentiment and Market Trends",
        "Link": "https://ieeexplore.ieee.org/document/10870333/",
        "Abstract": "This paper presents a novel approach to financial text analysis by jointly modeling topics and emotions within financial news and social media discussions, thereby advancing market trend understanding and investor sentiment analysis. Leveraging the Neural Variational Document Model (NVDM) for topic modeling, we effectively capture the thematic structure across global financial texts, achieving a coherence score of 0.68 and a perplexity of −8.5. For emotion classification, a fine-tuned FinBERT model yields an accuracy of 96.3%, F1 Score of 97.8%, precision of 98.3%, and recall of 97.5%. Our integrated framework not only uncovers the latent topics driving market discourse but also associates these topics with nuanced emotional states, providing a comprehensive perspective on financial sentiment. This joint modeling approach enhances the interpretability and reliability of financial market predictions, offering a scalable solution for understanding investor emotions with significant potential for applications in market analysis, trading strategies, and economic forecasting.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3538760",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md Nazmul Hossain Mir",
                "labs": [
                    "Master of Science in Cybersecurity, Washington University of Science and Technology, Alexandria, VA, USA"
                ]
            },
            {
                "name": "Md Shahriar Mahmud Bhuiyan",
                "labs": [
                    "Washington University of Science and Technology, Alexandria, VA, USA"
                ]
            },
            {
                "name": "Md Al Rafi",
                "labs": [
                    "Washington University of Science and Technology, Alexandria, VA, USA"
                ]
            },
            {
                "name": "Gourab Nicholas Rodrigues",
                "labs": [
                    "Washington University of Science and Technology, Alexandria, VA, USA"
                ]
            },
            {
                "name": "M. F. Mridha",
                "labs": [
                    "Department of Computer Science and Engineering, American International University-Bangladesh, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Abdul Hamid",
                "labs": [
                    "Department of Information Technology, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Mostafa Monowar",
                "labs": [
                    "Department of Information Technology, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Md Zia Uddin",
                "labs": [
                    "SINTEF Digital, Oslo, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Sentiment analysis",
                "Context modeling",
                "Social networking (online)",
                "Coherence",
                "Accuracy",
                "Predictive models",
                "Text analysis",
                "Finance",
                "Data models"
            ],
            "Author Keywords": [
                "Financial text analysis",
                "joint topic modeling",
                "emotion classification",
                "neural variational document model (NVDM)",
                "FinBERT",
                "sentiment analysis",
                "natural language processing (NLP)",
                "financial market prediction",
                "social media analysis"
            ]
        }
    },
    {
        "Title": "Optimizing Customer Satisfaction Through Sentiment Analysis: A BERT-Based Machine Learning Approach to Extract Insights",
        "Link": "https://ieeexplore.ieee.org/document/10714245/",
        "Abstract": "In the era of digital transformation, customer feedback has become crucial for improving service quality. This study aims to enhance customer satisfaction through sentiment analysis utilizing machine learning techniques, with additional case studies conducted to ensure comprehensive method validation. Traditional sentiment analysis methods frequently fail to manage the complexity and volume of feedback data, yielding to less accurate insights. To address this challenge, we analyzed six machine learning models: Naïve Bayes, Support Vector Machine (SVM), Long Short-Term Memory (LSTM), Random Forest, AdaBoost, and BERT, with a particular focus on BERT. Our results demonstrate that BERT outperformed the other models in terms of both accuracy and processing speed, achieving an accuracy of up to 95%. The excellence of BERT in managing large and complex datasets provides a more precise sentiment analysis, which can significantly improve service quality and customer loyalty, while increasing company revenue by up to 15%. This research advances to the field of sentiment analysis by validating the effectiveness of BERT over traditional models through extensive comparative analysis and practical case studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3478835",
            "Date of Publication": "11 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ben Rahman",
                "labs": [
                    "Faculty of Communication and Information Technology, Nasional University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Maryani",
                "labs": [
                    "Information System Department, Bina Nusantara University, Jakarta, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Long short term memory",
                "Analytical models",
                "Support vector machines",
                "Accuracy",
                "Encoding",
                "Bidirectional control",
                "Bayes methods",
                "Transformers",
                "Machine learning",
                "Machine learning"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "BERT",
                "machine learning",
                "customer satisfaction",
                "data preprocessing",
                "transformer models",
                "service quality",
                "NLP"
            ]
        }
    },
    {
        "Title": "FedITD: A Federated Parameter-Efficient Tuning With Pre-Trained Large Language Models and Transfer Learning Framework for Insider Threat Detection",
        "Link": "https://ieeexplore.ieee.org/document/10721229/",
        "Abstract": "Insider threats cause greater losses than external attacks, prompting organizations to invest in detection systems. However, there exist challenges: 1) Security and privacy concerns prevent data sharing, making it difficult to train robust models and identify new attacks. 2) The diversity and uniqueness of organizations require localized models, as a universal solution could be more effective. 3) High resource costs, delays, and data security concerns complicate building effective detection systems. This paper introduces FedITD, a flexible, hierarchy, and federated framework with local real-time detection systems, combining Large Language Models (LLM), Federated Learning (FL), Parameter Efficient Tuning (PETuning), and Transfer Learning (TF) for insider threat detection. FedITD uses FL to protect privacy while indirect integrating client information and employs PETuning methods (Adapter, BitFit, LoRA) with LLMs (BERT, RoBERTa, XLNet, DistilBERT) to reduce resource use and time delay. FedITD customizes client models and optimizes performance via transfer learning without central data transfer, further enhancing the detection of new attacks. FedITD outperforms other federated learning methods and its performance is very close to the best centrally trained method. Extensive experiment results show FedITD’s superior performance, adaptability to varied data, and reduction of resource costs, achieving an optimal balance in detection capabilities across source data, unlabeled local data, and global data. Alternative PETuning implementations are also explored in this paper.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482988",
            "Date of Publication": "17 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhi Qiang Wang",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Haopeng Wang",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Abdulmotaleb El Saddik",
                "labs": [
                    "Multimedia Communications Research Laboratory (MCRLab), School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada",
                    "Department of Computer Vision, MBZUAI, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Adaptation models",
                "Threat assessment",
                "Tuning",
                "Security",
                "Organizations",
                "Costs",
                "Computational modeling",
                "Transfer learning",
                "Deep learning",
                "Computer security",
                "Data augmentation",
                "Artificial intelligence",
                "Machine learning"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "insider threat",
                "deep learning",
                "transformer",
                "BERT",
                "RoBERTa",
                "XLNet",
                "DistilBERT",
                "GPT",
                "data augmentation",
                "artificial intelligence",
                "machine learning",
                "pre-trained LLM",
                "PETuning",
                "adapter",
                "LoRA",
                "BitFit",
                "LLM",
                "NLP"
            ]
        }
    },
    {
        "Title": "Leveraging LLMs for Financial News Analysis and Macroeconomic Indicator Nowcasting",
        "Link": "https://ieeexplore.ieee.org/document/10738800/",
        "Abstract": "Approximating macroeconomic indicators is challenging due to the complex interaction of various factors, including global and national economic trends, political decisions, and unpredictable events like pandemics and natural disasters. These complexities, combined with the volatility of economies and the limitations of available data, make accurate modeling difficult. Sentiment analysis of economic news offers a novel approach to this challenge by providing instantaneous insights into public mood and market trends, capturing psychological and behavioral aspects that traditional models may miss. This method can enhance understanding of consumer confidence, investment trends, and stock market performance, for instance. In this study, we developed a dictionary and transformer-based sentiment model applied to over two decades of Hungarian economic news. To improve the model’s accuracy, we utilized large language models (LLMs) with active learning to efficiently augment the manually labeled sentiment dataset. We then compared the resulting sentiment-based time series with macroeconomic indicators such as GDP (Gross Domestic Product), PMI (Purchasing Managers’ Index), and unemployment rate. Our results show that integrating LLMs significantly enhances the accuracy of the sentiment models, and the sentiment-based indicators can serve as effective nowcasting tools for the inspected macroeconomic indicators.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3488363",
            "Date of Publication": "30 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lívia Réka Ónozó",
                "labs": [
                    "Digitalization Technology Department, Central Bank of Hungary, Budapest, Hungary",
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            },
            {
                "name": "Frigyes Viktor Arthur",
                "labs": [
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            },
            {
                "name": "Bálint Gyires-Tóth",
                "labs": [
                    "Department of Telecommunications and Artificial Intelligence, Budapest University of Technology and Economics, Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Macroeconomics",
                "Economics",
                "Transformers",
                "Analytical models",
                "Data models",
                "Sentiment analysis",
                "Predictive models",
                "Market research",
                "Encoding"
            ],
            "Author Keywords": [
                "GDP",
                "large language model (LLM)",
                "macroeconomic indicator",
                "natural language processing (NLP)",
                "PMI",
                "sentiment analysis",
                "unemployment rate"
            ]
        }
    },
    {
        "Title": "Unleashing Competitive Intelligence: News Mining Analysis on Technology Trends and Digital Health Driving Healthcare Innovation",
        "Link": "https://ieeexplore.ieee.org/document/10314044/",
        "Abstract": "In the rapidly evolving digital health landscape, technology plays a pivotal role in transforming the healthcare industry. With the exponential growth of data, uncovering valuable insights has become a daunting task. In today's data-driven world, healthcare businesses must leverage emerging technologies to stay informed about trends in their field. This research article presents a novel approach to deriving business insights in digital health enabled by technology, including artificial intelligence, and other cutting-edge advancements. We propose a methodology that utilizes news mining techniques and the global data on events, location, and tone database as the primary data source. By employing natural language processing, we developed a practical way of extracting relevant insights from vast amounts of public data. We implemented named-entity recognition (NER) enriched with the DBpedia knowledge base and relationship extraction. In addition, we leveraged graph analytics to identify and analyze the most significant concept relationships within the text corpus and their evolution in time. By integrating these advanced techniques, healthcare businesses can extract actionable insights from public datasets, empowering them to stay abreast of emerging trends and advancements in digital health, such as telehealth, precision medicine, or medical imaging.",
        "Details": {
            "DOI": "10.1109/TEM.2023.3326233",
            "Date of Publication": "09 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Engineering Management"
        },
        "issn_info": {
            "Print ISSN": "0018-9391",
            "Electronic ISSN": "1558-0040"
        },
        "authors_data": [
            {
                "name": "Enrique Cano-Marin",
                "labs": [
                    "Computer Science Department, University of Alcalá, Alcalá de Henares, Spain"
                ]
            },
            {
                "name": "Salvador Sánchez-Alonso",
                "labs": [
                    "Computer Science Department, University of Alcalá, Alcalá de Henares, Spain"
                ]
            },
            {
                "name": "Marçal Mora-Cantallops",
                "labs": [
                    "Computer Science Department, University of Alcalá, Alcalá de Henares, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Data mining",
                "Electronic healthcare",
                "Market research",
                "Telemedicine",
                "Databases"
            ],
            "Author Keywords": [
                "Digital health",
                "emerging technologies",
                "entity extraction",
                "graph analytics",
                "healthcare",
                "innovation",
                "natural language processing (NLP)",
                "news mining"
            ]
        }
    },
    {
        "Title": "Nonlinear Model Predictive Control Based Adaptive Equivalent Consumption Minimization Strategy for Fuel Cell Electric Bus Considering Average Travel Speed",
        "Link": "https://ieeexplore.ieee.org/document/10253947/",
        "Abstract": "This paper presents nonlinear model predictive control based adaptive equivalent consumption minimization strategy for fuel cell hybrid electric bus. The proposed strategy considers the average travel speed profile of road segments in route of fuel cell hybrid electric bus. The proposed nonlinear model predictive control based adaptive equivalent consumption minimization strategy determines the optimal control input by considering the battery current-rate and the fuel cell balance-of-plant. The nonlinear model predictive control based adaptive equivalent consumption minimization strategy consists of three main stages: the data pre-processing stage, the nonlinear model predictive control stage, and the adaptive equivalent consumption minimization strategy stage. In the data preprocessing stage, reference power trajectory is generated while considering the response time of the fuel cell hybrid electric bus. In the nonlinear model predictive control stage, the reference state of charge trajectory is generated by considering the battery current-rate and the fuel cell balance-of-plant. In the adaptive equivalent consumption minimization strategy stage, the optimal control input is determined to minimize instantaneous equivalent fuel consumption by considering the reference state of charge trajectory. The proposed energy management system is compared with dynamic programming using actual bus route based real-driving scenarios. The comparison results demonstrate that the proposed energy management system can generate control inputs that are similar to the global optimal solution calculated by dynamic programming with a reasonable computation time.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3316263",
            "Date of Publication": "18 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jooin Lee",
                "labs": [
                    "Department of Electrical Engineering, Hanyang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Hyeongcheol Lee",
                "labs": [
                    "Department of Electrical and Biomedical Engineering, Hanyang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fuel cells",
                "Energy management",
                "Batteries",
                "Fuels",
                "Urban areas",
                "Predictive control",
                "State of charge",
                "Nonlinear systems",
                "Predictive control",
                "Fuel cells",
                "Velocity measurement"
            ],
            "Author Keywords": [
                "Nonlinear programming (NLP)",
                "model predictive control (MPC)",
                "equivalent consumption minimization strategy (ECMS)",
                "fuel cell hybrid electric vehicle (FCHEV)",
                "fuel cell hybrid electric bus (FCHEB)",
                "average travel speed"
            ]
        }
    },
    {
        "Title": "No-Reference Video Quality Assessment Using Transformers and Attention Recurrent Networks",
        "Link": "https://ieeexplore.ieee.org/document/10695075/",
        "Abstract": "In recent years, numerous studies have investigated the development of methods for video quality assessment (VQA). These studies have predominantly focused on specific types of video degradation tailored to the application of interest. However, natural videos or recent videos generated by users (UGC) present complex distortions that are not easy to model. Consequently, most current VQA approaches struggle to achieve high performance when applied to these videos. In this paper, we propose a novel Transformer-based architecture that extracts spatial distortion features and spatio-temporal features from videos in two specialized branches. The spatial distortion branch leverages a transfer learning strategy where a standard ViT is pre-trained using a masked autoencoder (MAE) self-supervised learning task, and then fine-tuned to predict the distortion type of corrupted images from the CSIQ database. The features from this branch capture degradation at the level of individual frames. On the other hand, the second branch employs a 3D Shifted Windows Transformer (Swin-T) to extract spatio-temporal features across multiple frames. Once again, we use transfer learning to extract rich features by pre-training this 3D Swin-T model on a video dataset for human action recognition. Finally, a temporal memory block hinged on an attention recurrent neural networks is proposed to predict the final video quality score from the spatio-temporal sequence of features. We evaluate the performance of our method on two popular UGC databases, namely KoNViD-1k and LIVE-VQC. Results show it outperforms state-of-the-art models on the KoNViD-1k database, achieving a SROCC performance of 0.927 and a PLCC of 0.925, while also delivering highly competitive results on the LIVE-VQC database.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3468336",
            "Date of Publication": "26 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Koffi Kossi",
                "labs": [
                    "Department of Electrical Engineering, École de Technologie Supérieure, Université du Québec, Montreal, QC, Canada",
                    "International Laboratory on Learning Systems (ILLS), McGill–ÉTS-Mila–CNRS-CentraleSupelec, Université Paris Saclay, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Stéphane Coulombe",
                "labs": [
                    "Department of Software and IT Engineering, École de Technologie Supérieure, Université du Québec, Montreal, QC, Canada",
                    "International Laboratory on Learning Systems (ILLS), McGill–ÉTS-Mila–CNRS-CentraleSupelec, Université Paris Saclay, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Christian Desrosiers",
                "labs": [
                    "Department of Software and IT Engineering, École de Technologie Supérieure, Université du Québec, Montreal, QC, Canada",
                    "International Laboratory on Learning Systems (ILLS), McGill–ÉTS-Mila–CNRS-CentraleSupelec, Université Paris Saclay, Montreal, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Distortion",
                "Transformers",
                "Three-dimensional displays",
                "Streaming media",
                "Video recording",
                "Quality assessment",
                "Convolutional neural networks",
                "Quality assessment"
            ],
            "Author Keywords": [
                "CNN",
                "distortion",
                "Swin-Transformers",
                "UGC",
                "video quality assessment",
                "vision Transformers",
                "ViT",
                "NLP"
            ]
        }
    },
    {
        "Title": "ACRF: Aggregated Conditional Random Field for Out of Vocab (OOV) Token Representation for Hindi NER",
        "Link": "https://ieeexplore.ieee.org/document/10422739/",
        "Abstract": "Named entities are random, like emerging entities and complex entities. Most of the large language model’s tokenizers have fixed vocab; hence, they tokenize out-of-vocab (OOV) words into multiple sub-words during tokenization. During fine-tuning for any downstream task, these sub-words (tokens) make the named entity classification more complex since, for each sub-word, an extra entity type is assigned for utilizing the word embedding of the sub-word. This work attempts to reduce this complexity by aggregating token embeddings of each word. In this work, we have applied Aggregated-CRF (ACRF), where a conditional random field (CRF) is applied at the top of aggregated token embeddings for named entity prediction. Aggregation is done at embeddings of all tokens generated by a tokenizer corresponding to a word. The experiment was done with two Hindi datasets (HiNER and Hindi Multiconer2). This work showed that the ACRF is better than vanilla CRF (where token embeddings are not aggregated). Also, our result outperformed the existing best result at HiNER data, which was done by applying a cross-entropy classification layer. Further, An analysis of the impact of tokenization has been conducted, both generally and according to entity types for each word present in test data, and the results show that ACRF performed better for the words which tokenized in more than one sub-words (OOV) compared to vanilla CRF. In addition, this work conducts a comparative analysis between two transformer-based models, MuRIL-large and XLM-roberta-large and investigates how these models adopt aggregation strategy based on OOV.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3362645",
            "Date of Publication": "05 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sumit Singh",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, India"
                ]
            },
            {
                "name": "Uma Shanker Tiwary",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Transformers",
                "Conditional random fields",
                "Hidden Markov models",
                "Training",
                "Feature extraction",
                "Data models",
                "Natural language processing"
            ],
            "Author Keywords": [
                "CRF",
                "LLM",
                "NER",
                "NLP",
                "transformer"
            ]
        }
    },
    {
        "Title": "Expanding AI’s Role in Healthcare Applications: A Systematic Review of Emotional and Cognitive Analysis Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10967253/",
        "Abstract": "This systematic literature review (SLR) analyzes the various applications of artificial intelligence (AI) in healthcare, with a particular emphasis on the integration of emotive and cognitive analytical frameworks. The primary aim of this investigation is to thoroughly evaluate the influence of AI technology on patient care by analyzing emotional processes and enabling patient-centered solutions. In this research, we investigate the cognitive and emotional approaches to sentiment analysis and other modeling and forecasting methods using AI. Primary sources include patients’ reviews, online health exchanges and doctors’ narratives. Key aspects of the present state of affairs are advances in the development of machine learning algorithms for emotion recognition, intracellular fusion of cognitive and affective modes of analysis, and the application of artificial intelligence for the enhancement of clinical support systems. Moreover, these technologies have significantly improved individualized clinical approaches, expedited the early identification of mental health problems, and strengthened the rationale for therapeutic treatments. Despite recent advancements, the discipline still faces numerous persistent obstacles. Pressing issues include the ethical implications of using artificial intelligence, the need to protect patient privacy, and the complexity of detecting biases in algorithms. Nevertheless, the impact of AI on healthcare practices is indisputable, indicating a future marked by a more intelligent, efficient, empathetic, and patient-centered healthcare system. This study examines the consequences of artificial intelligence in healthcare by analyzing its importance in emotional and cognitive computing, tracking ongoing developments, and promoting the use of AI in healthcare while considering individual requirements.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3562131",
            "Date of Publication": "17 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Prashant Kumar Nag",
                "labs": [
                    "Department of Mathematics, Bioinformatics and Computer Applications, Maulana Azad National Institute of Technology, Bhopal, Madhya Pradesh, India"
                ]
            },
            {
                "name": "Amit Bhagat",
                "labs": [
                    "Department of Mathematics, Bioinformatics and Computer Applications, Maulana Azad National Institute of Technology, Bhopal, Madhya Pradesh, India"
                ]
            },
            {
                "name": "R. Vishnu Priya",
                "labs": [
                    "Department of Computer Applications, National Institute of Technology at Tiruchirappalli, Tiruchirappalli, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Medical services",
                "Systematic literature review",
                "Emotion recognition",
                "Mental health",
                "Deep learning",
                "Social networking (online)",
                "Market research",
                "Ethics",
                "Depression"
            ],
            "Author Keywords": [
                "AI in healthcare",
                "cognitive assessment",
                "data security in AI",
                "deep learning applications",
                "emotion detection",
                "mental health analytics",
                "NLP in medical texts",
                "patient-centered approaches",
                "sentiment evaluation"
            ]
        }
    },
    {
        "Title": "Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source Framework Applied on Rett Syndrome and Alzheimer’s Disease",
        "Link": "https://ieeexplore.ieee.org/document/10772038/",
        "Abstract": "The rapidly increasing number of biomedical publications presents a significant challenge for efficient knowledge discovery. To address this, we introduce an open-source, end-to-end framework designed to automatically extract and construct knowledge about specific diseases directly from unstructured text. To facilitate research in disease-related knowledge discovery, we create two annotated datasets focused on Rett syndrome (RS) and Alzheimer’s disease (AD), enabling the identification of semantic relations between various biomedical entities. We perform extensive benchmarking to evaluate different approaches for representing relations and entities, providing insights into optimal modeling strategies for semantic relation detection and highlighting language models’ competence in knowledge discovery. To gain a deeper understanding of the internal mechanisms of transformer models, we also conduct probing experiments, analyzing different layer representations and attention scores, to explore transformers’ ability to capture semantic relations within the text. Both the code and the datasets will be publicly available at https://github.com/christos42/Enhancing-Biomedical-Knowledge-Discovery-for-Diseases, encouraging further research in biomedical knowledge discovery.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3509714",
            "Date of Publication": "02 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Christos Theodoropoulos",
                "labs": [
                    "Department of Computer Science, LIIR, KU Leuven, Leuven, Belgium"
                ]
            },
            {
                "name": "Andrei Catalin Coman",
                "labs": [
                    "Idiap Research Institute, Martigny, Switzerland",
                    "Department of Electrical Engineering, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne, Switzerland"
                ]
            },
            {
                "name": "James Henderson",
                "labs": [
                    "Idiap Research Institute, Martigny, Switzerland"
                ]
            },
            {
                "name": "Marie-Francine Moens",
                "labs": [
                    "Department of Computer Science, LIIR, KU Leuven, Leuven, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Diseases",
                "Semantics",
                "Knowledge discovery",
                "Proteins",
                "Protein engineering",
                "Annotations",
                "Alzheimer's disease",
                "Pipelines",
                "Biological system modeling",
                "Peptides"
            ],
            "Author Keywords": [
                "Benchmarking",
                "corpus creation",
                "evaluation",
                "knowledge discovery",
                "language model probing",
                "language resources",
                "NLP datasets",
                "relation detection"
            ]
        }
    },
    {
        "Title": "Developer Recommendation and Team Formation in Collaborative Crowdsourcing Platforms",
        "Link": "https://ieeexplore.ieee.org/document/10955209/",
        "Abstract": "The Competitive Crowdsourcing Software Development (CSE) environment is a dynamic and evolving field that interests researchers and the software industry. This ecosystem ensures the timely delivery of cost-effective, innovative, and high-quality solutions. As this environment grows in popularity, it faces the crucial challenge of developer recommendation and team formation, which must be addressed to ensure its ongoing success and progress. This research offers a novel method for assembling teams and recommending developers. It combines keyword-based embeddings and fuzzy logic to match developers with appropriate tasks with exceptional accuracy. The technique utilizes KeyBERT to extract keywords and perform embedding to capture relevant skills and task requirements without emphasizing common words. The embeddings are optimized using a fuzzy logic framework. This framework categorizes the quality of developer-task pairings into three distinct levels: “Strong,” “Average,” and “Weak.” This approach enables developer recommendations and team formation, balancing precision, recall and F1-score across varying team sizes to achieve high overall accuracy by a percentage increase of 4.19%. and TF score increased by 4.05%. The proposed method consistently outperforms existing methods, allowing the formation of capable and reliable teams of varying sizes. This ensures the creation of high-performing, well-balanced teams that can effectively handle diverse tasks with the percentage improvement from Content-Based Filtering (CBF). The results in percentage increase (precision, recall and f1-score) of the proposed approach (with k=5) from CBF improve by 30.29%, 36.49%, and 33.45%, and with User-based Collaborative Filtering (UCF) and Random Recommendation (RR) performances increase by (19.58%, 15.98%, and 17.92%) and (160.17%, 215.07%, and 188.31%), respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3558557",
            "Date of Publication": "08 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yasir Munir",
                "labs": [
                    "Department of Computer Science, Superior University, Lahore, Pakistan",
                    "Intelligent Data Visual Computing Research (IDVCR), Lahore, Pakistan"
                ]
            },
            {
                "name": "Qasim Umer",
                "labs": [
                    "Information and Computer Science Department, King Fahd University of Petroleum and Minerals (KFUPM), Dhahran, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Faheem",
                "labs": [
                    "VTT-Technical Research Centre of Finland, Espoo, Finland"
                ]
            },
            {
                "name": "Sheeraz Akram",
                "labs": [
                    "Department of Computer Science, Superior University, Lahore, Pakistan",
                    "Intelligent Data Visual Computing Research (IDVCR), Lahore, Pakistan",
                    "College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Arfan Jaffar",
                "labs": [
                    "Department of Computer Science, Superior University, Lahore, Pakistan",
                    "Intelligent Data Visual Computing Research (IDVCR), Lahore, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Collaboration",
                "Fuzzy logic",
                "Software",
                "Industries",
                "Crowdsourcing",
                "Semantics",
                "Electronic mail",
                "Faces",
                "Complexity theory",
                "Accuracy"
            ],
            "Author Keywords": [
                "CSE",
                "Topcoder",
                "key-bert",
                "developer recommendation",
                "NLP",
                "team formation",
                "fuzzy logic",
                "classification"
            ]
        }
    },
    {
        "Title": "Improving Multi-Label Emotion Classification on Imbalanced Social Media Data With BERT and Clipped Asymmetric Loss",
        "Link": "https://ieeexplore.ieee.org/document/10947681/",
        "Abstract": "This research addresses the challenge of multi-label emotion classification on imbalanced datasets using a BERT-based model. Emotion classification, essential for applications like social media analysis and sentiment monitoring, often suffers from class imbalance, which hinders the detection of rare emotions. To address this, our model incorporates a clipped asymmetric loss function to prioritize minority classes while mitigating the dominance of frequent classes. We conducted extensive experimentation on GoEmotions and SemEval-2018 Task 1C datasets to demonstrate the model’s effectiveness in achieving improved precision, recall, and F1-scores across various taxonomies, including GoEmotions, Ekman, and sentiment-grouped levels. Our approach achieved a notable improvement in macro-average F1-scores, increasing from 0.46 (baseline) to 0.54 on the GoEmotions dataset and 0.59 on the SemEval-2018 dataset. The results indicate significant advancements over standard BERT implementations and state-of-the-art models, particularly in recognizing rare emotions, making the model a robust solution for real-world, multi-label emotion classification tasks under imbalanced settings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3557091",
            "Date of Publication": "02 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sandhya Ramakrishnan",
                "labs": [
                    "School of Computer Science Engineering and Information Systems (SCORE), Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "L. D. Dhinesh Babu",
                "labs": [
                    "School of Computer Science Engineering and Information Systems (SCORE), Vellore Institute of Technology, Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Emotion recognition",
                "Taxonomy",
                "Multi label classification",
                "Encoding",
                "Bidirectional control",
                "Adaptation models",
                "Transformers",
                "Data augmentation",
                "Correlation"
            ],
            "Author Keywords": [
                "Asymmetric loss",
                "BERT",
                "emotion recognition",
                "GoEmotions dataset",
                "imbalanced data",
                "multi-label classification",
                "NLP"
            ]
        }
    },
    {
        "Title": "Evaluating Large Language Models for Optimized Intent Translation and Contradiction Detection Using KNN in IBN",
        "Link": "https://ieeexplore.ieee.org/document/10855447/",
        "Abstract": "Intent-Based Networking (IBN) simplifies network management by enabling users to express high-level intents in natural language, but existing approaches often fail to ensure alignment with network policies, leading to misconfigurations. Moreover, many methods lack robust validation mechanisms, reducing their reliability in dynamic environments. This research addresses these gaps by evaluating advanced Large Language Models (LLMs) such as BERT-base uncased (BERT-bu), GPT2, LLaMA3, Claude2 and small deep learning model BiLSTM with attention for translating intents and detecting contradictions. Using a curated dataset of 10,000 intent pairs, the proposed hybrid framework integrates a K-Nearest Neighbors (KNN) classifier to validate translations and recalibrate erroneous outputs. Experimental results demonstrate up to 5% higher accuracy (88%) and F1 scores compared to existing methods, ensuring precise intent translation and reliable network orchestration. This approach significantly enhances scalability and policy compliance in automated network environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3534880",
            "Date of Publication": "27 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Asif",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            },
            {
                "name": "Talha Ahmed Khan",
                "labs": [
                    "Institute for Communication Systems, University of Surrey, Guildford, U.K."
                ]
            },
            {
                "name": "Wang-Cheol Song",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, Jeju-do, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Translation",
                "Accuracy",
                "Nearest neighbor methods",
                "Reliability",
                "Bidirectional long short term memory",
                "Scalability",
                "Resource description framework",
                "Transformers",
                "Terminology",
                "Standardization"
            ],
            "Author Keywords": [
                "Intent-based networking",
                "K-Nearest Neighbors",
                "NLP",
                "LLM",
                "GPT",
                "LLaMa",
                "BERT"
            ]
        }
    },
    {
        "Title": "End-to-End Deployment of the Educational AI Hub for Personalized Learning and Engagement: A Case Study on Environmental Science Education",
        "Link": "https://ieeexplore.ieee.org/document/10938135/",
        "Abstract": "This study introduces an end-to-end framework for deploying conversational AI-enabled educational assistants, focusing on personalized support for students across diverse subject areas, including Business, Culture, Environmental Sciences, History, Politics, and Science, as outlined in our evaluation framework. The system leverages advanced conversational AI technologies to provide targeted, course-specific learning experiences by facilitating access to complex data and integrating seamlessly with Learning Management Systems (LMS) like Canvas. Key metrics—information retrieval accuracy, question-answering accuracy, and hallucination accuracy—were selected to rigorously evaluate the system’s ability to retrieve relevant contexts, generate accurate responses, and identify unanswerable questions. Additionally, the Educational AI Hub agents utilize innovative document parsing methods, such as the Nougat technique, to interpret content accurately, enabling adaptable academic support tailored to individual learning needs and extending to quantitative fields through code execution capabilities. This study also emphasizes the importance of accessibility, inclusivity, and user privacy. The results showcase the potential for enhanced engagement and improved understanding of environmental concepts and software tools, demonstrating the significant impact of conversational AI in educational settings, especially in disciplines involving complex data interactions. A case study, presented at the 12th International Congress on Environmental Modelling and Software, illustrates the Educational AI Hub’s effectiveness in enhancing student engagement and delivering personalized learning experiences in environmental sciences education.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554222",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ramteja Sajja",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Iowa, Iowa City, IA, USA",
                    "IIHR—Hydroscience and Engineering, University of Iowa, Iowa City, IA, USA"
                ]
            },
            {
                "name": "Yusuf Sermet",
                "labs": [
                    "IIHR—Hydroscience and Engineering, University of Iowa, Iowa City, IA, USA"
                ]
            },
            {
                "name": "Ibrahim Demir",
                "labs": [
                    "Department of River-Coastal Science and Engineering, Tulane University, New Orleans, LA, USA",
                    "ByWater Institute, Tulane University, New Orleans, LA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Artificial intelligence",
                "Adaptive learning",
                "Virtual assistants",
                "Accuracy",
                "Electronic learning",
                "Water quality",
                "Learning management systems",
                "Large language models",
                "Decision making"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "document parsing techniques",
                "generative pre-training transformer (GPT)",
                "large language models (LLM)",
                "natural language processing (NLP)",
                "personalized learning"
            ]
        }
    },
    {
        "Title": "Examining Customer Satisfaction Through Transformer-Based Sentiment Analysis for Improving Bilingual E-Commerce Experiences",
        "Link": "https://ieeexplore.ieee.org/document/10926527/",
        "Abstract": "As e-commerce continues its rapid expansion, accurately gauging and interpreting customer sentiment has become critical for optimizing user satisfaction and predicting purchasing behavior. This study advances feature-level sentiment analysis by examining Chinese e-commerce product reviews, translated into English, to uncover the contextual impact of sentiment-bearing keywords across diverse product categories. The research intends to discover trends, reasons, and broad conclusions associated with the volume, co-occurrence, and contextual use of keywords across various product types. Using sentiment intensity analysis, N-gram modeling, and machine learning, this research attempted to evaluate the performance of these models: ELECTRA, BERT, BiLSTM, Random Forest with XGBoost, and SVC with SGD. Empirical results demonstrate that ELECTRA yields the highest accuracy (98.09%) and F1 score (0.9711), illustrating superior performance in capturing nuanced sentiment cues, with low loss of 0.062. BiLSTM followed with 96.09% accuracy and F1 score of 0.9583. Although BERT performed strongly with an accuracy of 95.28% and an F1 score of 0.9528, it is extremely resource demanding. Ensemble methods like Random Forest with XGBoost and SVC with SGD had moderate performance, finding 82.43%, and 88.84% accuracy, respectively, but had better runtimes. The results supports the advantage of using transformer based models in attempting more sophisticated contextual analysis by uncovering paramount sentiment patterns, product specific issues, and customer needs. Furthermore, by translating Chinese reviews into English, the study highlights the potential for cross-lingual frameworks to enrich global e-commerce strategies. Future research directions include integrating cultural factors, extending analysis to additional languages, and refining computational approaches for resource-limited environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3551666",
            "Date of Publication": "14 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shizhong Shan",
                "labs": [
                    "China National Democratic Construction Association, Economic Research Institute, Yango University, Fujian, China"
                ]
            },
            {
                "name": "Jin Sun",
                "labs": [
                    "College of Business and Accountancy, National University, Manila, Philippines"
                ]
            },
            {
                "name": "Remson Mark C. Macawile",
                "labs": [
                    "College of Engineering, National University, Manila, Philippines"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electronic commerce",
                "Sentiment analysis",
                "Reviews",
                "Analytical models",
                "Social networking (online)",
                "Natural language processing",
                "Business",
                "Customer satisfaction",
                "Predictive models",
                "Consumer behavior"
            ],
            "Author Keywords": [
                "E-commerce",
                "customer satisfaction",
                "sentiment analysis",
                "natural language processing (NLP)",
                "machine learning models",
                "sentiment keywords",
                "feature-level sentiment analysis",
                "consumer behavior",
                "customer feedback",
                "N-gram modeling",
                "transformer-based models",
                "ELECTRA",
                "BERT",
                "BiLSTM",
                "random forest",
                "XGBoost",
                "purchase intentions",
                "data-driven decision-making",
                "product category prediction",
                "sentiment intensity analysis"
            ]
        }
    },
    {
        "Title": "Arabic Fake News Dataset Development: Humans and AI-Generated Contributions",
        "Link": "https://ieeexplore.ieee.org/document/10945848/",
        "Abstract": "The extensive use of social media platforms has promoted the rapid spread of fake news on the internet, such as fake reviews, rumors, and propaganda. Although these terminologies have different objectives, they share the aim of causing harm in the form of fake news. This study presents an Arabic fake news detection framework to overcome the widespread fake news phenomenon. The proposed framework introduces the first Arabic fake news dataset compiled by passing through strict guidelines to produce fake articles composed by humans and the generative pre-trained transformer (GPT). First, we performed human-based experiments to evaluate the ability of humans to distinguish real news articles from fake news articles. Our findings reveal that humans could roughly identify half of the fake articles from humans or GPT, raising concerns about their ability to detect fake news. This highlights the growing concern surrounding fake news, especially because GPT demonstrates the ability to generate fake news that closely resembles human-created content, further amplifying the issue. To address this issue, we performed the same task using Deep Learning (DL) and transformer-based methods with different word embeddings. Across all the employed models, the study revealed that the innovative transformer-based model, ARBERT, outperformed the DL models, reaching an accuracy of 78% in classifying real and fake news generated by humans and GPT. The findings suggest effective techniques for addressing and resolving this issue.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3556376",
            "Date of Publication": "31 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hanen Himdi",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Nuha Zamzami",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Fatma Najar",
                "labs": [
                    "Department of Mathematics and Computer Science, John Jay College of Criminal Justice, The City University of New York, New York, NY, USA"
                ]
            },
            {
                "name": "Mada Alrehaili",
                "labs": [
                    "Okaz Organization for Press and Publications, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Nizar Bouguila",
                "labs": [
                    "Concordia Institute for Information Systems Engineering (CIISE), Concordia University, Montreal, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Biological system modeling",
                "Accuracy",
                "Transformers",
                "Social networking (online)",
                "COVID-19",
                "Training",
                "Sports",
                "Generative Pre-trainer transformer",
                "Deep learning"
            ],
            "Author Keywords": [
                "Arabic fake news detection",
                "Okaz dataset",
                "deep learning (DL)",
                "transformers",
                "GPT-generated fake news",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "An Inferential Commonsense-Driven Framework for Predicting Political Bias in News Headlines",
        "Link": "https://ieeexplore.ieee.org/document/10193773/",
        "Abstract": "Identifying political bias in news headlines holds significant importance as it influences the dissemination and consumption of news stories. However, employing conventional methods to do so poses a formidable challenge, as the short headline text is often complex and lacks sufficient syntactic and semantic context. Existing approaches fail to acknowledge the potential of commonsense reasoning in facilitating text comprehension, although it has been shown to aid numerous downstream applications. To this end, to facilitate comprehension and compensate for the lack of context, we propose leveraging inferential commonsense knowledge to simplify, interpret, and explain events that are not explicitly stated in headlines. Furthermore, to fully utilise its potential and deal with the unnecessary noise it may introduce, we present a method for emphasising significant inferences. Using this knowledge, we introduce a novel framework, IC-BAIT, short for Inferential Commonsense aware BiAs IdenTifier, which is a flexible neural network framework designed to enhance political bias prediction in news headlines. We also present two bias-annotated datasets: MediaBias and GoodNews. Experiments on both datasets demonstrate that IC-BAIT significantly enhances the performance of the baseline models used in the framework. Experiments on the datasets show that IC-BAIT improves the baseline models in terms of accuracy (2.0-10.0%), macro-averaged F1 (2.2-22.2%), Jaccard-score (up to 15.1%), and micro-averaged F1 (up to 18.6%). Our in-depth qualitative analysis reveals the scenarios in which the selected knowledge is beneficial and when it is detrimental. Datasets and scripts are available at https://github.com/Swati17293/IC-BAIT.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3298877",
            "Date of Publication": "25 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Swati Swati",
                "labs": [
                    "Jožef Stefan Institute, Ljubljana, Slovenia",
                    "Jožef Stefan International Postgraduate School, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Dunja Mladenić",
                "labs": [
                    "Jožef Stefan Institute, Ljubljana, Slovenia",
                    "Jožef Stefan International Postgraduate School, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Marko Grobelnik",
                "labs": [
                    "Jožef Stefan Institute, Ljubljana, Slovenia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Commonsense reasoning",
                "Task analysis",
                "Manuals",
                "Annotations",
                "Syntactics",
                "Neural networks",
                "Semantics",
                "Deep learning",
                "Inference algorithms",
                "Knowledge engineering",
                "Text categorization"
            ],
            "Author Keywords": [
                "Deep learning",
                "inferential commonsense knowledge",
                "media bias",
                "news bias",
                "NLP",
                "short text classification"
            ]
        }
    },
    {
        "Title": "Unsupervised Concept Drift Detection From Deep Learning Representations in Real-Time",
        "Link": "https://ieeexplore.ieee.org/document/11103500/",
        "Abstract": "Concept drift is the phenomenon in which the underlying data distributions and statistical properties of a target domain change over time, leading to a degradation in model performance. Consequently, production models require continuous drift detection monitoring. Most drift detection methods to date are supervised, relying on ground-truth labels. However, they are inapplicable in many real-world scenarios, as true labels are often unavailable. Although recent efforts have proposed unsupervised drift detectors, many lack the accuracy required for reliable detection or are too computationally intensive for real-time use in high-dimensional, large-scale production environments. Moreover, they often fail to characterize or explain drift effectively. To address these limitations, we propose DriftLens, an unsupervised framework for real-time concept drift detection and characterization. Designed for deep learning classifiers handling unstructured data, DriftLens leverages distribution distances in deep learning representations to enable efficient and accurate detection. Additionally, it characterizes drift by analyzing and explaining its impact on each label. Our evaluation across classifiers and data-types demonstrates that DriftLens (i) outperforms previous methods in detecting drift in 15/17 use cases; (ii) runs at least 5 times faster; (iii) produces drift curves that align closely with actual drift (correlation\n≥0.85\n); (iv) effectively identifies representative drift samples as explanations.",
        "Details": {
            "DOI": "10.1109/TKDE.2025.3593123",
            "Date of Publication": "29 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Knowledge and Data Engineering"
        },
        "issn_info": {
            "Print ISSN": "1041-4347",
            "Electronic ISSN": "1558-2191"
        },
        "authors_data": [
            {
                "name": "Salvatore Greco",
                "labs": [
                    "Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Bartolomeo Vacchetti",
                "labs": [
                    "Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Daniele Apiletti",
                "labs": [
                    "Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Tania Cerquitelli",
                "labs": [
                    "Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Concept drift",
                "Deep learning",
                "Data models",
                "Computational modeling",
                "Real-time systems",
                "Adaptation models",
                "Detectors",
                "Complexity theory",
                "Production",
                "Monitoring"
            ],
            "Author Keywords": [
                "Concept drift",
                "data drift",
                "drift detection",
                "drift explanation",
                "deep learning",
                "NLP",
                "computer vision",
                "audio"
            ]
        }
    },
    {
        "Title": "Descriptor: Open-Domain Long-Form Context-Aware Question-Answering Dataset (DragonVerseQA)",
        "Link": "https://ieeexplore.ieee.org/document/10969604/",
        "Abstract": "This article proposes an open-domain and long-form Over-the-Top (OTT) Question-Answering (QA) dataset, DragonVerseQA, specifically oriented to the fantasy universe of “House of the Dragon” and “Game of Thrones” TV series. Most existing QA datasets focus on short, fact-based answers sourced almost solely from Wikipedia articles, devoid of depth and contextual richness for sophisticated narrative understanding. The curated dataset combines full episode summaries sourced from HBO and fandom wiki websites, user reviews from sources such as IMDb and Rotten Tomatoes, and high-quality, open-domain, legally admissible sources, and structured data from repositories such as WikiData into one dataset. The dataset provides a multi-dimensional context, reflecting complex character dynamics and plot developments from these varied sources. The comprehensive insights from the long-form answers generated from this enriched context make this dataset valuable for improving conversational AI, narrative analysis, sentiment analysis, summarization techniques, and relation extraction. A comparative analysis with state-of-the-art QA datasets such as SQuAD 2.0, TriviaQA, and Natural Questions brings to light the unique advantages of our dataset in terms of contextual complexity and answer length. Detailed reviews add layers to audience sentiment and narrative interpretation, raising the bar for domain-specific QA with a new quality benchmark. Our work also allows a deeper understanding of narrative-focused content and opens the door to more knowledgeable and creative AI-driven interactions within digital media environments. DATA TYPE/LOCATION Text (.json); Toronto Metropolitan University, Toronto, ON, Canada DATA DOI/PID 10.21227/tv3y-db94",
        "Details": {
            "DOI": "10.1109/IEEEDATA.2025.3562173",
            "Date of Publication": "17 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Data Descriptions"
        },
        "issn_info": {
            "Electronic ISSN": "2995-4274"
        },
        "authors_data": [
            {
                "name": "Aritra Kumar Lahiri",
                "labs": [
                    "Department of Computer Science, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Qinmin Vivian Hu",
                "labs": [
                    "Department of Computer Science, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Uniform resource locators",
                "Training",
                "Robots",
                "Internet",
                "Games",
                "TV",
                "Encyclopedias",
                "Context modeling",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Context-aware",
                "dataset",
                "Large Language Models (LLMs)",
                "long-form",
                "natural language processing (NLP)",
                "open-domain",
                "Question-Answering (QA)"
            ]
        }
    },
    {
        "Title": "An Unsupervised Approach for Keyphrase Extraction Using Within-Collection Resources",
        "Link": "https://ieeexplore.ieee.org/document/8819880/",
        "Abstract": "It is hard to select and read suitable documents due to the rapidly growing number of scholarly documents. Keyphrases can be considered as the gist of a document so that a researcher can select the documents that they want using keyphrase queries. However, there are also many scholarly documents without any keyphrases tagged by the authors or other researchers. Automatic keyphrase extraction can help researchers to quickly extract keyphrases. This paper proposed an unsupervised approach for keyphrase extraction using graph-based ranking and topic-based clustering under the assumption that we only use the within-collection resources. We use graph-based ranking to describe the relevance between two words and topic-based clustering to embed semantical information into words. In this paper, we assume that each word has its own meaning, and each meaning can be considered as a topic, though we know nothing about these meanings. We use topic-based clustering to assign the “correct meaning” to the “correct word”. In addition, by taking the relevance among phrases into consideration and only using within-collection resources, we can use the graph-based ranking in our approach. The edges in a graph that are built for phrases can describe the hidden relevance between two phrases, and the weights that are set for edges can measure the connection between two phrases. Then, after using the position feature, our approach consists of an enhanced graph-based ranking and a topic-based clustering. The experiments are run on four datasets: KDD, WWW, GSN and ACM. The results indicate that our approach has better performance than the state-of-the-art methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2938213",
            "Date of Publication": "29 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Teng-Fei Li",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            },
            {
                "name": "Liang Hu",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            },
            {
                "name": "Jian-Feng Chu",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            },
            {
                "name": "Hong-Tu Li",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            },
            {
                "name": "Ling Chi",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Clustering algorithms",
                "Feature extraction",
                "Encyclopedias",
                "Electronic publishing",
                "Internet"
            ],
            "Author Keywords": [
                "Phrase extraction",
                "graph-based ranking",
                "topic-based clustering",
                "within-collection resource",
                "NLP"
            ]
        }
    },
    {
        "Title": "Detecting Reported Side Effects of COVID-19 Vaccines From Arabic Twitter (X) Data",
        "Link": "https://ieeexplore.ieee.org/document/10500705/",
        "Abstract": "Vaccines might potentially cause side effects as any other drugs, which needs to be investigated and analyzed to identify the public safety concerns. The massive vaccination rollout against COVID-19 provoked discussion among people through social media platforms. Twitter (X), a popular social media platform, plays a significant role in disseminating information about COVID-19 vaccines and monitoring people’s reports regarding vaccination side effects. The aim of this study is to mine Twitter (X) to identify self-reported side effects related to COVID-19 vaccines in Arabic language, compare their distribution among six vaccine types, and construct Arabic lexicon of symptoms. We collected the tweets posts in Arabic language after the distribution of COVID-19 vaccines, then we developed a workflow for identifying self-report symptoms using biterm topic modeling (BTM) and support vector machine (SVM) to extract the symptoms then cluster them in groups based on their co-occurrence. A total of 51 symptoms were extracted from 65,387 tweets that were reported 148,324 times. We performed a more in-depth analysis to investigate the symptoms that tend to occur simultaneously. The results show that the symptoms that more likely to occur together may indicate to a particular connection. The findings suggested that the social media conversation can provide a comprehensive depiction of symptoms that may complement what identified in clinical studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3389655",
            "Date of Publication": "16 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maram K. Alhumayani",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, Umm Al-Qura University, Makkah, Saudi Arabia"
                ]
            },
            {
                "name": "Huda N. Alhazmi",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, Umm Al-Qura University, Makkah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vaccines",
                "Social networking (online)",
                "COVID-19",
                "Blogs",
                "Drugs",
                "Support vector machines",
                "Natural language processing",
                "Natural language processing",
                "Machine learning"
            ],
            "Author Keywords": [
                "Arabic language",
                "biterm topic modeling (BTM)",
                "COVID-19 vaccine",
                "machine learning",
                "NLP",
                "side effects",
                "support vector machine (SVM)",
                "Twitter (X)"
            ]
        }
    },
    {
        "Title": "Social Media as a Mirror: Reflecting Mental Health Through Computational Linguistics",
        "Link": "https://ieeexplore.ieee.org/document/10664621/",
        "Abstract": "The world is grappling with a serious problem: many young individuals are taking their own lives. There is also a challenge in understanding the rising trend of this tendency. It is essential to explore the reasons driving people of all ages to consider suicide and find ways to encourage them to choose life instead. In the modern era, social media acts as a crucial platform where people share their thoughts, activities, and emotional states. This has led to the consideration of whether analyzing social media posts could help discern whether individuals are experiencing joy or sadness, particularly to detect levels of sadness that could indicate suicidal thoughts. This paper employs artificial intelligence and machine learning tools to analyze the social media posts of individuals to gauge their mental state, specifically targeting signs that might indicate a risk of suicide. The study has found a high frequency of suicidal thoughts among those who appear depressed on social media. This research investigated the possibility to identify the likelihood of someone contemplating suicidal through their online behavior. This research demonstrates the potential of utilizing social media analysis to identify and support individuals at risk of suicide, providing new insights into recognizing and assessing suicidal thoughts and representing a significant advancement in suicide prevention efforts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3454292",
            "Date of Publication": "04 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md. Iftekharul Mobin",
                "labs": [
                    "Faculty of Science and Technology, American International University-Bangladesh (AIUB), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "A. F. M. Suaib Akhter",
                "labs": [
                    "Computer Engineering Department, Sakarya University of Applied Sciences, Serdivan, Sakarya, Türkiye"
                ]
            },
            {
                "name": "M. F. Mridha",
                "labs": [
                    "Faculty of Science and Technology, American International University-Bangladesh (AIUB), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "S. M. Hasan Mahmud",
                "labs": [
                    "Faculty of Science and Technology, American International University-Bangladesh (AIUB), Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Zeyar Aung",
                "labs": [
                    "Center for Secure Cyber-Physical Systems (C2PS), Khalifa University, Abu Dhabi, United Arab Emirates",
                    "Department of Computer Science, Khalifa University, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Depression",
                "Mental health",
                "Machine learning",
                "Analytical models",
                "Accuracy",
                "Mirrors",
                "Unsupervised learning"
            ],
            "Author Keywords": [
                "Depression",
                "exploratory analysis",
                "feature extraction",
                "LDA",
                "NLP",
                "suicide",
                "unsupervised model"
            ]
        }
    },
    {
        "Title": "LLM-Based Doppelgänger Models: Leveraging Synthetic Data for Human-Like Responses in Survey Simulations",
        "Link": "https://ieeexplore.ieee.org/document/10758652/",
        "Abstract": "This study explores whether large language models (LLMs) can learn a person’s opinions from their speech and act based on that knowledge. It also proposes the potential for utilizing such trained models in survey research. Traditional survey research collects information through standardized questions. However, surveys require repeated administration with new participants each time, which involves significant costs and time. With the recent advancements in LLMs, artificial intelligence (AI) has shown remarkable capabilities, often surpassing humans in tasks that require natural language understanding (NLU) and natural language generation (NLG). Despite this, research on whether AI can replicate human thought processes in tasks such as text interpretation or question-answering remains insufficient. This study proposes a Surveyed LLM, specialized for survey tasks, and a Doppelganger LLM that mimics human thought processes. It tests to what extent the Doppelganger model can replicate human judgment. Furthermore, it suggests the possibility of mimicking not only group distributions but also individual opinions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3502219",
            "Date of Publication": "20 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Suhyun Cho",
                "labs": [
                    "Department of Applied Artificial Intelligence, Sungkyunkwan University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jaeyun Kim",
                "labs": [
                    "AI Model Development, Dareesoft, Seongnam-si, Republic of Korea"
                ]
            },
            {
                "name": "Jang Hyun Kim",
                "labs": [
                    "Department of Applied Artificial Intelligence, Sungkyunkwan University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Mathematical models",
                "Data models",
                "Training",
                "Artificial intelligence",
                "Computational modeling",
                "Predictive models",
                "Adaptation models",
                "Oral communication",
                "Costs"
            ],
            "Author Keywords": [
                "LLM",
                "survey research",
                "NLP",
                "NLU",
                "synthetic data"
            ]
        }
    },
    {
        "Title": "Context-Aware Embedded Language Transformers for Evaluating Climate Change-Based Sustainable Development Goals",
        "Link": "https://ieeexplore.ieee.org/document/10962207/",
        "Abstract": "This research work addresses the pressing issue of climate change and the urgent need for a comprehensive and reliable dataset that can assist stakeholders, policymakers and researchers in making informed and data-driven decisions. We propose the process for leveraging publicly available raw data such as news articles and social media posts and help to create meaningful ontologies. The study demonstrates the use of advanced Natural Language Processing and Deep Learning techniques to transform raw data into potential insights. Additionally, we present a methodology for utilizing these generated ontologies to anticipate the impacts of decisions on climate change. The primary objective of this research is to present a Context-Aware Embedded Language Transformers model that can be easily integrated into various pipelines by generating meaningful ontologies to support more informed decision-making. These ontologies will serve as knowledge graphs and contribute to a large dataset for future research in the field and address the current lack of comprehensive resources.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3559548",
            "Date of Publication": "10 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pratham Mishra",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "Senthil Kumar Narayanasamy",
                "labs": [
                    "School of Computer Science Engineering and Information Systems, Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "Kathiravan Srinivasan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Climate change",
                "Meteorology",
                "Sustainable development",
                "Ontologies",
                "Transformers",
                "Social networking (online)",
                "Decision making",
                "Data models",
                "Databases",
                "Surveys"
            ],
            "Author Keywords": [
                "Climate change",
                "graph convolution networks (GCNs)",
                "knowledge graphs",
                "natural language processing (NLP)",
                "sustainable development goals",
                "transformers"
            ]
        }
    },
    {
        "Title": "Mental Health Safety and Depression Detection in Social Media Text Data: A Classification Approach Based on a Deep Learning Model",
        "Link": "https://ieeexplore.ieee.org/document/10960428/",
        "Abstract": "Social media expansion enables real-time mental health monitoring particularly for depression detection through its platforms. Traditional depression detection techniques, however, struggle to handle the informal, often ambiguous nature of language used in social media, including emojis, slang, and context-dependent expressions. To address this limitation, this research proposes a novel framework for depression detection that integrates advanced text preprocessing with a deep learning model. The preprocessing pipeline contains two key components where emojis are converted into text by emoji normalization then slang expressions are replaced through a customized dictionary. Emotion scores serve as additional components to identify depression-related emotional cues within the text. The model combines BERT’s contextual embeddings with BiLSTM’s sequential processing power to effectively represent emotional content in social media posts. The proposed approach demonstrates superior performance compared to traditional baseline models by achieving better results in accuracy, precision, recall, F1-score, AUC and RGA. This approach shows exceptional performance in detecting depression through informal texts which serves as a new benchmark for depression detection in dynamic social media environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3559170",
            "Date of Publication": "09 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shiwen Zhou",
                "labs": [
                    "Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Masnizah Mohd",
                "labs": [
                    "Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Depression",
                "Social networking (online)",
                "Mental health",
                "Encoding",
                "Bidirectional long short term memory",
                "Bidirectional control",
                "Semantics",
                "Emojis",
                "Accuracy",
                "Deep learning"
            ],
            "Author Keywords": [
                "BERT-BiLSTM",
                "depression detection",
                "social media",
                "mental health",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "ET-GNN: Ensemble Transformer-Based Graph Neural Networks for Holistic Automated Essay Scoring",
        "Link": "https://ieeexplore.ieee.org/document/10945775/",
        "Abstract": "Essay writing tasks are crucial for assessing students’ writing skills, but manual evaluation can be time-consuming and prone to inconsistencies. Automated Essay Scoring (AES) offers a solution by automatically evaluating essays, reducing the need for human intervention. This paper presents a hybrid method, called Ensemble Transformer-Based Graph Neural Networks (ET-GNN), which integrates Transformer-based models with Graph Convolutional Networks (GCNs) for holistic AES. Three Transformer models, DistilBERT, RoBERTa, and DeBERTaV3, were individually fine-tuned to generate contextual embeddings for each essay. The GCNs process these embeddings, effectively capturing relevant semantic information and inter-essay similarities. Additionally, ensemble methods are used to combine the DistilBERT-GCN, RoBERTa-GCN, and DeBERTaV3-GCN models employing averaging for regression tasks, majority voting for classification tasks, and a weighted ensemble method for both types of tasks. The proposed ET-GNN method enhances the performance and robustness of AES systems, achieving Quadratic Weighted Kappa (QWK) scores of 0.835 and 0.841 on the ASAP and AES 2.0 datasets, respectively. These results outperform other state-of-the-art models based on Transformer or GCNs architectures for the AES task.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3556352",
            "Date of Publication": "31 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hind Aljuaid",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Areej Alhothali",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Ohoud Alzamzami",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Hussein Assalahi",
                "labs": [
                    "English Language Institute, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Tahani Aldosemani",
                "labs": [
                    "College of Education, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Semantics",
                "Context modeling",
                "Feature extraction",
                "Ensemble learning",
                "Encoding",
                "Predictive models",
                "Bidirectional control",
                "Accuracy",
                "Deep learning"
            ],
            "Author Keywords": [
                "Automated essay scoring (AES)",
                "transformer models",
                "graph convolutional networks (GCNs)",
                "ensemble methods",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Doctor or AI? Efficient Neural Network for Response Classification in Health Consultations",
        "Link": "https://ieeexplore.ieee.org/document/10699329/",
        "Abstract": "Patients seek quality healthcare because they trust their doctors and the healthcare system. However, the use of AI models in medical consultations has undermined this trust. AI systems typically depend on accurate and large volumes of data for training, but in cases of insufficient or incorrect data, this can lead to incomplete or flawed outputs. The inaccuracies in the response generated by AI systems may result in biased outcomes, compromising patient care and further eroding the trust patients place in the healthcare system. In this paper, we describe an innovative approach to distinguishing between responses generated by AI and those written by human doctors during health consultations, using an efficient neural network. As part of our feature extraction approach, we converted text into numerical representations via word-level tokenization, mapping to integer sequences. This allows the neural network to efficiently process text while preserving semantic structure and handling a large vocabulary with fixed sequence lengths. Through rigorous experimentation and evaluation, we showcase the effectiveness and reliability of our proposed neural network architecture, MedXNet, in accurately classifying diverse responses encountered in health consultations. For the classification approach, we combined BiLSTM, Transformer, and CNN layers to capture local and global dependencies in sequence inputs and a dense layer that was fully connected with dropout regularization and softmax activation. We compared MedXNet performance with different RNNs, including LSTM, Bi-LSTM, GRU, and 1D-CNN, across three datasets of increasing complexity. Dataset A represents simple data, dataset B introduces greater complexity, and dataset C poses the highest level of challenge. Our findings revealed that MedXNet outperforms the others with an accuracy of 98.74% on dataset A. Although the accuracy of MedXNet decreased on B, it remains the top performer. With 94.63% accuracy, MedXNet still achieves the highest accuracy in dataset C. Based on these findings, MedXNet demonstrated robustness across a wide range of data complexity levels, making it an ideal classification tool for doctor-written and AI-generated text in health consultations. This can enhance the trust patients have in the responses they receive during online medical consultations.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3470134",
            "Date of Publication": "30 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Olumide E. Ojo",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico",
                    "Departments of Linguistics and Computer Science, Montclair State University, Montclair, NJ, USA"
                ]
            },
            {
                "name": "Olaronke O. Adebanji",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico",
                    "Departments of Linguistics and Computer Science, Montclair State University, Montclair, NJ, USA"
                ]
            },
            {
                "name": "Hiram Calvo",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Alexander Gelbukh",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Anna Feldman",
                "labs": [
                    "Departments of Linguistics and Computer Science, Montclair State University, Montclair, NJ, USA"
                ]
            },
            {
                "name": "Ofir Ben Shoham",
                "labs": [
                    "Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Be’er Sheva, Israel"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Artificial intelligence",
                "Neural networks",
                "Feature extraction",
                "Accuracy",
                "Biological system modeling",
                "Training",
                "Text categorization",
                "Predictive models",
                "Medical diagnostic imaging"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "classification models",
                "deep learning",
                "machine learning",
                "MedXNet",
                "neural network",
                "NLP",
                "response classification",
                "text classification"
            ]
        }
    },
    {
        "Title": "Morpho-Phraseological Based Classification of CEFR Italian L2 Learner Writing Proficiency",
        "Link": "https://ieeexplore.ieee.org/document/10734098/",
        "Abstract": "This paper presents a model for the automatic classification of writing proficiency in Italian as a second language (L2) according to the Common European Framework of Reference for languages (CEFR). The proposed method integrates lexical and morphosyntactic quantitative analysis with phraseological dimensions. Phraseological aspects include the ability to use and understand fixed expressions, idioms, and other multi-word units that are common in a language and reflect the depth of language comprehension typically manifested by native speakers. Specific techniques for encoding phraseological features have been introduced, and basic phraseological statistics, previously unavailable for Italy, have been extracted from an Italian corpus. The proposed model was experimentally compared with widely used machine learning models on a dataset of written texts produced by non-native speakers for the official Italian CEFR certification exams. The experimental results outperformed previous work on the CEFR classification of Italian L2 proficiency in terms of accuracy and all relevant prediction metrics, demonstrating the effectiveness of the proposed approach, which integrates morphosyntactic and phraseological features.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3485988",
            "Date of Publication": "24 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Valentina Franzoni",
                "labs": [
                    "Department of Mathematics and Computer Science, University of Perugia, Perugia, Italy",
                    "Department of Computer Science, Hong Kong Baptist University, Hong Kong, Kowloon Tsai, SAR, China"
                ]
            },
            {
                "name": "Giulio Biondi",
                "labs": [
                    "Department of Engineering, University of Perugia, Perugia, Italy"
                ]
            },
            {
                "name": "Alfredo Milani",
                "labs": [
                    "Department of Mathematics and Computer Science, University of Perugia, Perugia, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Complexity theory",
                "Syntactics",
                "Linguistics",
                "Feature extraction",
                "Accuracy",
                "Standards",
                "Machine learning",
                "Vocabulary",
                "Europe",
                "Current measurement"
            ],
            "Author Keywords": [
                "Machine learning",
                "classification algorithms",
                "complexity measures",
                "text complexity",
                "language proficiency",
                "L2 learners",
                "NLP"
            ]
        }
    },
    {
        "Title": "Convolutional Versus Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing",
        "Link": "https://ieeexplore.ieee.org/document/11072699/",
        "Abstract": "Software logs generated by sophisticated network emulators in the telecommunications industry, such as VIAVI TM500, are extremely complex, often comprising tens of thousands of text lines with minimal resemblance to natural language. Only specialised expert engineers can decipher such logs and troubleshoot defects in test runs. While AI offers a promising solution for automating defect triage, potentially leading to massive revenue savings for companies, state-of-the-art large language models (LLMs) suffer from significant drawbacks in this specialised domain. These include a constrained context window, limited applicability to text beyond natural language, and high inference costs. To address these limitations, we propose a compact convolutional neural network (CNN) architecture that offers a context window spanning up to 200,000 characters and achieves over 96% accuracy (F\n1>0.9\n) in classifying multifaceted software logs into various layers in the telecommunications protocol stack. Specifically, the proposed model is capable of identifying defects in test runs and triaging them to the relevant department, formerly a manual engineering process that required expert knowledge. We evaluate several LLMs; LLaMA2-7B, Mixtral_\n8×7\nB, Flan-T5, BERT and BigBird, and experimentally demonstrate their shortcomings in our specialized application. Despite being lightweight, our CNN achieves strong performance compared to LLM-based approaches in telecommunications log classification while minimizing the cost of production. Our defect triaging AI model is deployable on edge devices without dedicated hardware and is applicable across software logs in various industries.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3587029",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Achintha Ihalage",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K."
                ]
            },
            {
                "name": "Sayed Taheri",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K.",
                    "Department of Electronics and Electrical Engineering, Brunel University of London, London, U.K."
                ]
            },
            {
                "name": "Faris Muhammad",
                "labs": [
                    "VIAVI Solutions Inc., Stevenage, U.K."
                ]
            },
            {
                "name": "Hamed Al-Raweshidy",
                "labs": [
                    "Department of Electronics and Electrical Engineering, Brunel University of London, London, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Computer architecture",
                "Convolutional neural networks",
                "Telecommunications",
                "Long short term memory",
                "Anomaly detection",
                "Large language models",
                "Cellular networks",
                "Support vector machines",
                "Analytical models"
            ],
            "Author Keywords": [
                "Cellular networks",
                "LLM",
                "log analysis",
                "machine learning",
                "NLP"
            ]
        }
    },
    {
        "Title": "CLEFT: Contextualised Unified Learning of User Engagement in Video Lectures With Feedback",
        "Link": "https://ieeexplore.ieee.org/document/10045668/",
        "Abstract": "Predicting contextualised engagement in videos is a long-standing problem that has been popularly attempted by exploiting the number of views or likes using different computational methods. The recent decade has seen a boom in online learning resources, and during the pandemic, there has been an exponential rise of online teaching videos without much quality control. As a result, we are faced with two key challenges. First, how to decide which lecture videos are engaging to intrigue the listener and increase productivity, and second, how to automatically provide feedback to the content creator using which they could improve the content. The quality of the content could be improved if the creators could automatically get constructive feedback on their content. On the other hand, there has been a steep rise in developing computational methods to predict a user engagement score. In this paper, we have proposed a new unified model, CLEFT, that means “Contextualised unified Learning of user Engagement in video lectures with Feedback” that learns from the features extracted from freely available public online teaching videos and provides feedback on the video along with the user engagement score. Given the complexity of the task, our unified framework employs different pre-trained models working together as an ensemble of classifiers. Our model exploits a range of multi-modal features to model the complexity of language, context agnostic information, textual emotion of the delivered content, animation, speaker’s pitch, and speech emotions. Our results support hypothesis that proposed model can detect engagement reliably and the feedback component gives useful insights to the content creator to further help improve the content.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3245982",
            "Date of Publication": "15 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sujit Roy",
                "labs": [
                    "Brainalive Research Pvt. Ltd., Kanpur, India"
                ]
            },
            {
                "name": "Vishal Gaur",
                "labs": [
                    "Brainalive Research Pvt. Ltd., Kanpur, India"
                ]
            },
            {
                "name": "Haider Raza",
                "labs": [
                    "School of Computer Science and Electronics Engineering, University of Essex, CO4 3SQ Colchester, U.K"
                ]
            },
            {
                "name": "Shoaib Jameel",
                "labs": [
                    "School of Electronics and Computer Science, University of Southampton, SO17 1BJ Southampton, U.K"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Predictive models",
                "Context modeling",
                "Feature extraction",
                "Emotion recognition",
                "Text recognition",
                "Computational modeling",
                "Animation",
                "Bit error rate"
            ],
            "Author Keywords": [
                "NLP",
                "emotions",
                "video engagement",
                "contextual language models",
                "text-based emotions",
                "BERT"
            ]
        }
    },
    {
        "Title": "Evaluating Neural Network Models for Word Segmentation in Agglutinative Languages: Comparison With Rule-Based Approaches and Statistical Models",
        "Link": "https://ieeexplore.ieee.org/document/10734148/",
        "Abstract": "Word segmentation in agglutinative languages presents significant challenges due to morphological complexity and variability of linguistic structure. Although practical, traditional rule-based and statistical model-based approaches show limitations in handling these complexities. This study investigates the effectiveness of neural network models, specifically LSTM, Bi-LSTM with CRF, and BERT, in comparison to these traditional methods, using datasets from several agglutinative languages such as Turkish, Finnish, Hungarian, Nahuatl, and Swahili. The methodology includes preprocessing and data augmentation to improve data quality and consistency, followed by training and evaluating the selected models. The results reveal that the neural network models significantly outperform rule-based and statistical model-based approaches on all metrics assessed. Specifically, for the rule-based models, the BERT model achieved 92% accuracy and 91% F1-score in Turkish, compared to 70% and 67%, respectively. Moreover, the Bi-LSTM with CRF showed 86% recall in Finnish, significantly outperforming traditional models. Implementing advanced preprocessing and data augmentation techniques allows for optimizing the performance of the models. This study confirms the effectiveness of neural network models in word segmentation and provides a valuable framework for future research in natural language processing in complex linguistic contexts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3486188",
            "Date of Publication": "24 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "William Villegas-Ch",
                "labs": [
                    "Escuela de Ingeniería en Ciberseguridad, FICA, Universidad de Las Américas, Quito, Ecuador"
                ]
            },
            {
                "name": "Rommel Gutierrez",
                "labs": [
                    "Escuela de Ingeniería en Ciberseguridad, FICA, Universidad de Las Américas, Quito, Ecuador"
                ]
            },
            {
                "name": "Alexandra Maldonado Navarro",
                "labs": [
                    "Escuela de Posgrados, Maestría en Derecho Digital, Universidad de Las Américas, Quito, Ecuador"
                ]
            },
            {
                "name": "Aracely Mera-Navarrete",
                "labs": [
                    "Departamento de Sistemas, Universidad Internacional del Ecuador, Quito, Ecuador"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Neural networks",
                "Hidden Markov models",
                "Linguistics",
                "Context modeling",
                "Data augmentation",
                "Natural language processing",
                "Complexity theory",
                "Long short term memory",
                "Measurement"
            ],
            "Author Keywords": [
                "Word segmentation",
                "agglutinative languages",
                "neural networks",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Transformers for Domain-Specific Text Classification: A Case Study in the Banking Sector",
        "Link": "https://ieeexplore.ieee.org/document/11062818/",
        "Abstract": "The growing volume of unstructured text data in the banking sector has created a need for advanced classification methods to manage customer inquiries efficiently, resulting in faster response times, automated message classification, and reduced human errors. The classification results are integrated into live banking systems, enabling continuous 24/7 message processing and instant categorization. Previously, human operators could process up to 70 messages per day during working hours. With AI integration, the system now categorizes messages automatically and in real time, ensuring that relevant department managers receive them promptly, significantly improving operational workflows. Our research offers key insights into applying transformer models for domain-specific classification in banking. This paper presents a case study on fine-tuning transformer models—BERT, GPT-2, GPT-3, and Falcon-1B for domain-specific text classification in the banking industry. The dataset used in this investigation consists of 5,447 customer messages submitted between 2023 and 2024 through Invest Bankś secure messaging portal, which serves as a direct communication channel where customers can submit their requests at any time of the day without needing to visit the bank in person. The inquiries span fifteen service categories provided by the bank. To the best of our knowledge, no prior studies have focused on automating customer secure messages in the banking sector, especially those written in colloquial and abbreviated language. The models were fine-tuned to improve classification accuracy and operational efficiency. A heterogeneous ensemble of BERT and GPT-2 achieved the best performance with an Area Under the Curve (AUC) score of 99.42% and an F1 score of 86.74%. A homogeneous ensemble of BERT models also performed well, achieving an AUC score of 98.81% and an F1 score of 84.57%. Notably, the single BERT and GPT-2 models, with AUC scores of 97.65% and 97.9%, respectively, delivered competitive performance, making them viable alternatives when computational resources are limited.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3585164",
            "Date of Publication": "02 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Samer Murrar",
                "labs": [
                    "Faculty of Information Technology, Applied Science Private University, Amman, Jordan"
                ]
            },
            {
                "name": "Fatima M. Alhaj",
                "labs": [
                    "Faculty of Information Technology, Applied Science Private University, Amman, Jordan"
                ]
            },
            {
                "name": "Fadi Almasalha",
                "labs": [
                    "Faculty of Information Technology, Applied Science Private University, Amman, Jordan"
                ]
            },
            {
                "name": "Mahmoud H. Qutqut",
                "labs": [
                    "Computer Science Department, Center for Applied Mathematics and Bioinformatics (CAMB), Gulf University of Science and Technology (GUST), Hawally, Kuwait"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Banking",
                "Text categorization",
                "Accuracy",
                "Finance",
                "Context modeling",
                "Sentiment analysis",
                "Customer services",
                "Adaptation models",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Transformers",
                "text classification",
                "fine-tuning",
                "NLP",
                "GPT",
                "BERT"
            ]
        }
    },
    {
        "Title": "Extremist Ideology Classification in Kazakh: A Multi-Class Approach Using Machine Learning and Psycholinguistic Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11119495/",
        "Abstract": "This paper presents a new approach for analyzing extremist content in the Kazakh language on social media using advanced machine learning and natural language processing techniques. With the rapid growth of online data, especially on social networks, there is an urgent need for tools that can identify and classify extremist ideologies. Our study focuses on four primary categories: propaganda, recruitment, radicalization, and neutral content. We employ a hybrid methodology that combines traditional text vectorization techniques, machine learning algorithms, and a psycholinguistic analysis module (PLAM) specifically adapted for the Kazakh language. To improve the accuracy of classification and capture subtle emotional signals, we integrate psycholinguistic features extracted through PLAM. The experimental results demonstrate the effectiveness of our hybrid approach. The combination of CountVectorizer + Logistic Regression + PLAM achieved the highest performance among traditional models (F1-score: 0.9305, Accuracy: 0.9308, ROC AUC: 0.9892). Among deep learning models, the BERT + LSTM model yielded the best results (F1-score: 0.9481, Accuracy: 0.9485, ROC AUC: 0.9918), followed by the standalone BERT model (F1-score: 0.9412, Accuracy: 0.9414, ROC AUC: 0.9901). These findings confirm that combining contextual embeddings with sequential modeling improves classification performance, particularly for ideologically complex categories. This research provides an effective framework for multilingual text analysis. It also contributes to improved monitoring and prevention of extremist content in underrepresented languages, such as Kazakh. Future work will focus on refining these methods and exploring their application in other domains for robust content moderation and security in the digital space.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3596601",
            "Date of Publication": "07 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shynar Mussiraliyeva",
                "labs": [
                    "Department of Cybersecurity and Cryptology, Al-Farabi Kazakh National University (KazNU), Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Milana Bolatbek",
                "labs": [
                    "Department of Cybersecurity and Cryptology, Al-Farabi Kazakh National University (KazNU), Almaty, Kazakhstan"
                ]
            },
            {
                "name": "Kymbat Baisylbayeva",
                "labs": [
                    "Department of Cybersecurity and Cryptology, Al-Farabi Kazakh National University (KazNU), Almaty, Kazakhstan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Machine learning",
                "Social networking (online)",
                "Accuracy",
                "Recruitment",
                "Natural language processing",
                "Machine learning algorithms",
                "Adaptation models",
                "Analytical models",
                "Long short term memory",
                "Data models"
            ],
            "Author Keywords": [
                "Text classification",
                "NLP",
                "machine learning",
                "counter-extremism",
                "social network analysis",
                "Kazakh language",
                "ideology of extremist messages"
            ]
        }
    },
    {
        "Title": "Enhancing Domain Generalization Performance in Low-Resource Setting via External Dataset and Pseudo Labeling With Sentence-BERT",
        "Link": "https://ieeexplore.ieee.org/document/10878970/",
        "Abstract": "Recent studies on data augmentation have focused on improving model performance with limited training data within a specific dataset. While the goal is to enhance performance on the dataset itself, this approach also addresses broader challenges, such as enhancing domain generalization. Building on this, we propose the Out-of-Domain Pseudo Labeling (OOD-PL) method, a data augmentation technique designed to ensure data diversity and enhance domain generalization of model in low-resource settings. Our approach introduces external data and assigns pseudo labels based on semantic vicinal interpolation with the intended training data. We observed significant improvements in domain generalization across three datasets from different domains. Unlike traditional methods, this approach utilizes other samples as a form of augmentation for the training data. Our method can be flexibly integrated with existing augmentation techniques, and we demonstrated that it performs well even when the available training data is extremely limited. Furthermore, we conducted various in-depth analysis experiments to strengthen the validity of our proposed method and demonstrate its robustness in effectively enhancing domain generalization. As a result, we were able to propose a methodology that overcomes the limitations of using specific datasets, even in situations where their availability is restricted, by leveraging out-of-domain samples.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3540090",
            "Date of Publication": "10 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junho Lee",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Dongjak, Seoul, South Korea"
                ]
            },
            {
                "name": "Seunguk Yu",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Dongjak, Seoul, South Korea"
                ]
            },
            {
                "name": "Jinhee Jang",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Dongjak, Seoul, South Korea"
                ]
            },
            {
                "name": "Keunhyeung Park",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Dongjak, Seoul, South Korea"
                ]
            },
            {
                "name": "Youngbin Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Dongjak, Seoul, South Korea",
                    "Graduate School of Advanced Imaging Science, Multimedia and Film, Chung-Ang University, Dongjak, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Data augmentation",
                "Training",
                "Semantics",
                "Training data",
                "Translation",
                "Adaptation models",
                "Labeling",
                "Costs",
                "Interpolation"
            ],
            "Author Keywords": [
                "Data augmentation",
                "domain generalization",
                "low-resource NLP"
            ]
        }
    },
    {
        "Title": "IoT Rule Generation With Cross-View Contrastive Learning and Perplexity-Based Ranking",
        "Link": "https://ieeexplore.ieee.org/document/11036749/",
        "Abstract": "Trigger-action platforms (TAPs) streamline task automation in Internet of Things (IoT) ecosystems through intuitive IF-THEN rules. However, the rapid expansion of TAP devices, combined with the diversity and overlap of their functionalities, presents significant challenges for users in formulating rules that accurately capture their intentions and effectively map these intents to the appropriate device actions. This article presents Trigger-Action Rule GEneration (TARGE), a novel framework for generating IoT automation rules directly from natural language user intents. TARGE leverages large language models (LLMs) to interpret user intents and employs cross-view contrastive learning to generate rule embeddings that capture TAP functionality and device relationships. Its ranking mechanism combines semantic consistency with LLM-derived perplexity to prioritize contextually coherent rules. Evaluated on a dataset of IFTTT rules, TARGE demonstrates robust performance across scenarios involving both well-defined and ambiguous user intents, consistently outperforming state-of-the-art methods by at least 46% in exact match accuracy and 35% in multirule recommendations.",
        "Details": {
            "DOI": "10.1109/JIOT.2025.3579920",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Internet of Things Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2327-4662"
        },
        "authors_data": [
            {
                "name": "Gaetano Cimino",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Vincenzo Deufemia",
                "labs": [
                    "Department of Computer Science, University of Salerno, Fisciano, Italy"
                ]
            },
            {
                "name": "Mattia Limone",
                "labs": [
                    "Electronics Division, Leonardo S.p.A., Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Automation",
                "Internet of Things",
                "Natural languages",
                "Semantics",
                "Contrastive learning",
                "Smart homes",
                "Accuracy",
                "Translation",
                "Training",
                "Programming"
            ],
            "Author Keywords": [
                "Cross-view contrastive learning",
                "Internet of Things (IoT) rule generation",
                "natural language processing (NLP)",
                "smart home"
            ]
        }
    },
    {
        "Title": "LLM-Driven APT Detection for 6G Wireless Networks: A Systematic Review and Taxonomy",
        "Link": "https://ieeexplore.ieee.org/document/11112774/",
        "Abstract": "Sixth Generation (6G) wireless networks, which are expected to be deployed in the 2030s, have already created great excitement in academia and the private sector with their extremely high communication speed and low latency rates. However, despite the ultra-low latency, high throughput, and AI-assisted orchestration capabilities they promise, they are vulnerable to stealthy and long-term Advanced Persistent Threats (APTs). Large Language Models (LLMs) stand out as an ideal candidate to fill this gap with their high success in semantic reasoning and threat intelligence. This paper presents the first systematic review and taxonomy for LLM-assisted APT detection in 6G networks. It also provides insights by reviewing recent research on the intersection of LLMs, APTs, and 6G. Key challenges such as limitations in edge deployment, data scarcities, and explainability gaps are identified and a multidimensional taxonomy is provided in line with the APT lifecycle and 6G contexts. The paper is based on 142 studies from 2018 to 2025, searching leading databases such as IEEE Xplore, ACM Digital Library, SpringerLink, and Elsevier ScienceDirect.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595665",
            "Date of Publication": "05 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammed Golec",
                "labs": [
                    "Department of Computer Engineering, Boğaziçi University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Yaser Khamayseh",
                "labs": [
                    "College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Suhib Bani Melhem",
                "labs": [
                    "Department of Cybersecurity, College of Engineering, Al Ain University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Abdulmalik Alwarafy",
                "labs": [
                    "Department of Computer and Network Engineering, College of Information Technology, United Arab Emirates University, Al Ain, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "6G mobile communication",
                "Surveys",
                "Taxonomy",
                "Systematic literature review",
                "Wireless networks",
                "Systematics",
                "Semantics",
                "Image edge detection",
                "Threat assessment",
                "Reproducibility of results"
            ],
            "Author Keywords": [
                "6G wireless networks",
                "advanced persistent threat (APT)",
                "large language model (LLM)",
                "natural language processing (NLP)",
                "security"
            ]
        }
    },
    {
        "Title": "An Efficient Methodology for the Categorization of Software Requirements Using Natural Language Processing and Similarity Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10994440/",
        "Abstract": "The classification of software requirements into functional (FRs) and non-functional requirements (NFRs) is indispensable for the efficacious implementation of software systems. Traditionally, this endeavor reliant on manual exertion, this process has proven to be both protracted and inherently susceptible to errors, and inaccuracies. Recent advancements in machine learning (ML) have begun to offer promising avenues for automation, enhancing both the efficiency and accuracy of requirement classification. The following research study proposes “NLPReqClassifier,” a lightweight automated classification model that integrates Term Frequency-Inverse Document Frequency (TF-IDF) and Cosine Similarity. Leveraging the PROMISE dataset, which is enriched continually by academic and professional input, this model addresses the existing shortcomings of traditional classification methods. The proposed model utilizes a dual-evaluation approach, ensuring relevance and precision across varied software development contexts. By incorporating iterative feedback into the model’s training process, this research not only aligns with academic standards but also meets the practical demands of the industry. The model’s performance was tested in both academic settings dataset and real-world industry dataset, particularly focusing on its application in Enterprise Resource Planning (ERP) systems. The proposed model demonstrated superior capability to categorize a broad spectrum of software requirements accurately, outperforming existing traditional methodologies in terms of adaptability and efficiency. It showed significant improvements over traditional classification methods, particularly in its ability to dynamically adapt to new and evolving requirements. The dual-evaluation process verified the model’s effectiveness, showcasing high precision and recall rates in both controlled and practical environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3568504",
            "Date of Publication": "09 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahat Izhar",
                "labs": [
                    "Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand"
                ]
            },
            {
                "name": "Kenneth Cosh",
                "labs": [
                    "Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand"
                ]
            },
            {
                "name": "Lachana Ramingwon",
                "labs": [
                    "Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand"
                ]
            },
            {
                "name": "Sakgasit Ramingwong",
                "labs": [
                    "Faculty of Engineering, Chiang Mai University, Chiang Mai, Thailand"
                ]
            },
            {
                "name": "Shahid N. Bhatti",
                "labs": [
                    "Department of Software Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Accuracy",
                "Scalability",
                "Computational modeling",
                "Software",
                "Security",
                "Usability",
                "Nearest neighbor methods",
                "Natural language processing",
                "Machine learning"
            ],
            "Author Keywords": [
                "Software requirements engineering",
                "natural language processing (NLP)",
                "machine learning (ML)",
                "requirements classification"
            ]
        }
    },
    {
        "Title": "In-Context Learning in Large Language Models (LLMs): Mechanisms, Capabilities, and Implications for Advanced Knowledge Representation and Reasoning",
        "Link": "https://ieeexplore.ieee.org/document/11018434/",
        "Abstract": "The rapid growth of Large Language Models (LLMs) and their in-context learning (ICL) capabilities has significantly transformed paradigms in artificial intelligence (AI) and natural language processing. Notable models, such as OpenAI’s GPT series, have demonstrated previously unprecedented advancements in verbal comprehension and adaptability, dynamically responding to new tasks offered via contextual prompts. This study provides a detailed survey of recent advances in theoretical research on LLMs and ICL. The search was conducted across several scholarly databases including Google Scholar, arXiv, IEEE Xplore, ACM Digital Library, and SpringerLink, covering publications from January 2019 to March 2024. We investigate how LLMs encode and use knowledge via ICL, the evolving reasoning skills that result from this process, and the considerable impact of prompt design on LLM reasoning performance, particularly in symbolic reasoning tasks. Furthermore, we investigate the theoretical frameworks that explain or challenge LLM behaviors in ICL contexts and address the significance of these findings for the development of complex knowledge representation and reasoning systems. Using a systematic methodology consistent with accepted research criteria, this review synthesizes significant observations, highlights existing gaps and obstacles, and discusses implications for future research and practice. Our goal is to connect theoretical ideas with actual advances in Artificial Intelligence, ultimately contributing to the continuing discussion about the capabilities and applications of LLMs in knowledge representation and reasoning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3575303",
            "Date of Publication": "30 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Azza Mohamed",
                "labs": [
                    "Faculty of Engineering and Computing, Liwa University, Al Ain, United Arab Emirates"
                ]
            },
            {
                "name": "Mohamed El Rashid",
                "labs": [
                    "Imam Malik College, Dubai, United Arab Emirates"
                ]
            },
            {
                "name": "Khaled Shaalan",
                "labs": [
                    "Faculty of Engineering and IT, The British University in Dubai, Dubai, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Artificial intelligence",
                "Knowledge representation",
                "Systematic literature review",
                "Gaze tracking",
                "Solid modeling",
                "Benchmark testing",
                "Training",
                "Context modeling",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "in-context learning",
                "large language models (LLMs)",
                "knowledge representation reasoning",
                "advanced AI models",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "FArSS: Fast and Efficient Semantic Question Similarity in Arabic",
        "Link": "https://ieeexplore.ieee.org/document/10840214/",
        "Abstract": "This paper addresses the challenge of efficient semantic question similarity in Arabic by leveraging fastText embeddings and a simple neural network architecture. Our model (FArSS) avoids the complexities of recurrent connections and attention mechanisms, resulting in a streamlined and efficient approach. With strategic data augmentation, our model achieves an F1-score of 0.928, closely competing with state-of-the-art models that rely on advanced architectures employing self-attention mechanisms. Additionally, our model outperforms both GPT-4o and GPT-4 in semantic question similarity in Arabic, underscoring the potential of specialized, efficient models to surpass large language models in specific tasks. This work demonstrates that our method not only maintains high performance but also ensures fast training and inference times. The practical advantages of our approach make it especially suitable for real-time applications, contributing to the development of more effective and efficient natural language processing systems. Our findings highlight the continued importance of efficient tailored models in addressing specific natural language processing challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3529527",
            "Date of Publication": "14 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohamed Alkaoud",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Vectors",
                "Computational modeling",
                "Training",
                "Encoding",
                "Bidirectional control",
                "Computer architecture",
                "Transformers",
                "Feedforward neural networks",
                "Data models"
            ],
            "Author Keywords": [
                "Arabic NLP",
                "efficient machine learning",
                "fastText",
                "machine learning",
                "natural language processing",
                "neural networks",
                "semantic similarity",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "A Multi-Modal Attentive Framework That Can Interpret Text (MMAT)",
        "Link": "https://ieeexplore.ieee.org/document/11072709/",
        "Abstract": "Deep learning algorithms have demonstrated exceptional performance on various computer vision and natural language processing tasks. However, for machines to learn information signals, they must understand and have enough reasoning power to respond to general questions based on the linguistic features present in images. Questions such as “What temperature is my oven set to?” need the models to understand objects in the images visually and then spatially identify the text associated with them. The existing Visual Question Answering model fails to recognize linguistic features present in the images, which is crucial for assisting the visually impaired. This paper aims to deal with the task of a visual question answering system that can do reasoning with text, optical character recognition (OCR), and visual modalities. The proposed Visual Question Answering model focuses on the image’s most relevant part by using an attention mechanism and passing all the features to the fusion encoder after getting pairwise attention, where the model is inclined toward the OCR-Linguistic features. The proposed model uses the dynamic pointer network instead of classification for iterative answer prediction with a focal loss function to overcome the class imbalance problem. On the TextVQA dataset, the proposed model obtains an accuracy of 46.8% and an average of 55.21% on the STVQA dataset. The results indicate the effectiveness of the proposed approach and suggest a Multi-Modal Attentive Framework that can learn individual text, object, and OCR features and then predict answers based on the text in the image.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586900",
            "Date of Publication": "08 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vijay Kumari",
                "labs": [
                    "Department of CSIS, Birla Institute of Technology and Science Pilani, Pilani Campus, Jhunjhunu, Rajasthan, India"
                ]
            },
            {
                "name": "Sarthak Gupta",
                "labs": [
                    "Department of CSIS, Birla Institute of Technology and Science Pilani, Pilani Campus, Jhunjhunu, Rajasthan, India"
                ]
            },
            {
                "name": "Yashvardhan Sharma",
                "labs": [
                    "Department of CSIS, Birla Institute of Technology and Science Pilani, Pilani Campus, Jhunjhunu, Rajasthan, India"
                ]
            },
            {
                "name": "Lavika Goel",
                "labs": [
                    "Department of CSE, Malaviya National Institute of Technology, Jaipur, Rajasthan, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Visualization",
                "Optical character recognition",
                "Question answering (information retrieval)",
                "Computational modeling",
                "Cognition",
                "Linguistics",
                "Deep learning",
                "Predictive models",
                "Transformers",
                "Computer vision"
            ],
            "Author Keywords": [
                "Visual question answering system (VQA)",
                "text visual question answering system (Text-VQA)",
                "optical character recognition (OCR)",
                "attention mechanism",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "A Survey on Spoken Italian Datasets and Corpora",
        "Link": "https://ieeexplore.ieee.org/document/10872911/",
        "Abstract": "Spoken Italian datasets are curated collections of audio recordings featuring native Italian speech in various contexts (e.g., spontaneous dialogues, read text, telephone conversations), often accompanied by transcriptions or linguistic annotations. They serve as foundational resources for a wide range of applications, including Automatic Speech Recognition (ASR), Text-To-Speech (TTS) synthesis, emotion detection, and broader linguistic research. Despite Italian’s status as a richly diverse Romance language—marked by significant dialectal variation—publicly available large-scale corpora have remained comparatively underrepresented when contrasted with those of major world languages such as English or Mandarin. In this survey, we present a comprehensive examination of 66 spoken Italian datasets, highlighting their key characteristics, data collection methodologies, and annotation frameworks. We categorize the datasets by speech type (e.g., conversational, monologic, spontaneous), by source (e.g., broadcast media, telephone calls, field recordings), and by demographic or linguistic attributes (including dialects and sociolinguistic features). Our analysis uncovers critical issues around dataset scarcity, demographic underrepresentation, and restricted accessibility, limiting broader research and development efforts. To address these gaps, we propose best practices and future directions—such as expanding demographic coverage, promoting open-access models, and standardizing annotation protocols—to enrich Italian speech data resources. The complete dataset inventory is publicly available on GitHub and archived on Zenodo, offering researchers and developers a valuable reference. By highlighting both the achievements and the shortcomings in existing resources, this work ultimately aims to foster collaboration and to spur further advancements in Italian speech technologies and linguistic research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3538952",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marco Giordano",
                "labs": [
                    "Department of Information Engineering, Computer Science and Mathematics (DISIM), Università degli Studi dell’Aquila, L’Aquila, Italy"
                ]
            },
            {
                "name": "Claudia Rinaldi",
                "labs": [
                    "National Inter-University Consortium for Telecommunications (CNIT), Parma, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Linguistics",
                "Recording",
                "Surveys",
                "Speech recognition",
                "Training",
                "Telephone sets",
                "Oral communication",
                "Media",
                "Digital audio broadcasting",
                "Cultural differences"
            ],
            "Author Keywords": [
                "Spoken Italian datasets",
                "speech technology",
                "natural language processing (NLP)",
                "dataset annotation",
                "computational linguistics",
                "deep learning models"
            ]
        }
    },
    {
        "Title": "SHIFA: SBERT-Based Healthcare Information Focused Arabic Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/11005526/",
        "Abstract": "Question Answering (QA) systems have been developed as a promising solution and an efficient approach to retrieving significant information over the Internet. Answer selection is one of the key components of many types of QA applications, which requires addressing a semantic gap between question-answer pairs. The idea behind this research is to use the SBERT method for entities and context patterns to effectively capture the semantics between QA pairs in two different ways: the feature extractor and the transfer learning model. In the transfer learning approach, the Arabic BERT model is fine-tuned using SBERT on the AraMed dataset to adapt its parameters for Arabic answer selection classification. In the feature extraction approach, SBERT is combined with LSTM, GRU, and CNN classifiers to evaluate its performance in generating semantic embeddings. There are three models presented in SHIFA: the HT-SBERT-LSTM, HT-SBERT-GRU and HT-SBERT-CNN. These models deal with the problem of representing contextual data. The results show that the fine-tuned AraBERTv0.2 with the SBERT model accomplishes state-of the-art performance results and achieves up to 87% in terms of F1-score and accuracy compared to other Arabic pre-trained language models such as AraBERTv2, CAMeLBERT, mBERT and LaBSE. Besides, the HT-SBERT-LSTM reaches an accuracy of 94.25%, while the HT-SBERT-GRU reaches an accuracy of 94.13%. The SHIFA models show that mixing sentence-level embeddings with sequence models achieves competitively contextual and semantic representations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3570637",
            "Date of Publication": "15 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rahaf Alruwaithi",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sarah AlHumoud",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical services",
                "Deep learning",
                "Context modeling",
                "Semantics",
                "Feature extraction",
                "Accuracy",
                "Bidirectional long short term memory",
                "Internet",
                "Question answering (information retrieval)",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Answer selection",
                "Arabic NLP",
                "deep learning",
                "natural language processing",
                "neural network",
                "question answering system",
                "sentence-BERT"
            ]
        }
    },
    {
        "Title": "Improving Suicide Ideation Detection Through Feature Engineering and Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/11134373/",
        "Abstract": "Suicidal ideation detection from social media text is a growing area of research, yet many existing approaches suffer from limited contextual understanding, low interpretability, and inadequate scalability. This study addresses these challenges by proposing a comprehensive machine learning framework that balances performance, interpretability, and real-world applicability. Using a curated Reddit dataset (comparing “SuicideWatch” and “nonsuicide” posts), we evaluate both traditional feature extraction methods (TF-IDF, Bag-of-Words, and N-Grams) and contextual embeddings generated by BERT. These features are tested across five established classifiers: Random Forest, SVM, Logistic Regression, XGBoost, and LightGBM. Our results show that BERT combined with Logistic Regression achieves the highest F1-score (0.9392), outperforming both traditional models and ensemble methods. Additionally, we assess model robustness under varying dataset sizes and address class imbalance through targeted preprocessing and evaluation strategies. While our framework demonstrates strong performance, it is currently limited to English-language Reddit data and requires validation across platforms and demographics. This work contributes a reproducible and scalable pipeline to support mental health monitoring in online environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3601853",
            "Date of Publication": "22 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shadi Banitaan",
                "labs": [
                    "Department of Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates",
                    "Department of Electrical and Computer Engineering and Computer Science, University of Detroit Mercy, Detroit, MI, USA"
                ]
            },
            {
                "name": "Hebah Alquran",
                "labs": [
                    "Department of Information Technology, Yarmouk University, Irbid, Jordan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Feature extraction",
                "Accuracy",
                "Mental health",
                "Random forests",
                "Natural language processing",
                "Machine learning",
                "Linguistics",
                "Data models",
                "Training"
            ],
            "Author Keywords": [
                "Suicide ideation detection",
                "mental health",
                "text classification",
                "natural language processing (NLP)",
                "machine learning",
                "social media mining",
                "depression detection"
            ]
        }
    },
    {
        "Title": "AI-Generated Messaging for Life Events Using Structured Prompts: A Comparative Study of GPT With Human Experts and Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/11129070/",
        "Abstract": "Large Language Models (LLMs) are increasingly used to generate social media posts, emails, narratives, and other forms of communication, yet few studies systematically assess how well these outputs align with their original prompt intent. This study evaluates the effectiveness of a zero-shot structured narrative prompt for generating 24 000 life event messages (birth, death, hiring, and firing events) using OpenAI’s GPT-4. A manually tagged sample of 2880 messages shows that 87.43% align with the intended life event when framed as X (formerly Twitter) posts. To scale this evaluation, we train nine machine learning (ML) models, including BERT, Keras-based architectures, eXtreme Gradient Boosting, Random Forest, and Support Vector Machines, per life event type, resulting in 36 binary classifiers. We apply an ensemble approach based on simple majority agreement to classify the remaining 21 120 messages. Manual validation of a 1% sample (n = 212) confirms a 90.57% match rate with human reviewers, with binomial tests confirming statistical significance above a 75% threshold across all event types (P-values ranging from 0.00025 to 0.0115). While valid messages are reliably identified, classifying invalid cases remains more challenging. This work offers a reproducible framework for validating AI-generated messaging and provides practical guidance for prompt-based applications. Limitations include the narrow event scope, exclusive use of English text, and reliance on structured prompts, which may not generalize to open-ended tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3600146",
            "Date of Publication": "18 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Christopher J. Lynch",
                "labs": [
                    "Virginia Modeling, Analysis, and Simulation Center, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Erik Jensen",
                "labs": [
                    "Virginia Modeling, Analysis, and Simulation Center, Old Dominion University, Suffolk, VA, USA",
                    "Modeling and Simulation Engineering Department, Old Dominion University, Norfolk, VA, USA"
                ]
            },
            {
                "name": "Ross Gore",
                "labs": [
                    "Center for Secure and Intelligent Critical Systems, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Virginia Zamponi",
                "labs": [
                    "Office of Enterprise Research and Innovation, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Kevin O’Brien",
                "labs": [
                    "Office of Enterprise Research and Innovation, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Brandon Feldhaus",
                "labs": [
                    "Office of Enterprise Research and Innovation, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Katherine Smith",
                "labs": [
                    "Virginia Digital Maritime Center, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Joseph Martínez",
                "labs": [
                    "Virginia Modeling, Analysis, and Simulation Center, Old Dominion University, Suffolk, VA, USA"
                ]
            },
            {
                "name": "Madison H. Munro",
                "labs": [
                    "Software Engineering and Cybersecurity Laboratory, Gianforte School of Computing, Montana State University, Bozeman, MT, USA"
                ]
            },
            {
                "name": "Timur E. Ozkose",
                "labs": [
                    "Computational and Data Sciences Department, George Mason University, Fairfax, VA, USA"
                ]
            },
            {
                "name": "Tugce B. Gundogdu",
                "labs": [
                    "Computer Science Department, George Mason University, Fairfax, VA, USA"
                ]
            },
            {
                "name": "Ann Marie Reinhold",
                "labs": [
                    "Software Engineering and Cybersecurity Laboratory, Gianforte School of Computing, Montana State University, Bozeman, MT, USA",
                    "Pacific Northwest National Laboratory, Richland, WA, USA"
                ]
            },
            {
                "name": "Hamdi Kavak",
                "labs": [
                    "Computational and Data Sciences Department, George Mason University, Fairfax, VA, USA"
                ]
            },
            {
                "name": "Barry Ezell",
                "labs": [
                    "Virginia Modeling, Analysis, and Simulation Center, Old Dominion University, Suffolk, VA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electronic mail",
                "Machine learning",
                "Data models",
                "Predictive models",
                "Chatbots",
                "Zero shot learning",
                "Prompt engineering",
                "Stakeholders",
                "Social networking (online)",
                "Pipelines"
            ],
            "Author Keywords": [
                "AI-generated messages",
                "ChatGPT",
                "generative AI",
                "generative pretrained transformers (GPT)",
                "large language models (LLMs)",
                "machine learning",
                "natural language processing (NLP)",
                "prompt engineering",
                "structured narrative prompt"
            ]
        }
    },
    {
        "Title": "Where Does mBERT Understand Code-Mixing? Layer-Dependent Performance on Semantic Tasks",
        "Link": "https://ieeexplore.ieee.org/document/11104253/",
        "Abstract": "Semantic tasks like lexical relation prediction and word analogy are crucial for deep language understanding, yet pose significant challenges when applied to code-mixed text, where multiple languages are interwoven. This study investigates the ability of multilingual BERT (mBERT) to capture semantic nuances in code-mixed scenarios (English-Spanish and English-Telugu) through layer-wise probing across four distinct tasks: lexical relation prediction, word analogy prediction, sentiment analysis, and intent classification. We employ probing classifiers trained on representations extracted from each of mBERT’s 12 layers to assess semantic knowledge capture throughout the model. Our comprehensive experiments reveal that mid-level layers (approximately 4-7) generally exhibit the strongest performance for tasks like lexical relation and intent classification in code-mixed settings. However, performance varies significantly by task, with sentiment analysis proving particularly challenging (achieving near chance-level accuracy), highlighting mBERT’s limitations in capturing certain code-mixed semantic subtleties. This work contributes a multi-task layer-wise analysis of mBERT’s semantic capabilities on code-mixed data, providing insights into optimal layer usage and pinpointing areas requiring further research for robust multilingual, code-mixed natural language understanding.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3594135",
            "Date of Publication": "30 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aditya Somani",
                "labs": [
                    "CSIS Department, BITS Pilani, Hyderabad Campus, Hyderabad, India"
                ]
            },
            {
                "name": "S. R. Mithun Kumar",
                "labs": [
                    "CSIS Department, BITS Pilani, Hyderabad Campus, Hyderabad, India"
                ]
            },
            {
                "name": "Aruna Malapati",
                "labs": [
                    "CSIS Department, BITS Pilani, Hyderabad Campus, Hyderabad, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Accuracy",
                "Multilingual",
                "Training",
                "Sentiment analysis",
                "Adaptation models",
                "Syntactics",
                "Data models",
                "Intent recognition",
                "Head"
            ],
            "Author Keywords": [
                "Code-mixing",
                "mBERT",
                "probing",
                "semantic understanding",
                "layer-wise analysis",
                "multilingual",
                "NLP"
            ]
        }
    },
    {
        "Title": "Contrastive and Attention-Based Multimodal Fusion: Detecting Negative Memes Through Diverse Fusion Strategies",
        "Link": "https://ieeexplore.ieee.org/document/11177202/",
        "Abstract": "With the revolution of social media, the proper analysis of sentiment expressed through both textual and visual media is one of the most challenging problems. While not all negatively charged memes are harmful, sentiment analysis helps distinguish between general negativity and content that may contribute to online harms, such as cyberbullying, misinformation, or hate speech. Conventional sentiment analysis approaches, which mainly concentrate on text-based content, may miss out on nuanced emotional cues present in images, emojis, or the overall context of a conversation. Subtle negative expressions are often misclassified because models do not effectively learn fine-grained differences between sentiment classes. The existing works having static fusion often lack ability to detect fine-grained or subtle negativity. In this work we propose Gated Contrastive Multimodal Fusion Model that processes the text and image streams in memes, through independent modality-specific neural networks, combined by means of an attention mechanism. The gated fusion block present in our architecture allows the model to pay closer attention to the most sentiment-rich elements. The contrastive block provides an accurate training mechanism to improve the classification of negative memes. Through experiments on benchmark datasets, we show that our methodology provides interpretable insights into the contribution of each modality. Thus, outperform SOTA models and open the door to better identification of online harmful memes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3613694",
            "Date of Publication": "24 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "B. S. Narendiran",
                "labs": [
                    "Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India"
                ]
            },
            {
                "name": "Srividya",
                "labs": [
                    "Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India"
                ]
            },
            {
                "name": "N. Sumith",
                "labs": [
                    "Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Visualization",
                "Emotion recognition",
                "Reviews",
                "Accuracy",
                "Computational modeling",
                "Adaptation models",
                "Logic gates",
                "Deep learning"
            ],
            "Author Keywords": [
                "Memes",
                "OSN",
                "NLP",
                "CNN",
                "multimodal",
                "contrastive learning",
                "fusion"
            ]
        }
    },
    {
        "Title": "Explainable Document Classification via Concept Whitening and Stable Graph Patterns",
        "Link": "https://ieeexplore.ieee.org/document/11134415/",
        "Abstract": "This paper proposes a novel explainable document classification framework that integrates Concept Whitening (CW) with graph concepts that are derived from stable graph patterns, and extracted via methods based on Formal Concept Analysis (FCA) and pattern structures. Document graphs are constructed using Abstract Meaning Representation (AMR) graphs, from which graph concepts are extracted and aligned with the latent space axes of Graph Neural Networks (GNNs) using CW. We investigate four types of graph concepts for their effect on concept alignment: frequent subgraphs, graph pattern concepts, filtered equivalence classes, and closed subgraphs. A novel filtration mechanism based on support, along with a custom penalty metric, is proposed to refine graph concepts for maximizing concept alignment. Experiments on the 10 Newsgroups and BBC Sport datasets show that our document graphs effectively capture both structural and semantic information, thereby supporting competitive classification performance across multiple GNN model architectures and configurations. For the 10 Newsgroups dataset, GNN models equipped with a CW module show an average increase of 0.7599 in the macro-averaged F1 score of the Concept Alignment Performance (CAP) metric, with an average drop of only 0.0025 in the document classification macro-averaged F1 score. Similarly, on the BBC Sport dataset, the average CAP improvement is 0.6998, with an average drop of 0.0894 in document classification performance. Additionally, concept gradient importance analyses and concept similarity heatmaps provide insights into the interpretability and structural separability of the GNN’s latent representations, achieved using CW.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3602004",
            "Date of Publication": "22 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eric George Parakal",
                "labs": [
                    "School of Data Analysis and Artificial Intelligence, HSE University, Moscow, Russia"
                ]
            },
            {
                "name": "Sergei O. Kuznetsov",
                "labs": [
                    "School of Data Analysis and Artificial Intelligence, HSE University, Moscow, Russia",
                    "Research Center for Trusted Artificial Intelligence, ISP RAS, Moscow, Russia"
                ]
            },
            {
                "name": "Ilya Makarov",
                "labs": [
                    "Artificial Intelligence Research Institute (AIRI), Moscow, Russia",
                    "Research Center for Trusted Artificial Intelligence, ISP RAS, Moscow, Russia"
                ]
            },
            {
                "name": "Nikita Severin",
                "labs": [
                    "School of Data Analysis and Artificial Intelligence, HSE University, Moscow, Russia",
                    "Research Center for Trusted Artificial Intelligence, ISP RAS, Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Graph neural networks",
                "Vectors",
                "Training",
                "Measurement",
                "Formal concept analysis",
                "Text categorization",
                "Sports",
                "Space exploration",
                "Optimization",
                "Filtration"
            ],
            "Author Keywords": [
                "Concept-based explanations",
                "explainable artificial intelligence (XAI)",
                "formal concept analysis (FCA)",
                "graph neural network (GNN)",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Enhanced Sign Language Translation Between American Sign Language and Indian Sign Language Using LLMs",
        "Link": "https://ieeexplore.ieee.org/document/11113285/",
        "Abstract": "This research introduces a foundational framework aimed at bridging the communication gap between American Sign Language (ASL) and Indian Sign Language (ISL) by translating alphabet-level gestures. The proposed system employs a hybrid deep learning model for ASL gesture recognition, integrating a random forest classifier (RFC) and a convolutional neural network (CNN) to enhance accuracy. Recognised gestures are converted into text, which is refined using a prompt-configured large language model (LLM) for contextual and grammatical accuracy. The corrected text is then synthesised into ISL gestures using RIFE-Net, a real-time intermediate flow estimation network, to generate smooth and natural gesture videos. The framework addresses key challenges such as gesture variability and linguistic differences between ASL and ISL. The hybrid model achieves a gesture recognition accuracy of 93.0%, measuring how accurately the system identifies ASL signs. Following recognition, the raw text output is refined using the Large Language Model (LLM), resulting in a text correction accuracy of 94.2%, which reflects improvements in grammatical correctness and contextual relevance. These metrics collectively demonstrate the system’s effectiveness in alphabet-level recognition and gesture synthesis, laying the groundwork for more advanced sentence-level translation. Initial experimental results demonstrate real-time processing capabilities, averaging one gesture per second, with video outputs at 60 FPS. This system not only facilitates seamless communication between ASL and ISL users but also lays the groundwork for scalability to other sign language pairs. The results highlight the potential to improve accessibility and inclusion of the global hard of hearing community, paving the way for future research in multi-modal sign language translation systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595943",
            "Date of Publication": "05 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Malay Kumar",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "S. Sarvajit Visagan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "Tanish Mahajan",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "Anisha Natarajan",
                "labs": [
                    "School of Electronics Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            },
            {
                "name": "P. S. Sreeja",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sign language",
                "Translation",
                "Accuracy",
                "Convolutional neural networks",
                "Linguistics",
                "Real-time systems",
                "Videos",
                "Random forests",
                "Large language models",
                "Hands"
            ],
            "Author Keywords": [
                "American sign language (ASL)",
                "Indian sign language (ISL)",
                "sign language translation",
                "large language models (LLM)",
                "random forest classifier",
                "convolutional neural network",
                "natural language processing (NLP)",
                "RIFE-Net",
                "gesture recognition",
                "real-time translation"
            ]
        }
    },
    {
        "Title": "ReACT_OCRS: An AI-Driven Anonymous Online Reporting System Using Synergized Reasoning and Acting in Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11007115/",
        "Abstract": "Victims and witnesses of cybercrime often hesitate to report incidents due to concerns over privacy, complexity, and fear of retaliation. Traditional reporting mechanisms require manual data entry, creating accessibility barriers and delaying response times. To address these challenges, this paper introduces ReACT_OCRS, an AI-driven voice-based cybercrime reporting system that allows victims and witnesses to anonymously submit complaints through audio recordings. Leveraging speech recognition transformers, a recent language model, and encryption, the system processes real-time multilingual voice inputs, extracts meaningful content, and classifies reports with high precision using a hybrid voting mechanism. Experimental evaluations on synthetically generated and human-validated datasets confirm the system’s ability to accurately transcribe, classify, and securely process audio complaints while preserving user anonymity. This work improves cybercrime reporting by making it more accessible, efficient, and secure, fostering greater participation from victims and witnesses.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3571526",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amir Aboubakr Shaker Mahmoud",
                "labs": [
                    "School of Digital Forensics and Cyber Security, National Forensic Sciences University, Gandhinagar, India"
                ]
            },
            {
                "name": "Wesam Shishah",
                "labs": [
                    "College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nilay R. Mistry",
                "labs": [
                    "School of Digital Forensics and Cyber Security, National Forensic Sciences University, Gandhinagar, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer crime",
                "Law enforcement",
                "Law",
                "Manuals",
                "Encryption",
                "Multilingual",
                "Cognition",
                "Translation",
                "Transformers",
                "Reviews"
            ],
            "Author Keywords": [
                "Cybercrime",
                "encryption",
                "LLM",
                "ML",
                "NLP",
                "ReACT",
                "reporting system",
                "transformers"
            ]
        }
    },
    {
        "Title": "End-to-End Architecture for English Reading and Writing Content Assessment Based on Prompt Learning",
        "Link": "https://ieeexplore.ieee.org/document/10772188/",
        "Abstract": "With the acceleration of globalization, the use of English as an international language has become increasingly widespread, making the assessment of English reading and writing skills a key issue in the field of language education. However, traditional methods of English reading and writing content assessment rely on manually designed features, which struggle to effectively handle complex and diverse language structures. To address this issue, this study proposes an English reading and writing content assessment algorithm based on Prompt Learning, utilizing an end-to-end architecture enhanced with multi-scale attention mechanisms. The algorithm preprocesses the input English texts through the prompt learning framework and uses multi-scale attention mechanisms to improve the model’s ability to capture features at different linguistic levels. Within an end-to-end architecture, the entire assessment process is automated, from text input to output of assessment results, eliminating the need for manually designed feature extraction steps. Experimental results show that the algorithm performs excellently on multiple English reading and writing assessment datasets, significantly enhancing the accuracy and efficiency of assessments and offering an effective solution for English reading and writing evaluations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3509990",
            "Date of Publication": "02 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Su-Qin Wu",
                "labs": [
                    "School of Education Science, Nanjing Normal University, Nanjing, China"
                ]
            },
            {
                "name": "Ming-Yong Pang",
                "labs": [
                    "School of Education Science, Nanjing Normal University, Nanjing, China"
                ]
            },
            {
                "name": "Xue-Mei Sun",
                "labs": [
                    "Chuzhou Vocational and Technical College, Chuzhou, China"
                ]
            },
            {
                "name": "Xin-Jian Wang",
                "labs": [
                    "College of Health and Welfare, Dongshin University, Naju-si, Jeollanam-do, South Korea"
                ]
            },
            {
                "name": "Yun-Peng Ji",
                "labs": [
                    "School of Humanities, Zhujiang College, South China Agricultural University, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Writing",
                "Feature extraction",
                "Attention mechanisms",
                "Accuracy",
                "Semantics",
                "Context modeling",
                "Adaptation models",
                "Few shot learning",
                "Text detection",
                "Manuals"
            ],
            "Author Keywords": [
                "Prompt learning",
                "text assessment",
                "multi-scale attention",
                "NLP education",
                "language evaluation"
            ]
        }
    },
    {
        "Title": "SLAM: Sales Lead AMplification Through GenAI and ML for e-Learning Platforms",
        "Link": "https://ieeexplore.ieee.org/document/10770225/",
        "Abstract": "In the competitive landscape of contemporary business, predictive analytics, particularly in sales lead prediction, has become instrumental for enhancing sales effectiveness and maximizing revenue generation. This study investigates sales lead prediction utilizing machine learning techniques. In the domain of sales, the accurate prediction of leads is deemed essential for optimizing resource allocation and maximizing conversion rates. This study investigates sales lead prediction utilizing machine learning techniques, with a particular focus on the ensemble method of stacking algorithms. The research objective is to improve the predictive accuracy of sales lead identification through the utilization of advanced machine learning methodologies. Through rigorous experimentation and analysis, singular models were first explored, followed by the integration into a stacking ensemble model, achieving an accuracy rate of 94%. Extensive pre-processing techniques have been applied to ensure data quality and feature relevance, facilitating robust model training. The experimental results demonstrate the efficacy of both singular models and the proposed ensemble approach in accurately predicting sales leads. The implications of these findings extend to various sectors reliant on efficient lead management, including marketing, sales, and customer relationship management. By leveraging advanced machine learning techniques such as stacking ensembles, organizations can enhance their lead identification processes, leading to improved conversion rates and overall business performance. This research contributes to the growing body of knowledge in predictive analytics and offers valuable insights for practitioners seeking to optimize their sales strategies through the integration of machine learning technologies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3507878",
            "Date of Publication": "27 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ganesan Ramachandran",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Tanmay Narang",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Vallidevi Krishnamurthy",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Predictive models",
                "Machine learning",
                "Lead",
                "Business",
                "Industries",
                "Data models",
                "Analytical models",
                "Stacking",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "Large language models (LLM)",
                "random forest",
                "tokenizer",
                "classification",
                "one hot encoding",
                "synthetic generation",
                "generative pretrained transformers (GPT)",
                "normalisation",
                "natural language processor (NLP)",
                "sentiment intensity analyser",
                "stacking",
                "voting"
            ]
        }
    },
    {
        "Title": "Research on the Construction and Application of Earthquake Emergency Information Knowledge Graph Based on Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11075653/",
        "Abstract": "To address the challenges of semantic parsing of multi-source heterogeneous information and the delayed emergency response decisions caused by insufficient relational reasoning capabilities in earthquake emergency management, this study proposes a domain knowledge extraction method for earthquakes based on a large language model combined with a three-level prompt engineering system (TPES-LLM) of “instruction fine-tuning - demand awareness - case matching. ”The method deploys a local large language model using LangChain +QWEN2.5-7B, integrates earthquake domain knowledge through LoRa fine-tuning based on earthquake experts’ classifications and industry standards, and injects seismic knowledge into the model. The multi-head attention mechanism weights are optimized based on the co-occurrence frequency of historical earthquake entities, and demand-aware knowledge identifies key textual features that significantly impact knowledge extraction. Training is performed on 36 known earthquake disaster events to learn the association patterns of entities, relationships, and events hidden within the earthquake case data for case matching. This method significantly enhances the accuracy of entity recognition and the efficiency of relation extraction for complex disaster-related texts. Additionally, a bidirectional graph attention network (Bi-GAT) is designed to enable bidirectional propagation and dynamic aggregation of node features. The path confidence constraint algorithm (PCCA) is used to achieve deep semantic associations of earthquake disaster elements. Based on the Neo4j graph database, an earthquake emergency knowledge graph is constructed. Experimental results from real earthquake events such as the 2022 Luding 6.8-magnitude earthquake, the 2024 Jishishan 6.2-magnitude earthquake, and the 2025 Dingri 6.8-magnitude earthquake show that the accuracy of intelligent Q&A retrieval for the earthquake emergency knowledge graph reaches 89.62%, 87.28%, and 90.23%, respectively. The earthquake emergency knowledge graph based on large language models constructed in this study provides intelligent decision support for earthquake emergencies, with significant application value.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3586370",
            "Date of Publication": "10 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wentao Zhou",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Meng Huang",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Shuai Liu",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Qiao You",
                "labs": [
                    "Institute of Disaster Prevention, Langfang, China",
                    "Hebei Province University Smart Emergency Application Technology Research and Development Center, Langfang, China"
                ]
            },
            {
                "name": "Fanxin Meng",
                "labs": [
                    "Sichuan Disaster Reduction Center, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Earthquakes",
                "Disasters",
                "Semantics",
                "Emergency services",
                "Cognition",
                "Feature extraction",
                "Data mining",
                "Knowledge graphs",
                "Large language models",
                "Correlation"
            ],
            "Author Keywords": [
                "TPES-LLM",
                "NLP",
                "Bi-GAT",
                "PCCA",
                "Neo4j"
            ]
        }
    },
    {
        "Title": "Knowledge Graph-Driven Approach in Aspect-Based Sentiment Analysis: Exploring the Impact of Embedding Techniques",
        "Link": "https://ieeexplore.ieee.org/document/11026004/",
        "Abstract": "Despite the high performance of the existing embedding approaches for Aspect-Based Sentiment Analysis (ABSA), such as Word2Vec and GloVe, they still have several limitations, mainly in contextual understanding and relational insights of natural language, especially in complex and long sentences. This paper presents a novel approach that enhances ABSA by integrating knowledge graphs into a transformer model, where the graphs are automatically built from raw text without requiring external resources, making the system adaptable and fully data-driven. Our approach allows a better understanding of context and relationships between entities, by combining of the contextual understanding of BERT with the relational insights provided by Node2Vec, a graph-based embedding technique. In this paper, we benchmark our hybrid embedding technique with the existing state-of-the-art embedding techniques. Specifically, we compare traditional embeddings, such as Word2Vec and GloVe, against BERT for textual input, while also exploring Word2Vec and Node2Vec for graph-based embeddings. Our experiments demonstrate that combining BERT’s deep contextual embeddings with the structural insights of Node2Vec leads to promising improvements in sentiment classification performance. Our model achieved 98% accuracy on SemEval2015 Restaurant dataset. These results demonstrate that integrating both contextual and relational information significantly enhances the performance of ABSA models, thereby making them more effective at capturing nuanced sentiment relationships. The proposed model’s modular design also allows flexible integration of alternative embeddings or graph configurations, making it suitable for broader sentiment analysis applications beyond the benchmark datasets.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3577048",
            "Date of Publication": "05 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Souha Al Katat",
                "labs": [
                    "Isep, Laboratory of Informatics, Signal, Image, Telecommunication, and Electronics (LISITE), Issy-les-Moulineaux, France"
                ]
            },
            {
                "name": "Chamseddine Zaki",
                "labs": [
                    "College of Engineering and Technology, American University of the Middle East, Kuwait, Egaila, Kuwait"
                ]
            },
            {
                "name": "Hussein Hazimeh",
                "labs": [
                    "Computer Science Department, Faculty of Sciences, Lebanese University, Beirut, Lebanon"
                ]
            },
            {
                "name": "Ibrahim El Bitar",
                "labs": [
                    "LIP6, Sorbonne University, Paris, France"
                ]
            },
            {
                "name": "Rafael Angarita",
                "labs": [
                    "Paris Nanterre University, Nanterre, France"
                ]
            },
            {
                "name": "Lionel Trojman",
                "labs": [
                    "Isep, Laboratory of Informatics, Signal, Image, Telecommunication, and Electronics (LISITE), Issy-les-Moulineaux, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Sentiment analysis",
                "Knowledge graphs",
                "Syntactics",
                "Encoding",
                "Context modeling",
                "Bidirectional control",
                "Electronic mail",
                "Accuracy",
                "Analytical models"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "ABSA",
                "transformers",
                "knowledge graph",
                "NLP"
            ]
        }
    },
    {
        "Title": "FPGA Acceleration With Hessian-Based Comprehensive Intra-Layer Mixed-Precision Quantization for Transformer Models",
        "Link": "https://ieeexplore.ieee.org/document/10973048/",
        "Abstract": "Recent advancements in using FPGAs as co-processors for language model acceleration, particularly for energy efficiency and flexibility, face challenges due to limited memory capacity. This limitation hinders the deployment of transformer-based language models. To address this challenge, we propose a novel software-hardware co-optimization framework that integrates Hessian-based intra-layer mixed-precision quantization with a runtime bit-configurable FPGA accelerator. Our proposed Hessian-based row-wise weight quantization addresses hardware inefficiencies in traditional parameter-wise and channel-wise approaches by enabling mixed-precision weight matrices to be split into two uniform-precision matrices, thereby simplifying hardware requirements. Additionally, our Query-Key coupled attention activation quantization optimally aligns precision within each outer product pair in attention calculations, reducing hardware complexity and memory management overhead. Our concurrent quantization method balances the benefits of row-wise weight quantization and Query-Key coupled activation quantization while maximizing energy efficiency through multi-precision optimization. To support this algorithm, we design a multi-precision FPGA accelerator capable of handling both 2n-based and non-2n mixed-precision operations. It is implemented on a single Xilinx ZCU102 FPGA board, operating at 200MHz with a power consumption of 15.08W during inference on the 110-million-parameter BERT-Base and 345-million-parameter GPT-2 Medium transformer models. Coupled with the proposed algorithm and dataflow optimization, it enables on-chip storage of all necessary parameters, minimizing off-chip memory access. Experimental results demonstrate that our FPGA accelerator significantly outperforms existing solutions, achieving energy efficiency improvements ranging from\n2.22×\nto\n17.23×\nover state-of-the-art FPGA accelerators.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3563196",
            "Date of Publication": "22 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Woohong Byun",
                "labs": [
                    "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Jongseok Woo",
                "labs": [
                    "Mobile Display Design Team, Samsung Display Company Ltd., Yongin, South Korea"
                ]
            },
            {
                "name": "Saibal Mukhopadhyay",
                "labs": [
                    "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantization (signal)",
                "Hardware",
                "Field programmable gate arrays",
                "Transformers",
                "Energy efficiency",
                "Optimization",
                "Memory management",
                "Computational modeling",
                "Accuracy",
                "Sparse matrices"
            ],
            "Author Keywords": [
                "Accelerator",
                "activation",
                "BERT",
                "FPGA",
                "hardware acceleration",
                "Hessian",
                "language model",
                "mixed-precision",
                "NLP",
                "quantization",
                "transformer"
            ]
        }
    },
    {
        "Title": "Leveraging Machine Learning for Enhanced Bug Triaging in Open-Source Software Projects",
        "Link": "https://ieeexplore.ieee.org/document/11106424/",
        "Abstract": "Bug triaging–the process of classifying and assigning software issues to appropriate developers–is a critical yet challenging task in large-scale software development. Manual triaging is time-consuming, inconsistent, and prone to human bias, which often delays issue resolution and misallocates developer resources. This study explores the application of machine learning to automate and improve bug triaging efficiency and accuracy. Using a dataset of over 122,000 issues from the microsoft/vscode GitHub repository, we evaluate several machine learning models including Bidirectional LSTM, CNN-LSTM, Random Forest, and Multinomial Naive Bayes. Our primary contribution is the development of an Augmented Bidirectional LSTM model that integrates enriched textual features and contextual metadata. This model, optimized using Optuna, outperforms traditional baselines, achieving a Micro F1-score of 0.6469 and Hamming Loss of 0.0133 for label prediction, and a Micro F1-score of 0.5974 with Hamming Loss of 0.0062 for assignee recommendation. In addition to demonstrating strong predictive performance, we present a robust end-to-end pipeline for data preprocessing, augmentation, model training, and evaluation using multi-label classification techniques. The study highlights how deep learning architectures, in combination with feature engineering and hyperparameter tuning, can provide scalable and generalizable components to support the automation of bug triaging. These findings contribute to the growing field of intelligent software maintenance by offering data-driven approaches that can support developer workflows and improve issue management efficiency in open-source environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3595011",
            "Date of Publication": "01 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nitanta Adhikari",
                "labs": [
                    "Department of Computer Science and Engineering, Kathmandu University, Kavre, Dhulikhel, Nepal"
                ]
            },
            {
                "name": "Rabindra Bista",
                "labs": [
                    "Department of Computer Science and Engineering, Kathmandu University, Kavre, Dhulikhel, Nepal"
                ]
            },
            {
                "name": "João Carlos Ferreira",
                "labs": [
                    "Faculty of Logistics, Molde University College, Molde, Norway",
                    "Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisbon, Portugal",
                    "INOV INESC Inovação—Instituto de Novas Tecnologias, Lisbon, Portugal"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Software development management",
                "Machine learning",
                "Accuracy",
                "Open source software",
                "Data models",
                "Predictive models",
                "Machine learning algorithms",
                "Measurement",
                "Manuals"
            ],
            "Author Keywords": [
                "Bug triaging",
                "natural language processing (NLP)",
                "multi-label classification",
                "model evaluation metrics"
            ]
        }
    },
    {
        "Title": "Disentangling Reasoning Factors for Natural Language Inference",
        "Link": "https://ieeexplore.ieee.org/document/10949837/",
        "Abstract": "Natural Language Inference (NLI) seeks to deduce the relations of two texts: a premise and a hypothesis. These two texts may share similar or different basic contexts, while three distinct reasoning factors emerge in the inference from premise to hypothesis: entailment, neutrality, and contradiction. However, the entanglement of the reasoning factor with the basic context in the learned representation space often complicates the task of NLI models, hindering accurate classification and determination based on the reasoning factors. In this study, drawing inspiration from the successful application of disentangled variational autoencoders in other areas, we separate and extract the reasoning factor from the basic context of NLI data through latent variational inference. Meanwhile, we employ mutual information estimation when optimizing Variational AutoEncoders (VAE)-disentangled reasoning factors further. Leveraging disentanglement optimization in NLI, our proposed a Directed NLI (DNLI) model demonstrates excellent performance compared to state-of-the-art baseline models in experiments on three widely used datasets: Stanford Natural Language Inference (SNLI), Multi-genre Natural Language Inference (MNLI), and Adversarial Natural Language Inference (ANLI). It particularly achieves the best average validation scores, showing significant improvements over the second-best models. Notably, our approach effectively addresses the interpretability challenges commonly encountered in NLI methods.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020096",
            "Date of Publication": "04 April 2025",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Xixi Zhou",
                "labs": [
                    "Department of Radiology, The First Affiliated Hospital, Zhejiang University, School of Medicine, Hangzhou, China"
                ]
            },
            {
                "name": "Limin Zeng",
                "labs": [
                    "Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Ziping Zhao",
                "labs": [
                    "College of Computer Science, Tianjin Normal University, Tianjin, China"
                ]
            },
            {
                "name": "Jiajun Bu",
                "labs": [
                    "Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Wenjie Liang",
                "labs": [
                    "Department of Radiology, The First Affiliated Hospital, Zhejiang University, School of Medicine, Hangzhou, China"
                ]
            },
            {
                "name": "Haishuai Wang",
                "labs": [
                    "Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autoencoders",
                "Disentangled representation learning",
                "Estimation",
                "Cognition",
                "Natural language processing",
                "Encoding",
                "Data models",
                "Data mining",
                "Optimization",
                "Mutual information"
            ],
            "Author Keywords": [
                "Natural Language Processing (NLP)",
                "Natural Language Inference (NLI)",
                "disentangled representation learning",
                "variational autoencoder"
            ]
        }
    },
    {
        "Title": "A Review of Arabic Text Summarization: Methods, Datasets, and Evaluation Metrics, With a Proposed Solution",
        "Link": "https://ieeexplore.ieee.org/document/11062566/",
        "Abstract": "This survey comprehensively reviews Arabic text summarization, examining state-of-the-art methodologies, commonly used datasets, and evaluation practices. Despite notable progress, the field faces challenges such as fragmented benchmarking, inconsistent metric use, and lacking resources for long-document summarization. We categorize existing summarization methods into traditional, Transformer-based, and hybrid approaches, highlighting their strengths and limitations. We introduce Mukhtasar, a novel dataset supporting short and long summaries across diverse genres to address significant gaps. Additionally, we propose six standardized evaluation splits tailored to distinct summarization goals, promoting reproducibility and fair comparison. To address inconsistencies, we also recommend a consistent reporting protocol using ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-S. While lexical overlap metrics dominate evaluation practices, we identify the absence of neural-based metrics for Arabic as a significant limitation and call for future development in this area. Our contributions aim to unify evaluation protocols, enrich available resources, and guide the community toward more interpretable and scalable Arabic summarization research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3584855",
            "Date of Publication": "01 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zeyad Ezzat",
                "labs": [
                    "Center for Informatics Science, Information Technology and Computer Science School, Nile University, Giza, Egypt",
                    "Applied Innovation Centre, Alexandria, Egypt"
                ]
            },
            {
                "name": "Ghada Khoriba",
                "labs": [
                    "Center for Informatics Science, Information Technology and Computer Science School, Nile University, Giza, Egypt",
                    "Faculty of Computers and Artificial Intelligence, Helwan University, Cairo, Egypt"
                ]
            },
            {
                "name": "Ayman Khalafallah",
                "labs": [
                    "Applied Innovation Centre, Alexandria, Egypt",
                    "Computer and Systems Department, Faculty of Engineering, Alexandria University, Alexandria, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text summarization",
                "Transformers",
                "Natural language processing",
                "Systematic literature review",
                "Redundancy",
                "Market research",
                "Deep learning",
                "Context modeling",
                "Adaptation models",
                "Surveys"
            ],
            "Author Keywords": [
                "Text summarization",
                "Arabic NLP",
                "transformers",
                "deep learning",
                "summarization datasets"
            ]
        }
    },
    {
        "Title": "Hybrid Top Features Extraction Model for Detecting X Rumor Events Using an Ensemble Method",
        "Link": "https://ieeexplore.ieee.org/document/10924702/",
        "Abstract": "The paper describes a novel a hybrid ensemble algorithm (HEA) that combines ensemble learning, class imbalance handling, and feature extraction. To address class imbalance in the dataset, the suggested approach integrates SMOTE oversampling and random under sampling (RU) feature extraction. To begin, Pearson correlation analysis is used to detect highly associated features in a dataset. This analysis aids in the selection of the most relevant features, which are either substantially related to the target variable or have a strong association with other features. The method seeks to improve classification performance by focusing on these correlated features. Following that, the SMOTE oversampling and RU algorithms are used to balance the majority and minority categorization characteristics. The SMOTE (synthetic minority oversampling technique) develops synthetic cases for the minority class by interpolating between existing instances, enhancing minority class representation. RU, on the other hand, removes instances from the majority class at random to obtain a balanced distribution. Furthermore, the random forest classifier (RFC) model's key features are input into an ensemble of decision tree (DT), k-nearest neighbor (KNN), adaptive boosting (AdaBoost), and convolutional neural network (CNN) approaches. This ensemble approach combines multiple models' predictions, exploiting their particular strengths and catching varied patterns in the data. Popular machine learning algorithms include DT, KNN, AdaBoost, and CNN, which are notable for their capacity to handle many types of data and capture complicated relationships. The evaluation findings show that the suggested HEA approach is effective, with a maximum precision, recall, F-score, and accuracy of 90%. The proposed methodology produces encouraging results, proving its applicability to a variety of categorization problems.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2414",
            "Date of Publication": "January 2025",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Taukir Alam",
                "labs": [
                    "Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Wei Chung Shia",
                "labs": [
                    "Department of Research, Molecular Medicine Laboratory, Changhua Christian Hospital, Changhua, Taiwan",
                    "School of Big Data and Artificial Intelligence, Fujian Polytechnic Normal University, Fuqing, China"
                ]
            },
            {
                "name": "Fang Rong Hsu",
                "labs": [
                    "Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Taimoor Hassan",
                "labs": [
                    "Institute of Translational Medicine & New Drug Development, China Medical University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Pei-Chun Lin",
                "labs": [
                    "Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Eric Odle",
                "labs": [
                    "Department of Information Engineering and Computer Science, Feng Chia University, Taichung, Taiwan"
                ]
            },
            {
                "name": "Junzo Watada",
                "labs": [
                    "Waseda University, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Deep learning",
                "Machine learning algorithms",
                "Nearest neighbor methods",
                "Predictive models",
                "Feature extraction",
                "Natural language processing",
                "Ensemble learning",
                "Convolutional neural networks",
                "Random forests"
            ],
            "Author Keywords": [
                "Deep learning",
                "ensemble",
                "machine learning",
                "RFC",
                "RU",
                "SMOTE",
                "rumor detection",
                "natural language processing (NLP)"
            ]
        }
    },
    {
        "Title": "Big Data Meets Social Networks: A Survey of Analytical Strategies and Research Challenges",
        "Link": "https://ieeexplore.ieee.org/document/11021641/",
        "Abstract": "As the big data era transforms the information analysis landscape, social network (SN) analytics has emerged as a critical discipline to understand complex relationships and interactions within enormous social systems. This study aims to provide a comprehensive overview of SN analytics as big data, providing an in-depth exploration of concepts, methods, and applications within this rapidly evolving field. The survey covers a wide range of topics, including methods for pre-processing and cleaning social network data, as well as more advanced analytical approaches such as opinion mining, sentiment analysis, text mining, and natural language processing. It also discusses various big data architectures for SN analytics, like Lambda architecture, Kappa architecture, and GraphX architecture. In addition, it covers issues of scalability, data quality, privacy, and real-time analysis. SN analytics can be useful for researchers from across domains like business and marketing, healthcare and biomedicine, social sciences and psychology, politics and governance, cybersecurity and fraud detection, recommendation systems, crisis management, and disaster response to extract crucial information from vast datasets and formulate domain-specific strategies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3576143",
            "Date of Publication": "03 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shashank Sheshar Singh",
                "labs": [
                    "Department of Computer Science and Engineering, Thapar Institute of Engineering and Technology, Patiala, India"
                ]
            },
            {
                "name": "Shashank Singh",
                "labs": [
                    "Department of Computer Science and Engineering, Thapar Institute of Engineering and Technology, Patiala, India"
                ]
            },
            {
                "name": "Kuldeep Singh",
                "labs": [
                    "Department of Computer Science, University of Delhi, New Delhi, India"
                ]
            },
            {
                "name": "Vishal Srivastava",
                "labs": [
                    "Department of Computer Science and Engineering, Motilal Nehru National Institute of Technology Allahabad, Prayagraj, India"
                ]
            },
            {
                "name": "Harish Kumar Shakya",
                "labs": [
                    "Department of Artificial Intelligence and Machine Learning, School of Computer Science and Engineering, Manipal University Jaipur, Jaipur, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Big Data",
                "Systematic literature review",
                "Surveys",
                "Sentiment analysis",
                "Text mining",
                "Electronic mail",
                "Computer architecture",
                "Soft sensors",
                "Scalability"
            ],
            "Author Keywords": [
                "Social network analytics",
                "sentiment analysis",
                "NLP",
                "influence maximization",
                "community detection",
                "social networks",
                "link prediction",
                "big data"
            ]
        }
    },
    {
        "Title": "A Systematic Literature Review on Phishing Email Detection Using Natural Language Processing Techniques",
        "Link": "https://ieeexplore.ieee.org/document/9795286/",
        "Abstract": "Every year, phishing results in losses of billions of dollars and is a major threat to the Internet economy. Phishing attacks are now most often carried out by email. To better comprehend the existing research trend of phishing email detection, several review studies have been performed. However, it is important to assess this issue from different perspectives. None of the surveys have ever comprehensively studied the use of Natural Language Processing (NLP) techniques for detection of phishing except one that shed light on the use of NLP techniques for classification and training purposes, while exploring a few alternatives. To bridge the gap, this study aims to systematically review and synthesise research on the use of NLP for detecting phishing emails. Based on specific predefined criteria, a total of 100 research articles published between 2006 and 2022 were identified and analysed. We study the key research areas in phishing email detection using NLP, machine learning algorithms used in phishing detection email, text features in phishing emails, datasets and resources that have been used in phishing emails, and the evaluation criteria. The findings include that the main research area in phishing detection studies is feature extraction and selection, followed by methods for classifying and optimizing the detection of phishing emails. Amongst the range of classification algorithms, support vector machines (SVMs) are heavily utilised for detecting phishing emails. The most frequently used NLP techniques are found to be TF-IDF and word embeddings. Furthermore, the most commonly used datasets for benchmarking phishing email detection methods is the Nazario phishing corpus. Also, Python is the most commonly used one for phishing email detection. It is expected that the findings of this paper can be helpful for the scientific community, especially in the field of NLP application in cybersecurity problems. This survey also is unique in the sense that it relates works to their openly available tools and resources. The analysis of the presented works revealed that not much work had been performed on Arabic language phishing emails using NLP techniques. Therefore, many open issues are associated with Arabic phishing email detection.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3183083",
            "Date of Publication": "14 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Said Salloum",
                "labs": [
                    "School of Science, Engineering and Environment, University of Salford, Salford, U.K."
                ]
            },
            {
                "name": "Tarek Gaber",
                "labs": [
                    "School of Science, Engineering and Environment, University of Salford, Salford, U.K.",
                    "Faculty of Computers and Informatics, Suez Canal University, Ismailia, Egypt"
                ]
            },
            {
                "name": "Sunil Vadera",
                "labs": [
                    "School of Science, Engineering and Environment, University of Salford, Salford, U.K."
                ]
            },
            {
                "name": "Khaled Shaalan",
                "labs": [
                    "Faculty of Engineering and IT, The British University in Dubai, Dubai, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Electronic mail",
                "Natural language processing",
                "Feature extraction",
                "Bibliographies",
                "Uniform resource locators",
                "Training"
            ],
            "Author Keywords": [
                "Phishing email detection",
                "systematic literature review",
                "natural language processing",
                "machine learning"
            ]
        }
    },
    {
        "Title": "User Stories and Natural Language Processing: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/9393933/",
        "Abstract": "Context: User stories have been widely accepted as artifacts to capture the user requirements in agile software development. They are short pieces of texts in a semi-structured format that express requirements. Natural language processing (NLP) techniques offer a potential advantage in user story applications. Objective: Conduct a systematic literature review to capture the current state-of-the-art of NLP research on user stories. Method: The search strategy is used to obtain relevant papers from SCOPUS, ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, and Google Scholar. Inclusion and exclusion criteria are applied to filter the search results. We also use the forward and backward snowballing techniques to obtain more comprehensive results. Results: The search results identified 718 papers published between January 2009 to December 2020. After applying the inclusion/exclusion criteria and the snowballing technique, we identified 38 primary studies that discuss NLP techniques in user stories. Most studies used NLP techniques to extract aspects of who, what, and why from user stories. The purpose of NLP studies in user stories is broad, ranging from discovering defects, generating software artifacts, identifying the key abstraction of user stories, and tracing links between model and user stories. Conclusion: NLP can help system analysts manage user stories. Implementing NLP in user stories has many opportunities and challenges. Considering the exploration of NLP techniques and rigorous evaluation methods is required to obtain quality research. As with NLP research in general, the ability to understand a sentence’s context continues to be a challenge.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3070606",
            "Date of Publication": "02 April 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Indra Kharisma Raharjana",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia",
                    "Information Systems, Universitas Airlangga, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Daniel Siahaan",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Chastine Fatichah",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Software",
                "Requirements engineering",
                "Agile software development",
                "Stakeholders",
                "Search problems",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Agile software development",
                "natural language processing",
                "systematic review",
                "user story"
            ]
        }
    },
    {
        "Title": "Exploring Automated GDPR-Compliance in Requirements Engineering: A Systematic Mapping Study",
        "Link": "https://ieeexplore.ieee.org/document/9420457/",
        "Abstract": "The General Data Protection Regulation (GDPR), adopted in 2018, profoundly impacts information processing organizations as they must comply with this regulation. In this research, we consider GDPR-compliance as a high-level goal in software development that should be addressed at the outset of software development, meaning during requirements engineering (RE). In this work, we hypothesize that natural language processing (NLP) can offer a viable means to automate this process. We conducted a systematic mapping study to explore the existing literature on the intersection of GDPR, NLP, and RE. As a result, we identified 448 relevant studies, of which the majority (420) were related to NLP and RE. Research on the intersection of GDPR and NLP yielded nine studies, while 20 studies were related to GDPR and RE. Even though only one study was identified on the convergence of GDPR, NLP, and RE, the mapping results indicate opportunities for bridging the gap between these fields. In particular, we identified possibilities for introducing NLP techniques to automate manual RE tasks in the crossing of GDPR and RE, in addition to possibilities of using NLP-based machine learning techniques to achieve GDPR-compliance in RE.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3076921",
            "Date of Publication": "03 May 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdel-Jaouad Aberkane",
                "labs": [
                    "Business Informatics Research Group, Faculty of Economics and Business Administration, Ghent University, Ghent, Belgium"
                ]
            },
            {
                "name": "Geert Poels",
                "labs": [
                    "Business Informatics Research Group, Faculty of Economics and Business Administration, Ghent University, Ghent, Belgium"
                ]
            },
            {
                "name": "Seppe Vanden Broucke",
                "labs": [
                    "Business Informatics Research Group, Faculty of Economics and Business Administration, Ghent University, Ghent, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Systematics",
                "Natural language processing",
                "General Data Protection Regulation",
                "Unified modeling language",
                "Bibliographies",
                "Software systems",
                "Regulation"
            ],
            "Author Keywords": [
                "General data protection regulation",
                "systematic mapping study",
                "requirements engineering",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Analyzing Natural Language Processing Techniques to Extract Meaningful Information on Skills Acquisition From Textual Content",
        "Link": "https://ieeexplore.ieee.org/document/10684699/",
        "Abstract": "Natural Language Processing (NLP) combines linguistics, computer science, and AI to enable computers to understand and interpret human language, making it crucial for analyzing large amounts of language data. This technology, paired with predictive models, has significant potential to forecast the relevance and evolution of skills needed in the industry, enhancing skills acquisition and alignment with job market demands and playing a key role in workforce development and educational planning. This paper comprehensively analyzes skills acquisition using NLP and predictive models. This analysis highlights significant advancements in NLP, showcasing its transformational impact on extracting and interpreting data from textual content. We conducted an extensive literature search under the systematic review guidelines, from which we selected the most relevant works for this analysis. This work examined how NLP techniques are used and adapted to extract meaningful insights from the textual content and identified which NLP models are employed to create taxonomies or classifications of skills. It explored how these models predict behaviors or outcomes in specific areas. The obtained findings show that NLP has constantly evolved in recent years, encompassing techniques that reinforce textual information extraction and underline the adaptability of NLP to various disciplines and contexts. Creating taxonomies and structured knowledge organization was a significant focus, highlighting its applicability in multiple fields. Finally, we discuss the ongoing evolution and adaptability of the NLP models to different disciplines and their integration with predictive models, which offer valuable insights that enrich the interactions between textual data and AI.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3465409",
            "Date of Publication": "20 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Luis Jose Gonzalez-Gomez",
                "labs": [
                    "Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico"
                ]
            },
            {
                "name": "Sofia Margarita Hernandez-Munoz",
                "labs": [
                    "School of Engineering and Sciences, Tecnológico de Monterrey, Mexico City, Mexico"
                ]
            },
            {
                "name": "Abiel Borja",
                "labs": [
                    "School of Engineering and Sciences, Tecnológico de Monterrey, Mexico City, Mexico"
                ]
            },
            {
                "name": "Jose Daniel Azofeifa",
                "labs": [
                    "Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico"
                ]
            },
            {
                "name": "Julieta Noguez",
                "labs": [
                    "School of Engineering and Sciences, Tecnológico de Monterrey, Mexico City, Mexico"
                ]
            },
            {
                "name": "Patricia Caratozzolo",
                "labs": [
                    "Institute for the Future of Education, Tecnológico de Monterrey, Monterrey, Mexico",
                    "School of Engineering and Sciences, Tecnológico de Monterrey, Mexico City, Mexico"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Predictive models",
                "Databases",
                "Adaptation models",
                "Taxonomy",
                "Analytical models",
                "Context modeling",
                "Artificial intelligence",
                "Engineering education"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "engineering education",
                "future skills",
                "natural language processing",
                "predictive models"
            ]
        }
    },
    {
        "Title": "EILEEN: A Multi-Modal Framework for Extracting Alcohol Consumption Patterns From Bilingual Clinical Notes",
        "Link": "https://ieeexplore.ieee.org/document/10870246/",
        "Abstract": "In this work, we introduce EILEEN (Efficient Inference for Language-based Extraction of EHR Notes), a novel multi-modal natural language processing (NLP) framework designed to extract various alcohol consumption patterns from unstructured clinical notes, particularly in bilingual and non-English contexts. Recent advances in NLP have significantly improved information extraction capability across various domains. However, identifying patterns of alcohol consumption in medical documents remains underexplored, with existing approaches heavily relying on traditional NLP methods such as bag-of-words models that require extensive text preprocessing. These methods are often limited to English-language clinical settings, where robust medical ontologies and NLP toolkits are available to support preprocessing tasks. Therefore, this limitation hinders their use in multilingual healthcare settings and in environments lacking robust NLP toolkits to facilitate preprocessing. Motivated by the need for a more generalizable and accurate approach, this paper investigates the impact of large language models (LLMs) in advancing alcohol consumption pattern extraction from clinical notes. By reducing the need for manual preprocessing and improving adaptability to multilingual clinical notes, this work aims to enable broader, more practical applications of NLP models in extracting alcohol consumption patterns from clinical notes. By fine-tuning multilingual language models along with additional data sources, EILEEN effectively analyzes unstructured electronic health records (EHR) without relying on traditional concept normalization or extensive text preprocessing resources. Furthermore, the multi-modal component of EILEEN enables it to integrate and leverage diverse types of alcohol-related information, such as various types and amounts of alcohol consumed by a patient, thereby improving its pattern extraction accuracy. Our experiments, conducted in two different medical institutions in Korea, demonstrate that EILEEN significantly outperforms existing NLP methods in accurately identifying clinically relevant alcohol consumption patterns. By providing accurate, detailed, and clinically useful alcohol consumption patterns from unstructured clinical notes, EILEEN empowers healthcare practitioners with actionable insights essential for informed clinical decision-making.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3538803",
            "Date of Publication": "04 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Han Kyul Kim",
                "labs": [
                    "Daniel J. Epstein Department of Industrial and Systems Engineering, University of Southern California, Los Angeles, CA, USA"
                ]
            },
            {
                "name": "Yujin Park",
                "labs": [
                    "Healthcare Data Center, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Yoon Ji Kim",
                "labs": [
                    "Department of Statistics, Sungkyunkwan University, Seoul, South Korea",
                    "Big Data Research Institute, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Seungah Yi",
                "labs": [
                    "Samsung Electronics, Suwon, South Korea"
                ]
            },
            {
                "name": "Yeju Park",
                "labs": [
                    "Big Data Research Institute, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea",
                    "Department of Family Medicine, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Sujin So",
                "labs": [
                    "Department of Family Medicine, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Hyeon-Ji Lee",
                "labs": [
                    "Big Data Research Institute, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Ye Seul Bae",
                "labs": [
                    "Big Data Research Institute, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea",
                    "Department of Family Medicine, Kangbuk Samsung Hospital, Sungkyunkwan University School of Medicine, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Multilingual",
                "Accuracy",
                "Data mining",
                "Ontologies",
                "Hospitals",
                "Vectors",
                "Unified modeling language",
                "Transformers",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Clinical informatics",
                "alcohol information extraction",
                "natural language processing",
                "multimodal learning",
                "multilingual transformers"
            ]
        }
    },
    {
        "Title": "Pretrained models and evaluation data for the Khmer language",
        "Link": "https://ieeexplore.ieee.org/document/9645441/",
        "Abstract": "Trained on a large corpus, pretrained models (PTMs) can capture different levels of concepts in context and hence generate universal language representations, which greatly benefit downstream natural language processing (NLP) tasks. In recent years, PTMs have been widely used in most NLP applications, especially for high-resource languages, such as English and Chinese. However, scarce resources have discouraged the progress of PTMs for low-resource languages. Transformer-based PTMs for the Khmer language are presented in this work for the first time. We evaluate our models on two downstream tasks: Part-of-speech tagging and news categorization. The dataset for the latter task is self-constructed. Experiments demonstrate the effectiveness of the Khmer models. In addition, we find that the current Khmer word segmentation technology does not aid performance improvement. We aim to release our models and datasets to the community in hopes of facilitating the future development of Khmer NLP applications.",
        "Details": {
            "DOI": "10.26599/TST.2021.9010060",
            "Date of Publication": "09 December 2021",
            "Publisher": "TUP",
            "Published In": "Tsinghua Science and Technology"
        },
        "issn_info": {
            "Electronic ISSN": "1007-0214"
        },
        "authors_data": [
            {
                "name": "Shengyi Jiang",
                "labs": [
                    "School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            },
            {
                "name": "Sihui Fu",
                "labs": [
                    "School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            },
            {
                "name": "Nankai Lin",
                "labs": [
                    "School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            },
            {
                "name": "Yingwen Fu",
                "labs": [
                    "School of Information Science and Technology, Guangdong University of Foreign Studies, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Tagging",
                "Natural language processing",
                "Data models",
                "Transformers",
                "Context modeling"
            ],
            "Author Keywords": [
                "pretrained models",
                "Khmer language",
                "word segmentation",
                "part-of-speech (POS) tagging",
                "news categorization"
            ]
        }
    },
    {
        "Title": "A Review of the Trends and Challenges in Adopting Natural Language Processing Methods for Education Feedback Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9781308/",
        "Abstract": "Artificial Intelligence (AI) is a fast-growing area of study that stretching its presence to many business and research domains. Machine learning, deep learning, and natural language processing (NLP) are subsets of AI to tackle different areas of data processing and modelling. This review article presents an overview of AI’s impact on education outlining with current opportunities. In the education domain, student feedback data is crucial to uncover the merits and demerits of existing services provided to students. AI can assist in identifying the areas of improvement in educational infrastructure, learning management systems, teaching practices and study environment. NLP techniques play a vital role in analyzing student feedback in textual format. This research focuses on existing NLP methodologies and applications that could be adapted to educational domain applications like sentiment annotations, entity annotations, text summarization, and topic modelling. Trends and challenges in adopting NLP in education were reviewed and explored. Context-based challenges in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based sentiment analysis are explained with existing methodologies to overcome them. Research community approaches to extract the semantic meaning of emoticons and special characters in feedback which conveys user opinion and challenges in adopting NLP in education are explored.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3177752",
            "Date of Publication": "25 May 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thanveer Shaik",
                "labs": [
                    "School of Mathematics and Physics and Computing, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Xiaohui Tao",
                "labs": [
                    "School of Mathematics and Physics and Computing, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Yan Li",
                "labs": [
                    "School of Mathematics and Physics and Computing, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Christopher Dann",
                "labs": [
                    "School of Education, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Jacquie McDonald",
                "labs": [
                    "Academic Development, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Petrea Redmond",
                "labs": [
                    "School of Education, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            },
            {
                "name": "Linda Galligan",
                "labs": [
                    "School of Mathematics and Physics and Computing, University of Southern Queensland, Toowoomba, QLD, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Education",
                "Feature extraction",
                "Natural language processing",
                "Deep learning",
                "Machine learning",
                "Data models"
            ],
            "Author Keywords": [
                "Artificial Intelligence",
                "natural language processing",
                "education",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A Natural Language Processing Pipeline of Chinese Free-Text Radiology Reports for Liver Cancer Diagnosis",
        "Link": "https://ieeexplore.ieee.org/document/9179807/",
        "Abstract": "Despite the rapid development of natural language processing (NLP) implementation in electronic medical records (EMRs), Chinese EMRs processing remains challenging due to the limited corpus and specific grammatical characteristics, especially for radiology reports. In this study, we designed an NLP pipeline for the direct extraction of clinically relevant features from Chinese radiology reports, which is the first key step in computer-aided radiologic diagnosis. The pipeline was comprised of named entity recognition, synonyms normalization, and relationship extraction to finally derive the radiological features composed of one or more terms. In named entity recognition, we incorporated lexicon into deep learning model bidirectional long short-term memory-conditional random field (BiLSTM-CRF), and the model finally achieved an F1 score of 93.00%. With the extracted radiological features, least absolute shrinkage and selection operator and machine learning methods (support vector machine, random forest, decision tree, and logistic regression) were used to build the classifiers for liver cancer prediction. For liver cancer diagnosis, random forest had the highest predictive performance in liver cancer diagnosis (F1 score 86.97%, precision 87.71%, and recall 86.25%). This work was a comprehensive NLP study focusing on Chinese radiology reports and the application of NLP in cancer risk prediction. The proposed NLP pipeline for the radiological feature extraction could be easily implemented in other kinds of Chinese clinical texts and other disease predictive tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3020138",
            "Date of Publication": "28 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Honglei Liu",
                "labs": [
                    "School of Biomedical Engineering, Capital Medical University, Beijing, China",
                    "Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Yan Xu",
                "labs": [
                    "Department of Radiology, Beijing Friendship Hospital, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Zhiqiang Zhang",
                "labs": [
                    "School of Biomedical Engineering, Capital Medical University, Beijing, China",
                    "Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Ni Wang",
                "labs": [
                    "School of Biomedical Engineering, Capital Medical University, Beijing, China",
                    "Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Yanqun Huang",
                "labs": [
                    "School of Biomedical Engineering, Capital Medical University, Beijing, China",
                    "Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Yanjun Hu",
                "labs": [
                    "Department of Radiology, Beijing Friendship Hospital, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Zhenghan Yang",
                "labs": [
                    "Department of Radiology, Beijing Friendship Hospital, Capital Medical University, Beijing, China"
                ]
            },
            {
                "name": "Rui Jiang",
                "labs": [
                    "Department of Automation, Ministry of Education Key Laboratory of Bioinformatics, Bioinformatics Division, Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Hui Chen",
                "labs": [
                    "School of Biomedical Engineering, Capital Medical University, Beijing, China",
                    "Beijing Key Laboratory of Fundamental Research on Biomechanics in Clinical Application, Capital Medical University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Radiology",
                "Natural language processing",
                "Cancer",
                "Liver",
                "Task analysis",
                "Machine learning"
            ],
            "Author Keywords": [
                "Natural language processing",
                "radiology reports",
                "information extraction",
                "computer-aided diagnosis",
                "BiLSTM-CRF"
            ]
        }
    },
    {
        "Title": "Improving Turkish Text Sentiment Classification Through Task-Specific and Universal Transformations: An Ensemble Data Augmentation Approach",
        "Link": "https://ieeexplore.ieee.org/document/10380566/",
        "Abstract": "The exponential growth of digital data in recent years has spurred a significant interest in natural language processing (NLP) and sentiment analysis. However, the effectiveness of NLP models heavily relies on the availability of large, annotated datasets, which are often scarce or entirely absent for numerous languages, including Turkish. This scarcity of annotated data for Turkish presents a formidable obstacle in developing NLP models for the language. To overcome this challenge, various techniques have been proposed to augment the size of annotated datasets, with text data augmentation emerging as a promising solution. Text data augmentation involves the generation of synthetic data by transforming existing data, thus expanding the diversity and volume of the annotated dataset. While this technique has shown remarkable success in bolstering the performance of NLP models, its exploration in the context of Turkish and other low-resource languages has been limited. This paper introduces a novel ensemble approach to text data augmentation tailored for Turkish text sentiment classification. Our approach integrates both task-specific and universal transformations, capitalizing on the strengths of each to enrich the training dataset. We evaluate our proposed approach on the TRSAv1 dataset and compare it with established data augmentation techniques. The experimental results demonstrate that our ensemble method achieves superior accuracy in sentiment classification compared to conventional techniques. Additionally, we conduct an in-depth analysis to assess the impact of individual transformation functions on classification performance. Our contribution lies in bridging the gap in research on data augmentation techniques tailored to Turkish NLP, emphasizing the need for more advanced ensemble methods, and offering benchmarking results that pave the way for the development of precise NLP models not only for Turkish but also for other low-resource languages.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3349971",
            "Date of Publication": "04 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aytuğ Onan",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering and Architecture, İzmir Kâtip Çelebi University, İzmir, Turkey"
                ]
            },
            {
                "name": "Kadriye Filiz Balbal",
                "labs": [
                    "Department of Computer Science, Faculty of Science, Dokuz Eylül University, İzmir, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Data augmentation",
                "Task analysis",
                "Sentiment analysis",
                "Data models",
                "Ensemble learning",
                "Analytical models"
            ],
            "Author Keywords": [
                "Text classification",
                "sentiment analysis",
                "ensemble learning",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Switchable Generation of Multipulse Patterns of Noise-Like Pulse and Dissipative Soliton Resonance in a Fiber Laser",
        "Link": "https://ieeexplore.ieee.org/document/8836541/",
        "Abstract": "Impact Statement:\nSwitchable generation of multi-pulse patterns of NLPs and DSRs in one cavity configuration is reported for the first time.Benefiting from the change of saturation power i...Show More\nWe report on the switchable generation of versatile patterns of multiple noise-like pulse (NLP) and dissipative soliton resonance (DSR) pulses in a dual-pump figure-eight mode-locked fiber laser. Benefiting from the change of saturation power influenced by pump power intercoupling, harmonic DSR pulses, dual-pulse DSR, dual-pulse and tri-pulse NLP are formed depending on different pump power combinations and intra-cavity polarization states. We find that the NLP pulse profile can turn from h-shape to triangular-shape after splitting. The dual-wavelength spectrum of the pulse, consisting of an obvious stokes line, can tune its center from 1075 to 1097 nm. This type of fiber laser may be helpful for further in-depth study on the underlying dynamics of multiple NLP and DSR pulses.",
        "Details": {
            "DOI": "10.1109/JPHOT.2019.2941283",
            "Date of Publication": "13 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "He Xu",
                "labs": [
                    "College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Sheng-Ping Chen",
                "labs": [
                    "College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Yue Tao",
                "labs": [
                    "College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Zong-Fu Jiang",
                "labs": [
                    "College of Advanced Interdisciplinary Studies, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical fiber polarization",
                "Fiber lasers",
                "Cavity resonators",
                "Optical fiber dispersion",
                "Harmonic analysis",
                "Power harmonic filters",
                "Laser mode locking"
            ],
            "Author Keywords": [
                "Fiber lasers",
                "mode-locked lasers."
            ]
        }
    },
    {
        "Title": "Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/9853214/",
        "Abstract": "Recent natural language processing (NLP) techniques have accomplished high performance on benchmark data sets, primarily due to the significant improvement in the performance of deep learning. The advances in the research community have led to great enhancements in state-of-the-art production systems for NLP tasks, such as virtual assistants, speech recognition, and sentiment analysis. However, such NLP systems still often fail when tested with adversarial attacks. The initial lack of robustness exposed troubling gaps in current models’ language understanding capabilities, creating problems when NLP systems are deployed in real life. In this paper, we present a structured overview of NLP robustness research by summarizing the literature in a systemic way across various dimensions. We then take a deep-dive into the various dimensions of robustness, across techniques, metrics, embedding, and benchmarks. Finally, we argue that robustness should be multi-dimensional, provide insights into current research, identify gaps in the literature to suggest directions worth pursuing to address these gaps",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3197769",
            "Date of Publication": "10 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marwan Omar",
                "labs": [
                    "Department of Computer Science, University of Central Florida, Orlando, FL, USA",
                    "ITM Department, Illinois Institute of Technology, Chicago, IL, USA"
                ]
            },
            {
                "name": "Soohyeon Choi",
                "labs": [
                    "Department of Computer Science, University of Central Florida, Orlando, FL, USA"
                ]
            },
            {
                "name": "Daehun Nyang",
                "labs": [
                    "Cyber Security Department, Ewha Womans University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "David Mohaisen",
                "labs": [
                    "Department of Computer Science, University of Central Florida, Orlando, FL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Robustness",
                "Natural language processing",
                "Deep learning",
                "Measurement",
                "Predictive models",
                "Data models",
                "Benchmark testing",
                "Speech recognition",
                "Sentiment analysis",
                "Production systems"
            ],
            "Author Keywords": [
                "Natural language processing",
                "adversarial attacks",
                "robustness"
            ]
        }
    },
    {
        "Title": "A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and Challenges",
        "Link": "https://ieeexplore.ieee.org/document/10255647/",
        "Abstract": "Legal judgment prediction (LJP) applies Natural Language Processing (NLP) techniques to predict judgment results based on fact descriptions automatically. The present work addresses the growing interest in the application of NLP techniques to the task of LJP. Despite the current performance gap between machines and humans, promising results have been achieved in a variety of benchmark datasets, owing to recent advances in NLP research and the availability of large-scale public datasets. To provide a comprehensive survey of existing LJP tasks, datasets, models, and evaluations, this study presents the following contributions: 1) an analysis of 43 LJP datasets constructed in 9 different languages, together with a classification method of LJP based on three different attributes; 2) a summary of 16 evaluation metrics categorized into 4 different types to evaluate the performance of LJP models for different outputs; 3) a review of 8 legal-domain pretrained models in 4 languages, highlighting four major research directions for LJP; 4) state-of-the-art results for 11 representative datasets from different court cases and an in-depth discussion of the open challenges in this area. This study aims to provide a comprehensive review for NLP researchers and legal professionals to understand the advances in LJP over the past years, and to facilitate further joint efforts towards improving the performance of LJP models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3317083",
            "Date of Publication": "19 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junyun Cui",
                "labs": [
                    "School of Information, Xián University of Finance and Economics, Xián, China"
                ]
            },
            {
                "name": "Xiaoyu Shen",
                "labs": [
                    "Amazon Alexa AI, Berlin, Germany"
                ]
            },
            {
                "name": "Shaochun Wen",
                "labs": [
                    "ASEAN International School, Guangxi Transport Vocational and Technical College, Nanning, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Task analysis",
                "Surveys",
                "Benchmark testing",
                "Natural language processing",
                "Measurement",
                "Biological system modeling",
                "Benchmark testing",
                "Neural networks"
            ],
            "Author Keywords": [
                "Legal judgment prediction",
                "natural language processing",
                "survey",
                "benchmark datasets",
                "neural network"
            ]
        }
    },
    {
        "Title": "Comparison and Influence of Flywheels Energy Storage System Control Schemes in the Frequency Regulation of Isolated Power Systems",
        "Link": "https://ieeexplore.ieee.org/document/9745566/",
        "Abstract": "Increased renewable energy penetration in isolated power systems has a clear impact on the quality of system frequency. The flywheel energy storage system (FESS) is a mature technology with a fast frequency response, high power density, high round-trip efficiency, low maintenance, no depth of discharge effects, and resilience to withstand continuous charge-discharge cycling without lifetime degradation. These FESS properties allows to effectively address the frequency quality problem. This study analyzes the contribution of a FESS to reducing frequency deviations in an isolated system that combines a diesel plant, wind farm, and pump-storage hydropower plant based on the El Hierro power system. This study approaches this analysis by comparing six different FESS governor control schemes (GCSs). Of these six GCSs, the nonlinear proportional variant (NLP\nV\n) is a singular contribution based on the NLP scheme previously developed by the same researchers. Different governor’s parameter settings for the FESS GCSs were also compared, obtained from the proposed tuning methodology that considers the renewable energy generation distribution, frequency impact, and lifetime degradation of diesel, hydraulic groups, and flywheels. The GCSs were compared in terms of average frequency deviation, Zenith and Nadir frequency difference, wear and tear of diesel electromechanical elements and Pelton turbine nozzles, flywheels cycles per hour, and FESS average state of charge. The results show that including a FESS plant considerably improves frequency regulation. The tuning criteria and GCSs have a clear influence on the results, with NLP and NLPV GCSs offering relevant improvements in frequency deviations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3163708",
            "Date of Publication": "31 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hilel García-Pereira",
                "labs": [
                    "Department of Hydraulic, Energy and Environmental Engineering, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Marcos Blanco",
                "labs": [
                    "CIEMAT, Spanish National Research Centre on Energy, Environment and Technology, Madrid, Spain"
                ]
            },
            {
                "name": "Guillermo Martínez-Lucas",
                "labs": [
                    "Department of Hydraulic, Energy and Environmental Engineering, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Juan I. Pérez-Díaz",
                "labs": [
                    "Department of Hydraulic, Energy and Environmental Engineering, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "José-Ignacio Sarasúa",
                "labs": [
                    "Department of Hydraulic, Energy and Environmental Engineering, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Frequency control",
                "Flywheels",
                "Power systems",
                "Energy storage",
                "Wind turbines",
                "Power system stability",
                "Renewable energy sources"
            ],
            "Author Keywords": [
                "Flywheel control scheme",
                "flywheel energy storage",
                "frequency control",
                "hybrid power systems",
                "isolated system",
                "power system stability"
            ]
        }
    },
    {
        "Title": "AltibbiVec: A Word Embedding Model for Medical and Health Applications in the Arabic Language",
        "Link": "https://ieeexplore.ieee.org/document/9548088/",
        "Abstract": "In recent years, the utilization of natural language processing (NLP) and Machine Learning (ML) techniques in clinical decision support systems have shown their ability in improving and automating the diagnosis process, and reducing potential clinical errors. NLP in the Arabic language is more intricate due to several limitations, such as the lack of datasets and analytical resources compared to other languages like English. However, a clinical decision support system in the Arabic context is of significant importance. A fundamental process in NLP is extracting features from text-based data via text embedding. Word embedding is a representation of words in a numeric format that encodes the statistic, semantic, or context information. Building a neural word embedding model requires hundreds of thousands of data instances to find hidden patterns of relationships within sentences. Essentially, extracting relevant and informative features promotes the performance of the learning algorithms. The objective of this paper is to propose an Arabic neural-based word embedding model in the medical and healthcare context (called “AltibbiVec”). Around 1.5 million medical consultations and questions written in different dialects are obtained from Altibbi telemedicine company and used to train the embedding model. Three different embedding models are developed and compared, which are Word2Vec, fastText, and GloVe. The trained models were evaluated by different criteria, including the word clustering and the similarity of words. Besides, performing a specialty-based question classification. The results show that Word2Vec and fastText capture sufficiently the semantics of text more than GloVe. Hence, they are recommended for healthcare NLP-based applications.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3115617",
            "Date of Publication": "24 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maria Habib",
                "labs": []
            },
            {
                "name": "Mohammad Faris",
                "labs": []
            },
            {
                "name": "Alaa Alomari",
                "labs": []
            },
            {
                "name": "Hossam Faris",
                "labs": [
                    "King Abdullah II School for Information Technology, The University of Jordan, Amman, Jordan",
                    "School of Computing and Informatics, Al Hussein Technical University, Amman, Jordan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Context modeling",
                "Biological system modeling",
                "Data models",
                "Semantics",
                "Task analysis",
                "Medical services"
            ],
            "Author Keywords": [
                "Arabic",
                "fastText",
                "GloVe",
                "healthcare",
                "pre-trained",
                "word embedding",
                "Word2Vec"
            ]
        }
    },
    {
        "Title": "Mapping Consumer Sentiment Toward Wireless Services Using Geospatial Twitter Data",
        "Link": "https://ieeexplore.ieee.org/document/8796368/",
        "Abstract": "Hyper-dense wireless network deployment is one of the popular solutions to meeting high capacity requirement for 5G delivery. However, current operator understanding of consumer satisfaction comes from call centers and base station quality-of-service (QoS) reports with poor geographic accuracy. The dramatic increase in geo-tagged social media posts adds a new potential to understand consumer satisfaction towards target-specific quality-of-experience (QoE) topics. In our paper, we focus on evaluating users' opinion on wireless service-related topics by applying natural language processing (NLP) to geo-tagged Twitter data. Current generalized sentiment detection methods with generalized NLP corpora are not topic specific. Here, we develop a novel wireless service topic-specific sentiment framework, yielding higher targeting accuracy than generalized NLP frameworks. To do so, we first annotate a new sentiment corpus called SignalSentiWord (SSW) and compare its performance with two other popular corpus libraries, AFINN and SentiWordNet. We then apply three established machine learning methods, namely: Naïve Bayes (NB), Support Vector Machine (SVM), and Recurrent Neural Network (RNN) to build our topic-specific sentiment classifier. Furthermore, we discuss the capability of SSW to filter noisy and high-frequency irrelevant words to improve the performance of machine learning algorithms. Finally, the real-world testing results show that our proposed SSW improves the performance of NLP significantly.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2935200",
            "Date of Publication": "13 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Weijie Qi",
                "labs": [
                    "School of Engineering, University of Warwick, Coventry, U.K."
                ]
            },
            {
                "name": "Rob Procter",
                "labs": [
                    "Department of Computer Science, University of Warwick, Coventry, U.K."
                ]
            },
            {
                "name": "Jie Zhang",
                "labs": [
                    "Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield, U.K."
                ]
            },
            {
                "name": "Weisi Guo",
                "labs": [
                    "School of Engineering, University of Warwick, Coventry, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Twitter",
                "Machine learning",
                "Sentiment analysis",
                "Wireless communication",
                "Support vector machines",
                "Quality of experience"
            ],
            "Author Keywords": [
                "Wireless",
                "quality of experience",
                "natural language processing",
                "social media data",
                "consumer"
            ]
        }
    },
    {
        "Title": "Review: Privacy-Preservation in the Context of Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/9592788/",
        "Abstract": "Data privacy is one of the highly discussed issues in recent years as we encounter data breaches and privacy scandals often. This raises a lot of concerns about the ways the data is acquired and the potential information leaks. Especially in the field of Artificial Intelligence (AI), the widely using of AI models aggravates the vulnerability of user privacy because a considerable portion of user data that AI models used is represented in natural language. In the past few years, many researchers have proposed NLP-based methods to address these data privacy challenges. To the best of our knowledge, this is the first interdisciplinary review discussing privacy preservation in the context of NLP. In this paper, we present a comprehensive review of previous research conducted to gather techniques and challenges of building and testing privacy-preserving systems in the context of Natural Language Processing (NLP). We group the different works under four categories: 1) Data privacy in the medical domain, 2) Privacy preservation in the technology domain, 3) Analysis of privacy policies, and 4) Privacy leaks detection in the text representation. This review compares the contributions and pitfalls of the various privacy violation detection and prevention works done using NLP techniques to help guide a path ahead.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3124163",
            "Date of Publication": "28 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Darshini Mahendran",
                "labs": [
                    "Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA"
                ]
            },
            {
                "name": "Changqing Luo",
                "labs": [
                    "Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA"
                ]
            },
            {
                "name": "Bridget T. Mcinnes",
                "labs": [
                    "Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data privacy",
                "Privacy",
                "Natural language processing",
                "Feature extraction",
                "Task analysis",
                "Data models",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Data privacy",
                "natural language processing",
                "privacy preservation",
                "privacy policy"
            ]
        }
    },
    {
        "Title": "On the Effectiveness of Pre-Trained Language Models for Legal Natural Language Processing: An Empirical Study",
        "Link": "https://ieeexplore.ieee.org/document/9826728/",
        "Abstract": "We present the first comprehensive empirical evaluation of pre-trained language models (PLMs) for legal natural language processing (NLP) in order to examine their effectiveness in this domain. Our study covers eight representative and challenging legal datasets, ranging from 900 to 57K samples, across five NLP tasks: binary classification, multi-label classification, multiple choice question answering, summarization and information retrieval. We first run unsupervised, classical machine learning and/or non-PLM based deep learning methods on these datasets, and show that baseline systems’ performance can be 4%~35% lower than that of PLM-based methods. Next, we compare general-domain PLMs and those specifically pre-trained for the legal domain, and find that domain-specific PLMs demonstrate 1%~5% higher performance than general-domain models, but only when the datasets are extremely close to the pre-training corpora. Finally, we evaluate six general-domain state-of-the-art systems, and show that they have limited generalizability to legal data, with performance gains from 0.1% to 1.2% over other PLM-based methods. Our experiments suggest that both general-domain and domain-specific PLM-based methods generally achieve better results than simpler methods on most tasks, with the exception of the retrieval task, where the best-performing baseline outperformed all PLM-based methods by at least 5%. Our findings can help legal NLP practitioners choose the appropriate methods for different tasks, and also shed light on potential future directions for legal NLP research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3190408",
            "Date of Publication": "12 July 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dezhao Song",
                "labs": [
                    "Thomson Reuters, Eagan, MN, USA"
                ]
            },
            {
                "name": "Sally Gao",
                "labs": [
                    "Thomson Reuters, New York, NY, USA"
                ]
            },
            {
                "name": "Baosheng He",
                "labs": [
                    "Meta Platforms Inc., Menlo Park, CA, USA"
                ]
            },
            {
                "name": "Frank Schilder",
                "labs": [
                    "Thomson Reuters, Eagan, MN, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Task analysis",
                "Feature extraction",
                "Deep learning",
                "Bit error rate",
                "Support vector machines",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Legal natural language processing",
                "pre-trained language model",
                "deep learning",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Automating Articulation: Applying Natural Language Processing to Post-Secondary Credit Transfer",
        "Link": "https://ieeexplore.ieee.org/document/8685082/",
        "Abstract": "Within the field of post-secondary student mobility, the assessment, and evaluation of transfer credit is a labor-intensive human intelligence task that is subject to time limits and human bias. This paper introduces a semi-automated approach to assessing transfer credit and generating articulation agreements between post-secondary institutions using natural language processing (NLP). The output from the NLP system is tested using a content expert generated an assessment of transfer credit between computer science programs at two separate post-secondary institutions. Initial testing with an unsupervised NLP algorithm, despite good results against standardized measures, assessed the percentage of course overlap as 71% similar to the percentages selected by human content experts. The application of an algorithm based on the Word2Vec model using domain-specific Wikipedia corpus and dependency parsing was applied to compensate for domain specific language and improved the relationship between content experts ratings and NLP output to 86% related overlap.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2910145",
            "Date of Publication": "11 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Andrew Heppner",
                "labs": [
                    "DATALab.Science, Lakehead University, Thunder Bay, ON, Canada"
                ]
            },
            {
                "name": "Atish Pawar",
                "labs": [
                    "DATALab.Science, Lakehead University, Thunder Bay, ON, Canada"
                ]
            },
            {
                "name": "Daniel Kivi",
                "labs": [
                    "DATALab.Science, Lakehead University, Thunder Bay, ON, Canada"
                ]
            },
            {
                "name": "Vijay Mago",
                "labs": [
                    "DATALab.Science, Lakehead University, Thunder Bay, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Semantics",
                "Testing",
                "Education",
                "Medical services",
                "Computer science",
                "Task analysis"
            ],
            "Author Keywords": [
                "Articulation agreement",
                "natural language processing",
                "semantic similarity",
                "student mobility",
                "transfer credit",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "Named Entity Recognition Utilized to Enhance Text Classification While Preserving Privacy",
        "Link": "https://ieeexplore.ieee.org/document/10287940/",
        "Abstract": "Recent development in Natural Language Processing (NLP) techniques has encouraged NLP-based application in various field including business, legal and health. An important process for all NLP projects is text preprocessing which is a process that modifies text data before using them in a machine learning model. Usually text preprocessing process includes cleaning, filtering, removing and replacing some texts to increase model accuracy, robustness, reduce data size or preserve privacy. Named entities recognizer (NER) is an NLP tool which finds Named Entities in text such as: names, organization, addresses, numbers and date. In this work, we create a preproccessing approach that uses NER to find named entities and, then, replace them with their type i.e. location, person or organization name to improve accuracy and preserve privacy instead of removing them or letting them become noise to our data. Experiments for text classification task using our approach have been conducted on several datasets some of which were collected in-house. Experiments indicate that using this approach enhances classifier accuracy and reduces feature representation’s dimensionality while, also, preserve privacy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3325895",
            "Date of Publication": "19 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Kutbi",
                "labs": [
                    "Computer Science Department, Saudi Electronic University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Task analysis",
                "Law",
                "Text recognition",
                "Privacy",
                "Feature extraction",
                "Support vector machines"
            ],
            "Author Keywords": [
                "Named entities",
                "preprocessing",
                "text classification",
                "privacy"
            ]
        }
    },
    {
        "Title": "Applied Linguistics With Red-Tailed Hawk Optimizer-Based Ensemble Learning Strategy in Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10311595/",
        "Abstract": "Natural Language Processing (NLP) is the most vital technology in currently utilized, specifically caused by the huge and growing count of online texts that requires that understood for its massive value that completely asserted. NLP is create a sense of unstructured data, which are created by social networks and other social data sources, and is supported to organize them into an additional structured model that assists several kinds of tasks and applications. Sentiment analysis (SA), a subfield of NLP contains determining the sentiment expressed or emotional tone from a piece of text. Deep learning (DL) approaches are significantly advanced the field of SA, permitting for more accurate and nuanced classification of sentiments from the text data. In this article, we present an Advanced Sentiment Analysis using a Red-Tailed Hawk Optimizer with Ensemble Learning (ASA-RTHEL) Strategy in NLP. The aim of ASA-RTHEL technique is to exploit the strategies of ensemble learning with a hyperparameter tuning process for SA. The ASA-RTHEL technique mainly follows an ensemble learning-based classification process, which combines prediction from three DL approaches convolutional neural network (CNN), gated recurrent unit (GRU), and long short-term memory (LSTM). The ensemble process results in enhanced SA performance and decreases the risk of depending only on a single model bias or error. To boost the SA performance, the hyperparameter tuning strategy is performed by the use of the RTH algorithm. An extensive set of experiments were carried out for ensuring the superior SA results of ASA-RTHEL technique. The comprehensive comparison study highlighted the enhanced results of the MPONLP-TSA method on the recognition of various kinds of sentiments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3331061",
            "Date of Publication": "08 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hala J. Alshahrani",
                "labs": [
                    "Department of Applied Linguistics, College of Languages, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulkhaleq Q. A. Hassan",
                "labs": [
                    "Department of English and Applied Linguistics, College of Science and Arts at Mahayil, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Nabil Sharaf Almalki",
                "labs": [
                    "Department of Special Education, College of Education, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mrim M. Alnfiai",
                "labs": [
                    "Department of Information Technology, College of Computers and Information Technology, Taif University, Taif, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed S. Salama",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering and Technology, Future University in Egypt, New Cairo, Egypt"
                ]
            },
            {
                "name": "Manar Ahmed Hamza",
                "labs": [
                    "Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Social networking (online)",
                "Natural language processing",
                "Convolutional neural networks",
                "Task analysis",
                "Ensemble learning",
                "Sentiment analysis",
                "Deep learning",
                "Linguistics",
                "Ensemble learning"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "natural language processing",
                "red-tailed hawk optimizer",
                "deep learning",
                "ensemble learning"
            ]
        }
    },
    {
        "Title": "Exploring Universal Intrinsic Task Subspace for Few-Shot Learning via Prompt Tuning",
        "Link": "https://ieeexplore.ieee.org/document/10603438/",
        "Abstract": "Why can pre-trained language models (PLMs) learn universal representations and effectively adapt to broad NLP tasks differing a lot superficially? In this work, we empirically find evidence indicating that the adaptations of PLMs to various few-shot tasks can be reparameterized as optimizing only a few free parameters in a unified low-dimensional intrinsic task subspace, which may help us understand why PLMs could easily adapt to various NLP tasks with small-scale data. To find such a subspace and examine its universality, we propose an analysis pipeline called intrinsic prompt tuning (IPT). Specifically, we resort to the recent success of prompt tuning and decompose the soft prompts of multiple NLP tasks into the same low-dimensional nonlinear subspace, then we learn to adapt the PLM to unseen data or tasks by only tuning parameters in this subspace. In the experiments, we study diverse few-shot NLP tasks and surprisingly find that in a 250-dimensional subspace found with 100 tasks, by only tuning 250 free parameters, we can recover 97% and 83% of the full prompt tuning performance for 100 seen tasks (using different training data) and 20 unseen tasks, respectively, showing great generalization ability of the found intrinsic task subspace. Besides being an analysis tool, IPTcould further help us improve the prompt tuning stability.",
        "Details": {
            "DOI": "10.1109/TASLP.2024.3430545",
            "Date of Publication": "18 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
        },
        "issn_info": {
            "Print ISSN": "2329-9290",
            "Electronic ISSN": "2329-9304"
        },
        "authors_data": [
            {
                "name": "Yujia Qin",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Xiaozhi Wang",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Yusheng Su",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Yankai Lin",
                "labs": [
                    "Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China"
                ]
            },
            {
                "name": "Ning Ding",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Jing Yi",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Weize Chen",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Zhiyuan Liu",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Juanzi Li",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Lei Hou",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Peng Li",
                "labs": [
                    "Institute for AI Industry Research (AIR), Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Maosong Sun",
                "labs": [
                    "Department of Computer Science, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Jie Zhou",
                "labs": [
                    "Pattern Recognition Center, WeChat AI, Tencent Inc., Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Tuning",
                "Training",
                "Adaptation models",
                "Speech processing",
                "Natural language processing",
                "Vectors"
            ],
            "Author Keywords": [
                "Intrinsic dimension",
                "pre-trained language model",
                "prompt tuning",
                "task unification"
            ]
        }
    },
    {
        "Title": "A Model-Driven Approach Employing DSL and Generation Templates to Accelerate the Development of Conversational Agents for Smart Tourism",
        "Link": "https://ieeexplore.ieee.org/document/11016738/",
        "Abstract": "Conversational agents are intelligent, ubiquitous software applications widely used across various sectors, such as commerce, tourism, and more. Their key benefits include automating tasks, improving customer service, and ensuring service availability. The development of conversational agents utilizing artificial intelligence (AI) techniques represents a significant advancement in Natural Language Processing (NLP). Numerous studies employ deep learning and NLP methodologies to construct sophisticated conversational agent systems. Additionally, developers and companies often utilize APIs provided by intent recognition services like Dialogflow and Amazon Lex to easily create conversational agents using graphical forms, which enhance conversational agent functionality. However, these APIs have limitations, such as potential dependency on specific NLP service providers and associated high costs. Besides, the lack of a specialized conversational agent development platform for the tourism domain poses a considerable challenge. To address these limitations, this work tackles critical gaps in conversational agent development tools by constructing a graphical Domain-Specific Language (DSL) and code generation templates for accelerating the development of conversational agents tailored to smart tourism’s needs. First, we provide a designed metamodel to define the abstract syntax of a DSL. Second, we implement the metamodel using the Eclipse Modeling Framework. Third, we develop a graphical interface that incorporates intuitive icons to simplify the creation of conversational agent models. Fourth, we define code generation templates to translate the graphical models into executable agent source code. Finally, we validate the proposed approach to demonstrate its effectiveness and applicability in real-world scenarios, reducing development time and avoiding the costs associated with NLP services.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574641",
            "Date of Publication": "28 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Charaf Ouaddi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Lamya Benaddi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Adnane Souha",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Hamza Abdelmalek",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Abdeslam Jakimi",
                "labs": [
                    "Software Engineering and Information Systems Engineering (GL-ISI) Team, Faculty of Sciences and Techniques of Errachidia (FSTE), University of Moulay Ismail (UMI), Meknes, Morocco"
                ]
            },
            {
                "name": "Rachid Saadane",
                "labs": [
                    "Electrical Engineering Department, SIRC-LAGES, Hassania School of Public Works, Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "DSL",
                "Codes",
                "Costs",
                "Accelerated aging",
                "Chatbots",
                "Deep learning",
                "Source coding",
                "Software",
                "Natural language generation"
            ],
            "Author Keywords": [
                "Conversational agent",
                "chatbot",
                "domain specific language",
                "metamodel",
                "Rasa framework",
                "code generation",
                "tourism"
            ]
        }
    },
    {
        "Title": "Selecting the Best Compiler Optimization by Adopting Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10658977/",
        "Abstract": "Compiler is a tool that converts the high-level language into assembly code after enabling relevant optimizations. The automatic selection of suitable optimizations from an ample optimization space is a non-trivial task mainly accomplished through hardware profiling and application-level features. These features are then passed through an intelligent algorithm to predict the desired optimizations. However, collecting these features requires executing the application beforehand, which involves high overheads. With the evolution of Natural Language Processing (NLP), the performance of an application can be solely predicted at compile time via source code analysis. There has been substantial work in source code analysis using NLP, but most of it is focused on offloading the computation to suitable devices or detecting code vulnerabilities. Therefore, it has yet to be used to identify the best optimization sequence for an application. Similarly, most works have focused on finding the best machine learning or deep learning algorithms, hence ignoring the other important phases of the NLP pipeline. This paper pioneers the use of NLP to predict the best set of optimizations for a given application at compile time. Furthermore, this paper uniquely studies the impact of four vectorization and seven regression techniques in predicting the application performance. For most applications, we show that tfidf vectorization and huber regression result in the best outcomes. On average, the proposed technique predicts the optimal optimization sequence with a performance drop of 18%, achieving a minimum drop of merely 0.5% compared to the actual best combination.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3451516",
            "Date of Publication": "29 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hameeza Ahmed",
                "labs": [
                    "Department of Computer and Information Systems Engineering, NED University of Engineering and Technology, Karachi, Pakistan"
                ]
            },
            {
                "name": "Muhammad Fahim Ul Haque",
                "labs": [
                    "Department of Telecommunications Engineering, NED University of Engineering and Technology, Karachi, Pakistan"
                ]
            },
            {
                "name": "Hashim Raza Khan",
                "labs": [
                    "Department of Engineering Sciences and Technology, Iqra University, Karachi, Pakistan",
                    "Neurocomputation Lab, National Centre of Artificial Intelligence, NED University of Engineering and Technology, Karachi, Pakistan"
                ]
            },
            {
                "name": "Ghalib Nadeem",
                "labs": [
                    "Department of Engineering Sciences and Technology, Iqra University, Karachi, Pakistan"
                ]
            },
            {
                "name": "Kamran Arshad",
                "labs": [
                    "Department of Electrical and Computer Engineering, College of Engineering and Information Technology, Ajman University, Ajman, United Arab Emirates",
                    "Artificial Intelligence Research Centre, Ajman University, Ajman, United Arab Emirates"
                ]
            },
            {
                "name": "Khaled Assaleh",
                "labs": [
                    "Department of Electrical and Computer Engineering, College of Engineering and Information Technology, Ajman University, Ajman, United Arab Emirates",
                    "Artificial Intelligence Research Centre, Ajman University, Ajman, United Arab Emirates"
                ]
            },
            {
                "name": "Paulo Cesar Santos",
                "labs": [
                    "Institute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Optimization",
                "Natural language processing",
                "Source coding",
                "Feature extraction",
                "Hardware",
                "Bayes methods",
                "Program processors",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Compiler",
                "optimization",
                "source code analysis",
                "natural language processing",
                "vectorization",
                "regression"
            ]
        }
    },
    {
        "Title": "Hybrid Input Model Using Multiple Features From Surface Analysis for Malware Detection",
        "Link": "https://ieeexplore.ieee.org/document/10662914/",
        "Abstract": "Many malware detection models have been proposed to protect computers from the ever- increasing number of malware attacks. The features that are obtained from surface analysis and machine learning are often used for malware detection. Previous studies that performed surface analysis have proposed image-based methods using ensemble learning. However, no natural language processing (NLP)-based malware detection method that combines multiple features has yet been reported. Instead, previous malware detection methods using NLP techniques have focused only on single features. When hybrid features are used, the word order and detection rate is affected if the data are initially handled by combining the hybrid features into one data point. Consequently, using NLP techniques is challenging when considering the word order. This paper proposes a hybrid model that uses three hybrid features obtained from surface analysis for malware detection and demonstrates the effectiveness of using NLP techniques in combination with hybrid features. The F-measure for the combination of these three features was 0.927.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3452675",
            "Date of Publication": "02 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mamoru Mimura",
                "labs": [
                    "National Defense Academy, Yokosuka, Kanagawa, Japan"
                ]
            },
            {
                "name": "Satoki Kanno",
                "labs": [
                    "Japan Ground Self-Defense Force, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Malware",
                "Feature extraction",
                "Accuracy",
                "Surface treatment",
                "Machine learning",
                "Long short term memory",
                "Ensemble learning",
                "Natural language processing",
                "Artificial neural networks"
            ],
            "Author Keywords": [
                "Malware detection",
                "natural language processing",
                "deep neural network"
            ]
        }
    },
    {
        "Title": "Application of Optimal Control Method to Path Tracking Problem of Vehicle",
        "Link": "https://ieeexplore.ieee.org/document/10802908/",
        "Abstract": "Path tracking is an essential stage for vehicle safety control. The study proposes an optimal control method for path tracking problem. Firstly, a nonlinear 4-DOF vehicle model is established. Secondly, the path optimization problem of vehicle is transformed into a nonlinear programming problem(NLP) by discretizing both control variables and state variables using the local collocation method. Then, in order to improve the efficiency of solving the NLP, an efficient calculation method for partial derivatives is established. Finally, a real vehicle test is executed to verify the rationality of the proposed model and methodology. The results show that by decomposing the partial derivative of the NLP into the partial derivative of the original path optimization problem the computational complexity of the first order partial derivative of NLP is significantly reduced improving computational efficiency even more significantly.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3515081",
            "Date of Publication": "16 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yingjie Liu",
                "labs": [
                    "School of Machinery and Automation, Weifang University, Weifang, Shandong, China"
                ]
            },
            {
                "name": "Enhao Wang",
                "labs": [
                    "Department of Engineering, Durham University, Durham, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Target tracking",
                "Autonomous vehicles",
                "Accuracy",
                "Path planning",
                "Optimal control",
                "Planning",
                "Vehicle dynamics",
                "Real-time systems",
                "Computational modeling",
                "Computational efficiency"
            ],
            "Author Keywords": [
                "Vehicle dynamics",
                "path tracking",
                "optimal control",
                "symplectic pseudospectral method"
            ]
        }
    },
    {
        "Title": "Tokenizers for African Languages",
        "Link": "https://ieeexplore.ieee.org/document/10815724/",
        "Abstract": "Despite incredible development in the field of natural language processing (NLP), there has been a huge gap in the performance of NLP tasks between high-resource languages (HRLs) and low-resource languages (LRLs). African languages belong mainly to the LRLs, and one of the major contributing factors to the performance gap is tokenization, which plays a crucial role in NLP performance in general. Many recent studies on African languages often rely on multilingual tokenizers or general-purpose tokenizers, which are not optimized for African languages. This may lead to suboptimal performance in downstream NLP tasks. In this paper, we systematically analyze the performance of language-specific tokenizers for three African languages: Swahili, Hausa, and Yoruba. By experimental results on two classification tasks (i.e. sentiment classification and news classification), we found that the language-specific tokenizers for African languages consistently outperformed other monolingual tokenizers, with performance gaps of up to 5.43% in sentiment classification and 4.58% in news classification. We also found that multilingual tokenizers generally work well if they are trained in many African languages rather than global HRLs. For instance, African multilingual tokenizers outperformed global multilingual tokenizers by an average of 1.70% in sentiment classification and 1.41% in news classification. The largest observed improvement was 2.61% in news classification using Logistic Regression (LR). Based on the results, we suggest a method for choosing tokenizers when analyzing data or developing models for African languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3522285",
            "Date of Publication": "25 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Goodwill Erasmo Ndomba",
                "labs": [
                    "Department of Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea"
                ]
            },
            {
                "name": "Medard Edmund Mswahili",
                "labs": [
                    "Department of Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea"
                ]
            },
            {
                "name": "Young-Seob Jeong",
                "labs": [
                    "Department of Computer Engineering, Chungbuk National University, Cheongju, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tokenization",
                "Multilingual",
                "Natural language processing",
                "Training",
                "Vectors",
                "Complexity theory",
                "Vocabulary",
                "Accuracy",
                "Support vector machines",
                "Standards"
            ],
            "Author Keywords": [
                "Tokenizer",
                "classification",
                "African language",
                "Swahili",
                "Yoruba",
                "Hausa"
            ]
        }
    },
    {
        "Title": "Target-Dependent Sentiment Classification With BERT",
        "Link": "https://ieeexplore.ieee.org/document/8864964/",
        "Abstract": "Research on machine assisted text analysis follows the rapid development of digital media, and sentiment analysis is among the prevalent applications. Traditional sentiment analysis methods require complex feature engineering, and embedding representations have dominated leaderboards for a long time. However, the context-independent nature limits their representative power in rich context, hurting performance in Natural Language Processing (NLP) tasks. Bidirectional Encoder Representations from Transformers (BERT), among other pre-trained language models, beats existing best results in eleven NLP tasks (including sentence-level sentiment classification) by a large margin, which makes it the new baseline of text representation. As a more challenging task, fewer applications of BERT have been observed for sentiment classification at the aspect level. We implement three target-dependent variations of the BERTbase model, with positioned output at the target terms and an optional sentence with the target built in. Experiments on three data collections show that our TD-BERT model achieves new state-of-the-art performance, in comparison to traditional feature engineering methods, embedding-based models and earlier applications of BERT. With the successful application of BERT in many NLP tasks, our experiments try to verify if its context-aware representation can achieve similar performance improvement in aspect-based sentiment analysis. Surprisingly, coupling it with complex neural networks that used to work well with embedding representations does not show much value, sometimes with performance below the vanilla BERT-FC implementation. On the other hand, incorporation of target information shows stable accuracy improvement, and the most effective way of utilizing that information is displayed through the experiment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2946594",
            "Date of Publication": "11 October 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhengjie Gao",
                "labs": [
                    "Department of Computer Science, Chengdu University of Information Technology, Chengdu, China"
                ]
            },
            {
                "name": "Ao Feng",
                "labs": [
                    "Department of Computer Science, Chengdu University of Information Technology, Chengdu, China"
                ]
            },
            {
                "name": "Xinyu Song",
                "labs": [
                    "Department of Computer Science, Chengdu University of Information Technology, Chengdu, China"
                ]
            },
            {
                "name": "Xi Wu",
                "labs": [
                    "Department of Computer Science, Chengdu University of Information Technology, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Task analysis",
                "Neural networks",
                "Sentiment analysis",
                "Context modeling",
                "Media"
            ],
            "Author Keywords": [
                "Deep learning",
                "neural networks",
                "sentiment analysis",
                "BERT"
            ]
        }
    },
    {
        "Title": "A Review of Recent Advances, Challenges, and Opportunities in Malicious Insider Threat Detection Using Machine Learning Methods",
        "Link": "https://ieeexplore.ieee.org/document/10445123/",
        "Abstract": "Insider threat detection has become a paramount concern in modern times where organizations strive to safeguard their sensitive information and critical assets from malicious actions by individuals with privileged access. This survey paper provides a comprehensive overview of insider threat detection, highlighting its significance in the current landscape of cybersecurity. The review encompasses a broad spectrum of methodologies and techniques, with a particular focus on classical machine-learning approaches and their limitations in effectively addressing the intricacies of insider threats. Furthermore, the survey explores the utilization of modern deep learning and natural language processing (NLP) based methods as promising alternatives, shedding light on their advantages over traditional methods. The comprehensive analysis of results from experiments utilizing NLP and large language models to detect malicious insider threats on the CMU CERT dataset reveals promising insights. Studies surveyed in this paper indicate that these advanced techniques demonstrate notable efficacy in identifying suspicious activities and anomalous behaviors associated with insider threats within organizational systems. Additionally, the survey underscores the potential of NLP and large language model-based approaches, which can enhance threat detection by deciphering textual and contextual information. In the conclusion section, the paper offers valuable insights into the future directions of insider threat detection. It advocates for the integration of more sophisticated time-series-based techniques, recognizing the importance of temporal patterns in insider threat behaviors. These recommendations reflect the evolving nature of insider threats and emphasize the need for proactive, data-driven strategies to safeguard organizations against internal security breaches. In conclusion, this survey not only underscores the urgency of addressing insider threats but also provides a roadmap for the adoption of advanced methodologies to enhance detection and mitigation capabilities in contemporary cybersecurity paradigms.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3369906",
            "Date of Publication": "26 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatima Rashed Alzaabi",
                "labs": [
                    "College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Abid Mehmood",
                "labs": [
                    "College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Threat assessment",
                "Behavioral sciences",
                "Security",
                "Surveys",
                "Data breach",
                "Telecommunication traffic",
                "Reviews",
                "Malware",
                "Classification algorithms",
                "Natural language processing",
                "Time series analysis"
            ],
            "Author Keywords": [
                "Insider threat detection",
                "privilege escalation",
                "anomaly detection",
                "user action graph",
                "cyber security",
                "user behavior",
                "temporal information",
                "pre-trained language models",
                "word embedding",
                "CERT dataset"
            ]
        }
    },
    {
        "Title": "Mixed-Integer and Conditional Trajectory Planning for an Autonomous Mining Truck in Loading/Dumping Scenarios: A Global Optimization Approach",
        "Link": "https://ieeexplore.ieee.org/document/9919391/",
        "Abstract": "Trajectory planning for a heavy-duty mining truck near the loading/dumping sites of an open-pit mine is difficult. As opposed to trajectory planning for a small-sized passenger car in a parking lot, trajectory planning for a heavy-duty mining truck involves complex factors in vehicle kinematics and environment. These factors make the concerned trajectory planning scheme a mixed-integer nonlinear program (MINLP) incorporated with conditional constraints (denoted as C-MINLP). MINLP solvers can neither deal with conditional constraints nor find global optima in real time. Instead of solving the C-MINLP directly, we build a from-coarse-to-fine framework so that the coupled difficulties (the mixed integral variables, conditional constraints, and the demand for global optimality) are divided and conquered. At the coarse search stage, a global-optimality-enhanced hybrid A* search algorithm is proposed to find a near-optimal coarse trajectory with the mixed integral variables, conditional kinematic constraints, and global optimality considered. The coarse trajectory is further polished at the refinement stage, wherein the nominal C-MINLP is simplified as a small-scale NLP. The solution to the NLP is an optimized trajectory, which does not violate the complex constraints in the nominal C-MINLP. This indicates that conversion from the C-MINLP to an NLP is efficient with the help of a high-quality coarse trajectory.",
        "Details": {
            "DOI": "10.1109/TIV.2022.3214777",
            "Date of Publication": "14 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Intelligent Vehicles"
        },
        "issn_info": {
            "Electronic ISSN": "2379-8904",
            "Print ISSN": "2379-8858"
        },
        "authors_data": [
            {
                "name": "Bai Li",
                "labs": [
                    "State Key Laboratory of Advanced Design and Manufacturing for Vehicle Body, Changsha, China",
                    "College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Yakun Ouyang",
                "labs": [
                    "College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Xiaohui Li",
                "labs": [
                    "College of Intelligence Science, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Dongpu Cao",
                "labs": [
                    "School of Vehicle and Mobility, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Tantan Zhang",
                "labs": [
                    "College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China"
                ]
            },
            {
                "name": "Yaonan Wang",
                "labs": [
                    "College of Electrical and Information Engineering, Hunan University, Changsha, China",
                    "National Engineering Laboratory for Robot Visual Perception and Control, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory planning",
                "Trajectory",
                "Kinematics",
                "Costs",
                "Stochastic processes",
                "Planning",
                "Cost function"
            ],
            "Author Keywords": [
                "Trajectory planning",
                "autonomous mining vehicle",
                "computational optimal control",
                "mixed-integer nonlinear program"
            ]
        }
    },
    {
        "Title": "Cross-Domain Sentiment Classification With Bidirectional Contextualized Transformer Language Models",
        "Link": "https://ieeexplore.ieee.org/document/8894409/",
        "Abstract": "Cross-domain sentiment classification is an important Natural Language Processing (NLP) task that aims at leveraging knowledge obtained from a source domain to train a high-performance learner for sentiment classification on a target domain. Existing transfer learning methods applied on cross-domain sentiment classification mostly focus on inducing a low-dimensional feature representation shared across domains based on pivots and non-pivots, which is still a low-level representation of sequence data. Recently, there have been great progress in the NLP literature in developing high-level representation language models based on Transformer architecture, which are pre-trained on large text corpus and fine-tuned for specific task with an additional layer on top. Among such language models, the bidirectional contextualized Transformer language models of BERT and XLNet have greatly impacted NLP research field. In this paper, we fine-tune BERT and XLNet for the cross-domain sentiment classification. We then explore their transferability in the context of cross-domain sentiment classification through in-depth analysis of two models' performances and update the state-of-the-arts with a significant margin of improvement. Our results show that such bidirectional contextualized language models outperform the previous state-of-the-arts methods for cross-domain sentiment classification while using up to 120 times less data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2952360",
            "Date of Publication": "08 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Batsergelen Myagmar",
                "labs": [
                    "Department of Computer Science, University of Tsukuba, Tsukuba, Japan"
                ]
            },
            {
                "name": "Jie Li",
                "labs": [
                    "Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China"
                ]
            },
            {
                "name": "Shigetomo Kimura",
                "labs": [
                    "Department of Computer Science, University of Tsukuba, Tsukuba, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Data models",
                "Context modeling",
                "Natural language processing",
                "Computational modeling",
                "Training",
                "Bit error rate"
            ],
            "Author Keywords": [
                "Transfer learning",
                "cross-domain sentiment classification",
                "pre-trained language model"
            ]
        }
    },
    {
        "Title": "Fast UAV Trajectory Optimization Using Bilevel Optimization With Analytical Gradients",
        "Link": "https://ieeexplore.ieee.org/document/9457044/",
        "Abstract": "In the article, we present an efficient optimization framework that solves trajectory optimization problems by decoupling state variables from timing variables, thereby decomposing a challenging nonlinear programming (NLP) problem into two easier subproblems. With timing fixed, the state variables can be optimized efficiently using convex optimization, and the timing variables can be optimized in a separate NLP, which forms a bilevel optimization problem. The challenge of obtaining the gradient of the timing variables is solved by sensitivity analysis of parametric NLPs. The exact analytic gradient is computed from the dual solution as a by-product, whereas existing finite-difference techniques require additional optimization. The bilevel optimization framework efficiently optimizes both timing and state variables which is demonstrated on generating trajectories for an UAV. Numerical experiments demonstrate that bilevel optimization converges significantly more reliably than a standard NLP solver, and analytical gradients outperform finite differences in terms of computation speed and accuracy. Physical experiments demonstrate its real-time applicability for reactive target tracking tasks.",
        "Details": {
            "DOI": "10.1109/TRO.2021.3076454",
            "Date of Publication": "16 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Robotics"
        },
        "issn_info": {
            "Print ISSN": "1552-3098",
            "Electronic ISSN": "1941-0468"
        },
        "authors_data": [
            {
                "name": "Weidong Sun",
                "labs": [
                    "XYZ Robotics Inc., Shanghai, China"
                ]
            },
            {
                "name": "Gao Tang",
                "labs": [
                    "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Kris Hauser",
                "labs": [
                    "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimization",
                "Trajectory",
                "Autonomous aerial vehicles",
                "Trajectory optimization"
            ],
            "Author Keywords": [
                "Trajectory optimization",
                "unmanned aerial vehicle"
            ]
        }
    },
    {
        "Title": "Cross-Domain Visual Exploration of Academic Corpora via the Latent Meaning of User-Authored Keywords",
        "Link": "https://ieeexplore.ieee.org/document/8766090/",
        "Abstract": "Nowadays, scholars dedicate a substantial amount of their work to the querying and browsing of increasingly large collections of research papers on the Internet. In parallel, the recent surge of novel interdisciplinary approaches in science requires scholars to acquire competencies in new fields for which they may lack the necessary vocabulary to formulate adequate queries. This problem, together with the issue of information overload, poses new challenges in the fields of natural language processing (NLP) and visualization design that call for a rapid response from the scientific community. In this respect, we report on a novel visualization scheme that enables the exploration of research paper collections via the analysis of semantic proximity relationships found in author-assigned keywords. Our proposal replaces traditional string queries with a bag-of-words (BoW) extracted from a user-generated auxiliary corpus that captures the intentionality of the research. Continuing along the lines established by other authors in the fields of literature-based discovery (LBD), NLP, and visual analytics (VA), we combine novel advances in the fields of NLP with visual network analysis techniques to offer scholars a perspective of the target corpus that better fits their research interests. To highlight the advantages of our proposal, we conduct two experiments employing a collection of visualization research papers and an auxiliary cross-domain BoW. Here, we showcase how our visualization can be used to maximize the effectiveness of a browsing session by enhancing the language acquisition task, which allows for effectively extracting knowledge that is in line with the users' previous expectations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2929754",
            "Date of Publication": "18 July 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alejandro Benito-Santos",
                "labs": [
                    "Visual Analytics and Information Visualization Group, University of Salamanca, Salamanca, Spain"
                ]
            },
            {
                "name": "Roberto Therón Sánchez",
                "labs": [
                    "Visual Analytics and Information Visualization Group, University of Salamanca, Salamanca, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Analytical models",
                "Data visualization",
                "Visual analytics",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Academic corpora",
                "digital humanities",
                "document exploration",
                "human-computer interaction",
                "knowledge elicitation",
                "latent semantic analysis",
                "literature-based discovery",
                "visualization"
            ]
        }
    },
    {
        "Title": "Quantum-Enhanced Support Vector Machine for Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/10216989/",
        "Abstract": "Quantum computers have potential computational abilities such as speeding up complex computations, parallelism by superpositions, and handling large data sets. Moreover, the field of natural language processing (NLP) is rapidly attracting researchers and engineers in order to build larger model computations of NLP. Thus, the use of quantum technology in NLP tasks, especially sentiment classification, has the potential to be developed. In this research, we investigate the best technique to represent sentiment sentences so that sentiment can be analyzed using the Quantum-Enhanced Support Vector Machine (QE-SVM) algorithm. Investigations were carried out using circuit parameter optimization methods and data transformation. The pipeline of the proposed method consists of sentence-to-circuit conversion, circuit parameter training, state vector formation, and finally the training and testing processes. As a result, we obtained the best classification results with an accuracy of 93.33% using the SPSA optimization method and PCA transformation data. These results have also outperformed the baseline SVM method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3304990",
            "Date of Publication": "14 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fariska Zakhralativa Ruskanda",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",
                    "Artificial Intelligence Center, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Muhammad Rifat Abiwardani",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Rahmat Mulyawan",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence on Microelectronics, Bandung Institute of Technology, Bandung, Indonesia",
                    "Research Collaboration Center for Quantum Technology 2.0, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Infall Syafalni",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",
                    "University Center of Excellence on Microelectronics, Bandung Institute of Technology, Bandung, Indonesia"
                ]
            },
            {
                "name": "Harashta Tatimma Larasati",
                "labs": [
                    "School of Electrical Engineering and Informatics, Bandung Institute of Technology, Bandung, Indonesia",
                    "School of Computer Science and Engineering, Pusan National University, Busan, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Kernel",
                "Quantum computing",
                "Training",
                "Qubit",
                "Task analysis",
                "Sentiment analysis",
                "Support vector machines",
                "Quantum computing"
            ],
            "Author Keywords": [
                "Sentiment classification",
                "SVM",
                "quantum-enhanced",
                "quantum representation"
            ]
        }
    },
    {
        "Title": "A Differentiable Language Model Adversarial Attack on Text Classifiers",
        "Link": "https://ieeexplore.ieee.org/document/9712314/",
        "Abstract": "Transformer models play a crucial role in state of the art solutions to problems arising in the field of natural language processing (NLP). They have billions of parameters and are typically considered as black boxes. Robustness of huge Transformer-based models for NLP is an important question due to their wide adoption. One way to understand and improve robustness of these models is an exploration of an adversarial attack scenario: check if a small perturbation of an input invisible to a human eye can fool a model. Due to the discrete nature of textual data, gradient-based adversarial methods, widely used in computer vision, are not applicable per se. The standard strategy to overcome this issue is to develop token-level transformations, which do not take the whole sentence into account. The semantic meaning and grammatical correctness of the sentence are often lost in such approaches In this paper, we propose a new black-box sentence-level attack. Our method fine-tunes a pre-trained language model to generate adversarial examples. A proposed differentiable loss function depends on a substitute classifier score and an approximate edit distance computed via a deep learning model. We show that the proposed attack outperforms competitors on a diverse set of NLP problems for both computed metrics and human evaluation. Moreover, due to the usage of the fine-tuned language model, the generated adversarial examples are hard to detect, thus current models are not robust. Hence, it is difficult to defend from the proposed attack, which is not the case for others. Our attack demonstrates the highest decrease of classification accuracy on all datasets(on AG news: 0.95 without attack, 0.89 under SamplingFool attack, 0.82 under DILMA attack).",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3148413",
            "Date of Publication": "11 February 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ivan Fursov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Alexey Zaytsev",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Pavel Burnyshev",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia",
                    "Huawei Noah’s Ark Laboratory, Moscow, Russia"
                ]
            },
            {
                "name": "Ekaterina Dmitrieva",
                "labs": [
                    "HSE University, Moscow, Russia"
                ]
            },
            {
                "name": "Nikita Klyuchnikov",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Andrey Kravchenko",
                "labs": [
                    "University of Oxford, Oxford, U.K."
                ]
            },
            {
                "name": "Ekaterina Artemova",
                "labs": [
                    "Huawei Noah’s Ark Laboratory, Moscow, Russia",
                    "HSE University, Moscow, Russia"
                ]
            },
            {
                "name": "Evgenia Komleva",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia"
                ]
            },
            {
                "name": "Evgeny Burnaev",
                "labs": [
                    "Skolkovo Institute of Science and Technology, Moscow, Russia",
                    "Artificial Intelligence Research Institute (AIRI), Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Training",
                "Natural language processing",
                "Motion pictures",
                "Deep learning",
                "Task analysis",
                "Perturbation methods"
            ],
            "Author Keywords": [
                "Deep learning",
                "natural language processing",
                "adversarial attack",
                "generative model"
            ]
        }
    },
    {
        "Title": "Exploring Natural Language Processing in Model-To-Model Transformations",
        "Link": "https://ieeexplore.ieee.org/document/9938985/",
        "Abstract": "In this paper, we explore the possibility to apply natural language processing in visual model-to-model (M2M) transformations. Therefore, we present our research results on information extraction from text labels in process models modeled using Business Process Modeling Notation (BPMN) and use case models depicted in Unified Modeling Language (UML) using the most recent developments in natural language processing (NLP). Here, we focus on three relevant tasks, namely, the extraction of verb/noun phrases that would be used to form relations, parsing of conjunctive/disjunctive statements, and the detection of abbreviations and acronyms. Techniques combining state-of-the-art NLP language models with formal regular expressions grammar-based structure detection were implemented to solve relation extraction task. To achieve these goals, we benchmark the most recent state-of-the-art NLP tools (CoreNLP, Stanford Stanza, Flair, Spacy, AllenNLP, BERT, ELECTRA), as well as custom BERT-BiLSTM-CRF and ELMo-BiLSTM-CRF implementations, trained with certain data augmentations to improve performance on the most ambiguous cases; these tools are further used to extract noun and verb phrases from short text labels generally used in UML and BPMN models. Furthermore, we describe our attempts to improve these extractors by solving the abbreviation/acronym detection problem using machine learning-based detection, as well as process conjunctive and disjunctive statements, due to their relevance to performing advanced text normalization. The obtained results show that the best phrase extraction and conjunctive phrase processing performance was obtained using Stanza based implementation, yet, our trained BERT-BiLSTM-CRF outperformed it for the verb phrase detection task. While this work was inspired by our ongoing research on partial model-to-model transformations, we believe it to be applicable in other areas requiring similar text processing capabilities as well.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3219455",
            "Date of Publication": "04 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Paulius Danenas",
                "labs": [
                    "Center of Information Systems Design Technologies, Kaunas University of Technology, Kaunas, Lithuania"
                ]
            },
            {
                "name": "Tomas Skersys",
                "labs": [
                    "Center of Information Systems Design Technologies, Kaunas University of Technology, Kaunas, Lithuania",
                    "Department of Information Systems, Kaunas University of Technology, Kaunas, Lithuania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Unified modeling language",
                "Natural language processing",
                "Terminology",
                "Information analysis",
                "Solid modeling",
                "Context modeling",
                "Data mining"
            ],
            "Author Keywords": [
                "Information extraction",
                "relation extraction",
                "acronym detection",
                "process models",
                "use-case models",
                "natural language processing",
                "model-to-model transformation"
            ]
        }
    },
    {
        "Title": "CNO-LSTM: A Chaotic Neural Oscillatory Long Short-Term Memory Model for Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9982464/",
        "Abstract": "Long Short-Term Memory (LSTM) networks are unique to exercise data in its memory cell with long-term memory as Natural Language Processing (NLP) tasks have inklings of intensive time and computational power due to their complex structures like magnitude language model Transformer required to pre-train and learn billions of data performing different NLP tasks. In this paper, a dynamic chaotic model is proposed for the objective of transforming neurons states in network with neural dynamic characteristics by restructuring LSTM as Chaotic Neural Oscillatory-Long-Short Term Memory (CNO-LSTM), where neurons in LSTM memory cells are weighed in substitutes by oscillatory neurons to speed up computational training of language model and improve text classification accuracy for real-world applications. From the implementation perspective, five popular datasets of general text classification including binary, multi classification and multi-label classification are used to compare with mainstream baseline models on NLP tasks. Results showed that the performance of CNO-LSTM, a simplified model structure and oscillatory neurons state in exercising different types of text classification tasks are above baseline models in terms of evaluation index such as Accuracy, Precision, Recall and F1. The main contributions are time reduction and improved accuracy. It achieved approximately 46.76% of the highest reduction training time and 2.55% accuracy compared with vanilla LSTM model. Further, it achieved approximately 35.86% in time reduction compared with attention model without oscillatory indicating that the model restructure has reduced GPU dependency to improve training accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3228600",
            "Date of Publication": "12 December 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nuobei Shi",
                "labs": [
                    "Faculty of Science and Technology, Beijing Normal University–Hong Kong Baptist University United International College, Zhuhai, China"
                ]
            },
            {
                "name": "Zhuohui Chen",
                "labs": [
                    "Faculty of Innovation Engineering, Macau University of Science and Technology, Taipa, Macau, China"
                ]
            },
            {
                "name": "Ling Chen",
                "labs": [
                    "School of Applied Science and Civil Engineering, Beijing Institute of Technology Zhuhai, Zhuhai, China"
                ]
            },
            {
                "name": "Raymond S. T. Lee",
                "labs": [
                    "Faculty of Science and Technology, Beijing Normal University–Hong Kong Baptist University United International College, Zhuhai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Training",
                "Data models",
                "Computational modeling",
                "Task analysis",
                "Neurons",
                "Biological neural networks"
            ],
            "Author Keywords": [
                "Long short-term memory",
                "chaotic neural network",
                "Lee-oscillator",
                "text classification",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Performance Analysis of Federated Learning Algorithms for Multilingual Protest News Detection Using Pre-Trained DistilBERT and BERT",
        "Link": "https://ieeexplore.ieee.org/document/10330588/",
        "Abstract": "Data scientists in the Natural Language Processing (NLP) field confront the challenge of reconciling the necessity for data-centric analyses with the imperative to safeguard sensitive information, all while managing the substantial costs linked to the collection process of training data. In a Federated Learning (FL) system, these challenges can be alleviated by the training of a global model, eliminating the need to centralize sensitive data of clients. However, distributed NLP data is usually Non-Independent and Identically Distributed (Non-IID), which leads to poorer generalizability of the global model when trained with Federated Averaging (FedAvg). Recently proposed extensions to FedAvg promise to improve the global model performance on Non-IID data. Yet, such advanced FL algorithms trained on multilingual Non-IID texts have not been studied in industry and academia in detail. This paper compares, for the first time, the FL algorithms: FedAvg, FedAvgM, FedYogi, FedAdam and FedAdagrad for a binary text classification task using 12078 tailored real-world news reports in English, Portuguese, Spanish and Hindi. For this objective, pre-trained DistilBERT and BERT models fine-tuned with these texts are used. The paper results show that FedYogi is the most stable and robust FL algorithm when DistilBERT is used, achieving an average macro F1 score of 0.7789 for IID and 0.7755 for Non-IID protest news. The study also exhibits that BERT models trained with weighted FedAvg and FedAvgM can achieve a similar prediction power as centralized language models, demonstrating the potential of leveraging FL in the NLP domain without the need to collect data centrally.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3334910",
            "Date of Publication": "28 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pascal Riedel",
                "labs": [
                    "Institute of Databases and Information Systems, Ulm University, Ulm, Germany",
                    "Department of Computer Science, Ulm University of Applied Sciences, Ulm, Germany"
                ]
            },
            {
                "name": "Manfred Reichert",
                "labs": [
                    "Institute of Databases and Information Systems, Ulm University, Ulm, Germany"
                ]
            },
            {
                "name": "Reinhold Von Schwerin",
                "labs": [
                    "Department of Computer Science, Ulm University of Applied Sciences, Ulm, Germany"
                ]
            },
            {
                "name": "Alexander Hafner",
                "labs": [
                    "Department of Computer Science, Ulm University of Applied Sciences, Ulm, Germany"
                ]
            },
            {
                "name": "Daniel Schaudt",
                "labs": [
                    "Department of Computer Science, Ulm University of Applied Sciences, Ulm, Germany"
                ]
            },
            {
                "name": "Gaurav Singh",
                "labs": [
                    "Independent Researcher, Varanasi, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Transformers",
                "Analytical models",
                "Training",
                "Distributed databases",
                "Natural language processing",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Privacy",
                "natural language processing",
                "distributed learning",
                "optimization",
                "federated algorithms",
                "data distributions"
            ]
        }
    },
    {
        "Title": "Data Augmentation With Semantic Enrichment for Deep Learning Invoice Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10496671/",
        "Abstract": "Natural language processing (NLP) is a research field that provides huge potential to automate accounting tasks dealing with text data. This research studies the application of NLP in automatically categorizing invoices based on the invoice text description. The study employs semantic enrichment, data augmentation, and deep learning to address the NLP unique issues posed by the inherent short text and multi-class imbalance nature of invoice descriptions. Semantic enrichment was done using labels as an information source. Training data was artificially increased with either WordNet synonym replacement, Global Vectors for Word Representation (GloVe) word replacement, or the Bidirectional Encoder Representations from Transformers (BERT) word replacement method. Each training dataset was then supplied for training with one nondeep learning classifier and two deep learning classifiers respectively, namely Linear Support Vector Machine (LSVM), Bidirectional Long Short-Term Memory (Bi-LSTM), and BERT. Overall, the semantically enriched, WordNet augmented training set paired with the BERT classifier yielded the best results, successfully preserving semantics, reducing noise and overfitting while improving accuracy per class, achieving an increase of performance up to 20 percentage points (ppts) for macro F1 score and 6.7 ppts for accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3387860",
            "Date of Publication": "11 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wei Wen Chi",
                "labs": [
                    "Department of Business Analytics, Sunway Business School, Sunway University, Bandar Sunway, Selangor, Malaysia"
                ]
            },
            {
                "name": "Tiong Yew Tang",
                "labs": [
                    "Department of Business Analytics, Sunway Business School, Sunway University, Bandar Sunway, Selangor, Malaysia"
                ]
            },
            {
                "name": "Narishah Mohamed Salleh",
                "labs": [
                    "Department of Business Analytics, Sunway Business School, Sunway University, Bandar Sunway, Selangor, Malaysia"
                ]
            },
            {
                "name": "Muaadh Mukred",
                "labs": [
                    "Department of Business Analytics, Sunway Business School, Sunway University, Bandar Sunway, Selangor, Malaysia"
                ]
            },
            {
                "name": "Hussain AlSalman",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Zohaib",
                "labs": [
                    "Software Engineering Department, Lappeenranta-Lahti University of Technology, Lappeenranta, Finland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Text categorization",
                "Natural language processing",
                "Task analysis",
                "Data augmentation",
                "Data models",
                "Deep learning",
                "Long short term memory",
                "Machine learning"
            ],
            "Author Keywords": [
                "Long short-term memory",
                "data augmentation",
                "deep learning",
                "machine learning",
                "global vectors for word representation",
                "management accounting",
                "natural language processing",
                "semantics"
            ]
        }
    },
    {
        "Title": "Hierarchical Multi-Granularity Attention- Based Hybrid Neural Network for Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9167245/",
        "Abstract": "Neural network-based approaches have become the driven forces for Natural Language Processing (NLP) tasks. Conventionally, there are two mainstream neural architectures for NLP tasks: the recurrent neural network (RNN) and the convolution neural network (ConvNet). RNNs are good at modeling long-term dependencies over input texts, but preclude parallel computation. ConvNets do not have memory capability and it has to model sequential data as un-ordered features. Therefore, ConvNets fail to learn sequential dependencies over the input texts, but it is able to carry out high-efficient parallel computation. As each neural architecture, such as RNN and ConvNets, has its own pro and con, integration of different architectures is assumed to be able to enrich the semantic representation of texts, thus enhance the performance of NLP tasks. However, few investigation explores the reconciliation of these seemingly incompatible architectures. To address this issue, we propose a hybrid architecture based on a novel hierarchical multi-granularity attention mechanism, named Multi-granularity Attention-based Hybrid Neural Network (MahNN). The attention mechanism is to assign different weights to different parts of the input sequence to increase the computation efficiency and performance of neural models. In MahNN, two types of attentions are introduced: the syntactical attention and the semantical attention. The syntactical attention computes the importance of the syntactic elements (such as words or sentence) at the lower symbolic level and the semantical attention is used to compute the importance of the embedded space dimension corresponding to the upper latent semantics. We adopt the text classification as an exemplifying way to illustrate the ability of MahNN to understand texts. The experimental results on a variety of datasets demonstrate that MahNN outperforms most of the state-of-the-arts for text classification.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3016727",
            "Date of Publication": "14 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhenyu Liu",
                "labs": [
                    "School of Information Management for Law, China University of Political Science and Law, Beijing, China"
                ]
            },
            {
                "name": "Chaohong Lu",
                "labs": [
                    "School of Computer Science, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Haiwei Huang",
                "labs": [
                    "School of Computer Science, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Shengfei Lyu",
                "labs": [
                    "School of Computer Science, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Zhenchao Tao",
                "labs": [
                    "Division of Life Sciences and Medicine, The First Affiliated Hospital of USTC, University of Science and Technology of China, Hefei, China",
                    "Anhui Provincial Cancer Hospital, Hefei, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Computer architecture",
                "Recurrent neural networks",
                "Convolution",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "multichannel",
                "convolutional neural network",
                "text classification"
            ]
        }
    },
    {
        "Title": "A Deep Learning-Based Approach for Part of Speech (PoS) Tagging in the Pashto Language",
        "Link": "https://ieeexplore.ieee.org/document/10552703/",
        "Abstract": "A fundamental task in natural language processing (NLP) is part of speech (PoS) tagging. PoS tagging is crucial to many NLP applications, including question answering, machine translation, syntactic parsing, speech recognition, and semantic parsing. PoS tagging is a task for labeling sequences in which a tagger/system tags each word with its appropriate part of speech label. In NLP, PoS tagging is often considered as a language-specific task. Similarly, Pashto is a language that has not been explored regarding PoS tagging. Therefore, this research focuses on the PoS tagging considering the Pashto language and provides a baseline accuracy. The research has twofold benefits. First, it introduces a Pashto tag set that contains 2,81,205 words of the Pashto language. All these words are tagged with 17 unique PoS tags. Second, it proposes a deep learning-based model by examining classic Recursive Neural Networks (RNN) and Bidirectional Long Short Term Memory Networks (BLSTM). The results show promising performances when used with the word embedding technique. The proposed approach achieved 98.82% accuracy as a baseline on the test dataset by using the BLSTM model along with word embedding.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3412175",
            "Date of Publication": "11 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shaheen Ullah",
                "labs": [
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Riaz Ahmad",
                "labs": [
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Abdallah Namoun",
                "labs": [
                    "Faculty of Computer Science and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Siraj Muhammad",
                "labs": [
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Khalil Ullah",
                "labs": [
                    "Department of Software Engineering, University of Malakand (UOM), Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Ibrar Hussain",
                "labs": [
                    "Department of Computer Science and Information Technology, University of Malakand (UOM), Dir Lower, Chakdara, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Isa Ali Ibrahim",
                "labs": [
                    "Department of Cybersecurity, School of Information and Communication Technology, Federal University of Technology Owerri, Owerri, Nigeria"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tagging",
                "Hidden Markov models",
                "Natural language processing",
                "Long short term memory",
                "Accuracy",
                "Task analysis",
                "Deep learning",
                "Artificial intelligence",
                "Image analysis",
                "Document handling",
                "Handwriting recognition"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "document image analysis",
                "handwritten text",
                "natural language processing",
                "optical character recognition",
                "speech recognition",
                "standard dataset"
            ]
        }
    },
    {
        "Title": "Multi-Aspect Annotation and Analysis of Nepali Tweets on Anti-Establishment Election Discourse",
        "Link": "https://ieeexplore.ieee.org/document/10355965/",
        "Abstract": "In today’s social media-dominated landscape, digital platforms wield substantial influence over public opinion, particularly during crucial political events such as electoral processes. These platforms become hubs for diverse discussions, encompassing topics, reforms, and desired changes. Notably, in times of government dissatisfaction, they serve as arenas for anti-establishment discourse, highlighting the need to analyze public sentiment in these conversations. However, the analysis of such discourse is notably scarce, even in high-resource languages, and entirely non-existent in the context of the Nepali language. To address this critical gap, we present Nepal Anti Establishment discourse Tweets (NAET), a novel dataset comprising 4,445 multi-aspect annotated Nepali tweets, facilitating a comprehensive understanding of political conversations. Our contributions encompass evaluating tweet relevance, sentiment, and satire, while also exploring the presence of hate speech, identifying its targets, and distinguishing directed and non-directed expressions. Additionally, we investigate hope speech, an underexplored aspect crucial in the context of anti-establishment discourse, as it reflects the aspirations and expectations from new political figures and parties. Furthermore, we set NLP-based baselines for all these tasks. To ensure a holistic analysis, we also employ topic modeling, a powerful technique that helps us identify and understand the prevalent themes and patterns emerging from the discourse. Our research thus presents a comprehensive and multi-faceted perspective on anti-establishment election discourse in a low-resource language setting. The dataset is publicly available, facilitating in-depth analysis of political tweets in Nepali discourse and further advancing NLP research for the Nepali language through labeled data and baselines for various NLP tasks. The dataset for this work is made available at https://github.com/rkritesh210/NAET.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3342154",
            "Date of Publication": "13 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kritesh Rauniyar",
                "labs": [
                    "Department of Computer Science and Engineering, Delhi Technological University, New Delhi, India"
                ]
            },
            {
                "name": "Sweta Poudel",
                "labs": [
                    "Kathmandu Engineering College, Tribhuvan University, Kathmandu, Nepal"
                ]
            },
            {
                "name": "Shuvam Shiwakoti",
                "labs": [
                    "Department of Software Engineering, Delhi Technological University, New Delhi, India"
                ]
            },
            {
                "name": "Surendrabikram Thapa",
                "labs": [
                    "Department of Computer Science, Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "Junaid Rashid",
                "labs": [
                    "Department of Data Science, Sejong University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jungeun Kim",
                "labs": [
                    "Department of Software, Kongju National University, Cheonan, Republic of Korea"
                ]
            },
            {
                "name": "Muhammad Imran",
                "labs": [
                    "Institute of Innovation, Science and Sustainability, Federation University, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Usman Naseem",
                "labs": [
                    "College of Science and Engineering, James Cook University, Cairns, QLD, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Hate speech",
                "Voting",
                "Annotations",
                "Blogs",
                "Task analysis",
                "Sentiment analysis",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Natural language processing",
                "social media analytics",
                "sentiment analysis",
                "topic modeling",
                "Nepali election discourse"
            ]
        }
    },
    {
        "Title": "Pattern-Based Syntactic Simplification of Compound and Complex Sentences",
        "Link": "https://ieeexplore.ieee.org/document/9774397/",
        "Abstract": "With the advent of new technologies, simplifying text automatically has been very popular and of high importance among natural language researchers during the last decade. The predominant research done in the area of Automatic Sentence Simplification(ASS) is inclined to either lexical or syntactical simplification of sentences. From the literature survey, it is observed that existing research in lexical simplification makes use of word substitution technique. This causes word sense ambiguity in cases where the word synonyms are not appropriate for a sentence in the given context. In contrast, syntactical simplification though accurate and applicable to Natural Language Processing (NLP) tasks, requires tremendous efforts to construct rules for a given domain. The research proposes a framework called Pattern-based Automatic Syntactic Simplification(PASS) which identifies sentences and applies rules based on grammatical patterns to simplify the sentences thereby making it more generic for NLP tasks. PASS is evaluated by human experts to rate the usefulness of the framework based on fluency, adequacy and simplicity of the sentences. Furthermore, the framework is automatically evaluated with the available online corpus using automatic metrics of SARI, BLEU, and FKGL. The proposed approach generates promising results in the field of ASS and could be used as a preliminary module for NLP tasks as well as other natural language-related applications like summarization, anaphora resolution, question-answering, and many more.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3174846",
            "Date of Publication": "13 May 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Archana Praveen Kumar",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Ashalatha Nayak",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Manjula Shenoy K.",
                "labs": [
                    "Department of Information and Communication Technology, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Roshan Jacob Manoj",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Akansha Priyadarshi",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Compounds",
                "Syntactics",
                "Integrated circuits",
                "Natural language processing",
                "Mathematical models",
                "Task analysis",
                "Tagging"
            ],
            "Author Keywords": [
                "Complex sentences",
                "compound sentences",
                "simple sentences",
                "pattern-based syntactic simplification",
                "natural language processing",
                "summarization"
            ]
        }
    },
    {
        "Title": "Lighting Search Algorithm With Convolutional Neural Network-Based Image Captioning System for Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10355962/",
        "Abstract": "Recently, deep learning models have become more prominent due to their tremendous performance for real-time tasks like face recognition, object detection, natural language processing (NLP), instance segmentation, image classification, gesture recognition, and video classification. Image captioning is one of the critical tasks in NLP and computer vision (CV). It completes conversion from image to text; specifically, the model produces description text automatically based on the input images. In this aspect, this article develops a Lighting Search Algorithm (LSA) with a Hybrid Convolutional Neural Network Image Captioning System (LSAHCNN-ICS) for NLP. This introduced LSAHCNN-ICS system develops an end-to-end model which employs convolutional neural network (CNN) based ShuffleNet as an encoder and HCNN as a decoder. At the encoding part, the ShuffleNet model derives feature descriptors of the image. Besides, in the decoding part, the description of text can be generated using the proposed hybrid convolutional neural network (HCNN) model. To achieve improved captioning results, the LSA is applied as a hyperparameter tuning strategy, representing the innovation of the study. The simulation analysis of the presented LSAHCNN-ICS technique is performed on a benchmark database, and the obtained results demonstrated the enhanced outcomes of the LSAHCNN-ICS algorithm over other recent methods with maximum Consensus-based Image Description Evaluation (CIDEr Code) of 43.60, 59.54, and 135.14 on Flickr8k, Flickr30k, and MSCOCO datasets correspondingly.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3342703",
            "Date of Publication": "13 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rana Othman Alnashwan",
                "labs": [
                    "Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box, 84428, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Samia Allaoua Chelloug",
                "labs": [
                    "Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box, 84428, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nabil Sharaf Almalki",
                "labs": [
                    "Department of Special Education, College of Education, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Imène Issaoui",
                "labs": [
                    "Unit of Scientific Research, Applied College, Qassim University, Buraydah, Saudi Arabia"
                ]
            },
            {
                "name": "Abdelwahed Motwakel",
                "labs": [
                    "Department of Information Systems, College of Business Administration in Hawtat Bani Tamim, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed Sayed",
                "labs": [
                    "Research Center, Future University in Egypt, New Cairo, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Convolutional neural networks",
                "Visualization",
                "Convolutional neural networks",
                "Decoding",
                "Natural language processing",
                "Tuning"
            ],
            "Author Keywords": [
                "Deep convolutional neural network",
                "natural language processing",
                "image captioning",
                "machine learning",
                "hyperparameter tuning"
            ]
        }
    },
    {
        "Title": "Reciprocating Encoder Portrayal From Reliable Transformer Dependent Bidirectional Long Short-Term Memory for Question and Answering Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10595122/",
        "Abstract": "Diversity in use of Question and Answering (Q/A) is evolving as a popular application in the area of Natural Language Processing (NLP). The alive unsupervised word embedding approaches are efficient to collect Latent-Semantic data on number of tasks. But certain methods are still unable to tackle issues such as polysemous-unaware with task-unaware phenomena in NLP tasks. GloVe understands word embedding by availing information statistics from word co-occurrence matrices. Nevertheless, word-pairs in the matrices are taken from a pre-established window of local context, which may result in constrained word-pairs and also probably semantic inappropriate word-pairs. SemGloVe employed in this paper, refines semantic co-occurrences from BERT into static GloVe word-embedding with Bidirectional-Long-Short-Term-Memory (BERT- Bi-LSTM) model for text categorization in Q/A. This method utilizes the CR23K and CR1000k datasets for the effective text classification of NLP. The proposed model, with SemGloVe Embedding on BERT combined with Bi-LSTM, produced better results on metrics like accuracy, precision, recall, and F1 Score as 0.92, 0.79, 0.85, and 0.73, respectively, when compared to existing methods of Text2GraphQL, GPT-2, BERT and SPARQL. The BERT model with Bi-LSTM is better in every way for responding to different kinds of questions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3426604",
            "Date of Publication": "11 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. Suguna",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "K. S. Sakunthala Prabha",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Bidirectional control",
                "Task analysis",
                "Text categorization",
                "Semantics",
                "Natural language processing",
                "Accuracy",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "Bidirectional encoder representations from transformer",
                "natural language processing",
                "question and answering",
                "SemGloVe"
            ]
        }
    },
    {
        "Title": "From computer vision to short text understanding: Applying similar approaches into different disciplines",
        "Link": "https://ieeexplore.ieee.org/document/9878056/",
        "Abstract": "With the development of IoT and 5G technologies, more and more online resources are presented in trendy multimodal data forms over the Internet. Hence, effectively processing multimodal information is significant to the development of various online applications, including e-Iearning and digital health, to just name a few. However, most AI-driven systems or models can only handle limited forms of information. In this study, we investigate the correlation between natural language processing (NLP) and pattern recognition, trying to apply the mainstream approaches and models used in the computer vision (CV) to the task of NLP. Based on two different Twitter datasets, we propose a convolutional neural network based model to interpret the content of short text with different goals and application backgrounds. The experiments have demonstrated that our proposed model shows fairly competitive performance compared to the mainstream recurrent neural network based NLP models such as bidirectional long short-term memory (Bi-LSTM) and bidirectional gate recurrent unit (Bi-GRU). Moreover, the experimental results also demonstrate that the proposed model can precisely locate the key information in the given text.",
        "Details": {
            "DOI": "10.23919/ICN.2022.0010",
            "Date of Publication": "June 2022",
            "Publisher": "TUP",
            "Published In": "Intelligent and Converged Networks"
        },
        "issn_info": {
            "Electronic ISSN": "2708-6240"
        },
        "authors_data": [
            {
                "name": "Jiayin Lin",
                "labs": [
                    "College of Computer and Cyber Security, Fujian Normal University, Fuzhou, China"
                ]
            },
            {
                "name": "Geng Sun",
                "labs": [
                    "School of Computing and Information Technology, University of Wollongong, Wollongong, Australia"
                ]
            },
            {
                "name": "Jun Shen",
                "labs": [
                    "School of Computing and Information Technology, University of Wollongong, Wollongong, Australia"
                ]
            },
            {
                "name": "David E. Pritchard",
                "labs": [
                    "Research Lab of Electronics, Massachusetts Institute of Technology, Cambridge, MA, USA"
                ]
            },
            {
                "name": "Ping Yu",
                "labs": [
                    "School of Computing and Information Technology, University of Wollongong, Wollongong, Australia"
                ]
            },
            {
                "name": "Tingru Cui",
                "labs": [
                    "School of Computing and Information Systems, University of Melbourne, Melbourne, Australia"
                ]
            },
            {
                "name": "Dongming Xu",
                "labs": [
                    "UQ Business School, University of Queensland, Brisbane, Australia"
                ]
            },
            {
                "name": "Li Li",
                "labs": [
                    "Faculty of Computer and Information Science, Southwest University, Chongqing, China"
                ]
            },
            {
                "name": "Ghassan Beydoun",
                "labs": [
                    "School of Information System and Modelling, University of Technology Sydney, Sydney, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer vision",
                "Recurrent neural networks",
                "Social networking (online)",
                "Computational modeling",
                "Logic gates",
                "Natural language processing",
                "Pattern recognition"
            ],
            "Author Keywords": [
                "neural network",
                "natural language processing",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Noise-Like Pulse Generated by All-Fiber Ultrafast Thulium-Doped Fiber Laser Based on Single-Wall Carbon Nanotubes",
        "Link": "https://ieeexplore.ieee.org/document/9748035/",
        "Abstract": "A noise-like pulse (NLP) thulium-doped fiber laser based on single-wall carbon nanotubes (SWCNTs) has been proposed and demonstrated in this paper, which the microfiber decorated with SWCNTs work as a saturable absorber to generate an ultrafast pulse. The length of the cavity is 12 m, corresponding to the fundamental frequency of 17.2 MHz. NLP with a duration of 643 fs can be obtained at 1965 nm under the signal-to-noise ratio of 56 dB. This work may assist us to better understand the dynamic characteristic of NLP with the help of materials and offer a fine laser source to the subsequent applications just like the generation of supercontinuum.",
        "Details": {
            "DOI": "10.1109/JPHOT.2022.3148290",
            "Date of Publication": "01 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "Yingkui Li",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Lei Du",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Xin Li",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Zonghui Tao",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Wanzhuo Ma",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Tianshu Wang",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Yan Lou",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            },
            {
                "name": "Huilin Jiang",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, Jilin, China",
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, Jilin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Laser mode locking",
                "Optical fiber dispersion",
                "Optical fiber amplifiers",
                "Optical fiber polarization",
                "Optical attenuators",
                "Measurement by laser beam",
                "Optical pulses"
            ],
            "Author Keywords": [
                "Mode-locked laser",
                "thulium-doped fiber laser",
                "single-wall carbon nanotubes",
                "noise-like pulse"
            ]
        }
    },
    {
        "Title": "IAE: Irony-Based Adversarial Examples for Sentiment Analysis Systems",
        "Link": "https://ieeexplore.ieee.org/document/10614159/",
        "Abstract": "Adversarial examples, which are inputs deliberately perturbed with imperceptible changes to induce model errors, have raised serious concerns for the reliability and security of deep neural networks (DNNs). While adversarial attacks have been extensively studied in continuous data domains such as images, the discrete nature of text presents unique challenges. In this paper, we propose Irony-based Adversarial Examples (IAE), a method that transforms straightforward sentences into ironic ones to create adversarial text. This approach exploits the rhetorical device of irony, where the intended meaning is opposite to the literal interpretation, requiring a deeper understanding of context to detect. The IAE method is particularly challenging due to the need to accurately locate evaluation words, substitute them with appropriate collocations, and expand the text with suitable ironic elements while maintaining semantic coherence. Our research makes the following key contributions: (1) We introduce IAE, a strategy for generating textual adversarial examples using irony. This method does not rely on pre-existing irony corpora, making it a versatile tool for creating adversarial text in various NLP tasks. (2) We demonstrate that the performance of several state-of-the-art deep learning models on sentiment analysis tasks significantly deteriorates when subjected to IAE attacks. This finding underscores the susceptibility of current NLP systems to adversarial manipulation through irony. (3) We compare the impact of IAE on human judgment versus NLP systems, revealing that humans are less susceptible to the effects of irony in text.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3435573",
            "Date of Publication": "29 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiaoyin Yi",
                "labs": [
                    "Chongqing Key Laboratory of Public Big Data Security Technology, Chongqing, China",
                    "School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China"
                ]
            },
            {
                "name": "Jiacheng Huang",
                "labs": [
                    "School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Sentiment analysis",
                "Task analysis",
                "Analytical models",
                "Visualization",
                "Perturbation methods",
                "Adversarial machine learning",
                "Closed box"
            ],
            "Author Keywords": [
                "Adversarial examples",
                "sentiment analysis",
                "irony-based",
                "black-box"
            ]
        }
    },
    {
        "Title": "Data Hiding for Ensuring the Quality of the Host Image and the Security of the Message",
        "Link": "https://ieeexplore.ieee.org/document/8693642/",
        "Abstract": "Concealing a message in the APPn markers of a JPEG image not only protects the security of the message but also induces no change to the quality of the image. However, from the existing literature, whether it is a plaintext message or a ciphertext message hidden in APPn, it is easy for an attacker to identify the confidentiality of the hidden message, which is not conducive to the security of the message. Inspired by the natural language processing (NLP) and format-preserving encryption (FPE), this paper proposes a data hiding method, which is focused on the quality assurance of the host image and the concealment of the plain text having complete semantics based on the NLP and FPE. This method first uses the NLP and FPE to identify and encrypt the sensitive words in the plain text and then hides the ciphertext text with the plaintext style in the APPn of a JPEG image after replacing the plaintext words with the ciphertext words that have the plaintext style. The experimental results confirm that the structure, size, and quality of the host image do not show any changes before or after the data hiding and the recovered host image is also identical to its original appearance. In addition, the strategy that the semantic similarity is regulated autonomously by the user also makes it possible to obtain the ideal ciphertext words with very low similarity. Moreover, more than 80% of the ciphertext texts have reasonable semantics. Compared with the existing literature, our algorithm has a better performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2907530",
            "Date of Publication": "17 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Huaibo Sun",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Hong Luo",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yan Sun",
                "labs": [
                    "Beijing Key Laboratory of Intelligent Telecommunications Software and Multimedia, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encryption",
                "Transform coding",
                "Semantics",
                "Sun",
                "Natural language processing"
            ],
            "Author Keywords": [
                "APPn",
                "common text",
                "format-preserving encryption",
                "natural language processing",
                "quality of host image"
            ]
        }
    },
    {
        "Title": "A Novel Approach for Mitigating Class Imbalance in Arabic Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/11145759/",
        "Abstract": "Natural language processing (NLP) has become somewhat well-known because of its many uses; deep neural networks have driven major developments. Still, there are difficulties, especially in Arabic NLP, where the language’s large vocabulary of over 12 million words and several dialects cause special issues. Arabic has a large speaker base; however, NLP studies in this language find challenges, particularly with class imbalance. Many times, standard class balancing methods overlook intra-class similarity, a crucial element influencing model training. We present a new approach for computing intra-class similarity using cosine similarity and embedding models to find ideal class weights for model training, hence bridging this difference. On two benchmark datasets—the Arabic Semantic Question Similarity dataset (NSURL) and the Microsoft Research Paragraph Corpus (MRPC)—we assessed the proposed approach. With an accuracy of state-of-the-art 83.25% on the MRPC dataset and 96.931% on the NSURL dataset, the proposed approach proved successful in improving model performance in Arabic text classification.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3604427",
            "Date of Publication": "01 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Emad Nabil",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Abdelrahman Ezzeldin Nagib",
                "labs": [
                    "Faculty of Computer Science, October University for Modern Sciences and Arts (MSA), Giza, Egypt"
                ]
            },
            {
                "name": "Mena Hany",
                "labs": [
                    "King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia"
                ]
            },
            {
                "name": "Safiullah Faizullah",
                "labs": [
                    "Faculty of Computer and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Wael Hassan Gomaa",
                "labs": [
                    "Faculty of Computers and Artificial Intelligence, Beni-Suef University, Beni Suef, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Data models",
                "Linguistics",
                "Computational modeling",
                "Transformers",
                "Deep learning",
                "Standards",
                "Machine translation",
                "Electronic mail",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Natural language processing",
                "intra-class similarity",
                "Transformers",
                "classification",
                "class weights",
                "semantic similarity"
            ]
        }
    },
    {
        "Title": "Reinforcement Learning-Based Generative Security Framework for Host Intrusion Detection",
        "Link": "https://ieeexplore.ieee.org/document/10848062/",
        "Abstract": "Protecting users’ systems from evolving cybercrime is becoming increasingly challenging. Attackers create more complicated attack patterns and configure attack behavior to resemble normal behavior to evade detection by defenders. Thus, it is indispensable to configure a security system that accurately detects attacks on each user’s system. Since the attack does not occur only at a specific point in the network, there is a limitation in identifying computer intrusion simply using network packets. A Host-based Intrusion Detection System (HIDS) is a highly effective tool for monitoring computer systems and detecting unusual or unauthorized activities. HIDS can quickly identify potential security threats by closely monitoring and analyzing system logs, configurations, file integrity, and events specific to a host machine. It helps maintain the security and integrity of individual systems by detecting unauthorized activities or policy violations. With its advanced capabilities and reliable performance, HIDS is essential to any comprehensive host-based security strategy. Although HIDS can detect insider intrusions, the known HIDS detection methods are limited to specific attacks and may be ineffective against new attack patterns. Recently, researchers applied Natural Language Processing (NLP) in HIDS to scrutinize complex attack patterns, but they could have more effectively provided useful outputs for detecting intrusions based on these patterns. In this paper, we use reinforcement learning methodology, Actor-Critic, and NLP to extract keywords that occur on each anomaly system call log and propose a rule generation framework to prevent future intrusion detection using the extracted words. We analyze the anomaly log using NLP and extract the characteristics of each attack log as the ‘keyword.’ Based on the unique keywords of each attack log, we utilize reinforcement learning to establish a set of rules to protect against attacks. We extracted keywords based on textrank from the system call log sequence and simultaneously provided ground truth data using the extracted keywords. Based on the extracted keywords, the pre-trained Seq2Seq model generate rules according to the reward calculation method in reinforcement learning. When calculating the reward in reinforcement learning, we used the comparison value with the pre-trained Seq2Seq model, the malware log sequence detected by the rule set based on reinforcement learning, and the false positive value generated by the normal data to create its own rule set. We verified the proposed framework using the system call log datasets: ADFA-LD, LID-DS 2021 dataset. The proposed framework demonstrated a high accuracy rate of 96.5% average when faced with different attacks. We compared the accuracy based on the proposed framework detection, textrank, and Seq2Seq model-based keyword extraction methods. As a result, the proposed framework showed relatively high accuracy against various attack logs.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3532353",
            "Date of Publication": "20 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yongsik Kim",
                "labs": [
                    "School of Cybersecurity, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Su-Youn Hong",
                "labs": [
                    "LIG Nex1, Yongin-si, South Korea"
                ]
            },
            {
                "name": "Sungjin Park",
                "labs": [
                    "LIG Nex1, Yongin-si, South Korea"
                ]
            },
            {
                "name": "Huy Kang Kim",
                "labs": [
                    "School of Cybersecurity, Korea University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reinforcement learning",
                "Natural language processing",
                "Security",
                "Intrusion detection",
                "Accuracy",
                "Monitoring",
                "Convolutional neural networks",
                "Telecommunication traffic",
                "Predictive models",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "Reinforcement learning",
                "natural language processing",
                "host-based intrusion detection system"
            ]
        }
    },
    {
        "Title": "Performance Evaluation of Monolithic and Microservice Architectures for Natural Language Processing in Command and Control Applications",
        "Link": "https://ieeexplore.ieee.org/document/11146751/",
        "Abstract": "The success of Command and Control (C2) operations relies heavily on clear communication among participants, often under stressful and time-sensitive conditions that demand accurate decision-making. Examples of such operations include military engagements, reconnaissance missions, search and rescue efforts, and peacekeeping activities. The design of systems to support C2 is therefore challenging, as they must support structured communication and interaction means among participants. To address this, we developed a method called Method to Support Semantic Interoperability in Command and Control (MAISC2) to support C2, in which we have applied Natural Language Processing (NLP) and semantic techniques to pinpoint specific elements in sentences, thereby enhancing the participants’ understanding of the C2 communications. Microservices Architecture (MSA) are known to offer potential benefits over MA, particularly in terms of scalability, independence, and maintenance. Furthermore, some NLP applications have already been developed using MSA, confirming these benefits. This paper presents a version of our system developed using MSA and compares it to its Monolithic Architecture (MA) counterpart. Our objective is to evaluate whether the benefits of adopting MSA, observed in other domains, also apply to C2 support systems based on NLP and semantic techniques, as exemplified by the MAISC2 method. Our results show that MA outperforms MSA in many scenarios; however, as the application load increases, MSA shows increasingly better performance. In particular, although MA had shorter processing and delivery times under normal conditions, MSA delivered better processing performance when handling significantly higher levels of concurrent activity.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3604775",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Flavio Ferreira Da Silva Mosafi",
                "labs": [
                    "Military Institute of Engineering, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Mateus Sze Cosenza",
                "labs": [
                    "Military Institute of Engineering, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Léo Victor Cruz Vasconcelos",
                "labs": [
                    "Military Institute of Engineering, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Luís Ferreira Pires",
                "labs": [
                    "University of Twente, Enschede, The Netherlands"
                ]
            },
            {
                "name": "Julio Cesar Duarte",
                "labs": [
                    "Military Institute of Engineering, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Maria Claudia Reis Cavalcanti",
                "labs": [
                    "Military Institute of Engineering, Rio de Janeiro, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Microservice architectures",
                "Computer architecture",
                "Natural language processing",
                "Command and control systems",
                "Scalability",
                "Semantics",
                "Maintenance",
                "Pipelines",
                "Named entity recognition",
                "Medical services"
            ],
            "Author Keywords": [
                "Command and control",
                "microservice architecture",
                "military communication",
                "named entity recognition",
                "natural language processing",
                "semantic interoperability"
            ]
        }
    },
    {
        "Title": "Category-Based Sentiment Analysis of Sindhi News Headlines Using Machine Learning, Deep Learning, and Transformer Models",
        "Link": "https://ieeexplore.ieee.org/document/11025811/",
        "Abstract": "The rapid growth of digital content has made sentiment analysis (SA) an essential tool for understanding public sentiment and classifying textual data. Despite significant progress in natural language processing (NLP), low-resource languages, particularly Sindhi, remain underexplored due to the lack of computational tools and annotated datasets. This study addresses this gap by introducing the Sindhi News Headlines Dataset (SNHD), a novel corpus annotated for both SA and category classification across eight categories: Crime, Economy, Entertainment, Health, Politics, Science & Technology, Social, and Sports. To evaluate the effectiveness of different machine learning (ML), deep learning (DL), and transformer-based approaches, we conduct a comparative analysis of various models on SA and category classification tasks. Furthermore, we leverage Explainable Artificial Intelligence (XAI) techniques, such as Local Interpretable Model-Agnostic Explanations (LIME), to gain insights into model decision-making. Experimental results show that traditional ML models outperform DL and transformer-based models on the SNHD dataset. Specifically, Support Vector Machines with Radial Basis Function (SVM-RBF) achieves the highest performance for SA (0.74 accuracy and weighted F-score), while the Ridge Classifier (RC) delivers the best results for category classification (0.84 accuracy and weighted F-score). Among transformer models, XLM-RoBERTa demonstrates strong performance in category classification (0.82 accuracy and weighted F-score). These findings establish a benchmark for future research in Sindhi NLP and highlight the potential of hybrid approaches in tackling challenges associated with low-resource languages. This work provides a foundational resource for NLP researchers seeking to advance computational methods for Sindhi and similar underrepresented languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3576853",
            "Date of Publication": "05 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Safdar Ali Soomro",
                "labs": [
                    "Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia",
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Siti Sophiayati Yuhaniz",
                "labs": [
                    "Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Mazhar Ali Dootio",
                "labs": [
                    "Razak Faculty of Technology and Informatics, Universiti Teknologi Malaysia, Kuala Lumpur, Malaysia",
                    "Department of Computer Science, Benazir Bhutto Shaheed University, Karachi, Pakistan"
                ]
            },
            {
                "name": "Ghulam Mujtaba",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Jawaid Ahmed Siddiqui",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Transformers",
                "Support vector machines",
                "Deep learning",
                "Sentiment analysis",
                "Natural language processing",
                "Feature extraction",
                "Biological system modeling",
                "Electronic mail",
                "Analytical models"
            ],
            "Author Keywords": [
                "Sindhi news headline",
                "news classification",
                "machine learning",
                "deep learning",
                "explainable AI"
            ]
        }
    },
    {
        "Title": "An Analysis on Semantic Interpretation of Tamil Literary Texts",
        "Link": "https://ieeexplore.ieee.org/document/10970463/",
        "Abstract": "The interaction between a computer and a human or natural language is known as Natural Language Processing (NLP). The ultimate goal is to make the natural language text understandable, which in turn, requires its meaning to be captured. Text can be analyzed on several levels, such as lexical, syntax, semantics, discourse, and pragmatics. These NLP tasks deal with text at different levels, such as word, phrase, sentence, paragraph, and document. Discourse analysis is a type of text analysis that goes beyond the sentence level. The discourse analysis is currently performed on expository (essay) type of texts. There are currently no state-of-the-art NLP applications that handle Tamil literary texts at a discourse level. Tamil classical literature is rich with ethical, moral, and philosophical values that should be explored for the benefit of society. This paper proposes an automatic semantic interpretation framework for Tamil literary texts using discourse parsing by giving works on discourse parsing, text classification, discourse-based clustering and information retrieval, and Tamil language and Tamil literatures. This semantic interpretation can be developed as a smart mobile application using multimedia components. This paper also discusses how the Tamil literary text processing differs from the essay type of text.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.1839",
            "Date of Publication": "May 2022",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Anita Ramalingam",
                "labs": [
                    "Department of Computer Science and Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India"
                ]
            },
            {
                "name": "Subalalitha Chinnaudayar Navaneethakrishnan",
                "labs": [
                    "Department of Computer Science and Engineering, SRM Institute of Science and Technology, Kattankulathur, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ethics",
                "Semantics",
                "Text categorization",
                "Syntactics",
                "Information retrieval",
                "Natural language processing",
                "Mobile applications",
                "Text processing",
                "Pragmatics"
            ],
            "Author Keywords": [
                "Discourse parsing",
                "tamil literature",
                "text classification",
                "discourse-based clustering",
                "information retrieval",
                "mobile application",
                "multimedia",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Evaluation of Sentiment Analysis in Finance: From Lexicons to Transformers",
        "Link": "https://ieeexplore.ieee.org/document/9142175/",
        "Abstract": "Financial and economic news is continuously monitored by financial market participants. According to the efficient market hypothesis, all past information is reflected in stock prices and new information is instantaneously absorbed in determining future stock prices. Hence, prompt extraction of positive or negative sentiments from news is very important for investment decision-making by traders, portfolio managers and investors. Sentiment analysis models can provide an efficient method for extracting actionable signals from the news. However, financial sentiment analysis is challenging due to domain-specific language and unavailability of large labeled datasets. General sentiment analysis models are ineffective when applied to specific domains such as finance. To overcome these challenges, we design an evaluation platform which we use to assess the effectiveness and performance of various sentiment analysis approaches, based on combinations of text representation methods and machine-learning classifiers. We perform more than one hundred experiments using publicly available datasets, labeled by financial experts. We start the evaluation with specific lexicons for sentiment analysis in finance and gradually build the study to include word and sentence encoders, up to the latest available NLP transformers. The results show improved efficiency of contextual embeddings in sentiment analysis compared to lexicons and fixed word and sentence encoders, even when large datasets are not available. Furthermore, distilled versions of NLP transformers produce comparable results to their larger teacher models, which makes them suitable for use in production environments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3009626",
            "Date of Publication": "16 July 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kostadin Mishev",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Ana Gjorgjevikj",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Irena Vodenska",
                "labs": [
                    "Financial Informatics Lab, Metropolitan College, Boston University, Boston, USA"
                ]
            },
            {
                "name": "Lubomir T. Chitkushev",
                "labs": [
                    "Financial Informatics Lab, Metropolitan College, Boston University, Boston, USA"
                ]
            },
            {
                "name": "Dimitar Trajanov",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Feature extraction",
                "Analytical models",
                "Machine learning",
                "Dictionaries",
                "Semantics"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "finance",
                "natural language processing",
                "text representations",
                "deep-learning",
                "encoders",
                "word embedding",
                "sentence embedding",
                "transfer-learning",
                "transformers",
                "survey"
            ]
        }
    },
    {
        "Title": "Feature Extraction and Analysis of Natural Language Processing for Deep Learning English Language",
        "Link": "https://ieeexplore.ieee.org/document/8999624/",
        "Abstract": "NLP (Natural Language Processing) is a technology that enables computers to understand human languages. Deep-level grammatical and semantic analysis usually uses words as the basic unit, and word segmentation is usually the primary task of NLP. In order to solve the practical problem of huge structural differences between different data modalities in a multi-modal environment and traditional machine learning methods cannot be directly applied, this paper introduces the feature extraction method of deep learning and applies the ideas of deep learning to multi-modal feature extraction. This paper proposes a multi-modal neural network. For each mode, there is a multilayer sub-neural network with an independent structure corresponding to it. It is used to convert the features in different modes to the same-modal features. In terms of word segmentation processing, in view of the problems that existing word segmentation methods can hardly guarantee long-term dependency of text semantics and long training prediction time, a hybrid network English word segmentation processing method is proposed. This method applies BI-GRU (Bidirectional Gated Recurrent Unit) to English word segmentation, and uses the CRF (Conditional Random Field) model to annotate sentences in sequence, effectively solving the long-distance dependency of text semantics, shortening network training and predicted time. Experiments show that the processing effect of this method on word segmentation is similar to that of BI-LSTM-CRF (Bidirectional- Long Short Term Memory-Conditional Random Field) model, but the average predicted processing speed is 1.94 times that of BI-LSTM-CRF, effectively improving the efficiency of word segmentation processing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2974101",
            "Date of Publication": "14 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dongyang Wang",
                "labs": [
                    "College of Education, Arts and Science, Lyceum of the Philippines University, Batangas City, Philippines"
                ]
            },
            {
                "name": "Junli Su",
                "labs": [
                    "Department of Elementary Education, Jiaozuo Teachers College, Jiaozuo, China"
                ]
            },
            {
                "name": "Hongbin Yu",
                "labs": [
                    "School of Digital Media, Jiangnan University, Wuxi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Natural language processing",
                "Computers",
                "Neural networks",
                "Machine learning",
                "Dictionaries",
                "Semantics"
            ],
            "Author Keywords": [
                "Feature extraction",
                "English word segmentation processing",
                "long short term memory",
                "gated recurrent unit"
            ]
        }
    },
    {
        "Title": "An Attack Detection Framework Based on BERT and Deep Learning",
        "Link": "https://ieeexplore.ieee.org/document/9804700/",
        "Abstract": "Deep Learning (DL) and Natural Language Processing (NLP) techniques are improving and enriching with a rapid pace. Furthermore, we witness that the use of web applications is increasing in almost every direction in parallel with the related technologies. Web applications encompass a wide array of use cases utilizing personal, financial, defense, and political information (e.g., wikileaks incident). Indeed, to access and to manipulate such information are among the primary goals of attackers. Thus, vulnerability of the information targeted by adversaries is a vital problem and if such information is captured then the consequences can be devastating, which can, potentially, become national security risks in the extreme cases. In this study, as a remedy to this problem, we propose a novel model that is capable of distinguishing normal HTTP requests and anomalous HTTP requests. Our model employs NLP techniques, Bidirectional Encoder Representations from Transformers (BERT) model, and DL techniques. Our experimental results reveal that the proposed approach achieves a success rate over 99.98% and an F1 score over 98.70% in the classification of anomalous and normal requests. Furthermore, web attack detection time of our model is significantly lower (i.e., 0.4 ms) than the other approaches presented in the literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3185748",
            "Date of Publication": "23 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yunus Emre Seyyar",
                "labs": [
                    "Department of Computer Engineering, Graduate School of Natural and Applied Sciences, Kırıkkale University, Kırıkkale, Turkey"
                ]
            },
            {
                "name": "Ali Gökhan Yavuz",
                "labs": [
                    "Department of Computer Engineering, Graduate School of Natural and Applied Sciences, Turkish-German University, Istanbul, Turkey"
                ]
            },
            {
                "name": "Halil Murat Ünver",
                "labs": [
                    "Department of Computer Engineering, Graduate School of Natural and Applied Sciences, Kırıkkale University, Kırıkkale, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Protocols",
                "Bit error rate",
                "Natural language processing",
                "Uniform resource locators",
                "Structured Query Language",
                "Firewalls (computing)",
                "Deep learning"
            ],
            "Author Keywords": [
                "Anomalous request",
                "BERT",
                "deep learning",
                "web attack",
                "multilayer perceptron",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "A Deep Learning Model Based on BERT and Sentence Transformer for Semantic Keyphrase Extraction on Big Social Data",
        "Link": "https://ieeexplore.ieee.org/document/9641788/",
        "Abstract": "In the evolution of the Internet, social media platform like Twitter has permitted the public user to share information such as famous current affairs, events, opinions, news, and experiences. Extracting and analyzing keyphrases in Twitter content is an essential and challenging task. Keyphrases can become precise the main contribution of Twitter content as well as it is a vital issue in vast Natural Language Processing (NLP) application. Extracting keyphrases is not only a time-consuming process but also requires much effort. The current works are on graph-based models or machine learning models. The performance of these models relies on feature extraction or statistical measures. In recent year, the application of deep learning algorithms to Twitter data have more insight due to automatic feature extraction can improve the performance of several tasks. This work aims to extract the keyphrase from Big social data using a sentence transformer with Bidirectional Encoder Representation Transformers (BERT) deep learning model. This BERT representation retains semantic and syntactic connectivity between tweets, enhancing performance in every NLP task on large data sets. It can automatically extract the most typical phrases in the Tweets. The proposed Semkey-BERT model shows that BERT with sentence transformer accuracy of 86% is higher than the other existing models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3133651",
            "Date of Publication": "07 December 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "R. Devika",
                "labs": [
                    "School of Computing, SASTRA Deemed University, Thanjavur, India"
                ]
            },
            {
                "name": "Subramaniyaswamy Vairavasundaram",
                "labs": [
                    "School of Computing, SASTRA Deemed University, Thanjavur, India"
                ]
            },
            {
                "name": "C. Sakthi Jay Mahenthar",
                "labs": [
                    "School of Computing, SASTRA Deemed University, Thanjavur, India"
                ]
            },
            {
                "name": "Vijayakumar Varadarajan",
                "labs": [
                    "School of Computer Science and Engineering, University of New South Wales, Sydney, Kensington, NSW, Australia"
                ]
            },
            {
                "name": "Ketan Kotecha",
                "labs": [
                    "Symbiosis Centre for Applied Artificial Intelligence, Symbiosis International (Deemed University), Lavale, Pune, Maharashtra, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Feature extraction",
                "Data mining",
                "Bit error rate",
                "Social networking (online)",
                "Task analysis",
                "Blogs"
            ],
            "Author Keywords": [
                "Attention layer",
                "BERT",
                "deep learning",
                "keyphrase extraction",
                "social data"
            ]
        }
    },
    {
        "Title": "Noise-Like Pulse Generation Using Polarization Maintaining Mode-Locked Thulium-Doped Fiber Laser With Nonlinear Amplifying Loop Mirror",
        "Link": "https://ieeexplore.ieee.org/document/8848480/",
        "Abstract": "Impact Statement:\nIn contrast to most papers we present a detailed analysis of NLP generation in the all-PM-fiber NALM-based mode-locked TDFL. The influence of pump power as well as differ...Show More\nWe investigate noise-like pulse (NLP) generation in a mode-locked thulium-doped fiber laser with nonlinear amplifying loop mirror (NALM) and different net anomalous dispersions. The all-polarization maintaining (PM) fiber oscillator generates pulse trains with a frequency adjustable in the range of 4.06–20.4 MHz by utilizing different lengths of PM passive fiber in the NALM loop. An NLP with a coherence spike width of 232 fs was generated at 1993.6 nm with a 3-dB spectral width of 32.6 nm when the net cavity dispersion was −0.711 ps2.",
        "Details": {
            "DOI": "10.1109/JPHOT.2019.2943709",
            "Date of Publication": "25 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "Maria Michalska",
                "labs": [
                    "Institute of Optoelectronics, Military University of Technology, Warsaw, Poland"
                ]
            },
            {
                "name": "Jacek Swiderski",
                "labs": [
                    "Institute of Optoelectronics, Military University of Technology, Warsaw, Poland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical fiber dispersion",
                "Fiber lasers",
                "Optical fiber polarization",
                "Laser mode locking",
                "Laser excitation",
                "Pump lasers",
                "Optical fiber sensors"
            ],
            "Author Keywords": [
                "Noise-like generation",
                "fiber laser",
                "thulium-doped fiber",
                "mode-locked laser",
                "NALM"
            ]
        }
    },
    {
        "Title": "A Superior Arabic Text Categorization Deep Model (SATCDM)",
        "Link": "https://ieeexplore.ieee.org/document/8976160/",
        "Abstract": "Categorizing Arabic text documents is considered an important research topic in the field of Natural Language Processing (NLP) and Machine Learning (ML). The number of Arabic documents is tremendously increasing daily as new web pages, news articles, social media contents are added. Hence, classifying such documents in specific classes is of high importance to many people and applications. Convolutional Neural Network (CNN) is a class of deep learning that has been shown to be useful for many NLP tasks, including text translation and text categorization for the English language. Word embedding is a text representation currently used to represent text terms as real-valued vectors in vector space that represent both syntactic and semantic traits of text. Current research studies in classifying Arabic text documents use traditional text representation such as bag-of-words and TF-IDF weighting, but few use word embedding. Traditional ML algorithms have already been used in Arabic text categorization, and good results are achieved. In this study, we present a Multi-Kernel CNN model for classifying Arabic news documents enriched with n-gram word embedding, which we call A Superior Arabic Text Categorization Deep Model (SATCDM). The proposed solution achieves very high accuracy compared to current research in Arabic text categorization using 15 of freely available datasets. The model achieves an accuracy ranging from 97.58% to 99.90%, which is superior to similar studies on the Arabic document classification task.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2970504",
            "Date of Publication": "30 January 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. Alhawarat",
                "labs": [
                    "Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmad O. Aseeri",
                "labs": [
                    "Department of Computer Science, College of Computer Engineering and Sciences, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Natural language processing",
                "Text categorization",
                "Classification algorithms",
                "Convolutional neural networks",
                "Task analysis",
                "Support vector machines"
            ],
            "Author Keywords": [
                "Documents classification",
                "deep learning",
                "Arabic language",
                "convolutional neural networks",
                "word embedding",
                "skip-gram",
                "word2vec"
            ]
        }
    },
    {
        "Title": "Two End-to-End Quantum-Inspired Deep Neural Networks for Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9627527/",
        "Abstract": "In linguistics, the uncertainty of context due to polysemy is widespread, which attracts much attention. Quantum-inspired complex word embedding based on Hilbert space plays an important role in natural language processing (NLP), which fully leverages the similarity between quantum states and word tokens. A word containing multiple meanings could correspond to a single quantum particle which may exist in several possible states, and a sentence could be analogous to the quantum system where particles interfere with each other. Motivated by quantum-inspired complex word embedding, interpretable complex-valued word embedding (ICWE) is proposed to design two end-to-end quantum-inspired deep neural networks (ICWE-QNN and CICWE-QNN representing convolutional complex-valued neural network based on ICWE) for binary text classification. They have the proven feasibility and effectiveness in the application of NLP and can solve the problem of text information loss in CE-Mix [1] model caused by neglecting the important linguistic features of text, since linguistic feature extraction is presented in our model with deep learning algorithms, in which gated recurrent unit (GRU) extracts the sequence information of sentences, attention mechanism makes the model focus on important words in sentences and convolutional layer captures the local features of projected matrix. The model ICWE-QNN can avoid random combination of word tokens and CICWE-QNN fully considers textual features of the projected matrix. Experiments conducted on five benchmarking classification datasets demonstrate our proposed models have higher accuracy than the compared traditional models including CaptionRep BOW, DictRep BOW and Paragram-Phrase, and they also have great performance on F1-score. Eespecially, CICWE-QNN model has higher accuracy than the quantum-inspired model CE-Mix as well for four datasets including SST, SUBJ, CR and MPQA. It is a meaningful and effictive exploration to design quantum-inspired deep neural networks to promote the performance of text classification.\nShow Less",
        "Details": {
            "DOI": "10.1109/TKDE.2021.3130598",
            "Date of Publication": "25 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Knowledge and Data Engineering"
        },
        "issn_info": {
            "Print ISSN": "1041-4347",
            "Electronic ISSN": "1558-2191"
        },
        "authors_data": [
            {
                "name": "Jinjing Shi",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Zhenhuan Li",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Wei Lai",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Fangfang Li",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Ronghua Shi",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            },
            {
                "name": "Yanyan Feng",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China",
                    "College of Computer and Information Engineering, Central South University of Forestry and Technology, Changsha, China"
                ]
            },
            {
                "name": "Shichao Zhang",
                "labs": [
                    "School of Computer Science and Engineering, Central South University, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Quantum mechanics",
                "Feature extraction",
                "Deep learning",
                "Task analysis",
                "Natural language processing",
                "Linguistics",
                "Springs"
            ],
            "Author Keywords": [
                "Complex-valued word embedding",
                "text classification",
                "deep neural network",
                "deep learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "BERT-Based Chinese Relation Extraction for Public Security",
        "Link": "https://ieeexplore.ieee.org/document/9119385/",
        "Abstract": "The past few years have witnessed some public safety incidents occurring around the world. With the advent of the big data era, effectively extracting public security information from the internet has become of great significance. Up to hundreds of TBs of data are injected into the network every second, and thus it is impossible to process them manually. Natural Language Processing (NLP) is dedicated to the development of an intelligent system for effective text information mining. By analysing the text and quickly extracting the relationships between the relevant entities, NLP can establish the knowledge graph (KG) of public security, which lays the foundation for safety case analysis, information monitoring, and activity tracking and locating. One of the current pre-training relation extraction models is the Word2Vec model. The Word2vec model is single mapped, and it produces a static, single representation of the words in sentences. Then, the BERT model considers contextual information and provides more dynamic, richer vector representations of generated words. Therefore, in this paper, we propose a Bidirectional Encoder Representation from Transformers (BERT) based on the Chinese relation extraction algorithm for public security, which can effectively mine security information. The BERT model is obtained by training the Masked Language Model and predicting the next sentence task, which is based on the Transformer Encoder and the main model structure is the stacked Transformers. Extensive simulations are conducted to evaluate our proposed algorithm in comparison to some state-of-the-art schemes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3002863",
            "Date of Publication": "17 June 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiaqi Hou",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Xin Li",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Haipeng Yao",
                "labs": [
                    "School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Haichun Sun",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Tianle Mai",
                "labs": [
                    "School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Rongchen Zhu",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Feature extraction",
                "Security",
                "Task analysis",
                "Training",
                "Semantics",
                "Data mining"
            ],
            "Author Keywords": [
                "BERT",
                "relationship extraction",
                "public security",
                "MaxPooler",
                "ReLU"
            ]
        }
    },
    {
        "Title": "Passively Mode-Locked Fiber Lasers Based on Nonlinearity at 2-μm Band",
        "Link": "https://ieeexplore.ieee.org/document/8219388/",
        "Abstract": "2-μm fiber lasers are of wide potential applications in the fields of radar, sensing, and free-space communications. We introduced a simple approach to generate passively mode-locked pulse in thulium-doped fiber lasers based on nonlinear polarization rotation (NPR) in our previous work. The high repetition rate of 1.78 GHz is obtained by both NPR and semiconductor saturable absorption mirror. By using a polarization-maintaining fiber in the experiment, a birefringence Lyot filter as a fiber comb filter can be constructed, and then the tuning range of 94 nm can be obtained for the mode-locked laser. In this paper, we also demonstrated our recent research work, a square-wave mode-locked fiber laser at 2-μm band based on nonlinear amplifying loop mirror. The square-wave noiselike pulse (NLP) at longer wavelength of 2-μ m band can be observed. With the increase of the pump power, pulse width can be increased from 0.75 to 1.3 ns. The polarization vector characteristics of the square-wave NLP were analyzed experimentally. In addition, with the increase of the pump power, a kind of square-wave mode-locked pulse with low-intensity multipulse bunches can be observed, and these multipulse bunches can be operated at the multipulse mode-locked state. The side-mode suppression ratio decreased from 50 to 30 dB.",
        "Details": {
            "DOI": "10.1109/JSTQE.2017.2783047",
            "Date of Publication": "18 December 2017",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Selected Topics in Quantum Electronics"
        },
        "issn_info": {
            "Print ISSN": "1077-260X",
            "Electronic ISSN": "1558-4542"
        },
        "authors_data": [
            {
                "name": "Tianshu Wang",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, China"
                ]
            },
            {
                "name": "Wanzhuo Ma",
                "labs": [
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, China"
                ]
            },
            {
                "name": "Qingsong Jia",
                "labs": [
                    "College of Opto-Electronic Engineering, Changchun University of Science and Technology, Changchun, China"
                ]
            },
            {
                "name": "Qingchao Su",
                "labs": [
                    "College of Science, Changchun University of Science and Technology, Changchun, China"
                ]
            },
            {
                "name": "Peng Liu",
                "labs": [
                    "College of Science, Changchun University of Science and Technology, Changchun, China"
                ]
            },
            {
                "name": "Peng Zhang",
                "labs": [
                    "National and Local Joint Engineering Research Center of Space Optoelectronics Technology, Changchun University of Science and Technology, Changchun, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Laser mode locking",
                "Optical fiber polarization",
                "Fiber lasers",
                "Optical fiber dispersion",
                "Optical fiber communication",
                "Pump lasers",
                "Cavity resonators"
            ],
            "Author Keywords": [
                "Fiber laser",
                "2 μm band",
                "mode-locking",
                "nonlinear polarization rotation",
                "nonlinear amplifying loop mirror"
            ]
        }
    },
    {
        "Title": "Classical Arabic Named Entity Recognition Using Variant Deep Neural Network Architectures and BERT",
        "Link": "https://ieeexplore.ieee.org/document/9464352/",
        "Abstract": "Recurrent Neural Networks (RNNs) and transformers are deep learning models that have achieved remarkable success in several Natural Language Processing (NLP) tasks since they do not rely on handcrafted features nor enormous knowledge resources. Named Entity Recognition (NER) is an essential NLP task that is used in many applications such as information retrieval, question answering, and machine translation. NER aims to locate, extract, and classify named entities into predefined categories such as person, organization and location. Arabic NER is considered a challenging task because of the complexity and the unique characteristics of Arabic. Most of the previous research on deep learning based-Arabic NER focused on Modern Standard Arabic and Dialectal Arabic, which are different variations from Classical Arabic. In this paper, we investigate deep learning-based Classical Arabic NER using different deep neural network architectures and a BERT based contextual language model that is trained on general domain Arabic text. We propose two RNN-based models by fine-tunning the pretrained BERT language model to recognize and classify named entities from Classical Arabic. The pre-trained BERT contextual language model representations were used as input features to a BGRU/BLSTM model and were fine-tuned using a Classical Arabic NER dataset. In addition, we explore variant architectures of the proposed BERT-BGRU/BLSTM-CRF models. Experimentations showed that the BERT-BGRU-CRF model outperformed the other models by achieving an F-measure of 94.76% on the CANERCorpus. To the best of our knowledge, this is the first work that aims to recognize named entities in Classical Arabic using deep learning.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3092261",
            "Date of Publication": "24 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Norah Alsaaran",
                "labs": [
                    "Computer Science Department, Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Maha Alrabiah",
                "labs": [
                    "Computer Science Department, Imam Muhammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Deep learning",
                "Context modeling",
                "Natural language processing",
                "Transfer learning",
                "Feature extraction"
            ],
            "Author Keywords": [
                "NER",
                "named entity recognition",
                "classical arabic",
                "BGRU",
                "BLSTM",
                "BERT",
                "CRF",
                "deep learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Challenges and Issues in Sentiment Analysis: A Comprehensive Survey",
        "Link": "https://ieeexplore.ieee.org/document/10176115/",
        "Abstract": "Sentiment analysis, a specialization of natural language processing (NLP), has witnessed significant progress since its emergence in the late 1990s, owing to the swift advances in deep learning techniques and the abundance of vast digital datasets. Though sentiment analysis has reached a relatively advanced stage in the area of NLP, it is erroneously assumed that sentiment analysis has reached its pinnacle, leaving no room for further improvement. However, it is important to acknowledge that numerous challenges that require attention persist. This survey paper provides a comprehensive overview of sentiment analysis, including its applications, approaches to sentiment classification, and commonly used evaluation metrics. The survey primarily focuses on the challenges associated with different types of data for sentiment classification, namely cross-domain data, multimodal data, cross-lingual data, and small-scale data, and provides a review of the state-of-the-art in sentiment analysis to address these challenges. The paper also addresses the challenges faced during sentiment classification irrespective of the type of data available. It aims at a better understanding of sentiment analysis to enable practitioners and researchers select suitable methods for sentiment classification depending on the type of data being analyzed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3293041",
            "Date of Publication": "07 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nilaa Raghunathan",
                "labs": [
                    "Department of Computer Science, Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "Kandasamy Saravanakumar",
                "labs": [
                    "Department of Computer Science, Vellore Institute of Technology, Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Surveys",
                "Social networking (online)",
                "Natural language processing",
                "Deep learning",
                "Supervised learning",
                "Stock markets"
            ],
            "Author Keywords": [
                "Machine learning",
                "sentiment analysis",
                "natural language processing",
                "cross-domain data",
                "multimodal data",
                "cross-lingual data",
                "small-scale data"
            ]
        }
    },
    {
        "Title": "Semantic Similarity Computing Model Based on Multi Model Fine-Grained Nonlinear Fusion",
        "Link": "https://ieeexplore.ieee.org/document/9314168/",
        "Abstract": "Natural language processing (NLP) task has achieved excellent performance in many fields, including semantic understanding, automatic summarization, image recognition and so on. However, most of the neural network models for NLP extract the text in a fine-grained way, which is not conducive to grasp the meaning of the text from a global perspective. To alleviate the problem, the combination of the traditional statistical method and deep learning model as well as a novel model based on multi model nonlinear fusion are proposed in this paper. The model uses the Jaccard coefficient based on part of speech, Term Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm to measure the similarity of sentences respectively. According to the calculation accuracy of each model, the normalized weight coefficient is obtained and the calculation results are compared. The weighted vector is input into the fully connected neural network to give the final classification results. As a result, the statistical sentence similarity evaluation algorithm reduces the granularity of feature extraction, so it can grasp the sentence features globally. Experimental results show that the matching of sentence similarity calculation method based on multi model nonlinear fusion is 84%, and the F1 value of the model is 75%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3049378",
            "Date of Publication": "05 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Peiying Zhang",
                "labs": [
                    "College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China"
                ]
            },
            {
                "name": "Xingzhe Huang",
                "labs": [
                    "College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China"
                ]
            },
            {
                "name": "Yaqi Wang",
                "labs": [
                    "College of Computer Science and Technology, China University of Petroleum (East China), Qingdao, China"
                ]
            },
            {
                "name": "Chunxiao Jiang",
                "labs": [
                    "Beijing National Research Center for Information Science and Technology, Tsinghua University, Beijing, China",
                    "Tsinghua Space Center, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Shuqing He",
                "labs": [
                    "College of Computer Science and Engineering, Linyi University, Linyi, China"
                ]
            },
            {
                "name": "Haifeng Wang",
                "labs": [
                    "College of Computer Science and Engineering, Linyi University, Linyi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Semantics",
                "Computational modeling",
                "Neural networks",
                "Task analysis",
                "Statistical analysis",
                "Deep learning"
            ],
            "Author Keywords": [
                "Coarse grained",
                "convolution neural network",
                "attention mechanism",
                "statistical method",
                "multi model fusion"
            ]
        }
    },
    {
        "Title": "A Predictive Text System for Medical Recommendations in Telemedicine: A Deep Learning Approach in the Arabic Context",
        "Link": "https://ieeexplore.ieee.org/document/9448234/",
        "Abstract": "We are currently witnessing an immense proliferation of natural language processing (NLP) applications. Natural language generation (NLG) has emerged from NLP and is now commonly utilized in various applications, including chatting applications. The objective of this paper is to propose a deep learning-based language generation model that simplifies the process of writing medical recommendations for doctors in an Arabic context, to improve service satisfaction and patient-doctor interactions. The developed language generation model is a predictive text system intended for next word prediction in a telemedicine service. Altibbi-a digital platform for telemedicine and teleconsultations services in the Middle East and the North Africa (MENA) region-was utilized as a case study for the textual prediction process. The proposed model was trained using data obtained from Altibbi databases related to medical recommendations, particularly gynecology, dermatology, psychiatric diseases, urology, and internist diseases. Variants of deep learning models were implemented and optimized for next word prediction, based on the unidirectional and bidirectional long short-term memory (LSTM and BiLSTM), the one-dimensional convolutional neural network (CONV1D), and a combination of LSTM and CONV1D (LSTM-CONV1D). The algorithms were trained using two versions of the datasets (i.e., 3-gram and 4-gram representations) and evaluated in terms of their training accuracy and loss, validation accuracy and loss, and testing accuracy per their matching scores. The proposed models' performances were comparable. CONV1D produced the most promising matching score.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3087593",
            "Date of Publication": "08 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maria Habib",
                "labs": []
            },
            {
                "name": "Mohammad Faris",
                "labs": []
            },
            {
                "name": "Raneem Qaddoura",
                "labs": [
                    "Philadelphia University, Amman, Jordan"
                ]
            },
            {
                "name": "Alaa Alomari",
                "labs": []
            },
            {
                "name": "Hossam Faris",
                "labs": [
                    "King Abdullah II School of Information Technology, The University of Jordan, Amman, Jordan",
                    "School of Computing and Informatics, Al Hussein Technical University, Amman, Jordan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biomedical imaging",
                "Medical services",
                "Deep learning",
                "Predictive models",
                "Telemedicine",
                "Data models",
                "Training"
            ],
            "Author Keywords": [
                "Altibbi",
                "natural language processing",
                "deep learning",
                "telemedicine",
                "Arabic",
                "predictive text"
            ]
        }
    },
    {
        "Title": "Predicting CVSS Metric via Description Interpretation",
        "Link": "https://ieeexplore.ieee.org/document/9786831/",
        "Abstract": "Cybercrime affects companies worldwide, costing millions of dollars annually. The constant increase of threats and vulnerabilities raises the need to handle vulnerabilities in a prioritized manner. This prioritization can be achieved through Common Vulnerability Scoring System (CVSS), typically used to assign a score to a vulnerability. However, there is a temporal mismatch between the vulnerability finding and score assignment, which motivates the development of approaches to aid in this aspect. We explore the use of Natural Language Processing (NLP) models in CVSS score prediction given vulnerability descriptions. We start by creating a vulnerability dataset from the National Vulnerability Database (NVD). Then, we combine text pre-processing and vocabulary addition to improve the model accuracy and interpret its prediction reasoning by assessing word importance, via Shapley values. Experiments show that the combination of Lemmatization and 5,000-word addition is optimal for DistilBERT, the outperforming model in our experiments of the NLP methods, achieving state-of-the-art results. Furthermore, specific events (such as an attack on a known software) tend to influence model prediction, which may hinder CVSS prediction. Combining Lemmatization with vocabulary addition mitigates this effect, contributing to increased accuracy. Finally, binary classes benefit the most from pre-processing techniques, particularly when one class is much more prominent than the other. Our work demonstrates that DistilBERT is a state-of-the-art model for CVSS prediction, demonstrating the applicability of deep learning approaches to aid in vulnerability handling. The code and data are available at https://github.com/Joana-Cabral/CVSS_Prediction.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3179692",
            "Date of Publication": "02 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Joana Cabral Costa",
                "labs": [
                    "Department of Computer Science, Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal"
                ]
            },
            {
                "name": "Tiago Roxo",
                "labs": [
                    "Department of Computer Science, Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal"
                ]
            },
            {
                "name": "João B. F. Sequeiros",
                "labs": [
                    "Department of Computer Science, Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal"
                ]
            },
            {
                "name": "Hugo Proenca",
                "labs": [
                    "Department of Computer Science, Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal"
                ]
            },
            {
                "name": "Pedro R. M. INÁCIO",
                "labs": [
                    "Department of Computer Science, Instituto de Telecomunicações, University of Beira Interior, Covilhã, Portugal"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Predictive models",
                "Bit error rate",
                "Security",
                "Vocabulary",
                "Deep learning",
                "Correlation"
            ],
            "Author Keywords": [
                "Common vulnerability scoring system",
                "deep learning",
                "interpretability",
                "natural language processing",
                "security"
            ]
        }
    },
    {
        "Title": "Stories That Big Danmaku Data Can Tell as a New Media",
        "Link": "https://ieeexplore.ieee.org/document/8681067/",
        "Abstract": "In online video communities, an emerging source of comment, such as danmaku, allows viewers to interact when watching. Prior work discussed the feasibility of application using danmaku, while the comprehensive analysis of large-scale data is vacant to be filled in. We here release our danmaku data collection and report interesting observed phenomena in the danmaku comments. This analysis reveals the temporal distributions and user's access patterns of online time-sync comments. In particular, we distribute two novel natural language processing (NLP) tasks based on our danmaku dataset and provide baseline models. In the first task, we show how the naive models predict positive or negative sentiment given a danmaku comment, which effectively extends the real applications such as opinion poll prediction and marketing investigation. In the second task, we propose to use the NLP summarization model to make video tagging and summarization. The experimental results suggest that danmaku can not only support deeper and richer interactions between viewers and videos but also with high research value.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2909054",
            "Date of Publication": "03 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qingchun Bai",
                "labs": [
                    "School of Computer Science and Software Engineering, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Qinmin Vivian Hu",
                "labs": [
                    "Department of Computer Science, Ryerson University, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Linhui Ge",
                "labs": []
            },
            {
                "name": "Liang He",
                "labs": [
                    "School of Computer Science and Software Engineering, East China Normal University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tagging",
                "Natural language processing",
                "Task analysis",
                "Synchronization",
                "Media",
                "Data mining",
                "TV"
            ],
            "Author Keywords": [
                "Danmaku",
                "HCI",
                "big danmaku data",
                "text tagging",
                "sentiment analysis",
                "summarization"
            ]
        }
    },
    {
        "Title": "Shortcut Learning Explanations for Deep Natural Language Processing: A Survey on Dataset Biases",
        "Link": "https://ieeexplore.ieee.org/document/10416838/",
        "Abstract": "The introduction of pre-trained large language models (LLMs) has transformed NLP by fine-tuning task-specific datasets, enabling notable advancements in news classification, language translation, and sentiment analysis. This has revolutionized the field, driving remarkable breakthroughs and progress. However, the growing recognition of bias in textual data has emerged as a critical focus in the NLP community, revealing the inherent limitations of models trained on specific datasets. LLMs exploit these dataset biases and artifacts as expedient shortcuts for prediction. The reliance of LLMs on dataset bias and artifacts as shortcuts for prediction has hindered their generalizability and adversarial robustness. Addressing this issue is crucial to enhance the reliability and resilience of LLMs in various contexts. This survey provides a comprehensive overview of the rapidly growing body of research on shortcut learning in language models, classifying the research into four main areas: the factors of shortcut learning, the origin of bias, the detection methods of dataset biases, and understanding mitigation strategies to address data biases. The goal of this study is to offer a contextualized, in-depth look at the state of learning models, highlighting the major areas of attention and suggesting possible directions for further research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3360306",
            "Date of Publication": "30 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Varun Dogra",
                "labs": [
                    "School of Computer Science and Engineering, Lovely Professional University, Phagwara, Punjab, India"
                ]
            },
            {
                "name": "Sahil Verma",
                "labs": [
                    "Uttaranchal University, Dehradun, India"
                ]
            },
            {
                "name": "Kavita",
                "labs": [
                    "Uttaranchal University, Dehradun, India"
                ]
            },
            {
                "name": "Marcin Woźniak",
                "labs": [
                    "Faculty of Applied Mathematics, Silesian University of Technology, Gliwice, Poland"
                ]
            },
            {
                "name": "Jana Shafi",
                "labs": [
                    "Department of Computer Engineering and Information, College of Engineering in Wadi Alddawasir, Prince Sattam Bin Abdulaziz University, Wadi Alddawasir, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Fazal Ijaz",
                "labs": [
                    "School of IT and Engineering, Melbourne Institute of Technology, Melbourne, VIC, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Task analysis",
                "Predictive models",
                "Training",
                "Machine learning",
                "Data models",
                "Behavioral sciences",
                "Transfer learning"
            ],
            "Author Keywords": [
                "Dataset biases",
                "deep learning",
                "natural language processing",
                "shortcut learning",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "Entity Extraction of Electrical Equipment Malfunction Text by a Hybrid Natural Language Processing Algorithm",
        "Link": "https://ieeexplore.ieee.org/document/9367224/",
        "Abstract": "Many electrical equipment malfunction text messages are collected during power system operation and maintenance procedures. These texts usually contain crucial information for maintenance and condition monitoring. Because these power system malfunction texts are characterized by multidomain vocabularies, complex-syntactic structures, and long sentences, it is challenging to for automated systems to capture their semantic meaning and essential information. To address this issue, we propose a hybrid natural language processing (hybrid-NLP) algorithm to extract entities that represent electrical equipment. This algorithm is composed of a dictionary-based method, a language technology platform (LTP) tool, and the bidirectional encoder representations from a transformers-conditional random field (BERT-CRF) model. Significantly, the softmax output layer of the bidirectional encoder representations from the transformers (BERT) model is replaced by the conditional random field (CRF) algorithm to strengthen the contextual relationships between words and thus solve the local optimization of the preferred word label. The effectiveness of the proposed hybrid-NLP method is verified on a realistic dataset. Moreover, a statistical analysis is conducted to provide a reference for the operation and maintenance of power systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3063354",
            "Date of Publication": "02 March 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhe Kong",
                "labs": [
                    "School of Automation, Wuhan University of Technology, Wuhan, China"
                ]
            },
            {
                "name": "Changxi Yue",
                "labs": [
                    "China Electric Power Research Institute, Wuhan, China"
                ]
            },
            {
                "name": "Ying Shi",
                "labs": [
                    "School of Automation, Wuhan University of Technology, Wuhan, China"
                ]
            },
            {
                "name": "Jicheng Yu",
                "labs": [
                    "China Electric Power Research Institute, Wuhan, China"
                ]
            },
            {
                "name": "Changjun Xie",
                "labs": [
                    "School of Automation, Wuhan University of Technology, Wuhan, China"
                ]
            },
            {
                "name": "Lingyun Xie",
                "labs": [
                    "Fiftieth Research Institute, China Electronic Technology Group Corporation, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Power systems",
                "Dictionaries",
                "Maintenance engineering",
                "Data mining",
                "Natural language processing",
                "Tools",
                "Substations"
            ],
            "Author Keywords": [
                "Electrical equipment malfunction text",
                "natural language processing",
                "entity extraction",
                "BERT-CRF model"
            ]
        }
    },
    {
        "Title": "Toward Practical Usage of the Attention Mechanism as a Tool for Interpretability",
        "Link": "https://ieeexplore.ieee.org/document/9762294/",
        "Abstract": "Natural language processing (NLP) has been one of the subfields of artificial intelligence much affected by the recent neural revolution. Architectures such as recurrent neural networks (RNNs) and attention-based transformers helped propel the state of the art across various NLP tasks, such as sequence classification, machine translation, and natural language inference. However, if neural models are to be used in high-stakes decision making scenarios, the explainability of their decisions becomes a paramount issue. The attention mechanism has offered some transparency in the workings of otherwise black-box RNN models: attention weights (scalar values assigned input words) invite to be interpreted as the importance of that word, providing a simple method of interpretability. Recent work, however, has questioned the faithfulness of this practice. Subsequent experiments have shown that faithfulness of attention weights may still be achieved by incorporating word-level objectives in the training process of neural networks. In this article, we present a study that extends the techniques for improving faithfulness of attention based on regularization methods that promote retention of word-level information. We perform extensive experiments on a wide array of recurrent neural architectures and analyze to what extent the explanations provided by inspecting attention weights are correlated with the human notion of importance. We find that incorporating tying regularization consistently improves both the faithfulness (−0.14 F1, +0.07 Brier, on average) and plausibility (\n+53.6%\nattention mass on salient tokens) of explanations obtained through inspecting attention weights across analyzed datasets and models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3169772",
            "Date of Publication": "22 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Martin Tutek",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Jan Šnajder",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Artificial intelligence",
                "Recurrent neural networks",
                "Natural language processing",
                "Predictive models",
                "Training data"
            ],
            "Author Keywords": [
                "Natural language processing",
                "explainable AI",
                "interpretability",
                "LSTM",
                "GRU",
                "recurrent neural network"
            ]
        }
    },
    {
        "Title": "QoS Guaranteed Resource Allocation for Live Virtual Machine Migration in Edge Clouds",
        "Link": "https://ieeexplore.ieee.org/document/9075172/",
        "Abstract": "Live Virtual Machine (VM) migration among geographically distributed edge clouds is an important strategy for providing low latency and reliable services for mobile end users. VM migration among edge clouds is more challenging than that in cloud computing, because the network bandwidth among edge clouds is more constrained than the cloud data center networks. In this paper, we study the bandwidth allocation among multiple concurrent live VM migrations in edge clouds. This problem is novel in that existing works aim to reduce the migration time for a single live VM migration among the edge clouds, and also ignores the QoS requirement for the service running on the VM in migration. However, our problem considers multiple VM migration tasks, and aims to maximize the average QoS while meeting the migration time constraint for each VM migration task. We formulate the problem as a Non-Linear Programming (NLP) problem which is also shown to be NP-Hard. We develop a new method to solve this problem. In our approach, we first transfer the problem into a Linear Programming (LP) problem by reducing the solution space. Taking the output from the LP solver as an initial solution, we then develop a heuristic to adjust it in order to find a better one to the original NLP problem. Finally, we design a set of evolutionary algorithms to select the optimal initial solution from the LP solver. Extensive simulations show that our proposed method can achieve good QoS and also has a fast convergence speed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2989154",
            "Date of Publication": "21 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lei Yang",
                "labs": [
                    "School of Software Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Doudou Yang",
                "labs": [
                    "School of Software Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Jiannong Cao",
                "labs": [
                    "Department of Computing, The Hong Kong Polytechnic University, Hong Kong"
                ]
            },
            {
                "name": "Yuvraj Sahni",
                "labs": [
                    "Department of Computing, The Hong Kong Polytechnic University, Hong Kong"
                ]
            },
            {
                "name": "Xiaohua Xu",
                "labs": [
                    "Department of Computer Science, Kennesaw State University, Kennesaw, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cloud computing",
                "Quality of service",
                "Task analysis",
                "Bandwidth",
                "Virtual machining",
                "Resource management",
                "Data centers"
            ],
            "Author Keywords": [
                "Edge cloud",
                "live VM migration",
                "QoS",
                "resource allocation"
            ]
        }
    },
    {
        "Title": "Deep Learning for Latent Events Forecasting in Content Caching Networks",
        "Link": "https://ieeexplore.ieee.org/document/9494281/",
        "Abstract": "A novel Twitter context aided content caching (TAC) framework is proposed for enhancing the caching efficiency by taking advantage of the legibility and massive volume of Twitter data. For the purpose of promoting the caching efficiency, three machine learning models are proposed to predict latent events and events popularity, utilizing collected Twitter data with geo-tags and geographic information of the adjacent base stations (BSs). Firstly, we propose a latent Dirichlet allocation (LDA) model for latent events forecasting because of the superiority of LDA model in natural language processing (NLP). Then, we conceive long short-term memory (LSTM) with skip-gram embedding approach and LSTM with continuous skip-gram-Geo-aware embedding approach for the events popularity forecasting. Furthermore, we associate the predict latent events and the popularity of the events with the caching strategy. Lastly, we propose a non-orthogonal multiple access (NOMA) based content transmission scheme. Extensive practical experiments demonstrate that: 1) the proposed TAC framework outperforms conventional caching framework and is capable of being employed in practical applications thanks to the associating ability with public interests; 2) the proposed LDA approach conserves superiority for natural language processing (NLP) in Twitter data; 3) the perplexity of the proposed skip-gram based LSTM is lower compared with conventional LDA approach; and 4) evaluation of the model demonstrates that the hit rates of tweets of the model vary from 50% to 65% and the hit rate of the caching contents is up to approximately 75% with smaller caching space compared to conventional algorithms. Simulation results also shows that the proposed NOMA-enabled caching scheme outperforms conventional least frequently used (LFU) scheme by 25%.",
        "Details": {
            "DOI": "10.1109/TWC.2021.3096747",
            "Date of Publication": "26 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Wireless Communications"
        },
        "issn_info": {
            "Print ISSN": "1536-1276",
            "Electronic ISSN": "1558-2248"
        },
        "authors_data": [
            {
                "name": "Zhong Yang",
                "labs": [
                    "School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K."
                ]
            },
            {
                "name": "Yuanwei Liu",
                "labs": [
                    "School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K."
                ]
            },
            {
                "name": "Yue Chen",
                "labs": [
                    "School of Electronic Engineering and Computer Science, Queen Mary University of London, London, U.K."
                ]
            },
            {
                "name": "Joey Tianyi Zhou",
                "labs": [
                    "Agency for Science Technology and Research (A*STAR), Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Wireless communication",
                "Blogs",
                "Data models",
                "Natural language processing",
                "Media",
                "Wireless networks"
            ],
            "Author Keywords": [
                "Machine learning (ML)",
                "supervised learning",
                "neural networks",
                "edge computing"
            ]
        }
    },
    {
        "Title": "LETS: A Label-Efficient Training Scheme for Aspect-Based Sentiment Analysis by Using a Pre-Trained Language Model",
        "Link": "https://ieeexplore.ieee.org/document/9503416/",
        "Abstract": "Recently proposed pre-trained language models can be easily fine-tuned to a wide range of downstream tasks. However, a large-scale labelled task-specific dataset is required for fine-tuning creating a bottleneck in the development process of machine learning applications. To foster a fast development by reducing manual labelling efforts, we propose a Label-Efficient Training Scheme (LETS). The proposed LETS consists of three elements: (i) task-specific pre-training to exploit unlabelled task-specific corpus data, (ii) label augmentation to maximise the utility of labelled data, and (iii) active learning to label data strategically. In this paper, we apply LETS to a novel aspect-based sentiment analysis (ABSA) use-case for analysing the reviews of the health-related program supporting people to improve their sleep quality. We validate the proposed LETS on a custom health-related program-reviews dataset and another ABSA benchmark dataset. Experimental results show that the LETS can reduce manual labelling efforts 2-3 times compared to labelling with random sampling on both datasets. The LETS also outperforms other state-of-the-art active learning methods. Furthermore, the experimental results show that LETS can contribute to better generalisability with both datasets compared to other methods thanks to the task-specific pre-training and the proposed label augmentation. We expect this work could contribute to the natural language processing (NLP) domain by addressing the issue of the high cost of manually labelling data. Also, our work could contribute to the healthcare domain by introducing a new potential application of NLP techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3101867",
            "Date of Publication": "02 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Heereen Shim",
                "labs": [
                    "Department of Electrical Engineering (ESAT), eMedia Research Laboratory and STADIUS, KU Leuven, Leuven, Belgium",
                    "Philip Research, Eindhoven, AE, The Netherlands"
                ]
            },
            {
                "name": "Dietwig Lowet",
                "labs": [
                    "Philip Research, Eindhoven, AE, The Netherlands"
                ]
            },
            {
                "name": "Stijn Luca",
                "labs": [
                    "Department of Data Analysis and Mathematical Modelling, Ghent University, Ghent, Belgium"
                ]
            },
            {
                "name": "Bart Vanrumste",
                "labs": [
                    "Department of Electrical Engineering (ESAT), eMedia Research Laboratory and STADIUS, KU Leuven, Leuven, Belgium"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Labeling",
                "Uncertainty",
                "Sentiment analysis",
                "Natural language processing",
                "Data models",
                "Training"
            ],
            "Author Keywords": [
                "Active learning",
                "machine learning",
                "natural language processing",
                "neural networks",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Collaboratively Modeling and Embedding of Latent Topics for Short Texts",
        "Link": "https://ieeexplore.ieee.org/document/9102242/",
        "Abstract": "Deriving a successful document representation is the critical challenge in many downstream tasks in NLP, especially when documents are very short. It is challenging to handle the sparsity and the noise problems confronting short texts. Some approaches employ latent topic models, based on global word co-occurrence, to obtain topic distribution as the representation. Others leverage word embeddings, which consider local conditional dependencies, to map a document as a summation vector of them. Unlike the existing works which explore the strategy of utilizing one to help the other, i.e., topic models for word embeddings or vice versa, we propose CME-DMM, a collaboratively modeling and embedding framework for capturing coherent latent topics from short texts. CME-DMM incorporates topic and word embeddings through the attention mechanism and implants them into the latent topic models, which significantly improve the quality of latent topics. Extensive experiments demonstrate that CME-DMM could perceive more coherent topics than other popular methods, resulting in a better performance in downstream NLP tasks such as classification. Besides the interpretable latent topics, the corresponding topic embeddings can describe the meanings of latent topics in the semantic space. The attention vectors, as a by-product of the learning process, can identify the keywords in noisy short texts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2997973",
            "Date of Publication": "27 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zheng Liu",
                "labs": [
                    "School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China"
                ]
            },
            {
                "name": "Tingting Qin",
                "labs": [
                    "School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China"
                ]
            },
            {
                "name": "Ke-Jia Chen",
                "labs": [
                    "School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China"
                ]
            },
            {
                "name": "Yun Li",
                "labs": [
                    "School of Computer Science, Nanjing University of Posts and Telecommunications, Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Semantics",
                "Task analysis",
                "Context modeling",
                "Computational modeling",
                "Software",
                "Biological system modeling"
            ],
            "Author Keywords": [
                "Latent topic models",
                "short texts",
                "text classification",
                "text representation",
                "topic embedding"
            ]
        }
    },
    {
        "Title": "Testing Contextualized Word Embeddings to Improve NER in Spanish Clinical Case Narratives",
        "Link": "https://ieeexplore.ieee.org/document/9174741/",
        "Abstract": "In the Big Data era, there is an increasing need to fully exploit and analyze the huge quantity of information available about health. Natural Language Processing (NLP) technologies can contribute by extracting relevant information from unstructured data contained in Electronic Health Records (EHR) such as clinical notes, patients' discharge summaries and radiology reports. The extracted information can help in health-related decision making processes. The Named Entity Recognition (NER) task, which detects important concepts in texts (e.g., diseases, symptoms, drugs, etc.), is crucial in the information extraction process yet has received little attention in languages other than English. In this work, we develop a deep learning-based NLP pipeline for biomedical entity extraction in Spanish clinical narratives. We explore the use of contextualized word embeddings, which incorporate context variation into word representations, to enhance named entity recognition in Spanish language clinical text, particularly of pharmacological substances, compounds, and proteins. Various combinations of word and sense embeddings were tested on the evaluation corpus of the PharmacoNER 2019 task, the Spanish Clinical Case Corpus (SPACCC). This data set consists of clinical case sections extracted from open access Spanish-language medical publications. Our study shows that our deep-learning-based system with domain-specific contextualized embeddings coupled with stacking of complementary embeddings yields superior performance over a system with integrated standard and general-domain word embeddings. With this system, we achieve performance competitive with the state-of-the-art.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3018688",
            "Date of Publication": "24 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Liliya Akhtyamova",
                "labs": [
                    "Department of Computing, Technological University Dublin (Tallaght Campus), Dublin, Ireland"
                ]
            },
            {
                "name": "Paloma Martínez",
                "labs": [
                    "Computer Science Department, Carlos III University of Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Karin Verspoor",
                "labs": [
                    "School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia",
                    "Medical School, The University of Melbourne, Melbourne, Australia"
                ]
            },
            {
                "name": "John Cardiff",
                "labs": [
                    "Department of Computing, Technological University Dublin (Tallaght Campus), Dublin, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Natural language processing",
                "Artificial neural networks",
                "Biological system modeling",
                "Drugs",
                "Testing",
                "Data mining"
            ],
            "Author Keywords": [
                "Clinical case narratives",
                "contextualized word embeddings",
                "deep learning",
                "language representations",
                "named entity recognition",
                "natural language processing",
                "spanish language"
            ]
        }
    },
    {
        "Title": "Toward News Authenticity: Synthesizing Natural Language Processing and Human Expert Opinion to Evaluate News",
        "Link": "https://ieeexplore.ieee.org/document/10034750/",
        "Abstract": "The growing popularity of online news has prompted concerns regarding (i) the socio-political influence over news dissemination, (ii) the waning freedom of news media, (iii) and a facile news evaluation process. A piece of news having the power to capture a large audience and sow the seed of bizarre consequences on a national scale should be prudently evaluated before reaching the mass. In quest of making a substantial profit, and sometimes due to inevitable socio-political influence, news with biased heading outpours mass media, resulting in ambiguity and mass manipulation. In this paper, we suggest a blockchain, smart contract, and incremental machine learning-based news evaluation procedure for the Bengali language to overcome these challenges. Weighted synthesis of machine classification and human expert opinion in a decentralized platform are synthesized to evaluate news. With continuous data, the Natural Language Processing (NLP) model is incrementally trained, and the best version of the model is used to detect deprived fake news. During experiments, the NLP model with initial training and testing accuracy of 84.94% and 84.99% was increased to 93.75% and 93.80% after nine rounds of incremental model training. On the Ethereum test network, the protocols have been installed and tested. The simulation demonstrates successful implementation of our proposed system.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3241483",
            "Date of Publication": "01 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md. Anisul Islam Mahmud",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "A. A. Talha Talukder",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Arbiya Sultana",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Kazi Iftesam Amin Bhuiyan",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Samiur Rahman",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Tahmid Hasan Pranto",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Rashedur M. Rahman",
                "labs": [
                    "Department of Electrical and Computer Engineering, North South University, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Natural language processing",
                "Social networking (online)",
                "Blockchains",
                "Data models",
                "Support vector machines",
                "Smart contracts"
            ],
            "Author Keywords": [
                "Blockchain",
                "smart contract",
                "natural language processing",
                "incremental machine learning",
                "fake news evaluation"
            ]
        }
    },
    {
        "Title": "Enhanced Text Matching Based on Semantic Transformation",
        "Link": "https://ieeexplore.ieee.org/document/8993831/",
        "Abstract": "Text matching is the core of natural language processing (NLP) system. It's considered as a touchstone of the NLP, and it aims to find whether text pairs are equal in semantics. However, the semantic gap in text matching is still an open problem to solve. Inspired by successes of cycle-consistent adversarial network (CycleGAN) in image domain transformation, we propose an enhanced text matching method based on the CycleGAN combined with the Transformer network. Based on the proposed method, the text semantics in a source domain is transferred to a similar or different target domain, and the semantic distance between text pairs is decreased. Meanwhile, we demonstrate our method in paraphrase identification and question answer matching. The matching degree is computed by a standard text matching model to evaluate the transforming influence on narrowing the text semantic gap. The experiments show that our method achieves text domain adaptation, and the effects on different matching models are remarkable.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2973206",
            "Date of Publication": "11 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shutao Zhang",
                "labs": [
                    "Hefei Institute of Physical Science, Chinese Academy of Sciences, Hefei, China",
                    "University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Haibo Tan",
                "labs": [
                    "Hefei Institute of Physical Science, Chinese Academy of Sciences, Hefei, China"
                ]
            },
            {
                "name": "Liangfeng Chen",
                "labs": [
                    "Hefei Institute of Physical Science, Chinese Academy of Sciences, Hefei, China"
                ]
            },
            {
                "name": "Bo Lv",
                "labs": [
                    "Hefei Institute of Physical Science, Chinese Academy of Sciences, Hefei, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Generators",
                "Adaptation models",
                "Task analysis",
                "Training",
                "Natural language processing",
                "Face"
            ],
            "Author Keywords": [
                "Cycle-consistent adversarial network",
                "domain adaptation",
                "semantic transformation",
                "text matching",
                "transformer network"
            ]
        }
    },
    {
        "Title": "An Empirical Evaluation of the Zero-Shot, Few-Shot, and Traditional Fine-Tuning Based Pretrained Language Models for Sentiment Analysis in Software Engineering",
        "Link": "https://ieeexplore.ieee.org/document/10623654/",
        "Abstract": "Recent advances in natural language processing (NLP) have led to the development of revolutionized pretrained language models (PLMs) impacting various NLP tasks, including sentiment analysis in software engineering. Choosing the right PLMs is crucial to effectively leverage these advanced PLMs. This paper presents the largest comparative evaluation of the PLMs for sentiment analysis in software engineering. Specifically, the study initially quantifies the performances of four traditionally fine-tuned PLMs, five zero-shot PLMs including GPT-4 and GPT-3 models, and three few-shot PLMs on six domain-specific datasets. The performances of the selected PLMs are also compared against two software engineering domain-specific traditionally fine-tuned PLMs and two state-of-the-art tools. The quantitative analysis reveals varying strengths across the different PLM types. The traditionally fine-tuned domain-specific PLM seBERT achieves the best results in the larger datasets, whereas the few-shot PLMs, such as All-DistillRoBERTa, show the best performances in the smaller datasets. A qualitative error analysis with the help of an Explainable AI technique uncovers existing challenges faced by PLMs in sentiment analysis for software engineering. The comprehensive quantitative and qualitative experiments significantly enrich knowledge in sentiment analysis in software engineering through reproducible insights.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3439450",
            "Date of Publication": "06 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md Shafikuzzaman",
                "labs": [
                    "Department of Computer Science, Lamar University, Beaumont, TX, USA"
                ]
            },
            {
                "name": "Md Rakibul Islam",
                "labs": [
                    "Department of Computer Science, Lamar University, Beaumont, TX, USA"
                ]
            },
            {
                "name": "Alex C. Rolli",
                "labs": [
                    "Department of Computer Science, University of Wisconsin-Eau Claire, Eau Claire, WI, USA"
                ]
            },
            {
                "name": "Sharmin Akhter",
                "labs": [
                    "Department of Computer Science, Lamar University, Beaumont, TX, USA"
                ]
            },
            {
                "name": "Naeem Seliya",
                "labs": [
                    "Department of Computer Science, University of Wisconsin-Eau Claire, Eau Claire, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Software engineering",
                "Sentiment analysis",
                "Encoding",
                "Bidirectional control",
                "Analytical models",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "software engineering",
                "natural language processing",
                "pretrained language models",
                "GPT-4",
                "zero-shot learning",
                "few-shot learning"
            ]
        }
    },
    {
        "Title": "A Branch and Bound Algorithm for Transmission Network Expansion Planning Using Nonconvex Mixed-Integer Nonlinear Programming Models",
        "Link": "https://ieeexplore.ieee.org/document/9754581/",
        "Abstract": "The branch and bound (BB) algorithm is widely used to obtain the global solution of mixed-integer linear programming (MILP) problems. On the other hand, when the traditional BB structure is directly used to solve nonconvex mixed-integer nonlinear programming (MINLP) problems, it becomes ineffective, mainly due to the nonlinearity and nonconvexity of the feasible region of the problem. This article presents the difficulties and ineffectiveness of the direct use of the traditional BB algorithm for solving nonconvex MINLP problems and proposes the formulation of an efficient BB algorithm for solving this category of problems. The algorithm is formulated taking into account particular aspects of nonconvex MINLP problems, including (i) how to deal with the nonlinear programming (NLP) subproblems, (ii) how to detect the infeasibility of an NLP subproblem, (iii) how to treat the nonconvexity of the problem, and (iv) how to define the fathoming rules. The proposed BB algorithm is used to solve the transmission network expansion planning (TNEP) problem, a classical problem in power systems optimization, and its performance is compared with the performances of off-the-shelf optimization solvers for MINLP problems. The results obtained for four test systems, with different degrees of complexity, indicate that the proposed BB algorithm is effective for solving the TNEP problem with and without considering losses, showing equal or better performance than off-the-shelf optimization solvers.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3166153",
            "Date of Publication": "11 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Reinaldo T. Zoppei",
                "labs": [
                    "Institute of Exact and Natural Sciences, Federal University of Rondonópolis, Rondonópolis, Mato Grosso, Brazil"
                ]
            },
            {
                "name": "Marcos A. J. Delgado",
                "labs": [
                    "Institute of Exact and Natural Sciences, Federal University of Rondonópolis, Rondonópolis, Mato Grosso, Brazil"
                ]
            },
            {
                "name": "Leonardo H. Macedo",
                "labs": [
                    "Department of Electrical Engineering, São Paulo State University, Ilha Solteira, São Paulo, Brazil"
                ]
            },
            {
                "name": "Marcos J. Rider",
                "labs": [
                    "Department of Systems and Energy, University of Campinas, Campinas, São Paulo, Brazil"
                ]
            },
            {
                "name": "Rubén Romero",
                "labs": [
                    "Department of Electrical Engineering, São Paulo State University, Ilha Solteira, São Paulo, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Search problems",
                "Propagation losses",
                "Planning",
                "Metaheuristics",
                "Linear programming",
                "Biological system modeling",
                "Programming profession"
            ],
            "Author Keywords": [
                "Branch and bound algorithm",
                "mixed-integer nonlinear programming",
                "optimization",
                "transmission network expansion planning"
            ]
        }
    },
    {
        "Title": "Android Ransomware Analysis Using Convolutional Neural Network and Fuzzy Hashing Features",
        "Link": "https://ieeexplore.ieee.org/document/10299644/",
        "Abstract": "Most of the time, cybercriminals look for new ways to bypass security controls by improving their attacks. In the 1980s, attackers developed malware to kidnap user data by requesting payments. Malware is called a ransomware. Recently, they have demanded payment in Bitcoin or any other cryptocurrency. Ransomware is one of the most dangerous threats on the Internet, and this type of malware could affect almost all devices. Malware cipher device data, making them inaccessible to users. In this study, a new method for Android ransomware classification was proposed. This method implements a Convolutional Neural Network (CNN) for malware classification based on images. This paper presents a novel method for transforming an Android Application Package (APK) into a grayscale image. The image creation relies on using Natural Language Processing (NLP) techniques for text cleaning and Fuzzy Hashing to represent the decompiled code from the APK in a set of hashes after preprocessing using NLP techniques. The image is composed of\nn\nfuzzy hashes that represent the APK. The method was tested using a dataset of 7,765 Android ransomware samples obtained from external researchers and public sources. The accuracy of the proposed method was higher than that of other methods in the literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3328314",
            "Date of Publication": "30 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Horacio Rodriguez-Bazan",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Grigori Sidorov",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico"
                ]
            },
            {
                "name": "Ponciano Jorge Escamilla-Ambrosio",
                "labs": [
                    "Centro de Investigación en Computación (CIC), Instituto Politécnico Nacional (IPN), Mexico City, Mexico"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Operating systems",
                "Ransomware",
                "Natural language processing",
                "Classification algorithms",
                "XML",
                "Metadata",
                "Matched filters",
                "Androids",
                "Convolutional neural networks",
                "Deep learning",
                "Fuzzy systems"
            ],
            "Author Keywords": [
                "Android ransomware",
                "convolutional neural network",
                "deep learning",
                "fuzzy hashing",
                "malware classification",
                "ransomware"
            ]
        }
    },
    {
        "Title": "AI Knows You: Deep Learning Model for Prediction of Extroversion Personality Trait",
        "Link": "https://ieeexplore.ieee.org/document/10735203/",
        "Abstract": "The recent rise of Artificial Intelligence (AI) has already revolutionized human lives and is improving the quality of human life in many ways. The field of AI, Natural Language Processing (NLP), helps to understand, comprehend and even generate new content. NLP is used for various content analysis tasks such as sentiment analysis, fake news detection, etc. However, human personality traits detection is a new research domain. Analyzing users generated content has a significant role in identifying and understanding users’ views and behaviors. Users’ traits detection can be helpful in analysis of consumers’ personalization, finding top candidates for recruitment, career counselling, etc. In this research study, our aim is to predict personality of extroversion behaviors using machine and deep learning approaches. Extroversion means whether a person is an introvert or extrovert as this trait is relevant to certain jobs like team management, social ties etc. For empirical analysis, we investigate MBTI dataset with various feature engineering techniques including textual features like Term Frequency-Inverse Document Frequency (TF-IDF), Parts of Speech (PoS) tagging, as well as deep word embeddings ok word2vec, GloVe. The state-of-the-art shallow machine learning, ensemble modelling and deep learning models are applied. The main novelty is the exploration of latest sentence embeddings which captures semantic information of content in a better manner. Thus, the comprehensive results analysis reveals sentence embeddings as features to Bi-LSTM achieves highest accuracy of 92.52% and outperforms the existing studies in the relevant literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3486578",
            "Date of Publication": "25 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anam Naz",
                "labs": [
                    "Department of Computer Science, University of Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Hikmat Ullah Khan",
                "labs": [
                    "Department of Information Technology, University of Sargodha, Punjab, Pakistan"
                ]
            },
            {
                "name": "Sami Alesawi",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Rabigh, Saudi Arabia"
                ]
            },
            {
                "name": "Omar Ibrahim Abouola",
                "labs": [
                    "Department of Information Systems and Technology, College of Computer Science and Engineering, University of Jeddah, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Ali Daud",
                "labs": [
                    "Faculty of Resilience, Rabdan Academy, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Muhammad Ramzan",
                "labs": [
                    "Department of Software Engineering, University of Sargodha, Punjab, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Social networking (online)",
                "Predictive models",
                "Accuracy",
                "Deep learning",
                "Brain modeling",
                "Prediction algorithms",
                "Natural language processing",
                "Artificial intelligence",
                "Long short term memory"
            ],
            "Author Keywords": [
                "Cognitive science",
                "deep embeddings",
                "deep learning",
                "feature engineering",
                "machine learning",
                "psychology"
            ]
        }
    },
    {
        "Title": "JoinER-BART: Joint Entity and Relation Extraction With Constrained Decoding, Representation Reuse and Fusion",
        "Link": "https://ieeexplore.ieee.org/document/10236558/",
        "Abstract": "Joint Entity and Relation Extraction (JERE) is an important research direction in Information Extraction (IE). Given the surprising performance with fine-tuning of pre-trained BERT in a wide range of NLP tasks, nowadays most studies for JERE are based on the BERT model. Rather than predicting a simple tag for each word, these approaches are usually forced to design complex tagging schemes, as they may have to extract entity-relation pairs which may overlap with others from the same sequence of word representations in a sentence. Recently, sequence-to-sequence (seq2seq) pre-trained BART models show better performance than BERT models in many NLP tasks. Importantly, a seq2seq BART model can simply generate sequences of (many) entity-relation triplets with its decoder, rather than just tag input words. In this article, we present a new generative JERE framework based on pre-trained BART. Different from the basic seq2seq BART architecture: 1) our framework employs a constrained classifier which only predicts either a token of the input sentence or a relation in each decoding step, and 2) we reuse representations from the pre-trained BART encoder in the classifier instead of a newly trained weight matrix, as this better utilizes the knowledge of the pre-trained model and context-aware representations for classification, and empirically leads to better performance. In our experiments on the widely studied NYT and WebNLG datasets, we show that our approach outperforms previous studies and establishes a new state-of-the-art (92.91 and 91.37 F1 respectively in exact match evaluation).",
        "Details": {
            "DOI": "10.1109/TASLP.2023.3310879",
            "Date of Publication": "31 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
        },
        "issn_info": {
            "Print ISSN": "2329-9290",
            "Electronic ISSN": "2329-9304"
        },
        "authors_data": [
            {
                "name": "Hongyang Chang",
                "labs": [
                    "Zhengzhou University, Henan, China"
                ]
            },
            {
                "name": "Hongfei Xu",
                "labs": [
                    "Zhengzhou University, Henan, China"
                ]
            },
            {
                "name": "Josef van Genabith",
                "labs": [
                    "DFKI and Saarland University, Informatics Campus, Saarbrücken, Germany"
                ]
            },
            {
                "name": "Deyi Xiong",
                "labs": [
                    "Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Hongying Zan",
                "labs": [
                    "Zhengzhou University, Henan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Decoding",
                "Tagging",
                "Predictive models",
                "Context modeling",
                "Tail",
                "Speech processing"
            ],
            "Author Keywords": [
                "Joint Entity and Relation Extraction",
                "pre-trained BART",
                "sequence-to-sequence Model"
            ]
        }
    },
    {
        "Title": "MPSC: A Multiple-Perspective Semantics-Crossover Model for Matching Sentences",
        "Link": "https://ieeexplore.ieee.org/document/8710322/",
        "Abstract": "Sentence matching is crucial to many natural language processing (NLP) tasks. Generally, the degree of matching is measured from either of the two perspectives: topic-based match or semantic-based match. The former is to investigate if two sentences discuss the same topic, and the latter performs a deep level semantic matching of texts, which is currently the highlight in research. Deep semantic matching requires adequate modeling from the internal structure of the language objects as well as their interactions. To achieve this goal, this paper proposes a multiple-perspective semantics-crossover (MPSC) model for modeling the semantic-based match of two sentences. The model extracts the matching information of two sentences from the semantic interaction information generated from different angles, so as to calculate the matching degree of the two sentences. The MPSC model not only captures rich matching patterns at different levels but also acquires interactive features from different semantic angles. It can be used to address some important issues in NLP fields, such as information matching in text retrieval, question-answer matching in the Q&A system, and so on. The experimental results show that our proposed model of MPSC has better effectiveness than some popular semantic matching approaches.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2915937",
            "Date of Publication": "09 May 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dunlu Peng",
                "labs": [
                    "School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China"
                ]
            },
            {
                "name": "Shaohong Wu",
                "labs": [
                    "School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China"
                ]
            },
            {
                "name": "Cong Liu",
                "labs": [
                    "School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Natural language processing",
                "Computational modeling",
                "Analytical models",
                "Feature extraction",
                "Data mining"
            ],
            "Author Keywords": [
                "Natural language processing",
                "neural networks",
                "semantics matching",
                "text analysis"
            ]
        }
    },
    {
        "Title": "Identifying Alcohol-Related Information From Unstructured Bilingual Clinical Notes With Multilingual Transformers",
        "Link": "https://ieeexplore.ieee.org/document/10044673/",
        "Abstract": "As a key modifiable risk factor, alcohol consumption is clinically crucial information that allows medical professionals to further understand their patients’ medical conditions and suggest appropriate lifestyle modifying interventions. However, identifying alcohol-related information from unstructured free-text clinical notes is often challenging. Not only are the formats of the notes inconsistent, but they also include a massive amount of non-alcohol-related information. Furthermore, for medical institutions outside of English-speaking countries, these clinical notes contain both a mixture of English and local languages, inducing additional difficulty in the extraction. Thanks to the increasing availability of electronic medical record (EMR), several previous works explored the idea of using natural language processing (NLP) to train machine learning models that automatically identify alcohol-related information from unstructured clinical notes. However, all these previous works are limited to English clinical notes, thereby able to leverage various large-scale external ontologies during the text preprocessing. Furthermore, they rely on simple NLP techniques such as the bag-of-words models that suffer from high dimensionality and out-of-vocabulary issues. Addressing these issues, we adopt fine-tuning multilingual transformers. By leveraging their linguistically rich contextual information learned during their pre-training, we are able to extract alcohol-related information from unstructured clinical notes without preprocessing the clinical notes on any external ontologies. Furthermore, our work is the first to explore the use of transformers in bilingual clinical notes to extract alcohol-related information. Even with minimal text preprocessing, we achieve extraction accuracy of 84.70% in terms of macro F-1 score.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3245523",
            "Date of Publication": "14 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Han Kyul Kim",
                "labs": [
                    "Daniel J. Epstein Department of Industrial and Systems Engineering, University of Southern California, Los Angeles, CA, USA"
                ]
            },
            {
                "name": "Yujin Park",
                "labs": [
                    "Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Yeju Park",
                "labs": [
                    "Office of Hospital Information, Seoul National University Hospital, Seoul, South Korea"
                ]
            },
            {
                "name": "Eunji Choi",
                "labs": [
                    "Office of Hospital Information, Seoul National University Hospital, Seoul, South Korea"
                ]
            },
            {
                "name": "Sodam Kim",
                "labs": [
                    "Office of Hospital Information, Seoul National University Hospital, Seoul, South Korea"
                ]
            },
            {
                "name": "Hahyun You",
                "labs": [
                    "Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, South Korea"
                ]
            },
            {
                "name": "Ye Seul Bae",
                "labs": [
                    "Office of Hospital Information, Seoul National University Hospital, Seoul, South Korea",
                    "Department of Family Medicine, Seoul National University Hospital, Seoul, South Korea",
                    "Interdisciplinary Program of Medical Informatics, Seoul National University College of Medicine, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Data mining",
                "Hospitals",
                "Terminology",
                "Symbols",
                "Ontologies",
                "Alcoholic beverages",
                "Bioinformatics",
                "Natural language processing",
                "Informatics",
                "Clinical diagnosis"
            ],
            "Author Keywords": [
                "Clinical informatics",
                "alcohol information extraction",
                "natural language processing",
                "information extraction from clinical notes",
                "multilingual transformers"
            ]
        }
    },
    {
        "Title": "A Natural Language Process-Based Framework for Automatic Association Word Extraction",
        "Link": "https://ieeexplore.ieee.org/document/8945152/",
        "Abstract": "Word association, revealing mental representations and connections of human, has been widely studied in psychology. However, the scale of available associative cue-response words is severely restricted due to the traditional manually collecting methodology. Meanwhile, with the tremendous success in Natural Language Process (NLP) tasks, an extremely large amount of plain texts can be easily acquired. This suggests an insight about the potential to find association words automatically from the text corpus instead of manually collection. As an original attempt, this paper takes a small step toward proposing a deep learning based framework for automatic association word extraction. The framework mainly consists of two stages of association word detection and machine association network construction. In particular, attention mechanism based Reading Comprehension (RC) algorithm is explored to find valuable association words automatically. To validate the value of the extracted association words, the correlation coefficient between semantic similarities of machine and human association words is introduced as an effective measurement for evaluating association consistence. The experiments are conducted on two text datasets from which together about 20k association words, more than the existing largest human association word dataset, are finally derived. The experiment further verifies that the machine association words are generally consistent with human association words with respect to semantic similarity, which highlights the promising utilization of the machine association words in the future researches of both psychology and NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2962154",
            "Date of Publication": "30 December 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zheng Hu",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Jiao Luo",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Chunhong Zhang",
                "labs": [
                    "Key Laboratory of Universal Wireless Communications, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Wei Li",
                "labs": [
                    "Laboratory for Intelligent Networks and Systems, Northern Illinois University, DeKalb, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Psychology",
                "Natural languages",
                "Correlation",
                "Telecommunications",
                "Data mining"
            ],
            "Author Keywords": [
                "Word association",
                "natural language process",
                "semantic similarity",
                "attention mechanism"
            ]
        }
    },
    {
        "Title": "Mesh Adaptation Method for Optimal Control With Non-Smooth Control Using Second-Generation Wavelet",
        "Link": "https://ieeexplore.ieee.org/document/8839078/",
        "Abstract": "A mesh adaptation method is proposed for solving optimal control problems with non-smooth control. The original optimal control problem (OCP) is transcribed into a nonlinear programming (NLP) problem by using the Runge-Kutta discretization method, in which the NLP can be solved by using standard nonlinear programming codes. The method employs collocations from the dyadic background points, which used for the second-generation wavelet (SGW) translation simultaneously. The SGW is used to approximate the control variables and get the wavelet coefficients once they are obtained. In regions contain discontinuities, the magnitude of the relevant wavelet coefficients is large than other regions. The corresponding dyadic background points are reserved as the collocation points. Furthermore, the approximation error of the control and/or state variables can be predicted by a given threshold. Thus, the accuracy and efficiency can be balanced in a simple way. Finally, the method is demonstrated by three numerical examples from the open literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2941539",
            "Date of Publication": "16 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhiwei Feng",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Qingbin Zhang",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Jianquan Ge",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Wuyu Peng",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Tao Yang",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Jinliang Jie",
                "labs": [
                    "College of Aerospace Science and Engineering, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimal control",
                "Programming",
                "Wavelet coefficients",
                "Wavelet analysis",
                "Interpolation"
            ],
            "Author Keywords": [
                "Optimal control",
                "mesh adaptation",
                "adaptive collocation method",
                "second generation wavelets"
            ]
        }
    },
    {
        "Title": "Decoding Queries: An In-Depth Survey of Quality Techniques for Question Analysis in Arabic Question Answering Systems",
        "Link": "https://ieeexplore.ieee.org/document/10676963/",
        "Abstract": "In the field of natural language processing (NLP), natural language understanding (NLU) plays a critical role in transforming human languages into machine-interpretable formats. This paper provides an overview of methodologies and resources that have been developed so far concerning Arabic QAS, focusing on NLU regarding question analysis and classification. These components perform an important role in obtaining accurate, quality, context-sensitive answers. Findings indicate that deep learning models work wonders for complex languages, but machine learning algorithms usually do the job in most classification tasks. Further, there is mention of the potential of rule-based and hybrid approaches, whose research in the future should be integrated with evolving evaluation methods necessary to keep pace with the advances in NLP. Challenges especially pertinent to Arabic QAS are complex syntax, dialectal diversity, limited tool support, and a lack of benchmark datasets. Other directions for the future are the development of complete datasets, standardized test bed frameworks, and extra question classification, adopting a hybrid approach considering interrogative words along with question multiplicity. This survey would therefore be helpful in highlighting shortcomings in the literature, suggesting new directions for research, and emphasizing that innovation concerning NLU within QASs is an ongoing necessity.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3458466",
            "Date of Publication": "11 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mariam Essam",
                "labs": [
                    "Department of Artificial Intelligence, College of Information Technology, Misr University for Science and Technology (MUST), 6th of October City, Egypt"
                ]
            },
            {
                "name": "Mohanad A. Deif",
                "labs": [
                    "Department of Artificial Intelligence, College of Information Technology, Misr University for Science and Technology (MUST), 6th of October City, Egypt"
                ]
            },
            {
                "name": "Hani Attar",
                "labs": [
                    "Faculty of Engineering, Zarqa University, Zarqa, Jordan",
                    "College of Engineering, University of Business and Technology, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Ayat Alrosan",
                "labs": [
                    "School of Computing, Skyline University College, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Mohammad A. Kanan",
                "labs": [
                    "College of Engineering, University of Business and Technology, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Rania Elgohary",
                "labs": [
                    "Information Systems Department, Faculty of Computer and Information Sciences, Ain Shams University, Cairo, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Natural language processing",
                "Question answering (information retrieval)",
                "Chatbots",
                "Semantics",
                "Search engines",
                "Machine learning algorithms"
            ],
            "Author Keywords": [
                "Natural language understanding (NLU)",
                "Arabic question answering systems",
                "Arabic understanding",
                "question analysis",
                "challenges in Arabic question analysis"
            ]
        }
    },
    {
        "Title": "A Simple Yet Robust Algorithm for Automatic Extraction of Parallel Sentences: A Case Study on Arabic-English Wikipedia Articles",
        "Link": "https://ieeexplore.ieee.org/document/9661426/",
        "Abstract": "Parallel corpora are vital components in several applications of Natural Language Processing (NLP), particularly in machine translation. In this paper, we present a novel method for automatically creating parallel sentences from comparable corpora. The method requires a bilingual dictionary as well as an adequate word-vectorisation method. We use Arabic and English Wikipedia as a comparable corpus to apply our proposed method and construct a parallel corpus between Arabic and English. The created Arabic-English corpus consists of 105,010 parallel sentences with a total number of 4.6M words. During our study, we compared two methods of word vectorisation, word embedding and term frequency-inverse document frequency, in terms of their usefulness in computing similarities between well-formed and syntactically ill-formed sentences. We also quantitatively and qualitatively examined the parallel corpus produced by our proposed method and compared it with other available Arabic-English parallel corpora counterparts: GlobalVoices, TED, and Wiki-OPUS. We explored the main advantages and shortcomings of these corpora when used for NLP applications, such as word semantic similarity identification and Neural Machine Translation (NMT). The word semantic similarity models trained on our parallel corpus outperformed models trained on other corpora in the task of English non-similar word identification. Our parallel corpus also proved competitive when building Arabic-English NMT systems, yielding results comparable to those of the automatically created Wiki-OPUS corpus and of the manually created TED corpus, while achieving results superior to the smaller GlobalVoices corpus.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3137830",
            "Date of Publication": "23 December 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maha Jarallah Althobaiti",
                "labs": [
                    "Department of Computer Science, Taif University, Taif, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Online services",
                "Deep learning",
                "Encyclopedias",
                "Dictionaries",
                "Machine translation",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Automatic creation of parallel corpus",
                "automatic sentence alignment",
                "deep learning",
                "neural machine translation",
                "transformer model",
                "word embedding"
            ]
        }
    },
    {
        "Title": "Cyber Attack Prediction: From Traditional Machine Learning to Generative Artificial Intelligence",
        "Link": "https://ieeexplore.ieee.org/document/10909100/",
        "Abstract": "The escalating sophistication of cyber threats poses significant risks to individuals, organizations, and nations. Cybercrime, encompassing activities like hacking and data breaches, has severe economic and societal consequences. In today’s interconnected world, robust cybersecurity measures are paramount to mitigate these risks and protect sensitive information. However, traditional security solutions struggle to keep pace with the evolving threat landscape. Artificial Intelligence (AI) offers a powerful arsenal of techniques to address these challenges. This paper explores the application of AI methods, including Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Explainable AI (XAI), and Generative AI, in solving various cybersecurity problems. This paper presents a comprehensive analysis of AI techniques for enhancing cybersecurity. Key contributions include: 1) comparative study of ML and DL methods: Evaluating their accuracy, applicability, and suitability for various cybersecurity challenges; 2) investigation into XAI approaches: Enhancing the transparency and interpretability of AI-powered security solutions, particularly in anomaly detection; 3) exploration of emerging trends in Generative AI (Gen-AI) and NLP: Examining their potential to simulate and mitigate cyber threats through advanced techniques like threat intelligence generation and attack simulations; 4) application of GenAI in cybersecurity and real-world products of GenAI for cyber security. This research aims to advance the state-of-the-art in AI-driven cybersecurity by providing insights into effective and reliable solutions for mitigating cyber risks and improving the overall security posture.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3547433",
            "Date of Publication": "03 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shilpa Ankalaki",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Aparna Rajesh Atmakuri",
                "labs": [
                    "Department of CSE, SoET, Centurion University of Technology and Management, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "M. Pallavi",
                "labs": [
                    "School of Computer Science and Engineering, Presidency University, Bengaluru, India"
                ]
            },
            {
                "name": "Geetabai S Hukkeri",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Institute of Technology Bengaluru, Manipal Academy of Higher Education, Manipal, Karnataka, India"
                ]
            },
            {
                "name": "Tony Jan",
                "labs": [
                    "Centre for Artificial Intelligence Research and Optimization (AIRO), Design and Creative Technology Vertical, Torrens University, Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Ganesh R. Naik",
                "labs": [
                    "Centre for Artificial Intelligence Research and Optimization (AIRO), Design and Creative Technology Vertical, Torrens University, Ultimo, NSW, Australia",
                    "Design and Creative Technology Vertical, Torrens University, Adelaide, SA, Australia",
                    "College of Medicine and Public Health, Flinders University, Adelaide, SA, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Computer security",
                "Security",
                "Cyberattack",
                "Explainable AI",
                "Generative AI",
                "Ransomware",
                "Deep learning",
                "Chatbots",
                "Accuracy"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "cyber-attack prediction",
                "machine learning",
                "deep learning",
                "explainable AI",
                "generative AI"
            ]
        }
    },
    {
        "Title": "Multi-Level Fine-Grained Interactions for Collaborative Filtering",
        "Link": "https://ieeexplore.ieee.org/document/8844254/",
        "Abstract": "In recent years, review-based collaborative filtering (CF) has been extensively studied, which is an combination between natural language processing (NLP) and recommender systems. The core pattern behind CF is to first model user and item, and then adopts a relatively primitive interaction between them for personalized recommendation. This pattern is very similar to the issue of sequence matching in NLP, where sequence 1 and sequence 2 are matched with a fine-grained interaction leading to a better result. Therefore, there is a tremendous room for further improvement in current review-based CF to release the power of fine-grained interaction. To this end, we treat the user review set and item review set as two sequences, and design a multi-level matching attention layer for fine-grained interaction. In addition, we devise the aspect-level and review-level attention to measure the contribution of each review. Extensive experiments on 24 public datasets show that the proposed model consistently outperforms the state-of-the-art approaches. More importantly, by selecting the relevant reviews according to the aspect attention score and review attention score, we can observe which specific item aspects that user mainly concerned and which item characteristic highly matched with the user preference, in which the recommendation interpretability can be enhanced.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2941236",
            "Date of Publication": "18 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xingjie Feng",
                "labs": [
                    "College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China"
                ]
            },
            {
                "name": "Yunze Zeng",
                "labs": [
                    "College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Recommender systems",
                "Deep learning",
                "Collaboration",
                "Natural language processing",
                "Pattern matching",
                "Motion pictures"
            ],
            "Author Keywords": [
                "Recommender system",
                "collaborative filtering",
                "deep learning",
                "attention mechanism"
            ]
        }
    },
    {
        "Title": "Text Classification Based on Conditional Reflection",
        "Link": "https://ieeexplore.ieee.org/document/8734068/",
        "Abstract": "Text classification is an essential task in many natural language processing (NLP) applications; we know each sentence may have only a few words that play an important role in text classification, while other words have no significant effect on the classification results. Finding these keywords has an important impact on the classification accuracy. In this paper, we propose a network model, named RCNNA, recurrent convolution neural networks with attention (RCNNA), which models on the human conditional reflexes for text classification. The model combines bidirectional LSTM (BLSTM), attention mechanism, and convolutional neural networks (CNNs) as the receptors, nerve centers, and effectors in the reflex arc, respecctively. The receptors get the context information through BLSTM, the nerve centers get the important information of the sentence through the attention mechanism, and the effectors capture more key information by CNN. Finally, the model outputs the classification result by the softmax function. We test our NLP algorithm on four datasets containing Chinese and English for text classification, including a comparison of random initialization word vectors and pre-training word vectors. The experiments show that the RCNNA achieves the best performance by comparing with the state-of-the-art baseline methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2921976",
            "Date of Publication": "10 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanliang Jin",
                "labs": [
                    "Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China"
                ]
            },
            {
                "name": "Can Luo",
                "labs": [
                    "Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China"
                ]
            },
            {
                "name": "Weisi Guo",
                "labs": [
                    "School of Engineering, University of Warwick, Coventry, U.K."
                ]
            },
            {
                "name": "Jinfei Xie",
                "labs": [
                    "Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China"
                ]
            },
            {
                "name": "Dijia Wu",
                "labs": [
                    "Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China"
                ]
            },
            {
                "name": "Rui Wang",
                "labs": [
                    "Key Laboratory of Specialty Fiber Optics and Optical Access Networks, Joint International Research Laboratory of Specialty Fiber Optics and Advanced Communication, Shanghai Institute for Advanced Communication and Data Science, Shanghai University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Semantics",
                "Reflection",
                "Task analysis",
                "Feature extraction",
                "Neural networks",
                "Logic gates"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "bidirectional LSTM",
                "convolutional neural networks",
                "conditional reflection",
                "text classification"
            ]
        }
    },
    {
        "Title": "Learning a Planning Domain Model From Natural Language Process Manuals",
        "Link": "https://ieeexplore.ieee.org/document/9153768/",
        "Abstract": "Artificial intelligence planning techniques have been widely used in many applications. A big challenge is to automate a planning model, especially for planning applications based on natural language (NL) input. This requires the analysis and understanding of NL text and a general learning technique does not exist in real-world applications. In this article, we investigate an intelligent planning technique for natural disaster management, e.g. typhoon contingency plan generation, through natural language process manuals. A planning model is to optimise management operations when a disaster occurs in a short time. Instead of manually building the planning model, we aim to automate the planning model generation by extracting disaster management-related content through NL processing (NLP) techniques. The learning input comes from the published documents that describe the operational process of preventing potential loss in the typhoon management. We adopt a classical planning model, namely planning domain definition language (PDDL), in the typhoon contingency plan generation. We propose a novel framework of FPTCP, which stands for a Framework of Planning Typhoon Contingency Plan, for learning a domain model of PDDL from NL text. We adapt NLP techniques to construct a ternary template of sentences of NL inputs from which actions and their objects are extracted to build a domain model. We also develop a comprehensive suite of user interaction components and facilitate the involvement of users in order to improve the learned domain models. The user interaction is to remove semantic duplicates of NL objects such that the users can select model-generated actions and predicates to better fit the PDDL domain model. We detail the implementation steps of the proposed FPTCP and evaluate its performance on real-world typhoon datasets. In addition, we compare FPTCP with two state-of-the-art approaches in applications of narrative generation, and discuss its capability and limitations.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3013237",
            "Date of Publication": "31 July 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yongfeng Huo",
                "labs": [
                    "Department of Automation, Xiamen University, Xiamen, China",
                    "Xiamen Key Laboratory of Big Data Intelligent Analysis and Decision-Making, Xiamen, China"
                ]
            },
            {
                "name": "Jing Tang",
                "labs": [
                    "Newcastle Business School, Northumbria University, Newcastle upon Tyne, U.K."
                ]
            },
            {
                "name": "Yinghui Pan",
                "labs": [
                    "College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China"
                ]
            },
            {
                "name": "Yifeng Zeng",
                "labs": [
                    "Department of Computer and Information Sciences, Northumbria University, Newcastle upon Tyne, U.K."
                ]
            },
            {
                "name": "Langcai Cao",
                "labs": [
                    "Department of Automation, Xiamen University, Xiamen, China",
                    "Xiamen Key Laboratory of Big Data Intelligent Analysis and Decision-Making, Xiamen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Planning",
                "Tropical cyclones",
                "Natural languages",
                "Artificial intelligence",
                "Manuals",
                "Labeling",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Domain learning",
                "PDDL",
                "typhoon contingency plan"
            ]
        }
    },
    {
        "Title": "A Word Sense Disambiguation Method Applied to Natural Language Processing for the Portuguese Language",
        "Link": "https://ieeexplore.ieee.org/document/10535267/",
        "Abstract": "Natural language processing (NLP) and artificial intelligence (AI) have advanced significantly in recent years, enabling the development of various tasks, such as machine translation, text summarization, sentiment analysis, and speech analysis. However, there are still challenges to overcome, such as natural language ambiguity. One of the problems caused by ambiguity is the difficulty of determining the proper meaning of a word in a specific context. For example, the word “mouse” can mean a computer peripheral or an animal, depending on the context. This limitation can lead to an incorrect semantic interpretation of the processed sentence. In recent years, language models (LMs) have provided a new impetus to NLP and AI, including in the task of word sense disambiguation (WSD). LMs are capable of learning and generating texts as they are trained on large amounts of data. However, in the Portuguese language, there are still few studies on WSD using LMs. Given this scenario, this article presents a method for WSD for the Portuguese language. To do this, it uses the BERTimbau language model, which is specific to the Portuguese. The results will be evaluated using the metrics established in the literature.",
        "Details": {
            "DOI": "10.1109/OJCS.2024.3396518",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Clovis Holanda do Nascimento",
                "labs": [
                    "Informatics Center, Federal University of Pernambuco, Recife, Brazil"
                ]
            },
            {
                "name": "Vinicius Cardoso Garcia",
                "labs": [
                    "Informatics Center, Federal University of Pernambuco, Recife, Brazil"
                ]
            },
            {
                "name": "Ricardo de Andrade Araújo",
                "labs": [
                    "Araripe Computational Intelligence Laboratory, Federal Institute of the Sertao Pernambucano, Ouricuri, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Natural language processing",
                "Libraries",
                "Data models",
                "Computational modeling",
                "Context modeling",
                "Training"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "language models",
                "natural language processing",
                "word sense disambiguation"
            ]
        }
    },
    {
        "Title": "Classifying European Court of Human Rights Cases Using Transformer-Based Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10130544/",
        "Abstract": "In the field of text classification, researchers have repeatedly shown the value of transformer-based models such as Bidirectional Encoder Representation from Transformers (BERT) and its variants. Nonetheless, these models are expensive in terms of memory and computational power but have not been utilized to classify long documents of several domains. In addition, transformer models are also often pre-trained on generalized languages, making them less effective in language-specific domains, such as legal documents. In the natural language processing (NLP) domain, there is a growing interest in creating newer models that can handle more complex input sequences and domain-specific languages. Keeping the power of NLP in mind, this study proposes a legal documentation classifier that classifies the legal document by using the sliding window approach to increase the maximum sequence length of the model. We used the ECHR (European Court of Human Rights) publicly available dataset which to a large extent is imbalanced. Therefore, to balance the dataset we have scrapped the case articles from the web and extracted the data. Then, we employed conventional machine learning techniques such as SVM, DT, NB, AdaBoost, and transformer-based neural networks models including BERT, Legal-BERT, RoBERTa, BigBird, ELECTRA, and XLNet for the classification task. The experimental findings show that RoBERTa outperformed all the mentioned BERT versions by obtaining precision, recall, and F1-score of 89.1%, 86.2%, and 86.7%, respectively. While from conventional machine learning techniques, AdaBoost outclasses SVM, DT, and NB by achieving scores of 81.9%, 81.5%, and 81.7% for precision, recall, and F1-score, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3279034",
            "Date of Publication": "22 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ali Shariq Imran",
                "labs": [
                    "Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway"
                ]
            },
            {
                "name": "Henrik Hodnefjeld",
                "labs": [
                    "Department of Computer Science, Norwegian University of Science and Technology (NTNU), Gjøvik, Norway"
                ]
            },
            {
                "name": "Zenun Kastrati",
                "labs": [
                    "Department of Informatics, Linnaeus University, Växjö, Sweden"
                ]
            },
            {
                "name": "Noureen Fatima",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Sher Muhammad Daudpota",
                "labs": [
                    "Department of Computer Science, Sukkur IBA University, Sukkur, Pakistan"
                ]
            },
            {
                "name": "Mudasir Ahmad Wani",
                "labs": [
                    "EIAS Data Science Laboratory, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Transformers",
                "Bit error rate",
                "Natural language processing",
                "Legal aspects",
                "Europe",
                "Mathematical models"
            ],
            "Author Keywords": [
                "Legal documents classification",
                "European court of human rights (ECHR) dataset",
                "natural language processing",
                "transformers",
                "BERT",
                "BigBird",
                "ELECTRA",
                "XLNet",
                "legal-BERT"
            ]
        }
    },
    {
        "Title": "Identifying Hot Information Security Topics Using LDA and Multivariate Mann-Kendall Test",
        "Link": "https://ieeexplore.ieee.org/document/10049568/",
        "Abstract": "Discovering promising research themes in a scientific domain by evaluating semantic information extracted from bibliometric databases represents a challenging task for Natural Language Processing (NLP). While existing NLP methods generally characterize the research topics using unique key terms, we take a step further by more accurately modeling the research themes as finite sets of key terms. The proposed approach involves two stages: identifying the research themes from paper metadata using LDA topic modeling; and, evaluation of research theme trends by employing a version of the Mann-Kendall test that is able to cope with multivariate time series of term occurrences. The results obtained by applying this general methodology to Information Security domain confirm its viability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3247588",
            "Date of Publication": "22 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Christian-Daniel Curiac",
                "labs": [
                    "Computer and Information Technology Department, Politehnica University of Timisoara, Timisoara, Romania"
                ]
            },
            {
                "name": "Mihai V. Micea",
                "labs": [
                    "Computer and Information Technology Department, Politehnica University of Timisoara, Timisoara, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Market research",
                "Bibliometrics",
                "Natural language processing",
                "Databases",
                "Data mining",
                "Time series analysis",
                "Information security",
                "Metadata"
            ],
            "Author Keywords": [
                "LDA topic modeling",
                "multivariate Mann–Kendall test",
                "natural language processing",
                "paper metadata",
                "research theme",
                "research trend"
            ]
        }
    },
    {
        "Title": "Hardware Trojan Detection in Open-Source Hardware Designs Using Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/10904479/",
        "Abstract": "The globalization of the hardware supply chain reduces costs but increases security challenges with the potential insertion of hardware trojans by third parties. Traditional detection methods face scalability limitations by relying solely on simple examples (e.g., AES). Although open-source hardware promotes transparency, it does not guarantee security. In this research, Natural Language Processing (NLP) and Machine Learning (ML) techniques were applied to identify hardware trojans in complex open hardware designs (e.g., RISC-V, MIPS). Using data from existing benchmarks (ISCAS85-89, TrustHub) and synthetic data generated with Large Language Models (LLM), a dataset of 3,808 instances was used in this research. The approach using TF-IDF and Decision Tree (DT) achieved 97.26%, surpassing the state of the art. The use of LLMs with prompt optimization achieved a recall of 99%, minimizing false negatives. A novel framework integrating NLP, ML, and LLMs was developed to enhance the security of open-source hardware.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3546156",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Victor Takashi Hayashi",
                "labs": [
                    "Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil"
                ]
            },
            {
                "name": "Wilson Vicente Ruggiero",
                "labs": [
                    "Department of Computer Engineering and Digital Systems (PCS), Escola Politécnica, Laboratory of Computer Architecture and Networks (LARC), Universidade de São Paulo, São Paulo, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hardware",
                "Trojan horses",
                "Machine learning",
                "Hardware design languages",
                "Open source hardware",
                "Benchmark testing",
                "Static analysis",
                "Integrated circuit modeling",
                "Hardware security",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Hardware security",
                "hardware trojan",
                "machine learning",
                "natural language processing",
                "large language models",
                "open hardware",
                "open source"
            ]
        }
    },
    {
        "Title": "Smooth Trajectory Generation for Predefined Path With Pseudo Spectral Method",
        "Link": "https://ieeexplore.ieee.org/document/9180338/",
        "Abstract": "In view of smooth trajectory generation for a 3-axis machine tool, many methods have been presented. Among them, the optimal control based method is increasingly concerned, because it is considered to be able to make full use of kinematic abilities of machine tools. Under the unified framework of optimal control, the feedrate can be adjusted flexibly by adding or removing axial constraints and tangential constraints. But the problem of smooth trajectory generation (PSTG) based on optimal control for a machine tool is not easily to be solved. In this article, to efficiently solve the PSTG, it is divided into two sub-problems: the problem of minimum time trajectory planning (PMTTP) and the pseudo problem of smooth trajectory generation (PPSTG). Since both sub-problems are convex, the existence of unique solutions can be guaranteed. Then, the PMTTP and the PPSTG are transformed into nonlinear programming (NLP) problems with radau-pseudo-spectral (RPM) method successively. Due to convexity, the two NLP problems can be efficiently solved with mature optimization methods. In addition, the RPM method allows two sub-problems to have different Legendre-Gauss-Radau (LGR) points, thereby further saving computational costs. Finally, three different predefined paths are employed to test the proposed method, and simulation results show the effectiveness of proposed method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3020297",
            "Date of Publication": "31 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kai Zhao",
                "labs": [
                    "College of Control Science and Engineering, China University of Petroleum (East China), Qingdao, China",
                    "College of Computer Science and Information Engineering, Anyang Institute of Technology, Anyang, China"
                ]
            },
            {
                "name": "Zhongjian Kang",
                "labs": [
                    "College of New Energy, China University of Petroleum (East China), Qingdao, China"
                ]
            },
            {
                "name": "Xiaobo Guo",
                "labs": [
                    "College of Computer Science and Information Engineering, Anyang Institute of Technology, Anyang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimal control",
                "Trajectory",
                "Machining",
                "Machine tools",
                "Planning",
                "Splines (mathematics)",
                "Optimization"
            ],
            "Author Keywords": [
                "Trajectory planning",
                "numerical solution",
                "pseudo spectral method",
                "optimal control"
            ]
        }
    },
    {
        "Title": "Paraphrase Identification With Deep Learning: A Review of Datasets and Methods",
        "Link": "https://ieeexplore.ieee.org/document/10946892/",
        "Abstract": "The rapid advancement of Natural Language Processing (NLP) has greatly improved text-generation tools like ChatGPT and Claude, offering significant utility but also posing risks to media credibility through paraphrased plagiarism—a subtle yet widespread form of content misuse. Despite progress in automated paraphrase detection, inconsistencies in training datasets often limit their effectiveness. This study examines traditional and modern approaches to paraphrase identification, revealing how the under-representation of certain paraphrase types in widely-used datasets, including those for training Large Language Models (LLMs), undermines plagiarism detection accuracy. To address these issues, we introduce and validate ReParaphrased, a refined paraphrase typology, and extend the Extended Typology Paraphrase Corpus (ETPC) with meticulous manual annotations to enhance reliability. Using the augmented ETPC, we fine-tune the LLama3.1-7B-instruct model, uncovering significant disparities in paraphrase type distribution across existing datasets. A detailed analysis of the MRPC benchmark dataset further highlights critical distributional issues and their implications. We propose four key solutions to address dataset limitations, providing both theoretical and practical guidance for improving dataset quality. These contributions aim to establish a more robust foundation for NLP model training and evaluation. Finally, we outline future research directions and suggest improvements for dataset development to advance AI-driven paraphrase detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3556899",
            "Date of Publication": "01 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chao Zhou",
                "labs": [
                    "SingularDance, Shanghai, China"
                ]
            },
            {
                "name": "Cheng Qiu",
                "labs": [
                    "College of Arts and Science, Vanderbilt University, Nashville, TN, USA"
                ]
            },
            {
                "name": "Lizhen Liang",
                "labs": [
                    "School of Information Science, Syracuse University, Syracuse, NY, USA"
                ]
            },
            {
                "name": "Daniel E. Acuna",
                "labs": [
                    "Department of Computer Science, University of Colorado at Boulder, Boulder, CO, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Training",
                "Natural language processing",
                "Deep learning",
                "Sports",
                "Reviews",
                "Plagiarism",
                "Electronic mail",
                "Syntactics",
                "Switches"
            ],
            "Author Keywords": [
                "Paraphrase identification",
                "deep learning",
                "review",
                "plagiarism",
                "datasets"
            ]
        }
    },
    {
        "Title": "Comprehensive Readability Assessment of Scientific Learning Resources",
        "Link": "https://ieeexplore.ieee.org/document/10132466/",
        "Abstract": "Readability is the measure of how easier a piece of text is. Readability assessment plays a crucial role in facilitating content writers and proofreaders to receive guidance about how easy or difficult a piece of text is. In literature, classical readability, lexical measures, and deep learning based model have been proposed to assess the text readability. However, readability assessment using machine and deep learning is a data-intensive task, which requires a reasonable-sized dataset for accurate assessment. While several datasets, readability indices (RI) and assessment models have been proposed for military agencies manuals, health documents, and early educational materials, studies related to the readability assessment of computer science literature are limited. To address this gap, we have contributed Computer science (CS) literature dataset AGREE, comprising 42,850 learning resources(LR). We assessed the readability of learning objects(LOs) pertaining to domains of Computer Science (CS), machine learning (ML), software engineering (SE), and natural language processing (NLP). LOs consists of research papers, lecture notes and Wikipedia content of topics list of learning repositories for CS, NLP, SE and ML in English Language. From the statistically significant sample of LOs two annotators manually annotated LO’s text difficulty and established gold standard. Text readability was computed using 14 readability Indices (RI) and 12 lexical measures (LM). RI were ensembled, and readability measures were used to train the model for readability assessment. The results indicate that the extra tree classifier performs well on the AGREE dataset, exhibiting high accuracy, F1 score, and efficiency. We observed that there is no consensus among readability measures for shorter texts, but as the length of the text increases, the accuracy improves. The AGREE and SELRD datasets, along with the associated readability measures, provide a novel contribution to the field. They can be used to train deep learning models for readability assessment, develop recommender systems, and assist in curriculum planning within the domain of Computer Science. In the future, we plan to scale AGREE by adding more LOs and adding multimedia LOs. In addition, we would explore the use of deep learning methods for improved readability assessment.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3279360",
            "Date of Publication": "24 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muddassira Arshad",
                "labs": [
                    "Department of Computer Science, University of the Punjab, Lahore, Pakistan",
                    "Department of Software Engineering, University of the Punjab, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Murtaza Yousaf",
                "labs": [
                    "Department of Software Engineering, University of the Punjab, Lahore, Pakistan"
                ]
            },
            {
                "name": "Syed Mansoor Sarwar",
                "labs": [
                    "University of Engineering and Technology, Lahore, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer science",
                "Software engineering",
                "Indexes",
                "Deep learning",
                "Extraterrestrial measurements",
                "Computational modeling",
                "Readability metrics"
            ],
            "Author Keywords": [
                "Automated readability index",
                "CS learning resource repository",
                "Flesch Kincaid reading ease",
                "Flesch Kincaid grade index",
                "gunning fog readability index",
                "lexical diversity",
                "lexical richness",
                "lexical chains",
                "Lix",
                "new Dale-Chall",
                "readability assessment",
                "readability gold standard for CS learning objects"
            ]
        }
    },
    {
        "Title": "Chinese Medical Named Entity Recognition Based on Fusion of Global Features and Multi-Local Features",
        "Link": "https://ieeexplore.ieee.org/document/10343147/",
        "Abstract": "Chinese medical Named Entity Recognition (NER) is a task of Natural Language Processing (NLP), which aims to extract key information from Chinese medical texts. Recently, Transformer becomes the mainstream approach for NLP due to its powerful capability for global feature extraction. However, entities usually appear in the form of subsequences in NER, therefore the local features are not negligible, and the uncertainty of Chinese word segmentation increases the difficulty of this task. In this paper, we propose a network structure that combines global feature extraction and multi-local feature extraction to enhance the performance of Chinese medical NER. Based on the global feature extracted by the Transformer, Bi-LSTM is used to extract the multi-local features, and a context integration mechanism is used to enhance local features by integrating both forward and backward global contexts in each cell. This allows for a more comprehensive representation of individual cells. And a feature fusion method based on attention mechanism is proposed, which allows the decoder to better focus on the more important information for predicting the current character. During the global feature extraction, the flat-lattice structure is introduced to generate all the potential results of Chinese word segmentation. And the span-based relative positional encoding integrates direction and distance perception, which overcomes the shortcoming of Transformer’s inability to capture sequential characteristics. Finally, a CRF with conditional constraints is used as the decoder of the model. Experimental results on two benchmark datasets show the effectiveness of our model, and the method significantly outperforms the state-of-the-art methods in the medical NER task, achieving\nF1\nvalue of 93.64% on CCKS2017 and 85.01% on CCKS2019.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3339610",
            "Date of Publication": "05 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Huarong Sun",
                "labs": [
                    "Key Laboratory of Instrumentation Science and Dynamic Measurement of Ministry of Education, North University of China, Taiyuan, China"
                ]
            },
            {
                "name": "Jianfeng Wang",
                "labs": [
                    "School of Software, Taiyuan University of Technology, Taiyuan, China"
                ]
            },
            {
                "name": "Bo Li",
                "labs": [
                    "School of Software, North University of China, Taiyuan, China"
                ]
            },
            {
                "name": "Xiyuan Cao",
                "labs": [
                    "Key Laboratory of Instrumentation Science and Dynamic Measurement of Ministry of Education, North University of China, Taiyuan, China"
                ]
            },
            {
                "name": "Junbin Zang",
                "labs": [
                    "Key Laboratory of Instrumentation Science and Dynamic Measurement of Ministry of Education, North University of China, Taiyuan, China"
                ]
            },
            {
                "name": "Chenyang Xue",
                "labs": [
                    "Key Laboratory of Instrumentation Science and Dynamic Measurement of Ministry of Education, North University of China, Taiyuan, China"
                ]
            },
            {
                "name": "Zhidong Zhang",
                "labs": [
                    "Key Laboratory of Instrumentation Science and Dynamic Measurement of Ministry of Education, North University of China, Taiyuan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Transformers",
                "Feature extraction",
                "Hidden Markov models",
                "Encoding",
                "Context modeling",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Chinese medical named entity recognition",
                "relative positional encoding",
                "feature fusion",
                "lattice structure"
            ]
        }
    },
    {
        "Title": "Priority-based Residential Demand Response for Alleviating Crowding in Distribution Systems",
        "Link": "https://ieeexplore.ieee.org/document/9861344/",
        "Abstract": "The dynamic pricing environment offers flexibility to the consumers to reschedule their switching appliances. Though the dynamic pricing environment results in several benefits to the utilities and consumers, it also poses some challenges. The crowding among residential customers is one of such challenges. The scheduling of loads at low-cost intervals causes crowding among residential customers, which leads to a fall in voltage of the distribution system below its prescribed limits. In order to prevent crowding phenomena, this paper proposes a priority-based demand response program for local energy communities. In the program, past contributions made by residential houses and demand are considered as essential parameters while calculating the priority factor. The non-linear programming (NLP) model proposed in this study seeks to reschedule loads at low-cost intervals to alleviate crowding phenomena. Since the NLP model does not guarantee global optima due to its non-convex nature, a second-order cone programming model is proposed, which captures power flow characteristics and guarantees global optimum. The proposed formulation is solved using General Algebraic Modeling System (GAMS) software and is tested on a 12.66 kV IEEE 33-bus distribution system, which demonstrates its applicability and efficacy.",
        "Details": {
            "DOI": "10.35833/MPCE.2022.000034",
            "Date of Publication": "17 August 2022",
            "Publisher": "SGEPRI",
            "Published In": "Journal of Modern Power Systems and Clean Energy"
        },
        "issn_info": {
            "Print ISSN": "2196-5625",
            "Electronic ISSN": "2196-5420"
        },
        "authors_data": [
            {
                "name": "Venkateswarlu Gundu",
                "labs": [
                    "Department of Computer Science and Engineering, Koneru Lakshmaiah Education Foundation Guntur, Guntur, India"
                ]
            },
            {
                "name": "Sishaj P. Simon",
                "labs": [
                    "Department of Electrical and Electronics Engineering, National Institute of Technology Tiruchirappalli, Tiruchirappalli, India"
                ]
            },
            {
                "name": "Vemalaiah Kasi",
                "labs": [
                    "Department of Electrical Engineering (EED), Indian Institute of Technology Roorkee (IITR), Roorkee, India"
                ]
            },
            {
                "name": "Narayana Prasad Padhy",
                "labs": [
                    "Department of Electrical Engineering (EED), Indian Institute of Technology Roorkee (IITR), Roorkee, India"
                ]
            },
            {
                "name": "Dheeraj Kumar Khatod",
                "labs": [
                    "Department of Electrical Engineering (EED), Indian Institute of Technology Roorkee (IITR), Roorkee, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Voltage",
                "Indexes",
                "Reactive power",
                "Pricing",
                "Load modeling",
                "Power system dynamics",
                "Demand response"
            ],
            "Author Keywords": [
                "Crowding strategy",
                "demand response",
                "distribution system",
                "General Algebraic Modeling System (GAMS)",
                "local energy community",
                "second-order cone programming"
            ]
        }
    },
    {
        "Title": "TCNAEC: Advancing Sentence-Level Revision Evaluation Through Diverse Non-Native Academic English Insights",
        "Link": "https://ieeexplore.ieee.org/document/10360122/",
        "Abstract": "In the domain of Natural Language Processing (NLP), the English Writing Fluency Improvement for non-native speakers, particularly in academic contexts, poses significant challenges. While Sentence-level Revision (SentRev) endeavors to address this concern, the existing evaluation corpus, SMITH, falls short in offering a robust and comprehensive assessment of the task. To bridge this gap, our research offers a novel evaluation corpus generation scheme, leading to the creation of Ten-Country Non-native Academic English Corpus (TCNAEC). A meticulous analysis revealed the superior characteristics of TCNAEC over SMITH in various dimensions. Our evaluation also uncovered intriguing linguistic phenomena, offering valuable insights for fellow researchers. In contrast, the Grammatical Error Correction (GEC) task, which shares similarities with SentRev, has been more extensively explored, resulting in a richer set of training and evaluation corpora. However, the distinctive attributes of SentRev present a heightened challenge in NLP implementation. The TCNAEC, representing ten countries, captures the unique English expression styles of non-native speakers worldwide, offering a more holistic view compared to the Japan-centric SMITH. Furthermore, while SMITH primarily revolves around computational linguistics, TCNAEC spans multiple disciplines, accentuating its comprehensiveness. The construction strategy of TCNAEC, ensuring semantic consistency between Draft and Reference, emphasizes meaningful structural variations, reflecting the stylistic disparities between non-academic and academic texts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3342862",
            "Date of Publication": "14 December 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhendong Du",
                "labs": [
                    "Graduate School of Information, Production and Systems, Waseda University, Fukuoka, Japan"
                ]
            },
            {
                "name": "Kenji Hashimoto",
                "labs": [
                    "Graduate School of Information, Production and Systems, Waseda University, Fukuoka, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Writing",
                "Linguistics",
                "Symbols",
                "Semantics",
                "Chatbots",
                "Training data",
                "Natural language processing",
                "Text processing"
            ],
            "Author Keywords": [
                "Evaluation corpus",
                "linguistic phenomena",
                "natural language generation",
                "non-native academic English",
                "sentence-level revision"
            ]
        }
    },
    {
        "Title": "Speeding up Gaussian Belief Space Planning for Underwater Robots Through a Covariance Upper Bound",
        "Link": "https://ieeexplore.ieee.org/document/8788534/",
        "Abstract": "Existing belief space motion planning methods are not efficient for underwater robots that are subject to spatially varying motion and sensing uncertainties arising from the non-uniform current disturbances and landmark populations, respectively. Based on a closed-loop stochastic control framework, we propose a fast Gaussian belief space planning approach for coupled optimization of trajectory, localization and control, resulting in a non-linear programming problem (NLP). In particular, as opposed to advancing the covariance by a Kalman filter in the existing literature, we utilize an upper bound of the trace propagation of the covariance, thereby avoiding to solve Riccati equations and thus, reducing the computational complexity. The NLP is then efficiently solved by sequential quadratic programming based on the initial solutions obtained from RRT-connect. These initials lie in multiple homotopy classes guaranteed by H-signature discrimination, leading to global optimality with probability one as the number of samples in RRT-connect goes to infinity. Numerical simulations on holonomic and non-holonomic autonomous underwater vehicles (AUVs) and an Intervention-AUV with a manipulator in cluttered underwater environments demonstrate that optimal and collision-free trajectories with low localization uncertainty are obtained efficiently.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2933067",
            "Date of Publication": "05 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Huan Yu",
                "labs": [
                    "Centre for Autonomous Systems, University of Technology Sydney, Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Wenjie Lu",
                "labs": [
                    "Centre for Autonomous Systems, University of Technology Sydney, Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Dikai Liu",
                "labs": [
                    "Centre for Autonomous Systems, University of Technology Sydney, Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Yongqiang Han",
                "labs": [
                    "School of Automation, Beijing Institute of Technology, Beijing, China"
                ]
            },
            {
                "name": "Qinghe Wu",
                "labs": [
                    "School of Automation, Beijing Institute of Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Planning",
                "Uncertainty",
                "Aerospace electronics",
                "Trajectory",
                "Sensors",
                "Task analysis",
                "Unmanned underwater vehicles"
            ],
            "Author Keywords": [
                "Underwater robots",
                "motion planning",
                "belief space",
                "localization uncertainty",
                "stochastic control"
            ]
        }
    },
    {
        "Title": "Applications of Pruning Methods in Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10552272/",
        "Abstract": "Deep neural networks (DNN) are in high demand because of their widespread applications in natural language processing, image processing, and a lot of other domains. However, due to their computational expense, over-parameterization, and large memory requirements, DNN applications often require the use of substantial model resources. This strict requirement of latency and limited memory availability are hurdles in the device deployment of these technologies. Therefore, a common idea could be to mitigate the DNN-based models’ size without any performance degradation using different compression techniques. During the last few years, a great deal of progress has been made in the field of Natural Language Processing (NLP) using deep learning approaches. The objective of this research is to offer a thorough overview of the various pruning methods applied in the context of NLP. In this paper, we review several recent pruning-based schemes used for converting standard networks into their compact and accelerated versions. Traditionally, pruning is a technique for improving latency, reducing model size, and computational complexity which is a viable approach to deal with the above-mentioned challenges. In general, these techniques are divided into two main categories: structural and unstructured pruning methods. Structural pruning methods are further classified into filter, channel, layer, block, and movement pruning. Whereas, neuron, magnitude-based, and iterative pruning lie in the category of unstructured pruning. For each method, we discuss the related metrics and benchmarks. Then recent work on each method is discussed in detail, which provides insightful analysis of the performance, related applications, and pros and cons. Then, a comparative analysis is provided to analyze the differences among approaches. Finally, the paper concludes with possible future directions and some technical challenges.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3411776",
            "Date of Publication": "10 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marva Touheed",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Urooj Zubair",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Dilshad Sabir",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Ali Hassan",
                "labs": [
                    "Department of Computer and Software Engineering, College of Electrical and Mechanical Engineering, National University of Sciences and Technology, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Fasih Uddin Butt",
                "labs": [
                    "Department of Electrical and Computer Engineering, COMSATS University Islamabad, Islamabad, Pakistan",
                    "Next-Generation Communications Research Group, COMSATS University Islamabad, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Farhan Riaz",
                "labs": [
                    "School of Computer Science, College of Health and Science, University of Lincoln, Lincoln, U.K."
                ]
            },
            {
                "name": "Wadood Abdul",
                "labs": [
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Rashid Ayub",
                "labs": [
                    "Department of Science Technology and Innovation, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Data models",
                "Task analysis",
                "Neural networks",
                "Training",
                "Sentiment analysis",
                "Natural language processing",
                "Convolutional neural networks",
                "Artificial neural networks"
            ],
            "Author Keywords": [
                "Pruning",
                "convolution neural networks",
                "natural language processing",
                "DNN",
                "model compression",
                "acceleration"
            ]
        }
    },
    {
        "Title": "How Do Crowd-Users Express Their Opinions Against Software Applications in Social Media? A Fine-Grained Classification Approach",
        "Link": "https://ieeexplore.ieee.org/document/10591990/",
        "Abstract": "App stores allow users to search, download, and purchase software applications to accomplish daily tasks. Also, they enable crowd-users to submit textual feedback or star ratings to the downloaded software apps based on their satisfaction. Recently, crowd-user feedback contains critical information for software developers, including new features, issues, non-functional requirements, etc. Previously, identifying software bugs in low-star software applications was ignored in the literature. For this purpose, we proposed a natural language processing-based (NLP) approach to recover frequently occurring software issues in the Amazon Software App (ASA) store. The proposed approach identified prevalent issues using NLP part-of-speech (POS) analytics. Also, to better understand the implications of these issues on end-user satisfaction, different machine learning (ML) algorithms are used to identify crowd-user emotions such as anger, fear, sadness, and disgust with the identified issues. To this end, we shortlisted 45 software apps with comparatively low ratings from the ASA Store. We investigated how crowd-users reported their grudges and opinions against the software applications using the grounded theory & content analysis approaches and prepared a grounded truth for the ML experiments. ML algorithms, such as MNB, LR, RF, MLP, KNN, AdaBoost, and Voting Classifier, are used to identify the associated emotions with each captured issue by processing the annotated end-user data set. We obtained satisfactory classification results, with MLP and RF classifiers having 82% and 80% average accuracies, respectively. Furthermore, the ROC curves for better-performing ML classifiers are plotted to identify the best-performing under or oversampling classifier to be selected as the final best classifier. Based on our knowledge, the proposed approach is considered the first step in identifying frequently occurring issues and corresponding end-user emotions for low-ranked software applications. The software vendors can utilize the proposed approach to improve the performance of low-ranked software apps by incorporating it into the software evolution process promptly.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3425830",
            "Date of Publication": "10 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nek Dil Khan",
                "labs": [
                    "Faculty of Information Technology, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Javed Ali Khan",
                "labs": [
                    "Department of Computer Science, School of Physics, Engineering and Computer Science, University of Hertfordshire, Hatfield, U.K."
                ]
            },
            {
                "name": "Jianqiang Li",
                "labs": [
                    "Faculty of Information Technology, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Tahir Ullah",
                "labs": [
                    "Department of Software Engineering, University of Science and Technology Bannu, Bannu, Pakistan"
                ]
            },
            {
                "name": "Ayed Alwadain",
                "labs": [
                    "Computer Science Department, Community College, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Affan Yasin",
                "labs": [
                    "School of Software, Northwestern Polytechnical University, Xi’an, Shaanxi, China"
                ]
            },
            {
                "name": "Qing Zhao",
                "labs": [
                    "Faculty of Information Technology, Beijing University of Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Computer bugs",
                "Social networking (online)",
                "Software algorithms",
                "Blogs",
                "Data mining",
                "User experience"
            ],
            "Author Keywords": [
                "User reviews",
                "app store analytics",
                "software issues",
                "bug reports",
                "data-driven requirements"
            ]
        }
    },
    {
        "Title": "Robust Next-Day Scheduling of PV Generation Sources Supplying a Standalone DC Microgrid via a Semi-Definite Programming Model",
        "Link": "https://ieeexplore.ieee.org/document/10589696/",
        "Abstract": "This study focuses on optimizing the efficient operation of standalone direct-current (DC) microgrids with photovoltaic (PV) sources using semi-definite programming (SDP) optimization. The PV source operation model is formulated as a nonlinear programming (NLP) problem with the objective of minimizing daily energy losses and reducing CO2 emissions compared to diesel generators. Transforming the NLP model into convex optimization involves a linear matrix model that combines positive semi-definite matrices with an affine space. This approach enhances robustness by incorporating uncertainties in demand and PV source power. The robust SDP model employs a min–max strategy for worst-case scenario energy management dispatch (EMD). Evaluating a 27-bus standalone DC microgrid, the SDP model outperforms random-based algorithms by achieving global optima in both objectives. Under uncertainties, the energy loss objective increases by 21.6706% with demand uncertainty, 0.3997% with PV source uncertainty, and 22.2009% with both. Meanwhile, the CO2 emissions objective increases by 11.9184%, 1.8237%, and 14.0045%, respectively. Additional simulations on an 85-node DC network confirm the efficacy of SDP in worst-case scenario EMD. All simulations utilized MATLAB’s Yalmip tool with the Mosek solver.",
        "Details": {
            "DOI": "10.1109/OAJPE.2024.3425374",
            "Date of Publication": "09 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Access Journal of Power and Energy"
        },
        "issn_info": {
            "Electronic ISSN": "2687-7910"
        },
        "authors_data": [
            {
                "name": "Walter Gil-González",
                "labs": [
                    "Grupo de Campos Electromagnéticos y Fenómenos Energéticos (CAFE), Facultad de Ingeniería, Universidad Tecnológica de Pereira, Pereira, Colombia"
                ]
            },
            {
                "name": "Oscar Danilo Montoya",
                "labs": [
                    "Grupo de Compatibilidad e Interferencia Electromagnética (GCEM), Facultad de Ingeniería, Universidad Distrital Francisco José de Caldas, Bogotá, Colombia"
                ]
            },
            {
                "name": "Luis F. Grisales-Noreña",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering, Universidad de Talca, Curico, Chile"
                ]
            },
            {
                "name": "Fabio Andrade",
                "labs": [
                    "Electrical and Computer Engineering Department, University of Puerto Rico at Mayagüez, Mayagüez, PR, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Uncertainty",
                "Costs",
                "Microgrids",
                "Energy loss",
                "Programming",
                "Metaheuristics",
                "Energy management",
                "Energy consumption",
                "Photovoltaic systems"
            ],
            "Author Keywords": [
                "Robust semi-definite programming optimization",
                "daily energy losses",
                "energy management dispatch",
                "standalone direct-current microgrids",
                "photovoltaic plants",
                "carbon dioxide emissions"
            ]
        }
    },
    {
        "Title": "UniRaG: Unification, Retrieval, and Generation for Multimodal Question Answering With Pre-Trained Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10535103/",
        "Abstract": "Multimodal Question Answering (MMQA) has emerged as a challenging frontier at the intersection of natural language processing (NLP) and computer vision, demanding the integration of diverse modalities for effective comprehension and response. While pre-trained language models (PLMs) exhibit impressive performance across a range of NLP tasks, the investigation of text-based approaches to address MMQA represents a compelling and promising avenue for further research and advancement in the field. Although recent research has delved into text-based approaches for MMQA, the attained results have been unsatisfactory, which could be attributed to potential information loss during the knowledge transformation processes. In response, a novel three-stage framework named UniRaG is proposed for tackling MMQA, which encompasses unified knowledge representation, context retrieval, and answer generation. At the initial stage, advanced techniques are employed for unified knowledge representation, including LLaVA for image captioning and table linearization for tabular data, facilitating seamless integration of visual and tabular information into textual representation. For context retrieval, a cross-encoder trained on sequence classification is utilized to predict relevance scores for question-document pairs, and a top-k retrieval strategy is employed to retrieve the documents with the highest relevance scores as the contexts for answer generation. Finally, the answer generation stage is facilitated by a text-to-text PLM, Flan-T5-Base, which follows the encoder-decoder architecture with attention mechanisms. During this stage, uniform prefix conditioning is applied to the input text for enhanced adaptability and generalizability. Moreover, contextual diversity training is introduced to improve model robustness by including distractor documents as negative contexts during training. Experimental results on the MultimodalQA dataset demonstrate the superior performance of UniRaG, surpassing the existing state-of-the-art methods across all scenarios with 67.4% EM and 71.3% F1. Overall, UniRaG showcases robustness and reliability in MMQA, heralding significant advancements in multimodal comprehension and question answering research.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3403101",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qi Zhi Lim",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Chin Poo Lee",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Kian Ming Lim",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Ahmad Kamsani Samingan",
                "labs": [
                    "Telekom Research and Development Sdn. Bhd., Cyberjaya, Selangor, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Question answering (information retrieval)",
                "Visualization",
                "Context modeling",
                "Training",
                "Task analysis",
                "Knowledge representation",
                "Cognition",
                "Computer vision",
                "Information retrieval",
                "Natural language processing",
                "Knowledge representation"
            ],
            "Author Keywords": [
                "Computer vision",
                "information retrieval",
                "multimodal question answering",
                "natural language processing",
                "pre-trained language models",
                "unified knowledge representation"
            ]
        }
    },
    {
        "Title": "Click-Based Representation Learning Framework of Student Navigational Behavior in MOOCs",
        "Link": "https://ieeexplore.ieee.org/document/10649574/",
        "Abstract": "Predictive learning outcomes’ models for online students can provide useful information to instructors to estimate students’ final performance in the early stages of a course. Anticipating student performance can improve learning efficiency. Existing research models that analysed student data have focused on handcrafted features, but these models have limitations in exploring new behavioral patterns that indicate student performance and how they can be used in online courses. The clickstream data contains a significant amount of information that accurately describes students’ learning processes, which makes it difficult to construct using hand-crafted features. To analyze student behavior effectively, we attempted to capture critical knowledge from the field of natural language processing (NLP) to the field of student performance prediction in Massive Open Online Courses (MOOCs), owing to how closely they resemble each other. In this article, we propose a novel framework for automatically producing useful data representation that enhances prediction outcomes using student learning behavior clickstream data with a self-supervised learning approach. First, we developed a self-supervised clickstream pre-training setup to model learner click generation. Second, we adjusted these latent representations before applying them to a downstream supervised learning task. Extensive experimental results on two real-world datasets demonstrated that the proposed approach is effective. The combined approach of skip-gram embeddings with Principal Component Analysis (PCA) achieved the highest accuracy, particularly on the Xutangx dataset, with an accuracy of approximately 72.70% and an F1-score of approximately 81.03%. Furthermore, when applied to the KDDCUP dataset, this methodology exhibited even higher performance, with an accuracy of 80.91% and an F1-score of 87.42%. Our results showed the potential of NLP techniques to improve dropout prediction in MOOCs by extracting informative representations from clickstream data, allowing a deeper understanding of student behavior, and facilitating early intervention strategies.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3450514",
            "Date of Publication": "27 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shrooq Al Amoudi",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Areej Alhothali",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Rsha Mirza",
                "labs": [
                    "Department of Computer Science, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Hussein Assalahi",
                "labs": [
                    "English Language Institute, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Tahani Aldosemani",
                "labs": [
                    "College of Education, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Data models",
                "Predictive models",
                "Data mining",
                "Convolutional neural networks",
                "Vectors",
                "Natural language processing",
                "Representation learning",
                "Self-supervised learning"
            ],
            "Author Keywords": [
                "Student modeling",
                "representation learning",
                "self-supervised learning",
                "skip-gram model",
                "clickstream data",
                "MOOC"
            ]
        }
    },
    {
        "Title": "Examining the Characteristics of Practical Knowledge From Four Public Facebook Communities of Practice in Instructional Design and Technology",
        "Link": "https://ieeexplore.ieee.org/document/9867996/",
        "Abstract": "Instructional design and technology (IDT) professionals participate in communities of practice (CoPs) on Facebook to seek pedagogical and educational technology advice for solving instructional design (ID) problems. Much of the IDT literature has focused on formal educational environments and not on nonformal settings outside the classroom and beyond formal education. Further analysis of tacit or practical knowledge exchanged among community members is required to understand the purpose, functions, and organizational knowledge capital in online CoPs. To fill this gap, this study uses natural language processing (NLP) to analyze the practical knowledge of 6,066 anonymized users’ posts from four large public IDT CoPs on Facebook from September 2017 to September 2020 after cleaning the dataset. User posts were publicly available and required no password authentication for access, including Instructional Designer (4,717), Designers for Learning (228), Adobe Captivate Users (599), and Articulate Storyline (522). The proposed methodology aims to extract practical knowledge of individual online CoPs in three parts. First, the characteristics of written communication among members are extracted by calculating word and sentence lengths, word frequencies, and contiguous words. Second, the characteristics of members’ exchange of practical knowledge are obtained through sentiment identification, entity recognition, and relationships between pedagogical and educational technology entities. Third, the functions of individual online CoPs are developed through topic modeling with latent Dirichlet allocation (LDA) and BERTopic. The findings suggest similarities and differences among IDT CoPs, different resource distribution conventions, and members exchanging pedagogical and educational technology advice. The study highlights the need for pedagogical foundations to support instructional and technical decisions, mechanisms for self-assessment of practical knowledge concerning IDT competencies, community protocols for addressing misconceptions about learning, onboarding materials for new members, and new topic structures to classify practical knowledge. NLP tasks are implemented using Python libraries to support the future development of awareness tools.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3201893",
            "Date of Publication": "26 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Javier Leung",
                "labs": [
                    "School of Information Science and Learning Technologies, University of Missouri, Columbia, MO, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Data mining",
                "Electronic learning",
                "Syntactics",
                "Semantics",
                "Pandemics",
                "Online services",
                "Computer aided instruction",
                "Design methodology",
                "Educational technology"
            ],
            "Author Keywords": [
                "Data mining",
                "instructional design",
                "online learning",
                "communities of practice",
                "social media"
            ]
        }
    },
    {
        "Title": "QueryMintAI: Multipurpose Multimodal Large Language Models for Personal Data",
        "Link": "https://ieeexplore.ieee.org/document/10695061/",
        "Abstract": "QueryMintAI, a versatile multimodal Language Learning Model (LLM) designed to address the complex challenges associated with processing various types of user inputs and generating corresponding outputs across different modalities. The proliferation of diverse data formats, including text, images, videos, documents, URLs, and audio recordings, necessitates an intelligent system capable of understanding and responding to user queries effectively. Existing models often exhibit limitations in handling multimodal inputs and generating coherent outputs across different modalities. The proposed QueryMintAI framework leverages state-of-the-art language models such as GPT-3.5 Turbo, DALL-E-2, TTS-1 and Whisper v2 among others, to enable seamless interaction with users across multiple modalities. By integrating advanced natural language processing (NLP) techniques with domain-specific models, QueryMintAI offers a comprehensive solution for text-to-text, text-to-image, text-to-video, and text-to-audio conversions. Additionally, the system supports document processing, URL analysis, image description, video summarization, audio transcription, and database querying, catering to diverse user needs and preferences. The proposed model addresses several limitations observed in existing approaches, including restricted modality support, lack of adaptability to various data formats, and limited response generation capabilities. QueryMintAI overcomes these challenges by employing a combination of advanced NLP algorithms, deep learning architectures, and multimodal fusion techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3468996",
            "Date of Publication": "26 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ananya Ghosh",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology (VIT), Vellore, India"
                ]
            },
            {
                "name": "K. Deepa",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology (VIT), Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Accuracy",
                "Videos",
                "Natural language processing",
                "Computational modeling",
                "Adaptation models",
                "Deep learning",
                "Large language models",
                "Generative AI",
                "Open source software"
            ],
            "Author Keywords": [
                "Multimodal large language models",
                "generative AI",
                "private database",
                "Langchain",
                "OpenAI"
            ]
        }
    },
    {
        "Title": "From Pre-Training to Meta-Learning: A Journey in Low-Resource-Language Representation Learning",
        "Link": "https://ieeexplore.ieee.org/document/10288436/",
        "Abstract": "Language representation learning is a vital field in Natural Language Processing (NLP) that aims to capture the intricate semantics and contextual information of text. With the advent of deep learning and neural network architectures, representation learning has revolutionized the NLP landscape. However, the majority of research in this field has concentrated on resource-rich languages, putting Low-Resource Languages (LRL) at a disadvantage due to their limited linguistic resources and the absence of pre-trained models. This paper addresses the significance of language representation learning in a low-resource language, Greek, and its impact on various downstream tasks that heavily rely on semantically and contextually enriched language representations. Accurate classification requires an understanding of nuanced linguistic cues and contextual dependencies. Effective representations bridge the gap between raw text data and classification models, encoding semantic meaning, syntactic structures, and contextual information. By leveraging various representation learning techniques using Transformer-based Language Models (LM), such as domain-adaption and contrastive learning, we aim to enhance the performance of text classification in this LRL setting. We explore the challenges and opportunities in developing effective representations and propose a multi-stage LM pre-training and meta-learning approach to improve performance in classification downstream tasks. The proposed approach was evaluated on Greek expert-annotated texts from social media posts, news articles, press text clippings and internet articles such as blog posts and opinion pieces. The results show significant improvements in the classification effectiveness of each task in terms of micro-averaged F1-score in sentiment, irony, hate speech, emotion and three custom classification tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3326337",
            "Date of Publication": "20 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dimitrios Zaikis",
                "labs": [
                    "School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece"
                ]
            },
            {
                "name": "Ioannis Vlahavas",
                "labs": [
                    "School of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Representation learning",
                "Adaptation models",
                "Sentiment analysis",
                "Hate speech",
                "Context modeling",
                "Analytical models",
                "Classification algorithms",
                "Metalearning"
            ],
            "Author Keywords": [
                "Classification",
                "contrastive learning",
                "domain adaption",
                "Greek",
                "language models",
                "low resource language",
                "meta learning",
                "representation learning"
            ]
        }
    },
    {
        "Title": "Attention Retrieval Model for Entity Relation Extraction From Biological Literature",
        "Link": "https://ieeexplore.ieee.org/document/9721887/",
        "Abstract": "Natural Language Processing (NLP) has contributed to extracting relationships among biological entities, such as genes, their mutations, proteins, diseases, processes, phenotypes, and drugs, for a comprehensive and concise understanding of information in the literature. Self-attention-based models for Relationship Extraction (RE) have played an increasingly important role in NLP. However, self-attention models for RE are framed as a classification problem, which limits its practical usability in several ways. We present an alternative framework called the Attention Retrieval Model (ARM), which enhances the applicability of attention-based models compared to the regular classification approach, for RE. Given a text sequence containing related entities/keywords, ARM learns the association between a chosen entity/keyword with the other entities present in the sequence, using an underlying self-attention mechanism. ARM provides a flexible framework for a modeller to customise their model, facilitate data integration, and integrate expert knowledge to provide a more practical approach for RE. ARM can extract unseen relationships that are not annotated in the training data, analogous to zero-shot learning. To sum up, ARM provides an alternative self-attention-based deep learning framework for RE, that can capture directed entity relationships.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3154820",
            "Date of Publication": "25 February 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Prashant Srivastava",
                "labs": [
                    "Department of Systems Biology and Bioinformatics, Institute of Computer Science, University of Rostock, Rostock, Germany"
                ]
            },
            {
                "name": "Saptarshi Bej",
                "labs": [
                    "Department of Systems Biology and Bioinformatics, Institute of Computer Science, University of Rostock, Rostock, Germany",
                    "Leibniz-Institute for Food Systems Biology, Technical University of Munich, Freising, Germany"
                ]
            },
            {
                "name": "Kristian Schultz",
                "labs": [
                    "Department of Systems Biology and Bioinformatics, Institute of Computer Science, University of Rostock, Rostock, Germany"
                ]
            },
            {
                "name": "Kristina Yordanova",
                "labs": [
                    "Department of Systems Biology and Bioinformatics, Institute of Computer Science, University of Rostock, Rostock, Germany"
                ]
            },
            {
                "name": "Olaf Wolkenhauer",
                "labs": [
                    "Department of Systems Biology and Bioinformatics, Institute of Computer Science, University of Rostock, Rostock, Germany",
                    "Leibniz-Institute for Food Systems Biology, Technical University of Munich, Freising, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Proteins",
                "Task analysis",
                "Biology",
                "Annotations",
                "Data models",
                "Diseases"
            ],
            "Author Keywords": [
                "Attention models",
                "biological literature mining",
                "deep learning",
                "knowledge graphs"
            ]
        }
    },
    {
        "Title": "Img2Side: A Transfer Learning Based Model for Predicting Drug Side Effects Using 2D Chemical Structural Images",
        "Link": "https://ieeexplore.ieee.org/document/10483078/",
        "Abstract": "Drug Side Effects (DSE) are inconvenient and inadvertent retorts of the drugs. DSEs impact on public health and healthcare can prove costly. These DSEs can be an important factor in the failure/acceptance of drugs. Every approved drug should be either free from DSEs or these should be minor and reported properly. The drug discovery process should be capable of predicting and preventing these effects in advance. Previously, proposed studies for the prediction/prevention of DSEs utilized the features of 1D drug chemical structures or Natural Language Processing (NLP). Both these techniques required a complex transformation process. In this research authors have proposed a deep learning model, specifically using a transfer learning approach to predict DSEs directly from 2D chemical structure images, eliminating the need for the hefty transformation process of the NLP domain. For this study, a unique dataset is prepared that associates each image (taken from PubChem) with its specific side effects (SIDER). The results are evaluated using Accuracy, Precision, Recall and F-measure. The proposed model showed its dominance with an Accuracy of 73%, Precision of 83%, Recall of 73%, and an F1 score of 75%. The achieved results of the proposed model are compared against established transfer learning models like VGG16, DenseNet121 and some previously used traditional machine learning models like SVM and KNN. The collected results indicate a significant advancement in predicting drug side effects and offer a promising avenue for streamlining the drug development process.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3382936",
            "Date of Publication": "02 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Asad Arshed",
                "labs": [
                    "Faculty of Computing, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Muhammad Ibrahim",
                "labs": [
                    "Faculty of Computing, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Shahzad Mumtaz",
                "labs": [
                    "Faculty of Computing, The Islamia University of Bahawalpur, Bahawalpur, Pakistan",
                    "School of Natural and Computing Sciences, University of Aberdeen, Aberdeen, Scotland, U.K."
                ]
            },
            {
                "name": "Tenvir Ali",
                "labs": [
                    "Faculty of Computing, The Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Gyu Sang Choi",
                "labs": [
                    "School of Computer Science and Engineering, Yeungnam University, Gyeongsan, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Drugs",
                "Chemicals",
                "Predictive models",
                "Transfer learning",
                "Prediction algorithms",
                "Deep learning",
                "Biomedical imaging",
                "Behavioral sciences"
            ],
            "Author Keywords": [
                "Drug side effects",
                "drug 2D chemical structure images",
                "transfer learning",
                "fine tuning",
                "pretrained models",
                "deep learning"
            ]
        }
    },
    {
        "Title": "CzeGPT-2–Training New Model for Czech Generative Text Processing Evaluated With the Summarization Task",
        "Link": "https://ieeexplore.ieee.org/document/10453575/",
        "Abstract": "Automatic text summarization (ATS), alongside neural machine translation or question answering, is one of the leading tasks in Natural Language Processing (NLP). In recent years, ATS has experienced significant development, especially in the English NLP world. Modern approaches are mainly based on the versatile Transformer architecture proposed by Vaswani et al. in 2017, which has revolutionized the field, and was later tuned and adjusted to various needs of different tasks. Non-mainstream languages, with Czech taken as a representative, on the other hand, are a little bit behind these efforts and tend to use lighter or heuristic methods. With the new CzeGPT-2 model and abstractive summarizer, we would like to take a step forward detailing the process of training a GPT-2 generative transformer model for a new language with a comprehensive evaluation of the task of Czech summarization and pointing out the benefits of this approach. We also present an in-depth analysis of the errors in generated summaries, allowing to locate the model’s weak spots.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3371689",
            "Date of Publication": "29 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Adam Hájek",
                "labs": [
                    "Natural Language Processing Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic"
                ]
            },
            {
                "name": "Aleš Horák",
                "labs": [
                    "Natural Language Processing Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Training",
                "Measurement",
                "Transformers",
                "Decoding",
                "Computational modeling",
                "Vocabulary",
                "Natural language processing",
                "Modeling",
                "Performance evaluation",
                "Text analysis",
                "Text recognition",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "Czech",
                "GPT-2",
                "large language model",
                "model evaluation",
                "model training",
                "summarization"
            ]
        }
    },
    {
        "Title": "Collected Current by a Double Langmuir Probe Setup With Plasma Flow",
        "Link": "https://ieeexplore.ieee.org/document/10776030/",
        "Abstract": "The multineedle Langmuir probe (m-NLP) instrument, consisting of two or more fixed-bias cylindrical Langmuir probes, is designed to enhance data resolution, particularly for in situ measurement in space missions. However, like other spacecraft and instruments used in space missions, these probes may interact with the surrounding plasma, potentially leading to errors in plasma measurements. In this article, we investigate the interaction between a double Langmuir probe setup and plasma flow, specifically focusing on how the collected current on the probes is affected by the electric bias and varying distances between the probes. Results from Particle-in-Cell (PIC) simulations show that with a front probe and a rear probe aligned along the plasma flow, not only may the rear probe’s collected current be affected, but the entire system may also experience significant influences if the distance between probes is short. In particular, if both probes are positively biased, as in the m-NLP instrument, they will not significantly influence each other’s measurements if the distance between them is longer than 30 Debye lengths. We also employ test particle simulations to further illustrate the interaction between the double Langmuir probe system and its surrounding plasma.",
        "Details": {
            "DOI": "10.1109/TPS.2024.3501310",
            "Date of Publication": "03 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Plasma Science"
        },
        "issn_info": {
            "Print ISSN": "0093-3813",
            "Electronic ISSN": "1939-9375"
        },
        "authors_data": [
            {
                "name": "Chun-Sung Jao",
                "labs": [
                    "Department of Physics, National Cheng Kung University, Tainan, Taiwan"
                ]
            },
            {
                "name": "Wojciech J. Miloch",
                "labs": [
                    "Department of Physics, University of Oslo, Oslo, Norway"
                ]
            },
            {
                "name": "Yohei Miyake",
                "labs": [
                    "Graduate School of System Informatics, Kobe University, Kobe, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Probes",
                "Plasmas",
                "Electrons",
                "Extraterrestrial measurements",
                "Ions",
                "Space vehicles",
                "Mathematical models",
                "Space missions",
                "Numerical models",
                "Temperature measurement"
            ],
            "Author Keywords": [
                "Instruments-probes",
                "numerical simulation-plasma simulation",
                "plasmas-plasma measurements"
            ]
        }
    },
    {
        "Title": "Unstructured Electronic Health Records of Dysphagic Patients Analyzed by Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11006689/",
        "Abstract": "Objective: Dysphagia is a common and complex disorder that complicates both diagnoses and treatment. Consequently, the associated electronic health records (EHR) are often unstructured and complex, posing challenges for systematic data analysis.Methods and procedures: In this study, we employ natural language processing (NLP) techniques and large language models (LLMs) to automatically analyze clinical narratives and extract diagnostic information from a diverse set of EHRs. Our dataset includes medical records from 486 patients, representing a group with diverse dysphagic conditions. We analyze diagnoses provided in unstructured free text that do not follow a standardized structure. We utilize clustering algorithms on the extracted diagnostic features to identify distinct groups of patients who share similar pathophysiological swallowing dysfunctions.Results: We found that basic NLP techniques often provide limited insights due to the high variability of the data. In contrast, LLMs help to bridge the gap in understanding the nuanced medical information about dysphagia and related conditions. Although applying these advanced LLM models is not straightforward, our results demonstrate that leveraging closed-source models can effectively cluster different categories of dysphagia.Conclusion: Our study provides therefore evidence that LLMs are highly promising in future dysphagia research.Clinical impact: Dysphagia is a symptom associated with various diseases, though its underlying relationships remain unclear. This study demonstrates how analyzing large volumes of electronic health records can help clarify the causes of dysphagia and identify contributing factors. By applying natural language processing, we aim to enhance both understanding and treatment, supporting clinical staff in improving individualized care by identifying relevant patient cohorts. Clinical and Translational Impact Statement: This study uses LLMs to efficiently preprocess unstructured EHRs, improving dysphagia diagnosis and patient clustering. It aligns with Clinical Research, enhancing diagnostic speed and enabling personalized treatment.\nShow Less",
        "Details": {
            "DOI": "10.1109/JTEHM.2025.3571255",
            "Date of Publication": "19 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Translational Engineering in Health and Medicine"
        },
        "issn_info": {
            "Electronic ISSN": "2168-2372"
        },
        "authors_data": [
            {
                "name": "Luisa Neubig",
                "labs": [
                    "Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany"
                ]
            },
            {
                "name": "Deirdre Larsen",
                "labs": [
                    "Department of Communication Sciences and Disorders, East Carolina University, Greenville, NC, USA"
                ]
            },
            {
                "name": "Melda Kunduk",
                "labs": [
                    "Department of Communication Sciences and Disorders, Louisiana State University, Baton Rouge, LA, USA"
                ]
            },
            {
                "name": "Andreas M. Kist",
                "labs": [
                    "Department of Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Medical diagnostic imaging",
                "Natural language processing",
                "Translation",
                "Encoding",
                "Medical services",
                "Semantics",
                "Pathology",
                "Large language models",
                "Electronic medical records",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Dysphagia",
                "EHR",
                "clustering analysis",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "A Hybrid Neural-CRF Framework for Assamese Part-of-Speech Tagging",
        "Link": "https://ieeexplore.ieee.org/document/11162502/",
        "Abstract": "Natural Language Processing (NLP) involves computational techniques for analyzing and understanding human languages. Part-of-Speech (POS) tagging, a fundamental NLP task, assigns grammatical categories to words in text. The proposed research addresses the task of Part-of-Speech (POS) tagging for Assamese by integrating character-level embeddings into various neural architectures to handle the language’s complex morphology effectively. The study comparatively evaluates Conditional Random Fields (CRF), Hidden Markov Models (HMM), Long Short-Term Memory networks combined with CRF (LSTM-CRF), and Bidirectional LSTM-CRF (BiLSTM-CRF). Leveraging a comprehensive and manually annotated dataset consisting of 13,469 sentences with 213,087 tokens, the research employs the linguistically detailed LDCIL Assamese tagset developed by CIIL Mysore. Experimental results indicate that neural architectures substantially outperform traditional methods, with the BiLSTM-CRF model enhanced by character-level embeddings achieving the highest accuracy of 97.69%. These findings emphasize character-level embeddings’ critical role in elevating the performance of neural network-based POS tagging models compared to traditional CRF methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3609572",
            "Date of Publication": "12 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rituraj Phukan",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            },
            {
                "name": "Nomi Baruah",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            },
            {
                "name": "Mandira Neog",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            },
            {
                "name": "Shikhar KR. Sarma",
                "labs": [
                    "Gauhati University, Guwahati, India"
                ]
            },
            {
                "name": "Darpanjit Konwar",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hidden Markov models",
                "Tagging",
                "Accuracy",
                "Conditional random fields",
                "Natural language processing",
                "Deep learning",
                "Syntactics",
                "Mathematical models",
                "Linguistics",
                "Context modeling"
            ],
            "Author Keywords": [
                "Assamese",
                "Bi-LSTM",
                "CRF",
                "LSTM",
                "POS tagging"
            ]
        }
    },
    {
        "Title": "Idiomaticity Prediction of Chinese Noun Compounds and Its Applications",
        "Link": "https://ieeexplore.ieee.org/document/8853294/",
        "Abstract": "Idiomaticity refers to the situation where the meaning of a lexical unit cannot be derived from the usual meanings of its constituents. As a ubiquitous phenomenon in languages, the existence of idioms often causes significant challenges for semantic NLP tasks. While previous research mostly focuses on the idiomatic usage detection of English verb-noun combinations and the semantic analysis of Noun Compounds (NCs), the idiomaticity issues of Chinese NCs have been rarely studied. In this work, we aim at classifying Chinese NCs into four idiomaticity degrees. Each idiomaticity degree refers to a specific paradigm of how the NCs should be interpreted. To address this task, a Relational and Compositional Representation Learning model (RCRL) is proposed, which considers the relational textual patterns and the compositionality levels of Chinese NCs. RCRL learns relational representations of NCs to capture the semantic relations between two nouns within an NC, expressed by textual patterns and their statistical signals in the corpus. It further employs compositional representations to model the compositionality levels of NCs via network embeddings. Both loss functions of idiomaticity degree classification and representation learning are jointly optimized in an integrated neural network. Experiments over two datasets illustrate the effectiveness of RCRL, outperforming state-of-the-art approaches. Three applicational studies are further conducted to show the usefulness of RCRL and the roles of idiomaticity prediction of Chinese NCs in the fields of NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2944572",
            "Date of Publication": "30 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chengyu Wang",
                "labs": [
                    "School of Software Engineering, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Yan Fan",
                "labs": [
                    "Alibaba Group, Hangzhou, China"
                ]
            },
            {
                "name": "Xiaofeng He",
                "labs": [
                    "School of Computer Science and Technology, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Hongyuan Zha",
                "labs": [
                    "School of Computational Science and Engineering, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            },
            {
                "name": "Aoying Zhou",
                "labs": [
                    "School of Data Science and Engineering, East China Normal University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Compounds",
                "Task analysis",
                "Natural language processing",
                "Linguistics",
                "Solids"
            ],
            "Author Keywords": [
                "Representation learning",
                "idiomaticity prediction",
                "noun compound",
                "relational pattern",
                "compositionality analysis"
            ]
        }
    },
    {
        "Title": "Exploring the Effects of Personality Traits on Customer Perceived Value Based on Text Decomposition",
        "Link": "https://ieeexplore.ieee.org/document/10950447/",
        "Abstract": "Customer perceived value (CPV) is pivotal for hospitality competitiveness, but the impact of personality traits on CPV remains underexplored. This study examines how personality traits influence CPV in the hotel industry using advanced text mining and NLP techniques. By analyzing TripAdvisor reviews, we propose a framework that integrates LDA topic modeling, multi-level sentiment classification with an improved Doc2Vec-IOVO strategy, and a CNN-LIWC based personality trait recognition model to extract perceptual factors and infer reviewers’ Big Five personality traits. Our regression analysis reveals significant relationships between personality traits and CPV dimensions. Finally, we explore the predictive value of the personality measures. Incorporating new features into the model increases the recognition accuracy by up to 2.66%. Among the Big Five personality traits, extraversion, conscientiousness, and openness positively affect perceived value, whereas neuroticism has a negative effect. Extraversion and neuroticism exert a stronger influence than the other traits. The results demonstrate the significant predictive value of personality indicators. Compared with traditional surveys, NLP-based personality identification from online reviews offers a more efficient approach, enabling personalized recommendations to enhance customer satisfaction in the hotel industry.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3558374",
            "Date of Publication": "08 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zihan Jiang",
                "labs": [
                    "Jiangsu International Joint Informatics Laboratory, School of Information Management, Nanjing University, Qixia, Nanjing, China"
                ]
            },
            {
                "name": "Xuhui Zheng",
                "labs": [
                    "Jiangsu International Joint Informatics Laboratory, School of Information Management, Nanjing University, Qixia, Nanjing, China"
                ]
            },
            {
                "name": "Wei Yu",
                "labs": [
                    "Jiangsu International Joint Informatics Laboratory, School of Information Management, Nanjing University, Qixia, Nanjing, China"
                ]
            },
            {
                "name": "Junpeng Chen",
                "labs": [
                    "College of Information Engineering, Nanjing University of Finance & Economics, Qixia, Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Psychology",
                "Surveys",
                "Customer satisfaction",
                "Text mining",
                "Hands",
                "Analytical models",
                "Industries",
                "Consumer behavior",
                "Accuracy"
            ],
            "Author Keywords": [
                "Customer perceived value",
                "big five personality traits",
                "natural language processing",
                "text decomposition",
                "hospitality management"
            ]
        }
    },
    {
        "Title": "Automatic Identification of Amharic Text Idiomatic Expressions Using a Deep Learning Approach",
        "Link": "https://ieeexplore.ieee.org/document/10990222/",
        "Abstract": "Natural Language Processing (NLP) is a tract of artificial intelligence and linguistics devoted to making computers understand the statements or words written in human languages. Amharic, the most widely spoken language in Ethiopia, uses a lot of idiomatic expressions and proverbs to emphasize the message of the text. The meaning of an idiomatic phrase cannot be inferred from individual words. Developing a model to identify Amharic idiomatic terms is helpful for different NLP applications like machine translation, sentiment analysis, spam classification, intent recognition, and so on. Few studies have been conducted to identify idiomatic expressions using K-Nearest Neighbors (KNN) and Convolutional Neural Network (CNN) algorithms for the Amharic language. The KNN model was designed to identify only dual-word idioms by neglecting idioms with three or more words, and this study didn’t use the n-gram technique to identify idioms found in a sentence or paragraph. Like the former model, the CNN model did not use the n-gram technique, and the testing accuracy was not greater than 80%. Due to this gap, we need to develop a deep learning model that identifies Amharic idioms constructed from two or more words. To identify idioms found in a sentence or paragraph, we used the n-gram method to divide the sentence or the paragraph into phrases for enhancing the previous works. For designing our model, we used 4053 idiomatic phrases and 4051 literal Amharic phrases. After the data were collected, text preprocessing techniques were applied to the collected data, and FastText and Word2Vec models were used for word embedding purposes. We conducted experiments with 70:30 and 80:20 data split ratios with FastText and Word2Vec word embedding models along with long short-term memory (LSTM) and bidirectional LSTM (Bi-LSTM) with and without attention layer algorithms. Among those experiments, the highest accuracy of 98.95% was attained using an 80:20 train-test split ratio, Adamax optimizer, 64 batch sizes, and a 0.001 learning rate by using Bi-LSTM with an attention layer and FastText word embedding model.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3567811",
            "Date of Publication": "07 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Habtamu Hunegnaw Limenih",
                "labs": [
                    "Department of Information Technology, Debark University, Debark, Ethiopia"
                ]
            },
            {
                "name": "Abebe Belay Adege",
                "labs": [
                    "Department of Information Technology, Debre Markos University, Debre Markos, Ethiopia"
                ]
            },
            {
                "name": "Abrham Yaregal Alene",
                "labs": [
                    "Department of Information Technology, Debark University, Debark, Ethiopia"
                ]
            },
            {
                "name": "Habtamu Tariku Demasu",
                "labs": [
                    "Department of Information Technology, Debark University, Debark, Ethiopia"
                ]
            },
            {
                "name": "Habtamu Molla Belachew",
                "labs": [
                    "Department of Information Technology, Debark University, Debark, Ethiopia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Deep learning",
                "Nearest neighbor methods",
                "Testing",
                "Electronic mail",
                "Classification algorithms",
                "Information technology",
                "Training",
                "Machine translation",
                "Data models"
            ],
            "Author Keywords": [
                "Attention layer",
                "FastText",
                "grid search",
                "idiomatic terms",
                "n-gram",
                "Word2Vec"
            ]
        }
    },
    {
        "Title": "Assessing and Scoring Difficulty of Hard-to-Solve Data in Summarization Tasks",
        "Link": "https://ieeexplore.ieee.org/document/10806699/",
        "Abstract": "In recent years, data-driven and machine learning-based natural language processing (NLP) technologies have effectively addressed various challenges. To further enhance the performance of NLP models, it is crucial to understand the types of data that a model can handle well and those it struggles with. This study introduces a method to discern which types of data can be effectively processed by given neural network-based models and which pose difficulties. We define the criteria for hard-to-solve data, construct a pairwise easy-hard dataset, and propose a neural scoring model. This model ascertains the difficulty level of each data instance. To utilize the proposed difficulty level as an application, we employed curriculum learning. The experimental results show that our methodology can effectively distinguish between easy and hard data, and performance improves when applying the curriculum learning approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3519548",
            "Date of Publication": "18 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jeesu Jung",
                "labs": [
                    "Department of Computer Science and Engineering, Chungnam National University, Daejeon, South Korea"
                ]
            },
            {
                "name": "Hyein Seo",
                "labs": [
                    "Department of Computer Science and Engineering, Chungnam National University, Daejeon, South Korea"
                ]
            },
            {
                "name": "Hyuk Namgoong",
                "labs": [
                    "Department of Computer Science and Engineering, Chungnam National University, Daejeon, South Korea"
                ]
            },
            {
                "name": "Sangkeun Jung",
                "labs": [
                    "Department of Computer Science and Engineering, Chungnam National University, Daejeon, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Transformers",
                "Predictive models",
                "Monitoring",
                "Natural language processing",
                "Measurement",
                "Training data",
                "Testing",
                "Neural networks"
            ],
            "Author Keywords": [
                "Hard-to-solve",
                "data scoring",
                "model difficulty scoring"
            ]
        }
    },
    {
        "Title": "Beyond the Determiner “Al-”: Expanding the Determiner Class in Arabic, and Elimination of Lexical Ambiguities by Grammars",
        "Link": "https://ieeexplore.ieee.org/document/10973057/",
        "Abstract": "Arabic nouns can be marked for definiteness or indefiniteness. The definite article is the prefix “Al-,” which confines the determiner class to a single element “Al-.” This topic is generally discussed under noun inflections, such as Gender, Number, Definiteness, and Case (GNDC), in grammar textbooks. The primary aim of this paper is to expand the Arabic determiner class (DET) by incorporating additional lexical items and providing a detailed description of their syntactic context within noun phrases (NPs). In traditional grammar, these lexical items are typically classified as noun adjectives and, at best, are referred to as noun specifiers since they modify the head noun. However, these “nouns” exhibit limited inflection compared to regular adjectives and occupy a specific position within the NP sequence. Additionally, the modified head nouns are constrained in their inflectional attributes, Number, and Definiteness. Our approach is qualitative and guided by morpho-syntactic considerations. We conduct an in-depth analysis of the grammatical features of ten lexical items, focusing particularly on the dependencies between the determiner and the following noun. This analysis also addresses some semantic properties. By focusing on context-sensitive grammatical rules, the study shows how these methods can enhance precision in parsing and reduce ambiguity in NLP tasks, highlighting the potential for developing more refined grammar for Arabic. This work is a prototype for comprehensive studies in linguistics and NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3563414",
            "Date of Publication": "22 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Albatool Abalkheel",
                "labs": [
                    "Department of English Language and Literature, College of Languages and Humanities, Qassim University, Buraydah, Saudi Arabia"
                ]
            },
            {
                "name": "Alexis Amid Neme",
                "labs": [
                    "LIGM, Université Gustave Eiffel, Champs-sur-Marne, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Syntactics",
                "Semantics",
                "Linguistics",
                "Natural language processing",
                "Grammar",
                "Morphology",
                "Transformers",
                "Focusing",
                "Training",
                "Standards"
            ],
            "Author Keywords": [
                "Arabic",
                "corpus linguistics",
                "explainable AI",
                "large language model",
                "methodology",
                "natural language processing",
                "rule based systems",
                "syntax"
            ]
        }
    },
    {
        "Title": "Advancing Skin Disease Diagnosis: A Multimodal Approach Utilizing Telegram Api Token Chatbot for Text and Image Analysis in Skin Disease Classification",
        "Link": "https://ieeexplore.ieee.org/document/10798433/",
        "Abstract": "The human skin serves as a critical indicator of underlying health conditions, often manifesting early signs of disorders affecting internal organs. Recognizing these signs is crucial for timely diagnosis and treatment. However, the significance of the body’s natural defence mechanism through the skin is sometimes overlooked. This study aims to develop a skin disease classification system using a multimodal approach, integrating ensemble methodology using DenseNet169 – Resnet50 ensemble Transfer learning models, and Natural Language Processing (NLP) within a Telegram chatbot interface. The primary aim is to enhance the chatbot’s ability to deliver customised skin-related diagnoses by using user-provided information, including skin type, chemical exposure, and previous treatments, ensuring more precise and personalised interactions. Additionally, the accuracy and generalization capability of the classification system is improved by analysing the data from both the chatbot and image analysis. The chatbot’s self-learning capabilities allow it to improve its comprehension over time in response to user input, which makes it more adept at personalising queries. Integrating DenseNet169 and ResNet50 strengthens the feature reuse by connecting each layer to every other layer in a dense manner for efficient gradient flow thus reducing the number of parameters. ResNet50, with its residual connections, helps mitigate vanishing gradient issues, allowing for deeper networks with stable training leading to improved feature extraction and representation. This hybrid approach captures fine-grained global features enhancing the feature learning attaining good performance in complex tasks. A total of 11,747 images were evaluated in the proposed study, with 7,930 images allocated for training and validation, and 3,817 images designated for testing. The model attained an accuracy of 77.07% and an AUC score of 96.72%. The NLP training model achieved an accuracy of 93.62% ensuring a comprehensive understanding of user data and accelerating engagement, leading to more precise and personalized predictions of skin disorders.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3516884",
            "Date of Publication": "13 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Modigari Narendra",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "T. S. Harshini",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "L. Jani Anbarasi",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Skin",
                "Accuracy",
                "Diseases",
                "Chatbots",
                "Lesions",
                "Adaptation models",
                "Training",
                "Transfer learning",
                "Residual neural networks",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Multimodal approach",
                "convolutional neural networks",
                "transfer learning models",
                "self-learning chatbot",
                "natural language processing",
                "telegram API key"
            ]
        }
    },
    {
        "Title": "An Analytical Review of Preprocessing Techniques in Bengali Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/11016021/",
        "Abstract": "Research in Bengali Natural Language Processing (BNLP) is rapidly expanding. Despite being one of the most widely spoken languages in the world, BNLP research remains insufficient, particularly in Bengali speech recognition. The language’s rich morphology, agglutinative structure, and diverse dialects make text and speech processing especially challenging. However, these challenges can be addressed with effective preprocessing techniques. Various organizations in Bangladesh and West Bengal are integrating Natural Language Processing (NLP) into their services, but without a thorough understanding of preprocessing, these implementations remain incomplete. Applying proper preprocessing techniques to the Bengali language will serve as a foundation for developing robust NLP applications. This paper presents a comprehensive review of preprocessing techniques in BNLP based on state-of-the-art research. It covers key areas such as sentiment analysis, Named Entity Recognition, speech recognition, text categorization, and summarization. First, the paper provides an in-depth discussion of Bengali language characteristics and research areas in BNLP. It then explores the challenges faced by researchers in processing Bengali text and speech. Additionally, it details various preprocessing techniques, highlighting their advantages and disadvantages. Finally, the paper examines future directions for BNLP, emphasizing the role of effective preprocessing in advancing the field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574234",
            "Date of Publication": "27 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sovon Chakraborty",
                "labs": [
                    "C2SG Research Group, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Protiva Das",
                "labs": [
                    "C2SG Research Group, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Shakib Mahmud Dipto",
                "labs": [
                    "C2SG Research Group, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Aktaruzzaman Pramanik",
                "labs": [
                    "C2SG Research Group, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Jannatun Noor",
                "labs": [
                    "C2SG Research Group, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Natural language processing",
                "Social networking (online)",
                "Complexity theory",
                "Named entity recognition",
                "Text categorization",
                "Semantics",
                "Speech recognition",
                "Speech processing",
                "Text summarization"
            ],
            "Author Keywords": [
                "Bengali language datasets",
                "dialects",
                "BNLP",
                "literature preservation",
                "machine translation",
                "sentiment analysis",
                "speech processing",
                "text categorization"
            ]
        }
    },
    {
        "Title": "Clustering-Driven Optimization of RRH-BBU Assignment for Green Communication Networks With Big Data Analytics",
        "Link": "https://ieeexplore.ieee.org/document/10767270/",
        "Abstract": "The Centralized Radio Access Networks (CRAN) decentralizes data and control planes by separating the baseband unit (BBU) from the central office, enabling energy-efficient “green networks” through the shutdown of underutilized BBUs. Analyzing extensive Call Detail Records (CDR) as big data, collected by service providers, has gained traction for extracting network features and studying activities. Thus, big data analytics are deemed as potential techniques that various research proposed to analyze the CDR. This paper introduces an energy-efficient CRAN network architecture based on the CRAN framework, focused on an innovative remote radio head (RRH)-BBU assignment. The objective is twofold: minimizing power consumption by deactivating underutilized BBUs and reducing inter-BBU handover rates based on CDR insights. In literature, the problem of assigning RRH to BBU is described as hard nonlinear programming (NLP) problem (bin packing, mixed integer), different suboptimal algorithms have been proposed to offer suboptimal assignment. This study employs clustering techniques to divide the complex NLP problem into simpler optimization tasks, achieving optimal RRH-BBU assignments. The proposed algorithm’s effectiveness was assessed using Milan city CDR as a case study, and its performance was validated against Milan’s land use map. The results indicated a remarkable 28.8% reduction in power consumption, alongside improvements in inter-BBU handovers.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3506434",
            "Date of Publication": "25 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Asmaa Ibrahim",
                "labs": [
                    "Department of Signal Theory and Communications, Universitat Politècnica de Catalunya, Barcelona, Spain",
                    "Computer and Networks Engineering Department, College of Information Technology, United Arab Emirates University, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Ahmed Elsheikh",
                "labs": [
                    "Department of Mathematics and Engineering Physics, Faculty of Engineering, Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Bassem Mokhtar",
                "labs": [
                    "Computer and Networks Engineering Department, College of Information Technology, United Arab Emirates University, Abu Dhabi, United Arab Emirates",
                    "Department of Electrical Engineering, Faculty of Engineering, Alexandria University, Alexandria, Egypt"
                ]
            },
            {
                "name": "Josep Prat",
                "labs": [
                    "Department of Signal Theory and Communications, Universitat Politècnica de Catalunya, Barcelona, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Clustering algorithms",
                "Optimization",
                "Heuristic algorithms",
                "Quality of service",
                "Computer architecture",
                "Handover",
                "Resource management",
                "Power demand",
                "Urban areas",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "5G communication systems",
                "CRAN networks architecture",
                "temporal databases",
                "clustering optimization algorithms",
                "spatio-temporal clustering",
                "RRH",
                "BBU",
                "green communications"
            ]
        }
    },
    {
        "Title": "Read-All-in-Once (RAiO): Multi-Layer Contextual Architecture for Long-Text Machine Reading Comprehension",
        "Link": "https://ieeexplore.ieee.org/document/10190566/",
        "Abstract": "Machine reading comprehension (MRC) is a cutting-edge technology in natural language processing (NLP), which focuses on teaching machines to read and understand the meaning of texts based on the emergence of large-scale datasets and neural network models. Recently, with the successful development of pre-trained transformer models (e.g., BERT), MRC has advanced significantly, surpassing human parity in several public datasets and being applied in various NLP tasks (e.g., QA systems). Nevertheless, long document MRC is still a remain challenge since the transformer-based models are limited by the input length. For instance, several well-known pre-trained language models such as BERT and RoBERTa are limited by 512 tokens. This study aims to provide a new simple approach for long document MRC. Specifically, recent state-of-the-art models follow the architecture with two crucial stages for reading long texts in order to enable local and global context representations. In this study, we present a new architecture that is able to enrich the global information of the context with one stage by exploiting the interaction of different levels of semantic units of the context (i.e., sentence and word level). Therefore, we name the proposed model as RAiO (Read-All-in-Once) approach. For the experiment, we evaluate RAiO on two benchmark long document MRC datasets such as NewsQA and NLQuAD. Accordingly, the experiment shows promising results of the proposed approach compared with strong baselines in this research field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3298100",
            "Date of Publication": "24 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tuan-Anh Phan",
                "labs": [
                    "Viettel Cyberspace Center, Viettel Group, Hanoi, Vietnam"
                ]
            },
            {
                "name": "Jason J. Jung",
                "labs": [
                    "Department of Computer Engineering, Chung-Ang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Khac-Hoai Nam Bui",
                "labs": [
                    "Viettel Cyberspace Center, Viettel Group, Hanoi, Vietnam"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Data mining",
                "Context modeling",
                "Task analysis",
                "Natural language processing",
                "Transformers",
                "Computational modeling",
                "Text processing",
                "Question answering (information retrieval)"
            ],
            "Author Keywords": [
                "Natural language processing",
                "long-text machine reading comprehension",
                "question-answering system"
            ]
        }
    },
    {
        "Title": "Automated Text Structuring: Natural Language Processing and Regular Expressions in XML Tag Filling",
        "Link": "https://ieeexplore.ieee.org/document/10778543/",
        "Abstract": "The conversion of documents into XML markup requires efficient algorithms and automated solutions. The focus is on tagging documents to meet NISO STS standards, ensuring compatibility across systems. A method combining Natural Language Processing (NLP) and Regular Expressions (regex) for automated XML tag filling is proposed. NLP enhances content understanding, while regex enables precise pattern matching. This approach streamlines the conversion process, reducing manual effort and ensuring standardized tagging. Through experiments, the effectiveness of the method in achieving accurate XML markup aligned with NISO STS guidelines is validated. This research advances automated data structuring, exemplified by the GOST R ontology within NISO STS standards, providing a template for other ontology-based document XML-structuring.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3511674",
            "Date of Publication": "05 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ivan P. Malashin",
                "labs": [
                    "Artificial Intelligence Technology Scientific and Education Center, Bauman Moscow State Technical University, Moscow, Russia"
                ]
            },
            {
                "name": "Vadim S. Tynchenko",
                "labs": [
                    "Artificial Intelligence Technology Scientific and Education Center, Bauman Moscow State Technical University, Moscow, Russia",
                    "Information-Control Systems Department, Institute of Computer Science and Telecommunications, Reshetnev Siberian State University of Science and Technology, Krasnoyarsk, Russia"
                ]
            },
            {
                "name": "Andrei P. Gantimurov",
                "labs": [
                    "Artificial Intelligence Technology Scientific and Education Center, Bauman Moscow State Technical University, Moscow, Russia"
                ]
            },
            {
                "name": "Vladimir A. Nelyub",
                "labs": [
                    "Artificial Intelligence Technology Scientific and Education Center, Bauman Moscow State Technical University, Moscow, Russia",
                    "Scientific Department, Far Eastern Federal University, Vladivostok, Russia"
                ]
            },
            {
                "name": "Aleksei S. Borodulin",
                "labs": [
                    "Artificial Intelligence Technology Scientific and Education Center, Bauman Moscow State Technical University, Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "XML",
                "Semantics",
                "Tagging",
                "Portable document format",
                "Standards",
                "Manuals",
                "Libraries",
                "Ontologies",
                "Pipelines",
                "Law"
            ],
            "Author Keywords": [
                "XML",
                "automated structuring",
                "natural language processing",
                "regular expressions"
            ]
        }
    },
    {
        "Title": "Comprehensive Analysis of Word Embedding Models and Design of Effective Feature Vector for Classification of Amazon Product Reviews",
        "Link": "https://ieeexplore.ieee.org/document/10858136/",
        "Abstract": "Sentiment Analysis (SA) is a well-known and emerging research field in the area of Natural Language Processing (NLP) and text classification. Feature engineering is considered to be one of the major steps in the Machine Learning (ML) pipeline with effective feature extraction playing a vital role in improving the performance of the SA tasks. Choosing an appropriate feature from the text is considered to be the most challenging task in text classification. This study examines the implementation of different traditional feature extraction models such as Bag of Words (BoW), Term Frequency-Inverse Document Frequency (TF-IDF), N-grams, and word embeddings like Word2Vec and Bidirectional Encoder Representations from Transformers (BERT) on an Amazon review dataset. Furthermore, the hyperparameters of the BERT model were fine-tuned, optimizing its performance on the SA task. Additionally, this research explores the effectiveness of combining the word vectors generated using TF-IDF and BERT for SA. The proposed hybrid model implements an effective negation handling approach and combines TF-IDF with BERT to improve performance for Amazon product review classification.The hybrid model was evaluated using several performance metrics, including accuracy, recall, precision, and F1-score. The proposed hybrid model shows promising results achieving an accuracy of 88%. The integration of BERT and TF-IDF not only enhances the model’s ability to understand and interpret text but also demonstrates the potential of combining advanced and traditional NLP techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3536631",
            "Date of Publication": "29 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "B. Priya Kamath",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "M. Geetha",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "U. Dinesh Acharya",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "Dipesh Singh",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "Ayush Rao",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "Shwetha Rai",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            },
            {
                "name": "Roopashri Shetty",
                "labs": [
                    "Department of Computer Science and Engineering, Manipal Academy of Higher Education, Manipal, Manipal Institute of Technology, Udupi, Karnataka, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Feature extraction",
                "Vectors",
                "Encoding",
                "Bidirectional control",
                "Accuracy",
                "Social networking (online)",
                "Sentiment analysis",
                "Motion pictures",
                "Data models"
            ],
            "Author Keywords": [
                "BERT",
                "classification",
                "feature extraction",
                "machine learning",
                "sentiment analysis",
                "Word embeddings",
                "Word2Vec"
            ]
        }
    },
    {
        "Title": "Improving Commonsense Bias Classification by Mitigating the Influence of Demographic Terms",
        "Link": "https://ieeexplore.ieee.org/document/10713368/",
        "Abstract": "Understanding commonsense knowledge is crucial in the field of Natural Language Processing (NLP). However, the presence of demographic terms in commonsense knowledge poses a potential risk of compromising the performance of NLP models. This study aims to investigate and propose methods for enhancing the performance and effectiveness of a commonsense polarization classifier by mitigating the influence of demographic terms. Three methods are introduced in this paper: (1) hierarchical generalization of demographic terms (2) threshold-based augmentation and (3) integration of hierarchical generalization and threshold-based augmentation methods(IHTA). The first method involves replacing demographic terms with more general ones based on a term hierarchy ontology, aiming to mitigate the influence of specific terms. To address the limited bias-related information, the second method measures the polarization of demographic terms by comparing the changes in the model’s predictions when these terms are masked versus unmasked. This method augments commonsense sentences containing terms with high polarization values by replacing their predicates with synonyms generated by ChatGPT. The third method combines the two approaches, starting with threshold-based augmentation followed by hierarchical generalization. The experiments show that the first method increases the accuracy over the baseline by 2.33%, and the second one by 0.96% over standard augmentation methods. The IHTA techniques yielded an 8.82% and 9.96% higher accuracy than threshold-based and standard augmentation methods, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3477599",
            "Date of Publication": "10 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jinkyu Lee",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, Dongguk University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jihie Kim",
                "labs": [
                    "Department of Computer Science and Artificial Intelligence, Dongguk University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Predictive models",
                "Commonsense reasoning",
                "Standards",
                "Ontologies",
                "Chatbots",
                "Training data",
                "Systematics",
                "Semantics",
                "Prevention and mitigation",
                "Demography",
                "Natural language processing",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Commonsense bias",
                "demographic term",
                "bias mitigation",
                "hierarchical generalization",
                "threshold-based augmentation"
            ]
        }
    },
    {
        "Title": "Editorial: Special Section on Edge AI Empowered Giant Model Training",
        "Link": "https://ieeexplore.ieee.org/document/10778148/",
        "Abstract": "The realm of Artificial Intelligence (AI) has seen monumental shifts in recent years, particularly with the advent of large-scale models such as GPT-3, which have pushed the boundaries of natural language processing (NLP) and other AI applications. These models, while offering unprecedented capabilities, also present significant challenges in terms of the immense computational resources and energy required for training and deployment. The sheer scale of these models-175 billion parameters and over 3 million GPU hours in the case of GPT-3-places their development and use beyond the reach of many organizations and individuals.",
        "Details": {
            "DOI": "10.26599/BDMA.2024.9020080",
            "Date of Publication": "04 December 2024",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Dongxiao Yu",
                "labs": [
                    "Shandong University, China"
                ]
            },
            {
                "name": "Xu Chen",
                "labs": [
                    "Sun Yat-sen University, China"
                ]
            },
            {
                "name": "Zhipeng Cai",
                "labs": [
                    "Georgia State University, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [],
            "Author Keywords": []
        }
    },
    {
        "Title": "Descriptor: Benchmark Dataset for Generative AI on Edge Devices (BeDGED)",
        "Link": "https://ieeexplore.ieee.org/document/10930751/",
        "Abstract": "The rise of large language models (LLMs) has transformed natural language processing (NLP) and generative artificial intelligence (AI) applications. However, deploying these transformer-based models in resource-constrained environments poses a significant challenge due to their high computational and memory demands. To address this, we introduce in this article generative AI (GenAI) on the Edge, a comprehensive benchmarking dataset designed to evaluate the performance of LLMs deployed on edge devices. Leveraging a distributed testbed of Raspberry Pi 5 devices orchestrated with lightweight Kubernetes (K3s), the dataset captures a broad range of performance metrics essential for assessing the feasibility of local inference in constrained environments. These metrics include detailed measurements of throughput, inference latency, memory utilization, and computational efficiency, along with granular timing data for key stages of the inference pipeline—sample, prefill, and decode phases. We systematically evaluate LLMs of varying sizes under real-world deployment scenarios, with a particular emphasis on CPU-based edge platforms. By conducting multiple runs of conversation-based evaluations, GenAI on the Edge provides actionable insights into the tradeoffs between performance and resource efficiency, enabling better decision-making for LLM deployment in edge environments. IEEE SOCIETY/COUNCIL Communications Society (ComSoc) DATA TYPE/LOCATION Structured Text Data (CSV); Leeds, U.K. DATA DOI/PID 10.21227/7d08-8655",
        "Details": {
            "DOI": "10.1109/IEEEDATA.2025.3552083",
            "Date of Publication": "18 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Data Descriptions"
        },
        "issn_info": {
            "Electronic ISSN": "2995-4274"
        },
        "authors_data": [
            {
                "name": "Zeinab Nezami",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K.",
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Maryam Hafeez",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Karim Djemame",
                "labs": [
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Syed Ali Raza Zaidi",
                "labs": [
                    "School of Electronic and Electrical Engineering, University of Leeds, Leeds, U.K."
                ]
            },
            {
                "name": "Jie Xu",
                "labs": [
                    "School of Computing, University of Leeds, Leeds, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Benchmark testing",
                "Throughput",
                "Data models",
                "Artificial intelligence",
                "Performance evaluation",
                "Accuracy",
                "Hardware",
                "Generative AI",
                "Memory management"
            ],
            "Author Keywords": [
                "Benchmarking dataset",
                "edge artificial intelligence (AI)",
                "generative AI (GenAI)",
                "large language model (LLM)",
                "open radio access network (ORAN)",
                "performance evaluation"
            ]
        }
    },
    {
        "Title": "TForMIX: A Method That Combines LLM and Multidimensional Modeling for Technological Foresight",
        "Link": "https://ieeexplore.ieee.org/document/11146655/",
        "Abstract": "Technical documents, such as scientific papers and patents, are widely used as a basis for Technological Foresight (TF) processes. Typically, these analyses require identifying elements (e.g., terms) in the textual contents of these documents, which are relevant to the scientific-technological domain under investigation. Information Extraction (IE) and Natural Language Processing (NLP) techniques are useful tools to automate the identification of these elements, which is essential in TF processes that usually involve the analysis of a corpus of hundreds (and sometimes thousands) of documents. An analytical view over this corpus, based on the occurrence of those relevant elements, helps prioritize document analysis and, consequently, accelerates the whole TF process. However, building a system that provides such analytical insight is expensive. Moreover, for each domain-specific TF process, a new system would have to be built. Thus, there is a need for viable solutions to analytically explore a corpus, according to the specific requirements of each domain. This work presents Technological Foresight with Multidimensional Information eXtraction (TForMIX), a novel method for building Decision Support Systems (DSSs) that applies Named Entity Recognition (NER) and Relation Extraction (RE) while allowing multidimensional analytical exploration of entities and relations together with bibliometric data from documents. TForMIX is a flexible method that can be applied to different domains, and speeds up building DSSs for each domain. Additionally, we evaluate the applicability of the produced DSSs in TF processes by conducting a practical experiment that demonstrates that applying the method to generate DSSs, supported by IE techniques, can significantly contribute to the conduction of TF analyses. The combination of the used theories, innovative methods, and proposed practical validation highlighted the high-quality nature of the analysis in this study while offering the potential for valuable insights and contributions to the TF process.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605116",
            "Date of Publication": "02 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Giselle F. Rosa",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil",
                    "Agência de Gestão e Inovação Tecnológica (AGITEC), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Jones O. Avelino",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil",
                    "Centro de Análise de Sistemas Navais (CASNAV), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Maria Claudia Cavalcanti",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Julio Cesar Duarte",
                "labs": [
                    "Instituto Militar de Engenharia (IME), Rio de Janeiro, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Spread spectrum communication",
                "Information retrieval",
                "Decision support systems",
                "Data models",
                "Analytical models",
                "Patents",
                "Soft sensors",
                "Named entity recognition",
                "Buildings",
                "Transmission line measurements"
            ],
            "Author Keywords": [
                "Decision support systems",
                "information extraction",
                "multidimensional modeling",
                "technological foresighting",
                "technological forecasting"
            ]
        }
    },
    {
        "Title": "ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning",
        "Link": "https://ieeexplore.ieee.org/document/9477085/",
        "Abstract": "Computational biology and bioinformatics provide vast data gold-mines from protein sequences, ideal for Language Models (LMs) taken from Natural Language Processing (NLP). These LMs reach for new prediction frontiers at low inference costs. Here, we trained two auto-regressive models (Transformer-XL, XLNet) and four auto-encoder models (BERT, Albert, Electra, T5) on data from UniRef and BFD containing up to 393 billion amino acids. The protein LMs (pLMs) were trained on the Summit supercomputer using 5616 GPUs and TPU Pod up-to 1024 cores. Dimensionality reduction revealed that the raw pLM-embeddings from unlabeled data captured some biophysical features of protein sequences. We validated the advantage of using the embeddings as exclusive input for several subsequent tasks: (1) a per-residue (per-token) prediction of protein secondary structure (3-state accuracy Q3=81%-87%); (2) per-protein (pooling) predictions of protein sub-cellular location (ten-state accuracy: Q10=81%) and membrane versus water-soluble (2-state accuracy Q2=91%). For secondary structure, the most informative embeddings (ProtT5) for the first time outperformed the state-of-the-art without multiple sequence alignments (MSAs) or evolutionary information thereby bypassing expensive database searches. Taken together, the results implied that pLMs learned some of the grammar of the language of life. All our models are available through https://github.com/agemagician/ProtTrans.",
        "Details": {
            "DOI": "10.1109/TPAMI.2021.3095381",
            "Date of Publication": "07 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
        },
        "issn_info": {
            "Print ISSN": "0162-8828",
            "Electronic ISSN": "1939-3539"
        },
        "authors_data": [
            {
                "name": "Ahmed Elnaggar",
                "labs": [
                    "Department of Informatics, Bioinformatics & Computational Biology - i12, Technical University of Munich (TUM), Garching/Munich, Germany"
                ]
            },
            {
                "name": "Michael Heinzinger",
                "labs": [
                    "Department of Informatics, Bioinformatics & Computational Biology - i12, Technical University of Munich (TUM), Garching/Munich, Germany"
                ]
            },
            {
                "name": "Christian Dallago",
                "labs": [
                    "Department of Informatics, Bioinformatics & Computational Biology - i12, Technical University of Munich (TUM), Garching/Munich, Germany"
                ]
            },
            {
                "name": "Ghalia Rehawi",
                "labs": [
                    "Department of Informatics, Bioinformatics & Computational Biology - i12, Technical University of Munich (TUM), Garching/Munich, Germany"
                ]
            },
            {
                "name": "Yu Wang",
                "labs": [
                    "Med AI Technology (Wu Xi) Ltd., Wu Xi, Jiang Su, China"
                ]
            },
            {
                "name": "Llion Jones",
                "labs": [
                    "Google AI, Google, Mountain View, CA, USA"
                ]
            },
            {
                "name": "Tom Gibbs",
                "labs": [
                    "NVIDIA, Santa Clara, CA, USA"
                ]
            },
            {
                "name": "Tamas Feher",
                "labs": [
                    "NVIDIA, Santa Clara, CA, USA"
                ]
            },
            {
                "name": "Christoph Angerer",
                "labs": [
                    "NVIDIA, Santa Clara, CA, USA"
                ]
            },
            {
                "name": "Martin Steinegger",
                "labs": [
                    "School of Biological Sciences, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Debsindhu Bhowmik",
                "labs": [
                    "Oak Ridge National Laboratory (ORNL), Oak Ridge, TN, USA"
                ]
            },
            {
                "name": "Burkhard Rost",
                "labs": [
                    "Department of Informatics, Bioinformatics & Computational Biology - i12, Technical University of Munich (TUM), Garching/Munich, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Proteins",
                "Training",
                "Amino acids",
                "Task analysis",
                "Databases",
                "Computational modeling",
                "Three-dimensional displays"
            ],
            "Author Keywords": [
                "Computational biology",
                "high performance computing",
                "machine learning",
                "language modeling",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Detection of Depression-Related Posts in Reddit Social Media Forum",
        "Link": "https://ieeexplore.ieee.org/document/8681445/",
        "Abstract": "Depression is viewed as the largest contributor to global disability and a major reason for suicide. It has an impact on the language usage reflected in the written text. The key objective of our study is to examine Reddit users' posts to detect any factors that may reveal the depression attitudes of relevant online users. For such purpose, we employ the Natural Language Processing (NLP) techniques and machine learning approaches to train the data and evaluate the efficiency of our proposed method. We identify a lexicon of terms that are more common among depressed accounts. The results show that our proposed method can significantly improve performance accuracy. The best single feature is bigram with the Support Vector Machine (SVM) classifier to detect depression with 80% accuracy and 0.80 F1 scores. The strength and effectiveness of the combined features (LIWC+LDA+bigram) are most successfully demonstrated with the Multilayer Perceptron (MLP) classifier resulting in the top performance for depression detection reaching 91% accuracy and 0.93 F1 scores. According to our study, better performance improvement can be achieved by proper feature selections and their multiple feature combinations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2909180",
            "Date of Publication": "04 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Michael M. Tadesse",
                "labs": [
                    "Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Hongfei Lin",
                "labs": [
                    "Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Bo Xu",
                "labs": [
                    "Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Liang Yang",
                "labs": [
                    "Faculty of Electronic Information and Electrical Engineering, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Linguistics",
                "Twitter",
                "Natural language processing",
                "Support vector machines"
            ],
            "Author Keywords": [
                "Natural language processing",
                "machine learning",
                "Reddit",
                "social networks",
                "depression"
            ]
        }
    },
    {
        "Title": "A Term Weighted Neural Language Model and Stacked Bidirectional LSTM Based Framework for Sarcasm Identification",
        "Link": "https://ieeexplore.ieee.org/document/9316208/",
        "Abstract": "Sarcasm identification on text documents is one of the most challenging tasks in natural language processing (NLP), has become an essential research direction, due to its prevalence on social media data. The purpose of our research is to present an effective sarcasm identification framework on social media data by pursuing the paradigms of neural language models and deep neural networks. To represent text documents, we introduce inverse gravity moment based term weighted word embedding model with trigrams. In this way, critical words/terms have higher values by keeping the word-ordering information. In our model, we present a three-layer stacked bidirectional long short-term memory architecture to identify sarcastic text documents. For the evaluation task, the presented framework has been evaluated on three-sarcasm identification corpus. In the empirical analysis, three neural language models (i.e., word2vec, fastText and GloVe), two unsupervised term weighting functions (i.e., term-frequency, and TF-IDF) and eight supervised term weighting functions (i.e., odds ratio, relevance frequency, balanced distributional concentration, inverse question frequency-question frequency-inverse category frequency, short text weighting, inverse gravity moment, regularized entropy and inverse false negative-true positive-inverse category frequency) have been evaluated. For sarcasm identification task, the presented model yields promising results with a classification accuracy of 95.30%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3049734",
            "Date of Publication": "06 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aytug Onan",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering and Architecture, İzmir Katip Çelebi University, İzmir, Turkey"
                ]
            },
            {
                "name": "Mansur Alp Toçoğlu",
                "labs": [
                    "Department of Software Engineering, Faculty of Technology, Manisa Celal Bayar University, Manisa, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Social networking (online)",
                "Blogs",
                "Long short term memory",
                "Predictive models",
                "Gravity",
                "Analytical models"
            ],
            "Author Keywords": [
                "Sarcasm identification",
                "term weighting",
                "neural language model",
                "bidirectional long shortterm memory"
            ]
        }
    },
    {
        "Title": "Emotion Recognition in Conversation: Research Challenges, Datasets, and Recent Advances",
        "Link": "https://ieeexplore.ieee.org/document/8764449/",
        "Abstract": "Emotion is intrinsic to humans and consequently, emotion understanding is a key part of human-like artificial intelligence (AI). Emotion recognition in conversation (ERC) is becoming increasingly popular as a new research frontier in natural language processing (NLP) due to its ability to mine opinions from the plethora of publicly available conversational data on platforms such as Facebook, Youtube, Reddit, Twitter, and others. Moreover, it has potential applications in health-care systems (as a tool for psychological analysis), education (understanding student frustration), and more. In Addition, ERC is also extremely important for generating emotion-aware dialogues that require an understanding of the user’s emotions. Catering to these needs calls for effective and scalable conversational emotion-recognition algorithms. However, it is a difficult problem to solve because of several research challenges. In this paper, we discuss these challenges and shed light on recent research in this field. We also describe the drawbacks of these approaches and discuss the reasons why they fail to successfully overcome the research challenges in ERC.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2929050",
            "Date of Publication": "16 July 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Soujanya Poria",
                "labs": [
                    "ISTD, Singapore University of Technology and Design, Singapore"
                ]
            },
            {
                "name": "Navonil Majumder",
                "labs": [
                    "CIC, Instituto Politécnico Nacional, Mexico City, Mexico"
                ]
            },
            {
                "name": "Rada Mihalcea",
                "labs": [
                    "Computer Science and Engineering, University of Michigan, Ann Arbor, MI, USA"
                ]
            },
            {
                "name": "Eduard Hovy",
                "labs": [
                    "Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Task analysis",
                "Context modeling",
                "Taxonomy",
                "Natural language processing",
                "Pragmatics"
            ],
            "Author Keywords": [
                "Emotion recognition",
                "sentiment analysis",
                "dialogue systems",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Semantic-Emotion Neural Network for Emotion Recognition From Text",
        "Link": "https://ieeexplore.ieee.org/document/8794541/",
        "Abstract": "Emotion detection and recognition from text is a recent essential research area in Natural Language Processing (NLP) which may reveal some valuable input to a variety of purposes. Nowadays, writings take many forms of social media posts, micro-blogs, news articles, customer review, etc., and the content of these short-texts can be a useful resource for text mining to discover an unhide various aspects, including emotions. The previously presented models mainly adopted word embedding vectors that represent rich semantic/syntactic information and those models cannot capture the emotional relationship between words. Recently, some emotional word embeddings are proposed but it requires semantic and syntactic information vice versa. To address this issue, we proposed a novel neural network architecture, called SENN (Semantic-Emotion Neural Network) which can utilize both semantic/syntactic and emotional information by adopting pre-trained word representations. SENN model has mainly two sub-networks, the first sub-network uses bidirectional Long-Short Term Memory (BiLSTM) to capture contextual information and focuses on semantic relationship, the second sub-network uses the convolutional neural network (CNN) to extract emotional features and focuses on the emotional relationship between words from the text. We conducted a comprehensive performance evaluation for the proposed model using standard real-world datasets. We adopted the notion of Ekman's six basic emotions. The experimental results show that the proposed model achieves a significantly superior quality of emotion recognition with various state-of-the-art approaches and further can be improved by other emotional word embeddings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2934529",
            "Date of Publication": "12 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Erdenebileg Batbaatar",
                "labs": [
                    "School of Electrical and Computer Engineering, Chungbuk National University, Cheongju, South Korea"
                ]
            },
            {
                "name": "Meijing Li",
                "labs": [
                    "College of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Keun Ho Ryu",
                "labs": [
                    "Faculty of Information Technology, Ton Duc Thang University, Ho Chi Minh City, Vietnam"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Semantics",
                "Neural networks",
                "Task analysis",
                "Deep learning",
                "Dictionaries"
            ],
            "Author Keywords": [
                "Emotion recognition",
                "natural language processing",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A Novel Hybrid Deep Learning Model for Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/9044300/",
        "Abstract": "A massive use of social media platforms such as Twitter and Facebook by omnifarious organizations has increased the critical individual feedback on the situation, events, products, and services. However, sentiment classification plays an important role in the user's feedback evaluation. At present, deep learning such as long short-term memory (LSTM), gated recurrent unit (GRU), bidirectionally long short-term memory (BiLSTM) or convolutional neural network (CNN) are prevalently preferred in sentiment classification. Moreover, word embedding such as Word2Vec and FastText is closely examined in text for mapping closely related to the vectors of real numbers. However, both deep learning and word embedding methods have strengths and weaknesses. Combining the strengths of the deep learning models with that of word embedding is the key to high-performance sentiment classification in the field of natural language processing (NLP). In the present study, we propose a novel hybrid deep learning model that strategically combines different word embedding (Word2Vec, FastText, character-level embedding) with different deep learning methods (LSTM, GRU, BiLSTM, CNN). The proposed model extracts features of different deep learning methods of word embedding, combines these features and classifies texts in terms of sentiment. To verify the performance of the proposed model, several deep learning models called basic models were created to perform series of experiments. By comparing, the performance of the proposed model with that of past studies, the proposed model offers better sentiment classification performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2982538",
            "Date of Publication": "23 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mehmet Umut Salur",
                "labs": [
                    "Department of Computer Engineering, Harran University, Şanlıurfa, Turkey"
                ]
            },
            {
                "name": "Ilhan Aydin",
                "labs": [
                    "Department of Computer Engineering, Fırat University, Elazığ, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Feature extraction",
                "Sentiment analysis",
                "Numerical models",
                "Twitter"
            ],
            "Author Keywords": [
                "Sentiment classification",
                "Turkish tweets analysis",
                "hybrid model",
                "word embedding",
                "deep learning",
                "LSTM",
                "CNN"
            ]
        }
    },
    {
        "Title": "A Review of Fog Computing and Machine Learning: Concepts, Applications, Challenges, and Open Issues",
        "Link": "https://ieeexplore.ieee.org/document/8869895/",
        "Abstract": "Systems based on fog computing produce massive amounts of data; accordingly, an increasing number of fog computing apps and services are emerging. In addition, machine learning (ML), which is an essential area, has gained considerable progress in various research domains, including robotics, neuromorphic computing, computer graphics, natural language processing (NLP), decision-making, and speech recognition. Several researches have been proposed that study how to employ ML to settle fog computing problems. In recent years, an increasing trend has been observed in adopting ML to enhance fog computing applications and provide fog services, like efficient resource management, security, mitigating latency and energy consumption, and traffic modeling. Based on our understanding and knowledge, there is no study has yet investigated the role of ML in the fog computing paradigm. Accordingly, the current research shed light on presenting an overview of the ML functions in fog computing area. The ML application for fog computing become strong end-user and high layers services to gain profound analytics and more smart responses for needed tasks. We present a comprehensive review to underline the latest improvements in ML techniques that are associated with three aspects of fog computing: management of resource, accuracy, and security. The role of ML in edge computing is also highlighted. Moreover, other perspectives related to the ML domain, such as types of application support, technique, and dataset are provided. Lastly, research challenges and open issues are discussed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2947542",
            "Date of Publication": "15 October 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Karrar Hameed Abdulkareem",
                "labs": [
                    "College of Agriculture, Al-Muthanna University, Samawah, Iraq"
                ]
            },
            {
                "name": "Mazin Abed Mohammed",
                "labs": [
                    "College of Computer Science and Information Technology, University of Anbar, Anbar, Iraq"
                ]
            },
            {
                "name": "Saraswathy Shamini Gunasekaran",
                "labs": [
                    "College of Computing and Informatics, Universiti Tenaga Nasional, Selangor, Malaysia"
                ]
            },
            {
                "name": "Mohammed Nasser Al-Mhiqani",
                "labs": [
                    "Information Security and Networking Research Group (InFORSNET), Faculty of Information and Communication Technology, Universiti Teknikal Malaysia Melaka, Durian Tunggal, Malaysia"
                ]
            },
            {
                "name": "Ammar Awad Mutlag",
                "labs": [
                    "Biomedical Computing and Engineering Technologies (BIOCORE) Applied Research Group, Faculty of Information and Communication Technology, Universiti Teknikal Malaysia Melaka, Durian Tunggal, Malaysia"
                ]
            },
            {
                "name": "Salama A. Mostafa",
                "labs": [
                    "Faculty of Computer Science and Information Technology, Universiti Tun Hussein Onn Malaysia, Johor, Malaysia"
                ]
            },
            {
                "name": "Nabeel Salih Ali",
                "labs": [
                    "Information Technology Research and Development Centre, University of Kufa, Kufa, Iraq"
                ]
            },
            {
                "name": "Dheyaa Ahmed Ibrahim",
                "labs": [
                    "Computer Engineering Techniques Department, Imam Ja’afar Al-Sadiq University, Baghdad, Iraq"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Edge computing",
                "Cloud computing",
                "Internet of Things",
                "Sensors",
                "Security",
                "Computational modeling",
                "Monitoring"
            ],
            "Author Keywords": [
                "Fog computing",
                "machine learning",
                "Internet of Things (IoT)",
                "applications"
            ]
        }
    },
    {
        "Title": "A Comprehensive Review on Fake News Detection With Deep Learning",
        "Link": "https://ieeexplore.ieee.org/document/9620068/",
        "Abstract": "A protuberant issue of the present time is that, organizations from different domains are struggling to obtain effective solutions for detecting online-based fake news. It is quite thought-provoking to distinguish fake information on the internet as it is often written to deceive users. Compared with many machine learning techniques, deep learning-based techniques are capable of detecting fake news more accurately. Previous review papers were based on data mining and machine learning techniques, scarcely exploring the deep learning techniques for fake news detection. However, emerging deep learning-based approaches such as Attention, Generative Adversarial Networks, and Bidirectional Encoder Representations for Transformers are absent from previous surveys. This study attempts to investigate advanced and state-of-the-art fake news detection mechanisms pensively. We begin with highlighting the fake news consequences. Then, we proceed with the discussion on the dataset used in previous research and their NLP techniques. A comprehensive overview of deep learning-based techniques has been bestowed to organize representative methods into various categories. The prominent evaluation metrics in fake news detection are also discussed. Nevertheless, we suggest further recommendations to improve fake news detection mechanisms in future research directions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3129329",
            "Date of Publication": "18 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. F. Mridha",
                "labs": [
                    "Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Ashfia Jannat Keya",
                "labs": [
                    "Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Abdul Hamid",
                "labs": [
                    "Department of Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Muhammad Mostafa Monowar",
                "labs": [
                    "Department of Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Md. Saifur Rahman",
                "labs": [
                    "Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Deep learning",
                "Natural language processing",
                "Machine learning",
                "Convolutional neural networks",
                "Terminology",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Natural language processing",
                "machine learning",
                "deep learning",
                "fake news"
            ]
        }
    },
    {
        "Title": "Named Entity Extraction for Knowledge Graphs: A Literature Overview",
        "Link": "https://ieeexplore.ieee.org/document/8999622/",
        "Abstract": "An enormous amount of digital information is expressed as natural-language (NL) text that is not easily processable by computers. Knowledge Graphs (KG) offer a widely used format for representing information in computer-processable form. Natural Language Processing (NLP) is therefore needed for mining (or lifting) knowledge graphs from NL texts. A central part of the problem is to extract the named entities in the text. The paper presents an overview of recent advances in this area, covering: Named Entity Recognition (NER), Named Entity Disambiguation (NED), and Named Entity Linking (NEL). We comment that many approaches to NED and NEL are based on older approaches to NER and need to leverage the outputs of state-of-the-art NER systems. There is also a need for standard methods to evaluate and compare named-entity extraction approaches. We observe that NEL has recently moved from being stepwise and isolated into an integrated process along two dimensions: the first is that previously sequential steps are now being integrated into end-to-end processes, and the second is that entities that were previously analysed in isolation are now being lifted in each other's context. The current culmination of these trends are the deep-learning approaches that have recently reported promising results.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2973928",
            "Date of Publication": "14 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tareq Al-Moslmi",
                "labs": [
                    "Department of Information Science and Media Studies, University of Bergen, Bergen, Norway"
                ]
            },
            {
                "name": "Marc Gallofré Ocaña",
                "labs": [
                    "Department of Information Science and Media Studies, University of Bergen, Bergen, Norway"
                ]
            },
            {
                "name": "Andreas L. Opdahl",
                "labs": [
                    "Department of Information Science and Media Studies, University of Bergen, Bergen, Norway"
                ]
            },
            {
                "name": "Csaba Veres",
                "labs": [
                    "Department of Information Science and Media Studies, University of Bergen, Bergen, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Natural language processing",
                "Semantics",
                "Standards",
                "Hidden Markov models",
                "Iris recognition",
                "Data mining"
            ],
            "Author Keywords": [
                "Knowledge graphs",
                "natural-language processing",
                "named-entity extraction",
                "named-entity recognition",
                "named-entity disambiguation",
                "named-entity linking"
            ]
        }
    },
    {
        "Title": "A Survey of Sentiment Analysis Based on Transfer Learning",
        "Link": "https://ieeexplore.ieee.org/document/8746210/",
        "Abstract": "With the rapid development of the Internet industry, sentiment analysis has grown into one of the popular areas of natural language processing (NLP). Through it, the implicit emotion in the text can be effectively mined, which can help enterprises or organizations to make an effective decision, and the explosive growth of data undoubtedly brings more opportunities and challenges to the sentiment analysis. At the same time, transfer learning has emerged as a new machine learning technique that uses the existing knowledge to solve different domain problems and produces state-of-the-art prediction results. Many scholars apply transfer learning to the field of the sentiment analysis. This survey summarizes the relevant research results of the sentiment analysis in recent years and focuses on the algorithms and applications of transfer learning in the sentiment analysis, and we look forward to the development trend of the sentiment analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2925059",
            "Date of Publication": "26 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ruijun Liu",
                "labs": [
                    "Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing, China"
                ]
            },
            {
                "name": "Yuqian Shi",
                "labs": [
                    "Beijing Key Laboratory of Big Data Technology for Food Safety, Beijing Technology and Business University, Beijing, China"
                ]
            },
            {
                "name": "Changjiang Ji",
                "labs": [
                    "Beijing Moviebook Technology Corporation Ltd., Beijing, China"
                ]
            },
            {
                "name": "Ming Jia",
                "labs": [
                    "School of Computer and Information Engineering, Beijing Technology and Business University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Deep learning",
                "Computational modeling",
                "Task analysis",
                "Context modeling"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "transfer learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Chat2VIS: Generating Data Visualizations via Natural Language Using ChatGPT, Codex and GPT-3 Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10121440/",
        "Abstract": "The field of data visualisation has long aimed to devise solutions for generating visualisations directly from natural language text. Research in Natural Language Interfaces (NLIs) has contributed towards the development of such techniques. However, the implementation of workable NLIs has always been challenging due to the inherent ambiguity of natural language, as well as in consequence of unclear and poorly written user queries which pose problems for existing language models in discerning user intent. Instead of pursuing the usual path of developing new iterations of language models, this study uniquely proposes leveraging the advancements in pre-trained large language models (LLMs) such as ChatGPT and GPT-3 to convert free-form natural language directly into code for appropriate visualisations. This paper presents a novel system, Chat2VIS, which takes advantage of the capabilities of LLMs and demonstrates how, with effective prompt engineering, the complex problem of language understanding can be solved more efficiently, resulting in simpler and more accurate end-to-end solutions than prior approaches. Chat2VIS shows that LLMs together with the proposed prompts offer a reliable approach to rendering visualisations from natural language queries, even when queries are highly misspecified and underspecified. This solution also presents a significant reduction in costs for the development of NLI systems, while attaining greater visualisation inference abilities compared to traditional NLP approaches that use hand-crafted grammar rules and tailored models. This study also presents how LLM prompts can be constructed in a way that preserves data security and privacy while being generalisable to different datasets. This work compares the performance of GPT-3, Codex and ChatGPT across several case studies and contrasts the performances with prior studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3274199",
            "Date of Publication": "08 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Paula Maddigan",
                "labs": [
                    "School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand"
                ]
            },
            {
                "name": "Teo Susnjak",
                "labs": [
                    "School of Mathematical and Computational Sciences, Massey University, Auckland, New Zealand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data visualization",
                "Task analysis",
                "Data models",
                "Codes",
                "Chatbots",
                "Transformers",
                "Market research",
                "Natural language processing",
                "Text recognition"
            ],
            "Author Keywords": [
                "ChatGPT",
                "codex",
                "end-to-end visualisations from natural language",
                "GPT-3",
                "large language models",
                "natural language interfaces",
                "text-to-visualisation"
            ]
        }
    },
    {
        "Title": "Advantages and Constraints of a Hybrid Model K-12 E-Learning Assistant Chatbot",
        "Link": "https://ieeexplore.ieee.org/document/9069183/",
        "Abstract": "E-Learning has become more and more popular in recent years with the advance of new technologies. Using their mobile devices, people can expand their knowledge anytime and anywhere. E-Learning also makes it possible for people to manage their learning progression freely and follow their own learning style. However, studies show that E-Learning can cause the user to experience feelings of isolation and detachment due to the lack of human-like interactions in most E-Learning platforms. These feelings could reduce the user's motivation to learn. In this paper, we explore and evaluate how well current chatbot technologies assist users' learning on E-Learning platforms and how these technologies could possibly reduce problems such as feelings of isolation and detachment. For evaluation, we specifically designed a chatbot to be an E-Learning assistant. The NLP core of our chatbot is based on two different models: a retrieval-based model and a QANet model. We designed this two-model hybrid chatbot to be used alongside an E-Learning platform. The core response context of our chatbot is not only designed with course materials in mind but also everyday conversation and chitchat, which make it feel more like a human companion. Experiment and questionnaire evaluation results show that chatbots could be helpful in learning and could potentially reduce E-Learning users' feelings of isolation and detachment. Our chatbot also performed better than the teacher counselling service in the E-Learning platform on which the chatbot is based.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2988252",
            "Date of Publication": "16 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eric Hsiao-Kuang Wu",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan"
                ]
            },
            {
                "name": "Chun-Han Lin",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan"
                ]
            },
            {
                "name": "Yu-Yen Ou",
                "labs": [
                    "Department of Computer Science and Engineering, Yuan Ze University, Taoyuan City, Taiwan"
                ]
            },
            {
                "name": "Chen-Zhong Liu",
                "labs": [
                    "Graduate Institute of Network Learning Technology, National Central University, Taoyuan City, Taiwan"
                ]
            },
            {
                "name": "Wei-Kai Wang",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan"
                ]
            },
            {
                "name": "Chi-Yun Chao",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan City, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electronic learning",
                "Chatbot",
                "Google",
                "Urban areas",
                "Market research"
            ],
            "Author Keywords": [
                "E-Learning",
                "chatbot",
                "isolation",
                "detachment",
                "retrieval-based model",
                "QANet"
            ]
        }
    },
    {
        "Title": "Revolutionizing Cyber Threat Detection With Large Language Models: A Privacy-Preserving BERT-Based Lightweight Model for IoT/IIoT Devices",
        "Link": "https://ieeexplore.ieee.org/document/10423646/",
        "Abstract": "The field of Natural Language Processing (NLP) is currently undergoing a revolutionary transformation driven by the power of pre-trained Large Language Models (LLMs) based on groundbreaking Transformer architectures. As the frequency and diversity of cybersecurity attacks continue to rise, the importance of incident detection has significantly increased. IoT devices are expanding rapidly, resulting in a growing need for efficient techniques to autonomously identify network-based attacks in IoT networks with both high precision and minimal computational requirements. This paper presents SecurityBERT, a novel architecture that leverages the Bidirectional Encoder Representations from Transformers (BERT) model for cyber threat detection in IoT networks. During the training of SecurityBERT, we incorporated a novel privacy-preserving encoding technique called Privacy-Preserving Fixed-Length Encoding (PPFLE). We effectively represented network traffic data in a structured format by combining PPFLE with the Byte-level Byte-Pair Encoder (BBPE) Tokenizer. Our research demonstrates that SecurityBERT outperforms traditional Machine Learning (ML) and Deep Learning (DL) methods, such as Convolutional Neural Networks (CNNs) or Recurrent Neural Networks (RNNs), in cyber threat detection. Employing the Edge-IIoTset cybersecurity dataset, our experimental analysis shows that SecurityBERT achieved an impressive 98.2% overall accuracy in identifying fourteen distinct attack types, surpassing previous records set by hybrid solutions such as GAN-Transformer-based architectures and CNN-LSTM models. With an inference time of less than 0.15 seconds on an average CPU and a compact model size of just 16.7MB, SecurityBERT is ideally suited for real-life traffic analysis and a suitable choice for deployment on resource-constrained IoT devices.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3363469",
            "Date of Publication": "06 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohamed Amine Ferrag",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Mthandazo Ndhlovu",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Norbert Tihanyi",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Lucas C. Cordeiro",
                "labs": [
                    "Department of Computer Science, The University of Manchester, Manchester, U.K",
                    "Department of Electronics and Computing, Federal University of Amazonas, Manaus, Brazil"
                ]
            },
            {
                "name": "Merouane Debbah",
                "labs": [
                    "KU 6G Research Center, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Thierry Lestable",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Narinderjit Singh Thandi",
                "labs": [
                    "Technology Innovation Institute, Abu Dhabi, United Arab Emirates"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Threat assessment",
                "Internet of Things",
                "Encoding",
                "Transformers",
                "Data models",
                "Computer architecture",
                "Natural language processing",
                "Bit error rate",
                "Generative adversarial networks",
                "Artificial intelligence"
            ],
            "Author Keywords": [
                "Cyber threat detection",
                "IoT networks",
                "generative AI",
                "BERT",
                "large language models"
            ]
        }
    },
    {
        "Title": "Deep Learning and Explainable Artificial Intelligence Techniques Applied for Detecting Money Laundering–A Critical Review",
        "Link": "https://ieeexplore.ieee.org/document/9446887/",
        "Abstract": "Money laundering has been a global issue for decades, which is one of the major threat for economy and society. Government, regulatory and financial institutions are combating it together in their respective capacity, however still billions of dollars in fines by authorities make the headlines in the news. High-speed internet services have enabled financial institutions to deliver better customer experience through multi-channel engagements, which has led to exponential growth in transactions and new avenues for laundering the money for fraudsters. Literature shows the usage of statistical methods, data mining and Machine Learning (ML) techniques for money laundering detection, but limited research on Deep Learning (DL) techniques, primarily due to lack of model interpretability and explainability of the decisions made. Several studies are conducted on application of ML for Anti-Money Laundering (AML), and Explainable Artificial Intelligence (XAI) techniques in general, but lacks the study on usage of DL techniques together with XAI. This paper aims to review the current state-of-the-art literature on DL together with XAI for identifying suspicious money laundering transactions and identify future research areas. Key findings of the review are, researchers have preferred variants of Convolutional Neural Networks, and AutoEncoder; graph deep learning together with natural language processing is emerging as an important technology for AML; XAI use is not seen in AML domain; 51% ML methods used in AML are non-interpretable, 58% studies used sample of old real data; key challenges for researchers are access to recent real transaction data and scarcity of labelled training data; and data being highly imbalanced. Future research directions are, application of XAI techniques to bring-out explainability, graph deep learning using natural language processing (NLP), unsupervised and reinforcement learning to handle lack of labelled data; and joint research programs between research community and industry to benefit from domain knowledge and controlled access to data.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3086230",
            "Date of Publication": "04 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dattatray Vishnu Kute",
                "labs": [
                    "Centre for Advanced Modelling and Geospatial Information Systems (CAMGIS), Faculty of Engineering and IT, School of Information, Systems and Modelling, University of Technology Sydney, Sydney, NSW, Australia"
                ]
            },
            {
                "name": "Biswajeet Pradhan",
                "labs": [
                    "Centre for Advanced Modelling and Geospatial Information Systems (CAMGIS), Faculty of Engineering and IT, School of Information, Systems and Modelling, University of Technology Sydney, Sydney, NSW, Australia",
                    "Department of Energy and Mineral Resources Engineering, Sejong University, Seoul, South Korea",
                    "Earth Observation Centre, Institute of Climate Change, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Nagesh Shukla",
                "labs": [
                    "Centre for Advanced Modelling and Geospatial Information Systems (CAMGIS), Faculty of Engineering and IT, School of Information, Systems and Modelling, University of Technology Sydney, Sydney, NSW, Australia"
                ]
            },
            {
                "name": "Abdullah Alamri",
                "labs": [
                    "Department of Geology and Geophysics, College of Science, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Machine learning",
                "Artificial intelligence",
                "Finance",
                "Data mining",
                "Australia",
                "Statistical analysis"
            ],
            "Author Keywords": [
                "Money laundering",
                "machine learning",
                "deep learning",
                "explainable AI",
                "suspicious transaction"
            ]
        }
    },
    {
        "Title": "A CNN-Transformer Hybrid Approach for Crop Classification Using Multitemporal Multisensor Images",
        "Link": "https://ieeexplore.ieee.org/document/8999620/",
        "Abstract": "Multitemporal Earth observation capability plays an increasingly important role in crop monitoring. As the frequency of satellite acquisition of remote sensing images becomes higher, how to fully exploit the implicit phenological laws in dense multitemporal data is of increasing importance. In this article, we propose a CNN-transformer approach to perform the crop classification, in the model, we borrow the transformer architecture from the knowledge of NLP to dig into the pattern of multitemporal sequence. First, after unifying the spatial-spectral scale of each multiband data acquired from different sensors, we obtain the scale-consistent feature and position feature of multitemporal sequence. Second, with adopting multilayer encoder modules derived from the transformer, we mine deep correlation patterns of multitemporal sequence. Finally, the feed-forward layer and softmax layer serve as output layers of the model to predict crop categories. The proposed CNN-transformer approach is illustrated in a crop-rich agricultural region in central California, where 65 multitemporal profiles from multisensor Sentinel-2 A/B and Landsat-8 are obtained in 2018. Through multiband multiresolution fusion, sequence correlation extraction of multitemporal data and category feature extraction, the classification results show that the proposed method has a significant performance improvement compared with other traditional methods.",
        "Details": {
            "DOI": "10.1109/JSTARS.2020.2971763",
            "Date of Publication": "14 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing"
        },
        "issn_info": {
            "Print ISSN": "1939-1404",
            "Electronic ISSN": "2151-1535"
        },
        "authors_data": [
            {
                "name": "Zhengtao Li",
                "labs": [
                    "Institute for Pattern Recognition and Artificial Intelligence, Huazhong University of Science and Technology, Wuhan, China"
                ]
            },
            {
                "name": "Guokun Chen",
                "labs": [
                    "Wireless Technology Laboratory, Ericsson Research, Kista, Sweden"
                ]
            },
            {
                "name": "Tianxu Zhang",
                "labs": [
                    "Institute for Pattern Recognition and Artificial Intelligence, Huazhong University of Science and Technology, Wuhan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Agriculture",
                "Remote sensing",
                "Earth",
                "Artificial satellites",
                "Correlation",
                "Satellites",
                "Sensors"
            ],
            "Author Keywords": [
                "Crop classification",
                "multitemporal multisensor",
                "self-attention",
                "transformer"
            ]
        }
    },
    {
        "Title": "Limitations of Transformers on Clinical Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9364676/",
        "Abstract": "Bidirectional Encoder Representations from Transformers (BERT) and BERT-based approaches are the current state-of-the-art in many natural language processing (NLP) tasks; however, their application to document classification on long clinical texts is limited. In this work, we introduce four methods to scale BERT, which by default can only handle input sequences up to approximately 400 words long, to perform document classification on clinical texts several thousand words long. We compare these methods against two much simpler architectures – a word-level convolutional neural network and a hierarchical self-attention network – and show that BERT often cannot beat these simpler baselines when classifying MIMIC-III discharge summaries and SEER cancer pathology reports. In our analysis, we show that two key components of BERT – pretraining and WordPiece tokenization – may actually be inhibiting BERT's performance on clinical text classification tasks where the input document is several thousand words long and where correctly identifying labels may depend more on identifying a few key words or phrases rather than understanding the contextual meaning of sequences of text.",
        "Details": {
            "DOI": "10.1109/JBHI.2021.3062322",
            "Date of Publication": "26 February 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Biomedical and Health Informatics"
        },
        "issn_info": {
            "Print ISSN": "2168-2194",
            "Electronic ISSN": "2168-2208"
        },
        "authors_data": [
            {
                "name": "Shang Gao",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "Mohammed Alawad",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "M. Todd Young",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "John Gounley",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "Noah Schaefferkoetter",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "Hong Jun Yoon",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            },
            {
                "name": "Xiao-Cheng Wu",
                "labs": [
                    "Louisiana Tumor Registry, Louisiana State University Health Sciences Center, New Orleans, LA, USA"
                ]
            },
            {
                "name": "Eric B. Durbin",
                "labs": [
                    "Kentucky Cancer Registry, University of Kentucky, Lexington, KY 40536, USA"
                ]
            },
            {
                "name": "Jennifer Doherty",
                "labs": [
                    "Utah Cancer Registry, University of Utah Health Huntsman Cancer Institute, Salt Lake City, UT 84132, USA"
                ]
            },
            {
                "name": "Antoinette Stroup",
                "labs": [
                    "New Jersey State Cancer Registry, Trenton, NJ 08625, USA"
                ]
            },
            {
                "name": "Linda Coyle",
                "labs": [
                    "Information Management Services Inc., Calverton, MD 20705, USA"
                ]
            },
            {
                "name": "Georgia Tourassi",
                "labs": [
                    "Oak Ridge National Laboratory, Oak Ridge, TN 37830, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Task analysis",
                "Cancer",
                "MIMICs",
                "Biological system modeling",
                "Adaptation models",
                "Data models"
            ],
            "Author Keywords": [
                "BERT",
                "clinical text",
                "deep learning",
                "natural language processing",
                "neural networks",
                "text classification"
            ]
        }
    },
    {
        "Title": "A Long-Text Classification Method of Chinese News Based on BERT and CNN",
        "Link": "https://ieeexplore.ieee.org/document/9743465/",
        "Abstract": "Text Classification is an important research area in natural language processing (NLP) that has received a considerable amount of scholarly attention in recent years. However, real Chinese online news is characterized by long text, a large amount of information and complex structure, which also reduces the accuracy of Chinese long text classification as a result. To improve the accuracy of long text classification of Chinese news, we propose a BERT-based local feature convolutional network (LFCN) model including four novel modules. First, to address the limitation of Bidirectional Encoder Representations from Transformers (BERT) on the length of the max input sequence, we propose a named Dynamic LEAD-n (DLn) method to extract short texts within the long text based on the traditional LEAD digest algorithm. In Text-Text Encoder (TTE) module, we use BERT pretrained language model to complete the sentence-level feature vector representation of a news text and to capture global features by using the attention mechanism to identify correlated words in text. After that, we propose a CNN-based local feature convolution (LFC) module to capture local features in text, such as key phrases. Finally, the feature vectors generated by the different operations over several different periods are fused and used to predict the category of a news text. Experimental results show that the new method further improves the accuracy of long text classification of Chinese news.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3162614",
            "Date of Publication": "28 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xinying Chen",
                "labs": [
                    "School of Computer and Communication Engineering, Dalian Jiaotong University, Dalian, China"
                ]
            },
            {
                "name": "Peimin Cong",
                "labs": [
                    "School of Computer and Communication Engineering, Dalian Jiaotong University, Dalian, China"
                ]
            },
            {
                "name": "Shuo Lv",
                "labs": [
                    "School of Computer and Communication Engineering, Dalian Jiaotong University, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Task analysis",
                "Convolutional neural networks",
                "Feature extraction",
                "Lead",
                "Transformers",
                "Convolution"
            ],
            "Author Keywords": [
                "Bidirectional encoder representations from transformers",
                "Chinese long text classification",
                "convolutional neural network",
                "natural language processing",
                "representation learning"
            ]
        }
    },
    {
        "Title": "Multi-Task Learning Model Based on Multi-Scale CNN and LSTM for Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/9076160/",
        "Abstract": "Sentiment classification is an interesting and crucial research topic in the field of natural language processing (NLP). Data-driven methods, including machine learning and deep learning techniques, provide one direct and effective solution to solve the sentiment classification problem. However, the classification performance declines when the input includes review comments for multiple tasks. The most appropriate way of constructing a sentiment classification model under multi-tasking circumstances remains questionable in the related field. In this study, aiming at the multi-tasking sentiment classification problem, we propose a multi-task learning model based on a multi-scale convolutional neural network (CNN) and long short term memory (LSTM) for multi-task multi-scale sentiment classification (MTL-MSCNN-LSTM). The model comprehensively utilizes and properly handles global features and local features of different scales of text to model and represent sentences. The multi-task learning framework improves the encoder quality, simultaneously improving the results of emotion classification. Six different types of commodity review datasets were employed in the experiment. Using accuracy and F1-score as the metrics to evaluate the performance of the proposed model, comparing with methods such as single-task learning and LSTM encoder, the proposed MTL-MSCNN-LSTM model outperforms most of the existing methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2989428",
            "Date of Publication": "22 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ning Jin",
                "labs": [
                    "Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China"
                ]
            },
            {
                "name": "Jiaxian Wu",
                "labs": [
                    "Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China"
                ]
            },
            {
                "name": "Xiang Ma",
                "labs": [
                    "Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China"
                ]
            },
            {
                "name": "Ke Yan",
                "labs": [
                    "Key Laboratory of Electromagnetic Wave Information Technology and Metrology of Zhejiang Province, College of Information Engineering, China Jiliang University, Hangzhou, China"
                ]
            },
            {
                "name": "Yuchang Mo",
                "labs": [
                    "Fujian Province University Key Laboratory of Computational Science, School of Mathematical Sciences, Huaqiao University, Quanzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Feature extraction",
                "Machine learning",
                "Sentiment analysis",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Sentiment classification",
                "multi-task learning model",
                "long short term memory",
                "multi-scale convolutional neural network"
            ]
        }
    },
    {
        "Title": "Context-Based Feature Technique for Sarcasm Identification in Benchmark Datasets Using Deep Learning and BERT Model",
        "Link": "https://ieeexplore.ieee.org/document/9383219/",
        "Abstract": "Sarcasm is a complicated linguistic term commonly found in e-commerce and social media sites. Failure to identify sarcastic utterances in Natural Language Processing applications such as sentiment analysis and opinion mining will confuse classification algorithms and generate false results. Several studies on sarcasm detection have utilised different learning algorithms. However, most of these learning models have always focused on the contents of expression only, leaving the contextual information in isolation. As a result, they failed to capture the contextual information in the sarcastic expression. Secondly, many deep learning methods in NLP uses a word embedding learning algorithm as a standard approach for feature vector representation, which ignores the sentiment polarity of the words in the sarcastic expression. This study proposes a context-based feature technique for sarcasm Identification using the deep learning model, BERT model, and conventional machine learning to address the issues mentioned above. Two Twitter and Internet Argument Corpus, version two (IAC-v2) benchmark datasets were utilised for the classification using the three learning models. The first model uses embedding-based representation via deep learning model with bidirectional long short term memory (Bi-LSTM), a variant of Recurrent Neural Network (RNN), by applying Global Vector representation (GloVe) for the construction of word embedding and context learning. The second model is based on Transformer using a pre-trained Bidirectional Encoder representation and Transformer (BERT). In contrast, the third model is based on feature fusion that comprised BERT feature, sentiment related, syntactic, and GloVe embedding feature with conventional machine learning. The effectiveness of this technique is tested with various evaluation experiments. However, the technique's evaluation on two Twitter benchmark datasets attained 98.5% and 98.0% highest precision, respectively. The IAC-v2 dataset, on the other hand, achieved the highest precision of 81.2%, which shows the significance of the proposed technique over the baseline approaches for sarcasm analysis.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3068323",
            "Date of Publication": "23 March 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Christopher Ifeanyi Eke",
                "labs": [
                    "Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia",
                    "Department of Computer Science, Faculty of Computing, Federal University, Lafia, P.M.B 046"
                ]
            },
            {
                "name": "Azah Anir Norman",
                "labs": [
                    "Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Liyana Shuib",
                "labs": [
                    "Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Deep learning",
                "Context modeling",
                "Semantics",
                "Bit error rate",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Natural language processing",
                "sarcasm identification",
                "Bi-LSTM",
                "GloVe embedding",
                "BERT"
            ]
        }
    },
    {
        "Title": "Neural Architecture Search for Transformers: A Survey",
        "Link": "https://ieeexplore.ieee.org/document/9913476/",
        "Abstract": "Transformer-based Deep Neural Network architectures have gained tremendous interest due to their effectiveness in various applications across Natural Language Processing (NLP) and Computer Vision (CV) domains. These models are the de facto choice in several language tasks, such as Sentiment Analysis and Text Summarization, replacing Long Short Term Memory (LSTM) model. Vision Transformers (ViTs) have shown better model performance than traditional Convolutional Neural Networks (CNNs) in vision applications while requiring significantly fewer parameters and training time. The design pipeline of a neural architecture for a given task and dataset is extremely challenging as it requires expertise in several interdisciplinary areas such as signal processing, image processing, optimization and allied fields. Neural Architecture Search (NAS) is a promising technique to automate the architectural design process of a Neural Network in a data-driven way using Machine Learning (ML) methods. The search method explores several architectures without requiring significant human effort, and the searched models outperform the manually built networks. In this paper, we review Neural Architecture Search techniques, targeting the Transformer model and its family of architectures such as Bidirectional Encoder Representations from Transformers (BERT) and Vision Transformers. We provide an in-depth literature review of approximately 50 state-of-the-art Neural Architecture Search methods and explore future directions in this fast-evolving class of problems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3212767",
            "Date of Publication": "06 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Krishna Teja Chitty-Venkata",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            },
            {
                "name": "Murali Emani",
                "labs": [
                    "Argonne National Laboratory, Lemont, IL, USA"
                ]
            },
            {
                "name": "Venkatram Vishwanath",
                "labs": [
                    "Argonne National Laboratory, Lemont, IL, USA"
                ]
            },
            {
                "name": "Arun K. Somani",
                "labs": [
                    "Department of Electrical and Computer Engineering, Iowa State University, Ames, IA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Computer architecture",
                "Convolutional neural networks",
                "Computational modeling",
                "Bit error rate",
                "Search problems"
            ],
            "Author Keywords": [
                "Neural architecture search",
                "NAS",
                "transformers",
                "BERT",
                "vision transformers",
                "multi-head self-attention",
                "hardware-aware NAS"
            ]
        }
    },
    {
        "Title": "PrivFT: Private and Fast Text Classification With Homomorphic Encryption",
        "Link": "https://ieeexplore.ieee.org/document/9296754/",
        "Abstract": "We present an efficient and non-interactive method for Text Classification while preserving the privacy of the content using Fully Homomorphic Encryption (FHE). Our solution (named Private Fast Text (PrivFT)) provides two services: 1) making inference of encrypted user inputs using a plaintext model and 2) training an effective model using an encrypted dataset. For inference, we use a pre-trained plaintext model and outline a system for homomorphic inference on encrypted user inputs with zero loss to prediction accuracy compared to the non-encrypted version. In the second part, we show how to train a supervised model using fully encrypted data to generate an encrypted model. For improved performance, we provide a GPU implementation of the Cheon-Kim-Kim-Song (CKKS) FHE scheme that shows 1 to 2 orders of magnitude speedup against existing implementations. We build PrivFT on top of our FHE engine in GPUs to achieve a run time per inference of 0.17 seconds for various Natural Language Processing (NLP) public datasets. Training on a relatively large encrypted dataset is more computationally intensive requiring 5.04 days.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3045465",
            "Date of Publication": "17 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ahmad Al Badawi",
                "labs": [
                    "Institute for Infocomm Research, A*STAR, Connexis, Singapore"
                ]
            },
            {
                "name": "Louie Hoang",
                "labs": [
                    "Inferati Inc., Bellevue, WA, USA"
                ]
            },
            {
                "name": "Chan Fook Mun",
                "labs": [
                    "Institute for Infocomm Research, A*STAR, Connexis, Singapore"
                ]
            },
            {
                "name": "Kim Laine",
                "labs": [
                    "Microsoft Research, Redmond, WA, USA"
                ]
            },
            {
                "name": "Khin Mi Mi Aung",
                "labs": [
                    "Institute for Infocomm Research, A*STAR, Connexis, Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cryptography",
                "Training",
                "Cloud computing",
                "Electronic mail",
                "Computational modeling",
                "Data models",
                "Encryption"
            ],
            "Author Keywords": [
                "Cryptography",
                "data privacy",
                "data security",
                "homomorphic encryption",
                "natural language processing",
                "graphics processors"
            ]
        }
    },
    {
        "Title": "Learning Political Polarization on Social Media Using Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/9026882/",
        "Abstract": "Social media analysis is a fast growing research area aimed at extracting useful information from social media platforms. This paper presents a methodology, called IOM-NN (Iterative Opinion Mining using Neural Networks), for discovering the polarization of social media users during election campaigns characterized by the competition of political factions. The methodology uses an automatic incremental procedure based on feed-forward neural networks for analyzing the posts published by social media users. Starting from a limited set of classification rules, created from a small subset of hashtags that are notoriously in favor of specific factions, the methodology iteratively generates new classification rules. Such rules are then used to determine the polarization of people towards a faction. The methodology has been assessed on two case studies that analyze the polarization of a large number of Twitter users during the 2018 Italian general election and 2016 US presidential election. The achieved results are very close to the real ones and more accurate than the average of the opinion polls, revealing the high accuracy and effectiveness of the proposed approach. Moreover, our approach has been compared to the most relevant techniques used in the literature (sentiment analysis with NLP, adaptive sentiment analysis, emoji- and hashtag- based polarization) by achieving the best accuracy in estimating the polarization of social media users.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2978950",
            "Date of Publication": "06 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Loris Belcastro",
                "labs": [
                    "DIMES - University of Calabria, Rende, Italy"
                ]
            },
            {
                "name": "Riccardo Cantini",
                "labs": [
                    "DIMES - University of Calabria, Rende, Italy"
                ]
            },
            {
                "name": "Fabrizio Marozzo",
                "labs": [
                    "DIMES - University of Calabria, Rende, Italy",
                    "DtoK Lab Srl, Rende, Italy"
                ]
            },
            {
                "name": "Domenico Talia",
                "labs": [
                    "DIMES - University of Calabria, Rende, Italy",
                    "DtoK Lab Srl, Rende, Italy"
                ]
            },
            {
                "name": "Paolo Trunfio",
                "labs": [
                    "DIMES - University of Calabria, Rende, Italy",
                    "DtoK Lab Srl, Rende, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Voting",
                "Neural networks",
                "Twitter",
                "Sentiment analysis",
                "Tagging"
            ],
            "Author Keywords": [
                "Social media analysis",
                "opinion mining",
                "user polarization",
                "neural networks",
                "sentiment analysis",
                "political events"
            ]
        }
    },
    {
        "Title": "Identifying Enhancers and Their Strength by the Integration of Word Embedding and Convolution Neural Network",
        "Link": "https://ieeexplore.ieee.org/document/9044822/",
        "Abstract": "The enhancer is a short regulatory element that plays a major role in up-regulating eukaryotic gene expression. To identify enhancers, an experimental process takes a long time and high cost; therefore, an accurate computational tool is a much-needed work in this area. Existing techniques were developed by the use of handcrafted features followed by machine learning techniques, while the proposed model extracts the features of enhancers from raw DNA sequences by the integration of natural language processing (NLP) technique using word2vec and convolutional neural network (CNN). Therefore, an accurate computational tool, iEnhancer-CNN, is developed. The developed tool can predict enhancers and their strength. The evaluation results show that iEnhancer-CNN is remarkably superior to the existing state-of-the-art models. In more detail, iEnhancer-CNN improved the accuracy of enhancer and enhancer strength identification by 2.6% and 11.4%, respectively. A web server for the iEnhancer-CNN is freely available at https://home.jbnu.ac.kr/NSCL/iEnhancer-CNN.htm.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2982666",
            "Date of Publication": "23 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jhabindra Khanal",
                "labs": [
                    "Department of Electronics and Information Engineering, Chonbuk National University, Jeonju, South Korea"
                ]
            },
            {
                "name": "Hilal Tayara",
                "labs": [
                    "Department of Electronics and Information Engineering, Chonbuk National University, Jeonju, South Korea"
                ]
            },
            {
                "name": "Kil To Chong",
                "labs": [
                    "Advanced Electronics and Information Research Center, Chonbuk National University, Jeonju, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Genomics",
                "Bioinformatics",
                "DNA",
                "Benchmark testing",
                "Convolution",
                "Tools",
                "Predictive models"
            ],
            "Author Keywords": [
                "Convolutional neural network",
                "DNA sequence",
                "deep learning",
                "enhancers",
                "K-mers",
                "word2vec"
            ]
        }
    },
    {
        "Title": "Arabic Natural Language Processing and Machine Learning-Based Systems",
        "Link": "https://ieeexplore.ieee.org/document/8594541/",
        "Abstract": "Arabic natural language processing (ANLP) consists of developing techniques and tools that can utilize and analyze the Arabic language in both written and spoken contexts. ANLP makes an important contribution to many existing developed systems. It provides Arabic and non-Arabic speakers with helpful and convenient tools that can be used in different domains. Modern ANLP tools are developed using machine learning (ML) techniques. ML algorithms are widely used in NLP because of their high accuracy rate regardless of the robustness of the data that is used and because of the ease with which they can be implemented. On the other hand, the methodology of ANLP applications based on ML involves several distinct phases. It is, therefore, crucial to recognize and understand these phases in detail as well as the most widely used ML algorithms. This survey discusses this concept in detail, shows the involvement of ML techniques in developing such tools, and identifies well-known techniques used in ANLP. Moreover, this survey discusses the characteristics and complexity of the Arabic language in addition to the importance and needs of ANLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2018.2890076",
            "Date of Publication": "28 December 2018",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Souad Larabi Marie-Sainte",
                "labs": [
                    "Computer Science Department, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nada Alalyani",
                "labs": [
                    "Information Technology Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sihaam Alotaibi",
                "labs": [
                    "Computer Science and Information Technology Department, College of Community, Princess Noura bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sanaa Ghouzali",
                "labs": [
                    "Information Technology Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ibrahim Abunadi",
                "labs": [
                    "Computer Science Department, College of Computer and Information Sciences, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Tools",
                "Machine learning",
                "Task analysis",
                "Machine learning algorithms",
                "Complexity theory",
                "Software"
            ],
            "Author Keywords": [
                "Arabic natural language processing",
                "classification",
                "feature selection",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Multimodal Encoder-Decoder Attention Networks for Visual Question Answering",
        "Link": "https://ieeexplore.ieee.org/document/9003229/",
        "Abstract": "Visual Question Answering (VQA) is a multimodal task involving Computer Vision (CV) and Natural Language Processing (NLP), the goal is to establish a high-efficiency VQA model. Learning a fine-grained and simultaneous understanding of both the visual content of images and the textual content of questions is the heart of VQA. In this paper, a novel Multimodal Encoder-Decoder Attention Networks (MEDAN) is proposed. The MEDAN consists of Multimodal Encoder-Decoder Attention (MEDA) layers cascaded in depth, and can capture rich and reasonable question features and image features by associating keywords in question with important object regions in image. Each MEDA layer contains an Encoder module modeling the self-attention of questions, as well as a Decoder module modeling the question-guided-attention and self-attention of images. Experimental evaluation results on the benchmark VQA-v2 dataset demonstrate that MEDAN achieves state-of-the-art VQA performance. With the Adam solver, our best single model delivers 71.01% overall accuracy on the test-std set, and with the AdamW solver, we achieve an overall accuracy of 70.76% on the test-dev set. Additionally, extensive ablation studies are conducted to explore the reasons for MEDAN's effectiveness.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2975093",
            "Date of Publication": "19 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chongqing Chen",
                "labs": [
                    "School of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Dezhi Han",
                "labs": [
                    "School of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Jun Wang",
                "labs": [
                    "Department of ECE, University of Central Florida, Orlando, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Visualization",
                "Decoding",
                "Task analysis",
                "Knowledge discovery",
                "Natural language processing",
                "Benchmark testing"
            ],
            "Author Keywords": [
                "Computer vision",
                "encoder-decoder attention",
                "multimodal task",
                "natural language processing",
                "question-guided-attention",
                "self-attention",
                "visual question answering"
            ]
        }
    },
    {
        "Title": "Adaptive Bit Rate Control in Semantic Communication With Incremental Knowledge-Based HARQ",
        "Link": "https://ieeexplore.ieee.org/document/9827978/",
        "Abstract": "Semantic communication has witnessed a great progress with the development of natural language processing (NLP) and deep learning (DL). Although existing semantic communication technologies can effectively reduce errors in semantic interpretation, most of these solutions adopt a fixed bit length structure, along with a rigid transmission scheme, which is inefficient and lacks scalability faced with different meanings and signal-to-noise ratio (SNR) conditions. In this paper, we explore the impact of adaptive bit lengths on semantic coding (SC) under various channel conditions. First, we propose progressive semantic hybrid automatic repeat request (HARQ) schemes that utilize incremental knowledge (IK) to simultaneously reduce the communication cost and semantic error. On top of this, we design a novel semantic encoding solution with multi-bit length selection. In this fashion, the transmitter employs a policy network to decide the appropriate coding rate, so as to secure the correct information delivery at the cost of minimal bits. Moreover, a specific denoiser is further introduced to reduce the semantic errors encountered in the transmission process according to the semantic characteristics of context. Extensive simulation results have been conducted to verify the effectiveness of the proposed solution.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2022.3189023",
            "Date of Publication": "12 July 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Qingyang Zhou",
                "labs": [
                    "College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Rongpeng Li",
                "labs": [
                    "College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China"
                ]
            },
            {
                "name": "Zhifeng Zhao",
                "labs": [
                    "College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China",
                    "Zhejiang Lab, Hangzhou, China"
                ]
            },
            {
                "name": "Yong Xiao",
                "labs": [
                    "School of Electronic Information and Communications, Huazhong University of Science and Technology, Wuhan, China",
                    "Pengcheng National Laboratory (Guangzhou Base), Guangzhou, China"
                ]
            },
            {
                "name": "Honggang Zhang",
                "labs": [
                    "College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China",
                    "Zhejiang Lab, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Decoding",
                "Encoding",
                "Bit rate",
                "Transformers",
                "Noise reduction",
                "Channel coding"
            ],
            "Author Keywords": [
                "Semantic communication",
                "semantic coding",
                "joint source channel coding",
                "deep learning",
                "neural network",
                "transformer",
                "end-to-end communication",
                "HARQ"
            ]
        }
    },
    {
        "Title": "Predicting Depression Symptoms in an Arabic Psychological Forum",
        "Link": "https://ieeexplore.ieee.org/document/9040556/",
        "Abstract": "Recently, social media platforms have been widely used as a communication tool on social networks. Many users have utilized these platforms to reflect their personal lives. These users differ in terms of background, language, age, and educational level. The close relationship between these platforms and their users has created rich information that is related to these users and can be exploited by researchers. Their posts can be analysed using natural language processing (NLP) to predict psychological traits such as depression. However, to the best of our knowledge, no study has utilized social media to predict mental health disorders in Arabic posts, especially depression. Therefore, in this study, we investigate the application of natural language processing and machine learning on Arabic text for the prediction of depression, and we evaluate and compare the performance. Our research method is based on the collection of Arabic text from online forums and the application of either a lexicon-based approach or a machine-learning-based approach. In the former approach, the ArabDep lexicon is created, and a rule-based algorithm is used to predict depression symptoms using the created lexicon; however, in the latter approach, the data are annotated with the help of a psychologist, text features are extracted from Arabic posts, and machine learning algorithms are ultimately applied to predict depression symptoms. We demonstrate that our applied approaches exhibit promising performance in predicting whether a post corresponds to depression symptoms, with an accuracy of more than 80%, a recall of 82% and a precision of 79%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2981834",
            "Date of Publication": "18 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Norah Saleh Alghamdi",
                "labs": [
                    "College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Hanan A. Hosni Mahmoud",
                "labs": [
                    "College of Computer and Information Sciences, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia",
                    "Department of Computer and Systems Engineering, Faculty of Engineering, University of Alexandria, Alexandria, Egypt"
                ]
            },
            {
                "name": "Ajith Abraham",
                "labs": [
                    "Machine Intelligence Research Labs (MIR Labs), Washington, USA"
                ]
            },
            {
                "name": "Samar Awadh Alanazi",
                "labs": [
                    "Autism Centre, Prince Sultan Military Medical City, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Laura García-Hernández",
                "labs": [
                    "Area of Project Engineering, University of Córdoba, Córdoba, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Depression",
                "Feature extraction",
                "Natural language processing",
                "Social networking (online)",
                "Mental health",
                "Mental disorders"
            ],
            "Author Keywords": [
                "Supervised learning",
                "semi-supervised learning",
                "machine learning",
                "predictive models",
                "depression",
                "lexicon",
                "text analysis"
            ]
        }
    },
    {
        "Title": "Relation classification via recurrent neural network with attention and tensor layers",
        "Link": "https://ieeexplore.ieee.org/document/8361575/",
        "Abstract": "Relation classification is a crucial component in many Natural Language Processing (NLP) systems. In this paper, we propose a novel bidirectional recurrent neural network architecture (using Long Short-Term Memory, LSTM, cells) for relation classification, with an attention layer for organizing the context information on the word level and a tensor layer for detecting complex connections between two entities. The above two feature extraction operations are based on the LSTM networks and use their outputs. Our model allows end-to-end learning from the raw sentences in the dataset, without trimming or reconstructing them. Experiments on the SemEval-2010 Task 8 dataset show that our model outperforms most state-of-the-art methods.",
        "Details": {
            "DOI": "10.26599/BDMA.2018.9020022",
            "Date of Publication": "24 May 2018",
            "Publisher": "TUP",
            "Published In": "Big Data Mining and Analytics"
        },
        "issn_info": {
            "Print ISSN": "2096-0654",
            "Electronic ISSN": "2097-406X"
        },
        "authors_data": [
            {
                "name": "Runyan Zhang",
                "labs": [
                    "China University of Mining and Technology, Xuzhou, Jiangsu, CN"
                ]
            },
            {
                "name": "Fanrong Meng",
                "labs": [
                    "China University of Mining and Technology, Xuzhou, Jiangsu, CN"
                ]
            },
            {
                "name": "Yong Zhou",
                "labs": [
                    "China University of Mining and Technology, Xuzhou, Jiangsu, CN"
                ]
            },
            {
                "name": "Bing Liu",
                "labs": [
                    "China University of Mining and Technology, Xuzhou, Jiangsu, CN"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tensile stress",
                "Feature extraction",
                "Recurrent neural networks",
                "Task analysis",
                "Semantics",
                "Logic gates"
            ],
            "Author Keywords": [
                "semantic relation classification; bidirectional Recurrent Neural Network (RNNs); attention mechanism;neural tensor networks"
            ]
        }
    },
    {
        "Title": "Predicting Personality Using Answers to Open-Ended Interview Questions",
        "Link": "https://ieeexplore.ieee.org/document/9121971/",
        "Abstract": "One’s personality is widely accepted as an indicator of job performance, job satisfaction and tenure intention. The ability to measure an applicant’s personality in the selection process helps recruiters, hiring managers and the applicant make better hiring decisions. Our work shows that textual content of answers to standard interview questions related to past behaviour and situational judgement can be used to reliably infer personality traits. We used data from over 46,000 job applicants who completed an online chat interview that also included a personality questionnaire based on the six-factor HEXACO personality model to self-rate their personality. Using natural language processing (NLP) and machine learning methods we built a regression model to infer HEXACO trait values from textual content. We compared the performance of five different text representation methods and found that term frequency-inverse document frequency (TF-IDF) with Latent Dirichlet Allocation (LDA) topics performed the best with an average correlation of r = 0.39. As a comparison, a large study of Facebook messages based inference of Big 5 personality found an average correlation of r = 0.35 and IBM’s Personality Insights service built using twitter text data reports an average correlation of r = 0.31. We further validated our model with a group of 117 volunteers who used an agreement scale of yes/no/maybe to rate the individual trait descriptors generated based on the model outcomes. On average, 87.83% of the participants agreed with the personality description given for each of the six traits. The ability of algorithms to objectively infer a candidate’s personality using only the textual content of interview answers presents significant opportunities to remove the subjective biases involved in human interviewer judgement of candidate personality.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3004002",
            "Date of Publication": "22 June 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Madhura Jayaratne",
                "labs": [
                    "PredictiveHire Pty Ltd., Cremorne, VIC, Australia",
                    "Centre for Data Analytics and Cognition, La Trobe University, Bundoora, VIC, Australia"
                ]
            },
            {
                "name": "Buddhi Jayatilleke",
                "labs": [
                    "PredictiveHire Pty Ltd., Cremorne, VIC, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Interviews",
                "Correlation",
                "Predictive models",
                "Natural language processing",
                "Machine learning",
                "Engineering profession",
                "Employment"
            ],
            "Author Keywords": [
                "HEXACO personality traits",
                "linguistic analysis",
                "personality prediction"
            ]
        }
    },
    {
        "Title": "Oppositional Jaya Algorithm With Distance-Adaptive Coefficient in Solving Directional Over Current Relays Coordination Problem",
        "Link": "https://ieeexplore.ieee.org/document/8871186/",
        "Abstract": "The model of directional over current relays (DOCRs) coordination is considered as an optimization problem. It is generally formulated as linear programming (LP), non-linear programming (NLP) and mixed integer non-linear programming (MINLP), according to the nature of the design variables. For each kind of formulation, the main goal is to minimize the summation of operating times of primary relays, by setting optimal values for decision variables as time dial setting (TDS) and pickup current setting (IP) or plug setting (PS). In this paper, we proposed an oppositional Jaya (OJaya) algorithm with distance-adaptive coefficient (DAC), to effectively solve the DOCRs coordination problem. Firstly, by oppositional learning (OL), the searching space of Jaya is expanded and the diversity of its population is strengthened; secondly, by DAC, the population's trends of running towards the best position and escaping from the worst position is accelerated. The performance of OJaya is evaluated by 3-bus, 8-bus, 9-bus and 15-bus testing systems, in aspects of convergence rate, objective function value, robustness and computation efficiency. The results indicate the effectiveness and superiority of OJaya in solving DOCRs coordination problems compared with standard Jaya.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2947626",
            "Date of Publication": "16 October 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiangtao Yu",
                "labs": [
                    "Department of Electronic Information and Electrical Engineering, Anyang Institute of Technology, Anyang, China"
                ]
            },
            {
                "name": "Chang-Hwan Kim",
                "labs": [
                    "Department of Electrical Engineering, Yeungnam University, Kyonsan, South Korea"
                ]
            },
            {
                "name": "Sang-Bong Rhee",
                "labs": [
                    "Department of Electrical Engineering, Yeungnam University, Kyonsan, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Relays",
                "Sociology",
                "Statistics",
                "Optimization",
                "Linear programming",
                "Heuristic algorithms",
                "IP networks"
            ],
            "Author Keywords": [
                "Jaya",
                "oppositional learning",
                "distance-adaptive coefficient",
                "over current relays coordination"
            ]
        }
    },
    {
        "Title": "Optimal Multi-Period Dispatch of Distributed Energy Resources in Unbalanced Distribution Feeders",
        "Link": "https://ieeexplore.ieee.org/document/8952594/",
        "Abstract": "This paper presents an efficient algorithm for the multi-period optimal dispatch of deterministic inverter-interfaced energy storage in an unbalanced distribution feeder with significant solar PV penetration. The three-phase, non-convex loss-minimization problem is formulated as a convex second-order cone program (SOCP) for the dispatch of batteries in a receding-horizon fashion in order to counter against the variable, renewable generation. The solution of the SOCP is used to initialize a nonlinear program (NLP) in order to ensure a physically realizable solution. The phenomenon of simultaneous charging and discharging of batteries is rigorously analyzed and conditions are derived that guarantee it is avoided. Simulation scenarios are implemented with GridLab-D for the IEEE-13 and IEEE-123 node test feeders and illustrate not only AC feasibility of the solution, but also near-optimal performance and solve-times within a minute.",
        "Details": {
            "DOI": "10.1109/TPWRS.2019.2963249",
            "Date of Publication": "08 January 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Power Systems"
        },
        "issn_info": {
            "Print ISSN": "0885-8950",
            "Electronic ISSN": "1558-0679"
        },
        "authors_data": [
            {
                "name": "Nawaf Nazir",
                "labs": [
                    "Department of Electrical and Biomedical Engineering, University of Vermont, Burlington, USA"
                ]
            },
            {
                "name": "Pavan Racherla",
                "labs": [
                    "Department of Electrical and Biomedical Engineering, University of Vermont, Burlington, USA"
                ]
            },
            {
                "name": "Mads Almassalkhi",
                "labs": [
                    "Department of Electrical and Biomedical Engineering, University of Vermont, Burlington, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Batteries",
                "Mathematical model",
                "Load flow",
                "Optimization",
                "Computational modeling",
                "Inverters"
            ],
            "Author Keywords": [
                "Energy storage",
                "unbalanced distribution feeders",
                "loss minimization",
                "convex optimization"
            ]
        }
    },
    {
        "Title": "An Infoveillance System for Detecting and Tracking Relevant Topics From Italian Tweets During the COVID-19 Event",
        "Link": "https://ieeexplore.ieee.org/document/9143071/",
        "Abstract": "The year 2020 opened with a dramatic epidemic caused by a new species of coronavirus that soon has been declared a pandemic by the WHO due to the high number of deaths and the critical mass of worldwide hospitalized patients, of order of millions. The COVID-19 pandemic has forced the governments of hundreds of countries to apply several heavy restrictions in the citizens’ socio-economic life. Italy was one of the most affected countries with long-term restrictions, impacting the socio-economic tissue. During this lockdown period, people got informed mostly on Online Social Media, where a heated debate followed all main ongoing events. In this scenario, the following study presents an in-depth analysis of the main emergent topics discussed during the lockdown phase within the Italian Twitter community. The analysis has been conducted through a general purpose methodological framework, grounded on a biological metaphor and on a chain of NLP and graph analysis techniques, in charge of detecting and tracking emerging topics in Online Social Media, e.g. streams of Twitter data. A term-frequency analysis in subsequent time slots is pipelined with nutrition and energy metrics for computing hot terms by also exploiting the tweets quality information, such as the social influence of the users. Finally, a co-occurrence analysis is adopted for building a topic graph where emerging topics are suitably selected. We demonstrate via a careful parameter setting the effectiveness of the topic tracking system, tailored to the current Twitter standard API restrictions, in capturing the main sociopolitical events that occurred during this dramatic phase.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3010033",
            "Date of Publication": "17 July 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Enrico De Santis",
                "labs": [
                    "Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza,”, Rome, Italy"
                ]
            },
            {
                "name": "Alessio Martino",
                "labs": [
                    "Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza,”, Rome, Italy"
                ]
            },
            {
                "name": "Antonello Rizzi",
                "labs": [
                    "Department of Information Engineering, Electronics and Telecommunications, University of Rome “La Sapienza,”, Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Twitter",
                "Feature extraction",
                "Natural language processing",
                "Monitoring",
                "Windows",
                "COVID-19"
            ],
            "Author Keywords": [
                "Natural language processing",
                "topic tracking",
                "topic detection",
                "social network analysis",
                "text mining",
                "COVID-19",
                "infodemiology",
                "infoveillance"
            ]
        }
    },
    {
        "Title": "The Weighted Word2vec Paragraph Vectors for Anomaly Detection Over HTTP Traffic",
        "Link": "https://ieeexplore.ieee.org/document/9154702/",
        "Abstract": "Anomaly detection over HTTP traffic has attracted much attention in recent years, which plays a vital role in many domains. This article proposes an efficient machine learning approach to detect anomalous HTTP traffic that addresses the problems of existing methods, such as data redundancy and high training complexity. This algorithm draws on natural language processing (NLP) technology, uses the Word2vec algorithm to deal with the semantic gap, and implements Term Frequency-Inverse Document Frequency (TF-IDF) weighted mapping of HTTP traffic to construct a low-dimensional paragraph vector representation to reduce training complexity. Then we employs boosting algorithm Light Gradient Boosting Machine (LightGBM) and Categorical Boosting (CatBoost) to build an efficient and accurate anomaly detection model. The proposed method is tested on some artificial data sets, such as HTTP DATASET CSIC 2010, UNSW-NB15, and Malicious-URLs. Experimental results reveal that both the boosting algorithms have high detection accuracy, high true positive rate, and low false positive rate. Compared with other anomaly detection methods, the proposed algorithms require relatively short running time and low CPU memory consumption.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3013849",
            "Date of Publication": "03 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jieling Li",
                "labs": [
                    "College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China",
                    "Fujian Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China"
                ]
            },
            {
                "name": "Hao Zhang",
                "labs": [
                    "College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China",
                    "Fujian Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China"
                ]
            },
            {
                "name": "Zhiqiang Wei",
                "labs": [
                    "College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China",
                    "Fujian Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Anomaly detection",
                "Training",
                "Boosting",
                "Classification algorithms",
                "Prediction algorithms"
            ],
            "Author Keywords": [
                "Anomaly detection",
                "Word2vec",
                "TF-IDF",
                "LightGBM",
                "CatBoost"
            ]
        }
    },
    {
        "Title": "Blockchain-Based Event Detection and Trust Verification Using Natural Language Processing and Machine Learning",
        "Link": "https://ieeexplore.ieee.org/document/9665772/",
        "Abstract": "Information sharing is one of the huge topics in social media platform regarding the daily news related to events or disasters happens in nature or its human-made. The automatic urgent need identification and sharing posts and information delivery with a short response are essential tasks in this area. The key goal of this research is developing a solution for management of disasters and emergency response using social media platforms as a core component. This process focuses on text analysis techniques to improve the process of authorities in terms of emergency response and filter the information using the automatically gathered information to support the relief efforts. Specifically, we used state-of-art Machine Learning (ML), Deep Learning (DL), and Natural Language Processing (NLP) based on supervised and unsupervised learning using social media datasets to extract real-time content related to the emergency events to comfort the fast response in a critical situation. Similarly, the blockchain framework used in this process for trust verification of the detected events and eliminating the single authority on the system. The main reason of using the integrated system is to improve the system security and transparency to avoid sharing the wrong information related to an event in social media.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3139586",
            "Date of Publication": "30 December 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zeinab Shahbazi",
                "labs": [
                    "Department of Computer Engineering, Institute of Information Science Technology, Jeju National University, Jeju-si, South Korea"
                ]
            },
            {
                "name": "Yung-Cheol Byun",
                "labs": [
                    "Department of Computer Engineering, Institute of Information Science Technology, Jeju National University, Jeju-si, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blockchains",
                "Event detection",
                "Natural language processing",
                "Feature extraction",
                "Real-time systems",
                "Blogs"
            ],
            "Author Keywords": [
                "Event detection",
                "machine learning",
                "blockchain",
                "natural language processing",
                "deep learning"
            ]
        }
    },
    {
        "Title": "A MapReduce Opinion Mining for COVID-19-Related Tweets Classification Using Enhanced ID3 Decision Tree Classifier",
        "Link": "https://ieeexplore.ieee.org/document/9404185/",
        "Abstract": "Opinion Mining (OM) is a field of Natural Language Processing (NLP) that aims to capture human sentiment in the given text. With the ever-spreading of online purchasing websites, micro-blogging sites, and social media platforms, OM in online social media platforms has picked the interest of thousands of scientific researchers. Because the reviews, tweets and blogs acquired from these social media networks, act as a significant source for enhancing the decision making process. The obtained textual data (reviews, tweets, or blogs) are classified into three different class labels which are negative, neutral and positive for analyzing and extracting relevant information from the given dataset. In this contribution, we introduce an innovative MapReduce improved weighted ID3 decision tree classification approach for OM, which consists mainly of three aspects: Firstly We have used several feature extractors to efficiently detect and capture the relevant data from the given tweets, including N-grams or character-level, Bag-Of-Words, word embedding (GloVe, Word2Vec), FastText, and TF-IDF. Secondly, we have applied a multiple feature selector to reduce the high feature’s dimensionality, including Chi-square, Gain Ratio, Information Gain, and Gini Index. Finally, we have employed the obtained features to carry out the classification task using an improved ID3 decision tree classifier, which aims to calculate the weighted information gain instead of information gain used in traditional ID3. In other words, to measure the weighted information gain for the current conditioned feature, we follow two steps: First, we compute the weighted correlation function of the current conditioned feature. Second, we multiply the obtained weighted correlation function by the information gain of this current conditioned feature. This work is implemented in a distributed environment using the Hadoop framework, with its programming framework MapReduce and its distributed file system HDFS. Its primary goal is to enhance the performance of a well-known ID3 classifier in terms of accuracy, execution time, and ability to handle the massive datasets. We have carried out several experiences that aims to assess the effectiveness of our suggested classifier compared to some other contributions chosen from the literature. The experimental results demonstrated that our ID3 classifier works better on COVID-19_Sentiments dataset than other classifiers in terms of Recall (85.72 %), specificity (86.51 %), error rate (11.18 %), false-positive rate (13.49 %), execution time (15.95s), kappa statistic (87.69 %), F1-score (85.54 %), classification rate (88.82 %), false-negative rate (14.28 %), precision rate (86.67 %), convergence (it convergent towards the iteration 90), stability (it is more stable with mean deviation standard equal to 0.12 %), and complexity (it requires much lower time and space computational complexity).\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3073215",
            "Date of Publication": "14 April 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatima Es-Sabery",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Khadija Es-Sabery",
                "labs": [
                    "Department of Computer Science, National School of Applied Sciences, Cadi Ayyad University, Marrakech, Morocco"
                ]
            },
            {
                "name": "Junaid Qadir",
                "labs": [
                    "Department of Electronics, Quaid-i-Azam University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Beatriz Sainz-De-Abajo",
                "labs": [
                    "Department of Signal Theory, Communications and Telematics Engineering, University of Valladolid, Valladolid, Spain"
                ]
            },
            {
                "name": "Abdellatif Hair",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Begoña García-Zapirain",
                "labs": [
                    "eVIDA Research Group, University of Deusto, Bilbao, Spain"
                ]
            },
            {
                "name": "Isabel De La Torre-Díez",
                "labs": [
                    "Department of Signal Theory, Communications and Telematics Engineering, University of Valladolid, Valladolid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Feature extraction",
                "Sentiment analysis",
                "Decision trees",
                "Data mining",
                "Big Data"
            ],
            "Author Keywords": [
                "ID3 decision tree",
                "opinion mining",
                "Hadoop",
                "HDFS",
                "MapReduce",
                "feature extractors",
                "feature selectors",
                "DataMining",
                "big data",
                "information gain"
            ]
        }
    },
    {
        "Title": "A Semantic Approach for Automated Rule Compliance Checking in Construction Industry",
        "Link": "https://ieeexplore.ieee.org/document/9523738/",
        "Abstract": "Automated Compliance Checking (ACC) of building/construction projects is one of the important applications in Architecture, Engineering and Construction (AEC) industry, because it provides the checking processes and results of whether a building design complies with relevant laws, policies and regulations. Currently, Automated Compliance Checking still involves lots of manual operations, and massive time and cost consumption. Additionally, some sub-tasks of ACC have been researched, while few studies can automatically implement the whole ACC process. To solve related issues, we proposed a semantic approach to implement the whole ACC process in an automated way. Natural Language Processing (NLP) is used to extract rule terms and logic relationships among these terms from text regulatory documents. Rule terms are mapped to keywords (concepts or properties) in BIM data through term matching and semantic similarity analysis. After that, according to the mapped keywords in BIM and logic relationships among keywords, a corresponding SPARQL query is automatically generated. The query results can be non-compliance or compliance with rules based on the generated SPARQL query and requirements of stakeholders. The cases study proves that the proposed approach can provide a flexible and effective rule checking for BIM data. In addition, based on the proposed approach, we also further develop a semantic framework to implement automated rule compliance checking in construction industry.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3108226",
            "Date of Publication": "26 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dongming Guo",
                "labs": [
                    "Department of Manufacturing and Civil Engineering, Norwegian University of Science and Technology, Gjovik, Norway"
                ]
            },
            {
                "name": "Erling Onstein",
                "labs": [
                    "Department of Manufacturing and Civil Engineering, Norwegian University of Science and Technology, Gjovik, Norway"
                ]
            },
            {
                "name": "Angela Daniela La Rosa",
                "labs": [
                    "Department of Manufacturing and Civil Engineering, Norwegian University of Science and Technology, Gjovik, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Buildings",
                "Data mining",
                "Software",
                "Regulation",
                "Natural language processing",
                "Object oriented modeling"
            ],
            "Author Keywords": [
                "Automated compliance checking",
                "data extraction",
                "ifcOWL",
                "natural language processing",
                "SPARQL generation"
            ]
        }
    },
    {
        "Title": "A Systematic Review on Implicit and Explicit Aspect Extraction in Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9234464/",
        "Abstract": "Aspect-based sentiment analysis (ABSA) is currently among the most vigorous areas in natural language processing (NLP). Individuals, private and government institutions are increasingly using media sources for decision making. In the last decade, aspect extraction has been the most essential phase of sentiment analysis (SA) to conduct an abridged sentiment classification. However, previous studies on sentiment analysis mostly focused on explicit aspects extraction with limited work on implicit aspects. To the best of our knowledge, this is the first systematic review that covers implicit, explicit, and the combination of both implicit and explicit aspect extractions. Therefore, this systematic review has been conducted to, 1) identify techniques used for extracting implicit, explicit, or both implicit and explicit aspects; 2) analyze the various evaluation metrics, data domains, and languages involved in the implicit and explicit aspect extraction in sentiment analysis from years 2008 to 2019; 3) identify the key challenges associated with the techniques based on the result of a comprehensive comparative analysis; and finally, 4) highlight the feasible opportunities for future research directions. This review can be used to assist novice and prominent researchers to understand the concept of both implicit and explicit aspect extractions in aspect-based sentiment analysis domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3031217",
            "Date of Publication": "21 October 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jaafar Zubairu Maitama",
                "labs": [
                    "Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia",
                    "Department of Information Technology, Faculty of Computer Science and Information Technology, Bayero University Kano, Kano, Nigeria"
                ]
            },
            {
                "name": "Norisma Idris",
                "labs": [
                    "Department of Artificial Intelligence, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Asad Abdi",
                "labs": [
                    "Department of Industrial Engineering and Business Information Systems, University of Twente, Enschede, The Netherlands"
                ]
            },
            {
                "name": "Liyana Shuib",
                "labs": [
                    "Department of Information Systems, Faculty of Computer Science and Information Technology, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            },
            {
                "name": "Rosmadi Fauzi",
                "labs": [
                    "Department of Geography, Faculty of Arts and Social Sciences, University of Malaya, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Systematics",
                "Data mining",
                "Deep learning",
                "Information technology",
                "Task analysis"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis",
                "aspect extraction",
                "explicit aspect",
                "feature extraction",
                "implicit aspect"
            ]
        }
    },
    {
        "Title": "SignExplainer: An Explainable AI-Enabled Framework for Sign Language Recognition With Ensemble Learning",
        "Link": "https://ieeexplore.ieee.org/document/10122570/",
        "Abstract": "Deep learning has significantly aided current advancements in artificial intelligence. Deep learning techniques have significantly outperformed more than typical machine learning approaches, in various fields like Computer Vision, Natural Language Processing (NLP), Robotics Science, and Human-Computer Interaction (HCI). Deep learning models are ineffective in outlining their fundamental mechanism. That’s the reason the deep learning model mainly consider as Black-Box. To establish confidence and responsibility, deep learning applications need to explain the model’s decision in addition to the prediction of results. The explainable AI (XAI) research has created methods that offer these interpretations for already trained neural networks. It’s highly recommended for computer vision tasks relevant to medical science, defense system, and many more. The proposed study is associated with XAI for Sign Language Recognition. The methodology uses an attention-based ensemble learning approach to create a prediction model more accurate. The proposed methodology used ResNet50 with the Self Attention model to design ensemble learning architecture. The proposed ensemble learning approach has achieved remarkable accuracy at 98.20%. In interpreting ensemble learning prediction, the author has proposed SignExplainer to explain the relevancy (in percentage) of predicted results. SignExplainer has illustrated excellent results, compared to other conventional Explainable AI models reported in state of the art.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3274851",
            "Date of Publication": "10 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Deep R. Kothadiya",
                "labs": [
                    "U & P U Patel Department of Computer Engineering, Faculty of Technology (FTE), Chandubhai S. Patel Institute of Technology (CSPIT), Charotar University of Science and Technology (CHARUSAT), Changa, India",
                    "Artificial Intelligence and Data Analytics Laboratory (AIDA),College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Chintan M. Bhatt",
                "labs": [
                    "Department of Computer Science and Engineering, School of Engineering and Technology, Pandit Deendayal Energy University, Gujarat, Gandhinagar, India"
                ]
            },
            {
                "name": "Amjad Rehman",
                "labs": [
                    "Artificial Intelligence and Data Analytics Laboratory (AIDA),College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Faten S. Alamri",
                "labs": [
                    "Department of Mathematical Sciences, College of Science, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Tanzila Saba",
                "labs": [
                    "Artificial Intelligence and Data Analytics Laboratory (AIDA),College of Computer and Information Sciences (CCIS), Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Artificial intelligence",
                "Computational modeling",
                "Predictive models",
                "Assistive technologies",
                "Computer vision",
                "Gesture recognition"
            ],
            "Author Keywords": [
                "Deep learning",
                "computer vision",
                "explainable AI",
                "SignExplainer",
                "classification",
                "sign language",
                "technological development"
            ]
        }
    },
    {
        "Title": "All Your Fake Detector are Belong to Us: Evaluating Adversarial Robustness of Fake-News Detectors Under Black-Box Settings",
        "Link": "https://ieeexplore.ieee.org/document/9446139/",
        "Abstract": "With the hyperconnectivity and ubiquity of the Internet, the fake news problem now presents a greater threat than ever before. One promising solution for countering this threat is to leverage deep learning (DL)-based text classification methods for fake-news detection. However, since such methods have been shown to be vulnerable to adversarial attacks, the integrity and security of DL-based fake news classifiers are under question. Although many works study text classification under the adversarial threat, to the best of our knowledge, we do not find any work in literature that specifically analyzes the performance of DL-based fake-news detectors under adversarial settings. We bridge this gap by evaluating the performance of fake-news detectors under various configurations under black-box settings. In particular, we investigate the robustness of four different DL architectural choices—multilayer perceptron (MLP), convolutional neural network (CNN), recurrent neural network (RNN) and a recently proposed Hybrid CNN-RNN trained on three different state-of-the-art datasets—under different adversarial attacks (Text Bugger, Text Fooler, PWWS, and Deep Word Bug) implemented using the state-of-the-art NLP attack library, Text-Attack. Additionally, we explore how changing the detector complexity, the input sequence length, and the training loss affect the robustness of the learned model. Our experiments suggest that RNNs are robust as compared to other architectures. Further, we show that increasing the input sequence length generally increases the detector’s robustness. Our evaluations provide key insights to robustify fake-news detectors against adversarial attacks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3085875",
            "Date of Publication": "03 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hassan Ali",
                "labs": [
                    "IHSAN Lab, Information Technology University, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Suleman Khan",
                "labs": [
                    "Department of Computer Science, Information Technology University (ITU), Lahore, Pakistan"
                ]
            },
            {
                "name": "Amer Alghadhban",
                "labs": [
                    "Department of Electrical Engineering, College of Engineering, University of Ha’il, Ha’il, Saudi Arabia"
                ]
            },
            {
                "name": "Meshari Alazmi",
                "labs": [
                    "Department of Information and Computer Science, College of Computer Science and Engineering, University of Ha’il, Ha’il, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmad Alzamil",
                "labs": [
                    "Department of Electrical Engineering, College of Engineering, University of Ha’il, Ha’il, Saudi Arabia"
                ]
            },
            {
                "name": "Khaled Al-Utaibi",
                "labs": [
                    "Department of Computer Engineering, College of Computer Science and Engineering, University of Ha’il, Ha’il, Saudi Arabia"
                ]
            },
            {
                "name": "Junaid Qadir",
                "labs": [
                    "Department of Electrical Engineering, Information Technology University (ITU), Lahore, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Detectors",
                "Robustness",
                "Electronic mail",
                "Training",
                "Analytical models",
                "Natural language processing",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Fake news detection",
                "deep neural networks",
                "adversarial attacks",
                "adversarial robustness"
            ]
        }
    },
    {
        "Title": "A Fusion Model-Based Label Embedding and Self-Interaction Attention for Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/8908707/",
        "Abstract": "Text classification is a pivotal task in NLP (Natural Language Processing), which has received widespread attention recently. Most of the existing methods leverage the power of deep learning to improve the performance of models. However, these models ignore the interaction information between all the sentences in a text when generating the current text representation, which results in a partial semantics loss. Labels play a central role in text classification. And the attention learned from text-label in the joint space of labels and words is not leveraged, leaving enough room for further improvement. In this paper, we propose a text classification method based on Self-Interaction attention mechanism and label embedding. Firstly, our method introduce BERT (Bidirectional Encoder Representation from Transformers) to extract text features. Then Self-Interaction attention mechanism is employed to obtain text representations containing more comprehensive semantics. Moreover, we focus on the embedding of labels and words in the joint space to achieve the dual-label embedding, which further leverages the attention learned from text-label. Finally, the texts are classified by the classifier according to the weighted labels representations. The experimental results show that our method outperforms other state-of-the-art methods in terms of classification accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2954985",
            "Date of Publication": "21 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanru Dong",
                "labs": [
                    "School of Information Science and Engineering, Shandong Normal University, Jinan, China"
                ]
            },
            {
                "name": "Peiyu Liu",
                "labs": [
                    "School of Information Science and Engineering, Shandong Normal University, Jinan, China"
                ]
            },
            {
                "name": "Zhenfang Zhu",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Jinan, China"
                ]
            },
            {
                "name": "Qicai Wang",
                "labs": [
                    "School of Information Science and Engineering, Shandong Normal University, Jinan, China"
                ]
            },
            {
                "name": "Qiuyue Zhang",
                "labs": [
                    "School of Information Science and Engineering, Shandong Normal University, Jinan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Semantics",
                "Feature extraction",
                "Natural language processing",
                "Bit error rate",
                "Task analysis",
                "Neural networks"
            ],
            "Author Keywords": [
                "Text classification",
                "text representations",
                "label embedding"
            ]
        }
    },
    {
        "Title": "Twitter Hate Speech Detection: A Systematic Review of Methods, Taxonomy Analysis, Challenges, and Opportunities",
        "Link": "https://ieeexplore.ieee.org/document/10025718/",
        "Abstract": "Hate speech detection has substantially increased interest among researchers in the domain of natural language processing (NLP) and text mining. The number of studies on this topic has been growing dramatically. Thus, the purpose of this analysis is to develop a resource that consists of an outline of the approaches, methods, and techniques employed to address the issue of Twitter hate speech. This study can be used to aid researchers in the development of a more effective model for future studies. This review focused on studies published over the past eight years, i.e., from 2015 to 2022. This systematic search was carried out in December 2020 and updated in July 2022. Ninety-one articles published within the mentioned period met the set criteria and were selected for this review. From the evaluation of these works, it is clear that a perfect solution has yet to be found. To conclude, this paper focused on presenting an in-depth understanding of current perspectives and highlighted research opportunities to boost the quality of hate speech detection systems. In turn, this helps social networking services that seek to detect hate messages generated by users before they are posted, thus reducing the risk of targeted harassment.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3239375",
            "Date of Publication": "25 January 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zainab Mansur",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia",
                    "Department of Computer Science, Faculty of Sciences, Omar Al-Mukhtar University, Al Bayda, Libya"
                ]
            },
            {
                "name": "Nazlia Omar",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Sabrina Tiun",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hate speech",
                "Social networking (online)",
                "Blogs",
                "Systematics",
                "Machine learning",
                "Natural language processing",
                "Media"
            ],
            "Author Keywords": [
                "Hate speech",
                "classification",
                "automatic detection",
                "twitter",
                "systematic review",
                "natural language processing",
                "social media"
            ]
        }
    },
    {
        "Title": "Deep Learning Model for Fine-Grained Aspect-Based Opinion Mining",
        "Link": "https://ieeexplore.ieee.org/document/9139221/",
        "Abstract": "Despite the great manufactures' efforts to achieve customer satisfaction and improve their performance, social media opinion mining is still on the fly a big challenge. Current opinion mining requires sophisticated feature engineering and syntactic word embedding without considering semantic interaction between aspect term and opinionated features, which degrade the performance of most of opinion mining tasks, especially those that are designed for smart manufacturing. Research on intelligent aspect level opinion mining (AOM) follows the fast proliferation of user-generated data through social media for industrial manufacturing purposes. Google's pre-trained language model, Bidirectional Encoder Representations from Transformers (BERT) widely overcomes existing methods in eleven natural language processing (NLP) tasks, which makes it the standard way for semantic text representation. In this paper, we introduce a novel deep learning model for fine-grained aspect-based opinion mining, named as FGAOM. First, we train the BERT model on three specific domain corpora for domain adaption, then use adjusted BERT as embedding layer for concurrent extraction of local and global context features. Then, we propose Multi-head Self-Attention (MSHA) to effectively fuse internal semantic text representation and take advantage of convolutional layers to model aspect term interaction with surrounding sentiment features. Finally, the performance of the proposed model is evaluated via extensive experiments on three public datasets. Results show that performance of the proposed model outperforms performances of recent the-of-the-art models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3008824",
            "Date of Publication": "13 July 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ahmed R. Abas",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            },
            {
                "name": "Ibrahim El-Henawy",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            },
            {
                "name": "Hossam Mohamed",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            },
            {
                "name": "Amr Abdellatif",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Informatics, Zagazig University, Zagazig, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Bit error rate",
                "Adaptation models",
                "Semantics",
                "Feature extraction",
                "Context modeling",
                "Deep learning"
            ],
            "Author Keywords": [
                "Deep learning",
                "opinion mining",
                "sentiment analysis",
                "social media analytics"
            ]
        }
    },
    {
        "Title": "Enhancing Aspect-Based Sentiment Analysis With Capsule Network",
        "Link": "https://ieeexplore.ieee.org/document/9099843/",
        "Abstract": "Existing feature-based neural approaches for aspect-based sentiment analysis (ABSA) try to improve their performance with pre-trained word embeddings and by modeling the relations between the text sequence and the aspect (or category), thus heavily depending on the quality of word embeddings and task-specific architectures. Although the recently pre-trained language models, i.e., BERT and XLNet, have achieved state-of-the-art performance in a variety of natural language processing (NLP) tasks, they still subject to the aspect-specific, local feature-aware and task-agnostic challenges. To address these challenges, this paper proposes a XLNet and capsule network based model XLNetCN for ABSA. XLNetCN firstly constructs auxiliary sentence to model the sequence-aspect relation and generate global aspect-specific representations, which enables to enhance aspect-awareness and ensure the full pre-training of XLNet for improving task-agnostic capability. After that, XLNetCN also employs a capsule network with the dynamic routing algorithm to extract the local and spatial hierarchical relations of the text sequence, and yield its local feature representations, which are then merged with the global aspect-related representations for downstream classification via a softmax classifier. Experimental results show that XLNetCN outperforms significantly than the classical BERT, XLNet and traditional feature-based approaches on the two benchmark datasets of SemEval 2014, Laptop and Restaurant, and achieves new state-of-the-art results.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2997675",
            "Date of Publication": "26 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jindian Su",
                "labs": [
                    "College of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Shanshan Yu",
                "labs": [
                    "College of Medical Information Engineering, Guangdong Pharmaceutical University, Guangzhou, China",
                    "Guangdong Province Precise Medicine and Big Data Engineering Technology Research Center for Traditional Chinese Medicine, Guangdong Pharmaceutical University, Guangzhou, China"
                ]
            },
            {
                "name": "Da Luo",
                "labs": [
                    "College of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Context modeling",
                "Sun",
                "Sentiment analysis",
                "Neural networks",
                "Training data"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis",
                "natural language processing",
                "text analysis",
                "deep learning",
                "neural network"
            ]
        }
    },
    {
        "Title": "vPipe: A Virtualized Acceleration System for Achieving Efficient and Scalable Pipeline Parallel DNN Training",
        "Link": "https://ieeexplore.ieee.org/document/9472938/",
        "Abstract": "The increasing computational complexity of DNNs achieved unprecedented successes in various areas such as machine vision and natural language processing (NLP), e.g., the recent advanced Transformer has billions of parameters. However, as large-scale DNNs significantly exceed GPU’s physical memory limit, they cannot be trained by conventional methods such as data parallelism. Pipeline parallelism that partitions a large DNN into small subnets and trains them on different GPUs is a plausible solution. Unfortunately, the layer partitioning and memory management in existing pipeline parallel systems are fixed during training, making them easily impeded by out-of-memory errors and the GPU under-utilization. These drawbacks amplify when performing neural architecture search (NAS) such as the evolved Transformer, where different network architectures of Transformer needed to be trained repeatedly. vPipe is the first system that transparently provides dynamic layer partitioning and memory management for pipeline parallelism. vPipe has two unique contributions, including (1) an online algorithm for searching a near-optimal layer partitioning and memory management plan, and (2) a live layer migration protocol for re-balancing the layer distribution across a training pipeline. vPipe improved the training throughput of two notable baselines (Pipedream and GPipe) by 61.4-463.4 percent and 24.8-291.3 percent on various large DNNs and training settings.",
        "Details": {
            "DOI": "10.1109/TPDS.2021.3094364",
            "Date of Publication": "02 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Parallel and Distributed Systems"
        },
        "issn_info": {
            "Print ISSN": "1045-9219",
            "Electronic ISSN": "1558-2183"
        },
        "authors_data": [
            {
                "name": "Shixiong Zhao",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Fanxin Li",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Xusheng Chen",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Xiuxian Guan",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Jianyu Jiang",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Dong Huang",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Yuhao Qing",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Sen Wang",
                "labs": [
                    "2012 Labs, Theory Lab, Huawei Technoloies, Co. Ltd, Shenzhen, China"
                ]
            },
            {
                "name": "Peng Wang",
                "labs": [
                    "2012 Labs, Theory Lab, Huawei Technoloies, Co. Ltd, Shenzhen, China"
                ]
            },
            {
                "name": "Gong Zhang",
                "labs": [
                    "2012 Labs, Theory Lab, Huawei Technoloies, Co. Ltd, Shenzhen, China"
                ]
            },
            {
                "name": "Cheng Li",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui, China"
                ]
            },
            {
                "name": "Ping Luo",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            },
            {
                "name": "Heming Cui",
                "labs": [
                    "Department of Computer Computer Science, The University of Hong Kong, Hong Kong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Pipelines",
                "Training",
                "Graphics processing units",
                "Throughput",
                "Memory management",
                "Parallel processing",
                "Tensors"
            ],
            "Author Keywords": [
                "Machine learning",
                "distributed systems",
                "distributed artificial intelligence",
                "pipeline",
                "parallel systems",
                "memory management"
            ]
        }
    },
    {
        "Title": "Metaheuristic Ant Lion and Moth Flame Optimization-Based Novel Approach for Automatic Detection of Hate Speech in Online Social Networks",
        "Link": "https://ieeexplore.ieee.org/document/9505636/",
        "Abstract": "In the online social networks, blogs, microblogs, social bookmarking services and sharing sites, and various web forum pages; the sharing of knowledge, opinions, ideas, etc. are spreading very quickly. This situation brings very dangerous problems in social networks. One of these problems is hate speech detection (HSD) problem which is covering issues such as insults, swearing, humiliation, discrimination, exclusion, detest, abhor, blast, damn, and intolerance. These can be reactions to a person, a group, an organization, an order, or an event. Although few machine learning methods have been used in the literature to solve this important problem in online social media, the performance of the HSD models in terms of many metrics needs to be increased. In this study, an automatic HSD system based on metaheuristic methodology was proposed for better results in this new and important problem. In the proposed optimization approach, Ant Lion Optimization (ALO) algorithm and Moth Flame Optimization (MFO) algorithm were designed for the HSD problem. This is the first attempt to use optimization algorithms as solution search strategies for automatic HSD. An efficient representation scheme and flexible fitness function were designed for this purpose. Many metrics can easily be embedded into the designed fitness function in order to be simultaneously optimized. Firstly, the basic natural language processing (NLP) steps were carried out. Feature extraction was performed using Bag of Words (BoW), Term Frequency (TF), and document vector (Word2Vec). Then, the performances of the proposed novel approaches were analyzed in detail on the three different real-world data. The obtained results were also checked against eight popular supervised machine learning algorithms, Social Spider Optimization (SSO) algorithm, and state-of-the-art Tunicate Swarm Algorithm (TSA). Considering the evaluation criteria for three sets of experiments, it was observed that the accuracy, sensitivity, precision, and f-score results of the ALO and MFO algorithms were superior to machine learning methods. As a result of the experimental studies, the highest accuracy value was 92.1% for ALO, while this value was 90.7% for MFO. Other numerical values obtained in the study were given in the experiments and results section with tables and graphics in detail. Due to the promising results of the proposed approaches, they are anticipated to be used in the solution of many social media and networking problems.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3102277",
            "Date of Publication": "03 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cem Baydogan",
                "labs": [
                    "Department of Software Engineering, Faculty of Technology, Firat University, Elâziğ, Turkey"
                ]
            },
            {
                "name": "Bilal Alatas",
                "labs": [
                    "Department of Software Engineering, Faculty of Engineering, Firat University, Elâziğ, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Measurement",
                "Machine learning algorithms",
                "Search problems",
                "Feature extraction",
                "Deep learning"
            ],
            "Author Keywords": [
                "Hate speech detection",
                "metaheuristic optimization",
                "natural language processing",
                "social network analysis",
                "text mining"
            ]
        }
    },
    {
        "Title": "A New Mixed Integer Linear Programming Formulation for Protection Relay Coordination Using Disjunctive Inequalities",
        "Link": "https://ieeexplore.ieee.org/document/8673890/",
        "Abstract": "Numerical optimization-based solution to directional overcurrent relay (DOCR) coordination problem has been a widely addressed research problem in the recent past. Many linear (LP), nonlinear (NLP), mixed integer nonlinear (MINLP), mixed integer linear (MILP), and quadratically constrained quadratic programming (QCQP)-based formulations have been presented in the past literature. This paper proposes a new MILP-based formulation using disjunctive inequalities. The nonlinear DOCR protection coordination model is formulated as MILP by linearizing the bilinear terms existing in the original formulation. One of the variables in each bilinear term is discretized over its interval into a fixed number of steps. After assigning binary variables to each discrete interval, the resulting bilinear terms with binary variables are written in terms of disjunctive inequalities. The results have shown that the proposed MILP formulation fetch better optimal solutions compared with past MILP and MINLP formulations. The MILP problem is programmed in GAMS package with CPLEX solver and tested on standard 3 bus, 9 bus, 15 bus, and 30 bus systems and results are found to be satisfactory.",
        "Details": {
            "DOI": "10.1109/JPETS.2019.2907320",
            "Date of Publication": "25 March 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Power and Energy Technology Systems Journal"
        },
        "issn_info": {
            "Electronic ISSN": "2332-7707"
        },
        "authors_data": [
            {
                "name": "S. T. P. Srinivas",
                "labs": [
                    "Department of Electrical Engineering, IIT Madras, Chennai, India"
                ]
            },
            {
                "name": "K. Shanti Swarup",
                "labs": [
                    "Department of Electrical Engineering, IIT Madras, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Relays",
                "Circuit faults",
                "Linear programming",
                "Fault location",
                "Quadratic programming",
                "Fault currents"
            ],
            "Author Keywords": [
                "Directional overcurrent relay",
                "bilinear relaxation",
                "mixed integer programming",
                "current pickup settings"
            ]
        }
    },
    {
        "Title": "MEDT: Using Multimodal Encoding-Decoding Network as in Transformer for Multimodal Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9733279/",
        "Abstract": "Multimodal sentiment analysis is a challenging task in the field of natural language processing (NLP). It uses multimodal signals (natural language, facial gestures, and acoustic behavior) in videos to generate emotional understanding. However, the importance of single modality data in the video to emotional outcomes is not static. With the extension of the time dimension, the emotional attributes of a specific natural language will be affected by non-natural language data, resulting in a vector shift in the feature space. At the same time, long-term dependencies within a specific modality and long-term dependencies between multiple modalities that are “unaligned” need to be considered. In response to the above problems, this paper proposes Multimodal Encoding-Decoding Network with Transformer. The network model encodes multimodal data through a Bidirectional Encoder Representations from Transformers (BERT) network and Transformer encoder to resolve long-term dependencies within modalities. And the network reconstructs the Transformer decoder to solve the weight problem of multimodal data in an iterative way. The network fully considers the long-term dependencies between modalities and the offset effect of non-natural language data on natural language data. Under the same experimental conditions, we validated our model on general multimodal sentiment analysis datasets. Compared with state-of-the-art models, the network achieves good progress and strong stability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3157712",
            "Date of Publication": "11 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qingfu Qi",
                "labs": [
                    "College of Electronic Information and Automation, Tianjin University of Science and Technology, Tianjin, China",
                    "School of Software and Communications, Tianjin Sino-German University of Applied Sciences, Tianjin, China"
                ]
            },
            {
                "name": "Liyuan Lin",
                "labs": [
                    "College of Electronic Information and Automation, Tianjin University of Science and Technology, Tianjin, China"
                ]
            },
            {
                "name": "Rui Zhang",
                "labs": [
                    "College of Electronic Information and Automation, Tianjin University of Science and Technology, Tianjin, China",
                    "School of Software and Communications, Tianjin Sino-German University of Applied Sciences, Tianjin, China"
                ]
            },
            {
                "name": "Chengrong Xue",
                "labs": [
                    "College of Electronic Information and Automation, Tianjin University of Science and Technology, Tianjin, China",
                    "School of Software and Communications, Tianjin Sino-German University of Applied Sciences, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Natural languages",
                "Bit error rate",
                "Transformers",
                "Data models",
                "Analytical models",
                "Encoding"
            ],
            "Author Keywords": [
                "Auxiliary information",
                "long-term dependence",
                "multimodal sentiment analysis",
                "transformer",
                "vector offsets"
            ]
        }
    },
    {
        "Title": "LAW-U: Legal Guidance Through Artificial Intelligence Chatbot for Sexual Violence Victims and Survivors",
        "Link": "https://ieeexplore.ieee.org/document/9539229/",
        "Abstract": "Sexual violence is a severe and chronic occurrence around the world that has not been resolved. The stigmatized nature of sexual violence has forced victims and survivors to accept prejudiced accusations cultivated from discriminatory norms when they are never at fault nor responsible for such violations against their sexuality. LAW-U is an Artificial Intelligence (AI) chatbot that gives legal guidance to survivors of sexual violence by recommending the most relevant Supreme Court decisions to the survivors’ situations. In Thai, “LAW-U” − pronounced similarly to “ ” − means “I will wait for you”, which signifies the chatbot’s unconditional support to the user. 182 Thai Supreme Court cases of sexual violence, relating to Sections 276, 277, 278, and 279 of the Criminal Code, were used to develop Natural Language Processing (NLP) pipelines for LAW-U. Legal experts then generated mock-up dialogs from Supreme Court decisions which became the conversations used to train LAW-U. The computation of the similarity scores and the calculation of percentages of common keywords and keywords’ synonyms were completed to increase the model’s accuracy. When applying the model to the hold-out testing dataset, the accuracy was 88.89% for an exact match between the user’s input and the Supreme Court case − this confirmed that LAW-U was ready for real-life application. LAW-U’s unique design hopes to act as a precedent for other works at home and abroad to perpetuate awareness of sexual violence and eliminate any tolerance against these crimes by empowering sexual violence victims and survivors to reaffirm their inherent rights.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3113172",
            "Date of Publication": "15 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vorada Socatiyanurak",
                "labs": [
                    "Center of Excellence in Intelligent Informatics, Speech and Language Technology, and Service Innovation (CILS), Thammasat University, Rangsit Campus, Khlong Luang, Thailand",
                    "College of Arts and Sciences, University of Pennsylvania, Philadelphia, PA, USA"
                ]
            },
            {
                "name": "Nittayapa Klangpornkun",
                "labs": [
                    "Center of Excellence in Intelligent Informatics, Speech and Language Technology, and Service Innovation (CILS), Thammasat University, Rangsit Campus, Khlong Luang, Thailand",
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Adirek Munthuli",
                "labs": [
                    "Center of Excellence in Intelligent Informatics, Speech and Language Technology, and Service Innovation (CILS), Thammasat University, Rangsit Campus, Khlong Luang, Thailand",
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Phongphan Phienphanich",
                "labs": [
                    "Center of Excellence in Intelligent Informatics, Speech and Language Technology, and Service Innovation (CILS), Thammasat University, Rangsit Campus, Khlong Luang, Thailand",
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Lalin Kovudhikulrungsri",
                "labs": [
                    "Faculty of Law, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Nantawat Saksakulkunakorn",
                "labs": [
                    "Faculty of Law, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Phonkanok Chairaungsri",
                "labs": [
                    "Faculty of Law, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            },
            {
                "name": "Charturong Tantibundhit",
                "labs": [
                    "Center of Excellence in Intelligent Informatics, Speech and Language Technology, and Service Innovation (CILS), Thammasat University, Rangsit Campus, Khlong Luang, Thailand",
                    "Department of Electrical and Computer Engineering, Faculty of Engineering, Thammasat University, Rangsit Campus, Khlong Luang, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Education",
                "Cultural differences",
                "Chatbots",
                "Artificial intelligence",
                "Pandemics",
                "Law enforcement",
                "Codes"
            ],
            "Author Keywords": [
                "Thai sexual violence law",
                "sexual violence",
                "legal artificial intelligence",
                "chatbot",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Sentence-Level Classification Using Parallel Fuzzy Deep Learning Classifier",
        "Link": "https://ieeexplore.ieee.org/document/9333555/",
        "Abstract": "At present, with the growing number of Web 2.0 platforms such as Instagram, Facebook, and Twitter, users honestly communicate their opinions and ideas about events, services, and products. Owing to this rise in the number of social platforms and their extensive use by people, enormous amounts of data are produced hourly. However, sentiment analysis or opinion mining is considered as a useful tool that aims to extract the emotion and attitude from the user-posted data on social media platforms by using different computational methods to linguistic terms and various Natural Language Processing (NLP). Therefore, enhancing text sentiment classification accuracy has become feasible, and an interesting research area for many community researchers. In this study, a new Fuzzy Deep Learning Classifier (FDLC) is suggested for improving the performance of data-sentiment classification. Our proposed FDLC integrates Convolutional Neural Network (CNN) to build an effective automatic process for extracting the features from collected unstructured data and Feedforward Neural Network (FFNN) to compute both positive and negative sentimental scores. Then, we used the Mamdani Fuzzy System (MFS) as a fuzzy classifier to classify the outcomes of the two used deep (CNN+FFNN) learning models in three classes, which are: Neutral, Negative, and Positive. Also, to prevent the long execution time taking by our hybrid proposed FDLC, we have implemented our proposal under the Hadoop cluster. An experimental comparative study between our FDLC and some other suggestions from the literature is performed to demonstrate our offered classifier’s effectiveness. The empirical result proved that our FDLC performs better than other classifiers in terms of true positive rate, true negative rate, false positive rate, false negative rate, error rate, precision, classification rate, kappa statistic, F1-score and time consumption, complexity, convergence, and stability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3053917",
            "Date of Publication": "22 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatima Es-Sabery",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Abdellatif Hair",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Junaid Qadir",
                "labs": [
                    "Department of Electronics, Quaid-i-Azam University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Beatriz Sainz-De-Abajo",
                "labs": [
                    "Department of Signal Theory, Communications and Telematics Engineering, University of Valladolid, 47011, Spain"
                ]
            },
            {
                "name": "Begoña García-Zapirain",
                "labs": [
                    "EVIDA Research Group, University of Deusto, Bilbao, Spain"
                ]
            },
            {
                "name": "Isabel De La Torre-Díez",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Linguistics",
                "Social networking (online)",
                "Fuzzy logic",
                "Deep learning",
                "Data models",
                "Data mining"
            ],
            "Author Keywords": [
                "Deep learning",
                "convolutional neural network (CNN)",
                "sentiment analysis",
                "feedforward neural network (FFNN)",
                "fuzzy logic",
                "Hadoop framework",
                "MapReduce",
                "Hadoop Distributed File System (HDFS)"
            ]
        }
    },
    {
        "Title": "Fake Media Detection Based on Natural Language Processing and Blockchain Approaches",
        "Link": "https://ieeexplore.ieee.org/document/9536745/",
        "Abstract": "Social media network is one of the important parts of human life based on the recent technologies and developments in terms of computer science area. This environment has become a famous platform for sharing information and news on any topics and daily reports, which is the main era for collecting data and data transmission. There are various advantages of this environment, but in another point of view there are lots of fake news and information that mislead the reader and user for the information needed. Lack of trust-able information and real news of social media information is one of the huge problems of this system. To overcome this problem, we have proposed an integrated system for various aspects of blockchain and natural language processing (NLP) to apply machine learning techniques to detect fake news and better predict fake user accounts and posts. The Reinforcement Learning technique is applied for this process. To improve this platform in terms of security, the decentralized blockchain framework applied, which provides the outline of digital contents authority proof. More specifically, the concept of this system is developing a secure platform to predict and identify fake news in social media networks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3112607",
            "Date of Publication": "14 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zeinab Shahbazi",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, IIST, South Korea"
                ]
            },
            {
                "name": "Yung-Cheol Byun",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju-si, IIST, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Blockchains",
                "Natural language processing",
                "Social networking (online)",
                "Reinforcement learning",
                "Feature extraction",
                "Machine learning",
                "Information sharing"
            ],
            "Author Keywords": [
                "Natural language processing",
                "blockchain",
                "fake media",
                "reinforcement learning"
            ]
        }
    },
    {
        "Title": "Elicitation of Nonfunctional Requirements in Agile Development Using Cloud Computing Environment",
        "Link": "https://ieeexplore.ieee.org/document/9178791/",
        "Abstract": "Nonfunctional requirements get less attention because functional requirements are considered more important in the domain of agile software methodologies. This is due to the lack of mature requirement elicitation methodologies and the nature of the software agile software development process. The less attention caused few solutions in the domain which lead to software project failure. Cloud computing helps to practice twelve (12) agile principles including nonfunctional requirement elicitation. This study proposed a semi-automated methodology which will help analyst and developers in eliciting nonfunctional requirements in agile development and cloud computing environment. The methodology used an NLP based automatic NFR extraction approach to fast the NFR elicitation process. The methodology is evaluated by applying on eProcurement dataset. The results are improved by 8.77% and 1.76% in terms of “Successful” NFR. It is decreased by 7.02% and 1.75% in term of “Partial success”, and 1.76% to 0.0% in term of “Failure” as compared to existing studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3014381",
            "Date of Publication": "27 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Younas",
                "labs": [
                    "Department of Computer Science, Government College University Faisalabad, Faisalabad, Pakistan",
                    "Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia"
                ]
            },
            {
                "name": "Dayang Norhayati Abang Jawawi",
                "labs": [
                    "Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia"
                ]
            },
            {
                "name": "Muhammad Arif Shah",
                "labs": [
                    "Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia",
                    "Department of IT and Computer Science, Pak–Austria Fachhochschule Institute of Applied Sciences and Technology, Haripur, Pakistan"
                ]
            },
            {
                "name": "Ahmad Mustafa",
                "labs": [
                    "Faculty of Engineering, School of Computing, Universiti Teknologi Malaysia, Johor Bahru, Malaysia"
                ]
            },
            {
                "name": "Muhammad Awais",
                "labs": [
                    "Department of Software Engineering, Government College University Faisalabad, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Kamran Ishfaq",
                "labs": [
                    "Department of Electrical Engineering Technology, Government College University Faisalabad, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Karzan Wakil",
                "labs": [
                    "Research Center, Sulaimani Polytechnic University, Sulaimani, Iraq"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software",
                "Cloud computing",
                "Tools",
                "Agile software development",
                "Standards",
                "Adaptation models"
            ],
            "Author Keywords": [
                "Agile development",
                "case study",
                "cloud-based agile tools",
                "cloud computing",
                "software requirement elicitation"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis Using Stacked Gated Recurrent Unit for Arabic Tweets",
        "Link": "https://ieeexplore.ieee.org/document/9541361/",
        "Abstract": "Over the last decade, the amount of Arabic content created on websites and social media has grown significantly. Opinions are shared openly and freely on social media, a process that provides a rich source for trend analyses. These analyses could be accomplished artificially by natural language processing tasks, such as sentiment analysis. Those tasks are implemented initially using machine learning. Due to its accuracy in studying unstructured data, deep learning has been increasingly used as well. The gated recurrent unit (GRU) is a promising approach in textual analysis and exhibits large morphological variations. We propose two neural models, i.e., the stacked gated recurrent unit (SGRU) and stacked bidirectional gated recurrent unit (SBi-GRU), with word embedding to mine Arabic opinions. We also propose a new way of discarding stop words using automatic sentiment refinement (ASR) instead of using manually collected stop words or using low quality available Arabic stop words’ lists. The performance of our proposed models is compared with that of long short-term memory (LSTM), the support vector machine (SVM), and the most recent pretrained Arabic bidirectional encoder representations from transformers (AraBERT). In addition, we compare our models’ performance to that of an ensemble architecture of the abovementioned models to find the best model architecture for Arabic natural language processing (NLP). To the best of our knowledge, no previous studies have applied either the unidirectional or bidirectional SGRU for Arabic sentiment classification. Furthermore, no ensemble models have been implemented from these architectures for the Arabic language. The results show that the six-layer SGRU stacking and five-layer SBi-GRU stacking achieve the highest accuracy and that the ensemble method outperforms all other models, with an accuracy exceeding 90%.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3114313",
            "Date of Publication": "20 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Asma Al Wazrah",
                "labs": [
                    "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sarah Alhumoud",
                "labs": [
                    "College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Social networking (online)",
                "Transformers",
                "Deep learning",
                "Convolutional neural networks",
                "Stacking"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "deep learning",
                "natural language processing",
                "recurrent neural networks",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "A Semantic Conceptualization Using Tagged Bag-of-Concepts for Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9521534/",
        "Abstract": "Sentiment could be expressed implicitly or explicitly in the text. Hence, it is the main challenge for current sentiment analysis (SA) approaches to identify hidden sentiments, other common challenges include false classification of opinion words, ignoring context information, and bad handling of a short text that arise from the bad interpretation of the text and lack of enough data required for analysis tasks. In this study, a semantic conceptualization method using tagged bag-of-concepts for SA is proposed to detect the correct sentiment towards the actual target entity that considers all affective and conceptual information conveyed in the text with a special focus on the short text. Tagged bag-of-concepts (TBoC) is a novel approach to analyze and decompose text to uncover latent sentiments while preserving all relations and vital information to boost the accuracy of SA. This study answers questions: Does the information provided via TBoC enhance sentiment classification results on different analysis levels? Is building a structure of concepts increases the accuracy of overall sentiment towards specific opinion target? Does TBoC approach enhance SA results for short text messages? The proposed solution has been applied on two datasets from the restaurant domain, sentiment analysis is performed using the TBoCs structure on multiple levels including document, aspect, aspect-category, and topic levels. TBoC method with domain-specific sentiment lexicon showed exceptional performance and outperformed other state-of-the-art NB, SVM, and NN methods, especially for aspect-level SA. The use of TBoC within the semantic conceptualization model that leverages NLP tasks, Ontology, and semantic methods proved its high capabilities for concept extraction while preserving the information about the context, interrelations, and latent feelings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3107237",
            "Date of Publication": "24 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yassin S. Mehanna",
                "labs": [
                    "Internetworks Research Laboratory, School of Computing, Universiti Utara Malaysia, Sintok, Malaysia"
                ]
            },
            {
                "name": "Massudi Bin Mahmuddin",
                "labs": [
                    "Internetworks Research Laboratory, School of Computing, Universiti Utara Malaysia, Sintok, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Sentiment analysis",
                "Task analysis",
                "Ontologies",
                "Knowledge based systems",
                "Feature extraction",
                "Statistical analysis"
            ],
            "Author Keywords": [
                "Concept extraction",
                "semantic sentiment",
                "sentiment lexicon",
                "natural language processing",
                "sentiment analysis",
                "text processing"
            ]
        }
    },
    {
        "Title": "Large-Scale Text Classification Using Scope-Based Convolutional Neural Network: A Deep Learning Approach",
        "Link": "https://ieeexplore.ieee.org/document/8913565/",
        "Abstract": "Text classification is one of the most important and typical tasks in Natural Language Processing (NLP) which can be applied for many applications. Recently, deep learning approaches has shown their advantages in solving text classification problem, in which Convolutional Neural Network (CNN) is one of the most successful model in the field. In this paper, we propose a novel deep learning approach for categorizing text documents by using scope-based convolutional neural network. Different from window-based CNN, scope does not require the words that construct a local feature have to be contiguous. It can represent deeper local information of text data. We propose a large-scale scope-based convolutional neural network (LSS-CNN), which is based on scope convolution, aggregation optimization, and max pooling operation. Based on these techniques, we can gradually extract the most valuable local information of the text document. This paper also discusses how to effectively calculate the scope-based information and parallel training for large-scale datasets. Extensive experiments have been conducted on real datasets to compare our model with several state-of-the-art approaches. The experimental results show that LSS-CNN can achieve both effectiveness and good scalability on big text data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2955924",
            "Date of Publication": "26 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiaying Wang",
                "labs": [
                    "Big Data Management and Analysis Laboratory of Urban Construction, Shenyang Jianzhu University, Shenyang, China"
                ]
            },
            {
                "name": "Yaxin Li",
                "labs": [
                    "Big Data Management and Analysis Laboratory of Urban Construction, Shenyang Jianzhu University, Shenyang, China"
                ]
            },
            {
                "name": "Jing Shan",
                "labs": [
                    "Big Data Management and Analysis Laboratory of Urban Construction, Shenyang Jianzhu University, Shenyang, China"
                ]
            },
            {
                "name": "Jinling Bao",
                "labs": [
                    "Computer Science Faculty, Baicheng Normal University, Baicheng, China"
                ]
            },
            {
                "name": "Chuanyu Zong",
                "labs": [
                    "College of Computer Science, Shenyang Aerospace University, Shenyang, China"
                ]
            },
            {
                "name": "Liang Zhao",
                "labs": [
                    "College of Computer Science, Shenyang Aerospace University, Shenyang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Feature extraction",
                "Convolutional neural nets",
                "Task analysis",
                "Convolution",
                "Microsoft Windows",
                "Semantics"
            ],
            "Author Keywords": [
                "Text classification",
                "deep learning",
                "convolutional neural network",
                "scope-based convolution",
                "local feature"
            ]
        }
    },
    {
        "Title": "Depression Classification From Tweets Using Small Deep Transfer Learning Language Models",
        "Link": "https://ieeexplore.ieee.org/document/9954391/",
        "Abstract": "Depression detection from social media texts such as Tweets or Facebook comments could be very beneficial as early detection of depression may even avoid extreme consequences of long-term depression i.e. suicide. In this study, depression intensity classification is performed using a labeled Twitter dataset. Further, this study makes a detailed performance evaluation of four transformer-based pre-trained small language models, particularly those having less than 15 million tunable parameters i.e. Electra Small Generator (ESG), Electra Small Discriminator (ESD), XtremeDistil-L6 (XDL) and Albert Base V2 (ABV) for classification of depression intensity using Tweets. The models are fine-tuned to get the best performance by applying different hyperparameters. The models are tested by classification of depression intensity of labeled tweets for three label classes i.e. ‘severe’, ‘moderate’, and ‘mild’ by downstream fine-tuning the parameters. Evaluation metrics such as accuracy, F1, precision, recall, and specificity are calculated to evaluate the performance of the models. Comparative analysis of these models is also done with a moderately larger model i.e. DistilBert which has 67 million tunable parameters for the same task with the same experimental settings. Results indicate that ESG outperforms all other models including DistilBert due to its better deep contextualized text representation as it gets the best F1 score of 89% with comparatively less training time. Further optimization of ESG is also proposed to make it suitable for low-powered devices. This study helps to achieve better classification performance of depression detection as well as to choose the best language model in terms of performance and less training time for Twitter-related downstream NLP tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3223049",
            "Date of Publication": "17 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Rizwan",
                "labs": [
                    "Department of Artificial Intelligence, Islamia University of Bahawalpur, Bahawalpur, Pakistan",
                    "Department of Information Technology, Khwaja Fareed University of Engineering and Information Technology, Rahim Yar Khan, Pakistan"
                ]
            },
            {
                "name": "Muhammad Faheem Mushtaq",
                "labs": [
                    "Department of Artificial Intelligence, Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Urooj Akram",
                "labs": [
                    "Department of Artificial Intelligence, Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Arif Mehmood",
                "labs": [
                    "Department of Computer Science and Information Technology, Islamia University of Bahawalpur, Bahawalpur, Pakistan"
                ]
            },
            {
                "name": "Imran Ashraf",
                "labs": [
                    "Department of Information and Communication Engineering, Yeungnam University, Gyeongsan, South Korea"
                ]
            },
            {
                "name": "Benjamín Sahelices",
                "labs": [
                    "Department of Informatics, University of Valladolid, Valladolid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Depression",
                "Bit error rate",
                "Social networking (online)",
                "Transformers",
                "Public healthcare",
                "Transfer learning",
                "Blogs"
            ],
            "Author Keywords": [
                "Depression classification",
                "transfer learning",
                "transformer language models",
                "public health"
            ]
        }
    },
    {
        "Title": "Event Detection System Based on User Behavior Changes in Online Social Networks: Case of the COVID-19 Pandemic",
        "Link": "https://ieeexplore.ieee.org/document/9180335/",
        "Abstract": "People use Online Social Networks (OSNs) to express their opinions and feelings about many topics. Depending on the nature of an event and its dissemination rate in OSNs, and considering specific regions, the users’ behavior can drastically change over a specific period of time. In this context, this work aims to propose an event detection system at the early stages of an event based on changes in the users’ behavior in an OSN. This system can detect an event of any subject, and thus, it can be used for different purposes. The proposed event detection system is composed of the following main modules: (1) determination of the user’s location, (2) message extraction from an OSN, (3) topic identification using natural language processing (NLP) based on the Deep Belief Network (DBN), (4) the user behavior change analyzer in the OSN, and (5) affective analysis for emotion identification based on a tree-convolutional neural network (tree-CNN). In the case of public health, the early event detection is very relevant for the population and the authorities in order to be able take corrective actions. Hence, the new coronavirus disease (COVID-19) is used as a case study in this work. For performance validation, the modules related to the topic identification and affective analysis were compared with other similar solutions or implemented with other machine learning algorithms. In the performance assessment, the proposed event detection system achieved an accuracy higher than 0.90, while other similar methods reached accuracy values less than 0.74. Additionally, our proposed system was able to detect an event almost three days earlier than the other methods. Furthermore, the information provided by the system permits to understand the predominant characteristics of an event, such as keywords and emotion type of messages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3020391",
            "Date of Publication": "31 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Renata Lopes Rosa",
                "labs": [
                    "Department of Computer Science, Universidade Federal de Lavras (UFLA), Lavras, Brazil"
                ]
            },
            {
                "name": "Marielle Jordane De Silva",
                "labs": [
                    "Department of Computer Science, Universidade Federal de Lavras (UFLA), Lavras, Brazil"
                ]
            },
            {
                "name": "Douglas Henrique Silva",
                "labs": [
                    "Department of Computer Science, Universidade Federal de Lavras (UFLA), Lavras, Brazil"
                ]
            },
            {
                "name": "Muhammad Shoaib Ayub",
                "labs": [
                    "Department of Electrical Engineering, Chulalongkorn University, Bangkok, Thailand"
                ]
            },
            {
                "name": "Dick Carrillo",
                "labs": [
                    "School of Energy Systems, Lappeenranta–Lahti University University of Technology, Lappeenranta, Finland"
                ]
            },
            {
                "name": "Pedro H. J. Nardelli",
                "labs": [
                    "School of Energy Systems, Lappeenranta–Lahti University University of Technology, Lappeenranta, Finland"
                ]
            },
            {
                "name": "Demóstenes Zegarra Rodríguez",
                "labs": [
                    "Department of Computer Science, Universidade Federal de Lavras (UFLA), Lavras, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Diseases",
                "Event detection",
                "Natural language processing",
                "Public healthcare",
                "Market research",
                "Twitter"
            ],
            "Author Keywords": [
                "Event detection",
                "online social networks",
                "affective analysis",
                "natural language processing",
                "COVID-19"
            ]
        }
    },
    {
        "Title": "On Prediction Model Fidelity in Explicit Nonlinear Model Predictive Vehicle Stability Control",
        "Link": "https://ieeexplore.ieee.org/document/9217490/",
        "Abstract": "This study discusses vehicle stability control based on explicit nonlinear model predictive control (NMPC) and investigates the influence of prediction model fidelity on controller performance. The explicit solutions are generated through an algorithm using multiparametric quadratic programming (mp-QP) approximations of the multiparametric nonlinear programming (mp-NLP) problems. Controllers with different prediction models are assessed through objective indicators in sine-with-dwell tests. The analysis considers the following prediction model features: 1) nonlinear lateral tire forces as functions of slip angles, which are essential for the operation of the stability controller at the limit of handling. Moreover, a simple nonlinear tire force model with saturation is shown to be an effective alternative to a more complex model based on a simplified version of the Magic Formula; 2) longitudinal and lateral load transfers, playing a crucial role in the accurate prediction of the lateral tire forces and their yaw moment contributions; 3) coupling between longitudinal and lateral tire forces, which has a significant influence on the front-to-rear distribution of the braking forces generated by the controller; and 4) nonlinear peak and stiffness factors of the tire model, with visible yet negligible effects on the results.",
        "Details": {
            "DOI": "10.1109/TCST.2020.3012683",
            "Date of Publication": "08 October 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Control Systems Technology"
        },
        "issn_info": {
            "Print ISSN": "1063-6536",
            "Electronic ISSN": "1558-0865"
        },
        "authors_data": [
            {
                "name": "Mathias Metzler",
                "labs": [
                    "Arrival Germany GmbH, Pforzheim, Germany"
                ]
            },
            {
                "name": "Davide Tavernini",
                "labs": [
                    "Centre for Automotive Engineering, University of Surrey, Guildford, U.K."
                ]
            },
            {
                "name": "Patrick Gruber",
                "labs": [
                    "Centre for Automotive Engineering, University of Surrey, Guildford, U.K."
                ]
            },
            {
                "name": "Aldo Sorniotti",
                "labs": [
                    "Centre for Automotive Engineering, University of Surrey, Guildford, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Load modeling",
                "Predictive models",
                "Mathematical model",
                "Stability criteria",
                "Predictive control"
            ],
            "Author Keywords": [
                "Explicit solution",
                "nonlinear model predictive control (NMPC)",
                "prediction model",
                "vehicle stability control"
            ]
        }
    },
    {
        "Title": "Automatic Short Answer Grading With SemSpace Sense Vectors and MaLSTM",
        "Link": "https://ieeexplore.ieee.org/document/9335022/",
        "Abstract": "Automatic assessment of exams is widely preferred by educators than multiple-choice exams because of its efficiency in measuring student performance, lack of subjectivity when evaluating student response, and faster evaluation time than the time consuming manual evaluation. In this study, a new approach for the Automatic Short Answer Grading (ASAG) is proposed using MaLSTM and the sense vectors obtained by SemSpace, a synset based sense embedding method built leveraging WordNet. Synset representations of the Student's answers and reference answers are given as input into parallel LSTM architecture, they are transformed into sentence representations in the hidden layer and the vectorial similarity of these two representation vectors are computed with Manhattan Similarity in the output layer. The proposed approach has been tested using the Mohler ASAG dataset and successful results are obtained in terms of Pearson (r) correlation and RMSE. Also, the proposed approach has been tested as a case study using a specific dataset (CU-NLP) created from the exam of the “Natural Language Processing” course in the Computer Engineering Department of Cukurova University. And it has achieved a successful correlation. The results obtained in the experiments show that the proposed system can be used efficiently and effectively in context-dependent ASAG tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3054346",
            "Date of Publication": "25 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cagatay Neftali Tulu",
                "labs": [
                    "Information Technologies Division, Adana Alparslan Turkes Science and Technology University, Adana, Turkey"
                ]
            },
            {
                "name": "Ozge Ozkaya",
                "labs": [
                    "Computer Engineering Department, Cukurova University, Adana, Turkey"
                ]
            },
            {
                "name": "Umut Orhan",
                "labs": [
                    "Computer Engineering Department, Cukurova University, Adana, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Natural language processing",
                "Benchmark testing",
                "Long short term memory",
                "Deep learning",
                "Task analysis",
                "Learning systems"
            ],
            "Author Keywords": [
                "Automatic short answer grading",
                "MaLSTM",
                "semspace sense vectors",
                "synset based sense embedding",
                "sentence similarity"
            ]
        }
    },
    {
        "Title": "Ethically Responsible Machine Learning in Fintech",
        "Link": "https://ieeexplore.ieee.org/document/9869843/",
        "Abstract": "Rapid technological developments in the last decade have contributed to using machine learning (ML) in various economic sectors. Financial institutions have embraced technology and have applied ML algorithms in trading, portfolio management, and investment advising. Large-scale automation capabilities and cost savings make the ML algorithms attractive for personal and corporate finance applications. Using ML applications in finance raises ethical issues that need to be carefully examined. We engage a group of experts in finance and ethics to evaluate the relationship between ethical principles of finance and ML. The paper compares the experts’ findings with the results obtained using natural language processing (NLP) transformer models, given their ability to capture the semantic text similarity. The results reveal that the finance principles of integrity and fairness have the most significant relationships with ML ethics. The study includes a use case with SHapley Additive exPlanations (SHAP) and Microsoft Responsible AI Widgets explainability tools for error analysis and visualization of ML models. It analyzes credit card approval data and demonstrates that the explainability tools can address ethical issues in fintech, and improve transparency, thereby increasing the overall trustworthiness of ML models. The results show that both humans and machines could err in approving credit card requests despite using their best judgment based on the available information. Hence, human-machine collaboration could contribute to improved decision-making in finance. We propose a conceptual framework for addressing ethical challenges in fintech such as bias, discrimination, differential pricing, conflict of interest, and data protection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3202889",
            "Date of Publication": "29 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maryan Rizinski",
                "labs": [
                    "Department of Computer Science, Metropolitan College, Boston University, Boston, MA, USA",
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Hristijan Peshov",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Kostadin Mishev",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Lubomir T. Chitkushev",
                "labs": [
                    "Department of Computer Science, Metropolitan College, Boston University, Boston, MA, USA"
                ]
            },
            {
                "name": "Irena Vodenska",
                "labs": [
                    "Administrative Sciences Department, Laboratory for Interdisciplinary Finance and Economics (LIFE) Research, Metropolitan College, Boston University, Boston, MA, USA"
                ]
            },
            {
                "name": "Dimitar Trajanov",
                "labs": [
                    "Department of Computer Science, Metropolitan College, Boston University, Boston, MA, USA",
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ethics",
                "Finance",
                "Machine learning",
                "Financial services",
                "Codes",
                "Biological system modeling",
                "Credit cards"
            ],
            "Author Keywords": [
                "Ethics",
                "machine learning",
                "explainability",
                "finance",
                "fintech",
                "financial services"
            ]
        }
    },
    {
        "Title": "Feature Based Automatic Text Summarization Methods: A Comprehensive State-of-the-Art Survey",
        "Link": "https://ieeexplore.ieee.org/document/9994688/",
        "Abstract": "With the advent of the World Wide Web, there are numerous online platforms that generate huge amounts of textual material, including social networks, online blogs, magazines, etc. This textual content contains useful information that can be used to advance humanity. Text summarization has been a significant area of research in natural language processing (NLP). With the expansion of the internet, the amount of data in the world has exploded. Large volumes of data make locating the required and best information time-consuming. It is impractical to manually summarize petabytes of data; hence, computerized text summarization is rising in popularity. This study presents a comprehensive overview of the current status of text summarizing approaches, techniques, standard datasets, assessment criteria, and future research directions. The summarizing approaches are assessed based on several characteristics, including approach-based, document-number-based, Summarization domain-based, document-language-based, output summary nature, etc. This study concludes with a discussion of many obstacles and research opportunities linked to text summarizing research that may be relevant for future researchers in this field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3231016",
            "Date of Publication": "20 December 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Divakar Yadav",
                "labs": [
                    "School of Computer and Information Sciences (SOCIS), Indira Gandhi National Open University (IGNOU), Maidan Garhi, New Delhi, India"
                ]
            },
            {
                "name": "Rishabh Katna",
                "labs": [
                    "Department of Computer Science and Engineering, National Institute of Technology Hamirpur (NIT Hamirpur), Hamirpur, Himachal Pradesh, India"
                ]
            },
            {
                "name": "Arun Kumar Yadav",
                "labs": [
                    "School of Computer and Information Sciences (SOCIS), Indira Gandhi National Open University (IGNOU), Maidan Garhi, New Delhi, India"
                ]
            },
            {
                "name": "Jorge Morato",
                "labs": [
                    "Department of Computer Science, Universidad Carlos III de Madrid, Leganés, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Data mining",
                "Web sites",
                "Market research",
                "Deep learning",
                "Neural networks",
                "Computer science"
            ],
            "Author Keywords": [
                "Abstractive summarization",
                "cosine-similarity",
                "deep learning",
                "extractive summarization",
                "graph-based algorithm",
                "neural networks"
            ]
        }
    },
    {
        "Title": "A Residual BiLSTM Model for Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/9301306/",
        "Abstract": "As one of the most powerful neural networks, Long Short-Term Memory (LSTM) is widely used in natural language processing (NLP) tasks. Meanwhile, the BiLSTM-CRF model is one of the most popular models for named entity recognition (NER), and many state-of-the-art models for NER are based on it. In this paper, we propose a new residual BiLSTM model and perform it with a conditional random field (CRF) layer together on NER tasks. Based on the most popular BiLSTM-CRF model, we replace the BiLSTM with our residual BiLSTM blocks to encode words or characters. We evaluate our model on Chinese and English datasets. We utilize both word2vec and BERT to generate word or character vectors. Furthermore, we conduct experiments to compare the performance of NER by using different structures of residual blocks. The experimental results show that our model can improve the performance of both Chinese and English NER effectively without introducing any external knowledge.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3046253",
            "Date of Publication": "21 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gang Yang",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Hongzhe Xu",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Natural language processing",
                "Bit error rate",
                "Feature extraction",
                "Context modeling",
                "Semantics",
                "Residual neural networks"
            ],
            "Author Keywords": [
                "Natural language processing",
                "named entity recognition",
                "residual bi-directional LSTM"
            ]
        }
    },
    {
        "Title": "Multi-Objective Optimization of Energy Management Strategy on Hybrid Energy Storage System Based on Radau Pseudospectral Method",
        "Link": "https://ieeexplore.ieee.org/document/8796381/",
        "Abstract": "In this study, a multi-objective optimization method based on the Radau pseudospectral method is proposed for the energy management strategy in the hybrid energy storage system (HESS). In the proposed method, by approximating state and control variables in the system with global interpolating polynomials, the optimal control problem (OCP) is transformed into a nonlinear programming problem (NLP) and solved by a sparse nonlinear optimizer. Further, the Pareto solution set is obtained by taking the energy consumption of the HESS and the equivalent life of the battery as objective functions. Three solutions representing different tradeoffs were selected for comparative analysis: minimum system energy consumption (5819.60 kJ), with battery life 68368 cycles; maximum battery life (76227 cycles), with energy consumption 5865.68 kJ; and the balanced tradeoff optimal solution with battery life 72488 cycles and energy consumption 5841.96 kJ. The results showed that for every additional 5 kJ in system energy consumption, the battery Ah-throughput was reduced by 0.053 Ah and its equivalent life extended by 876 cycles. Further, compared with the single-cell energy source, the balanced tradeoff optimal solution increased the battery life by 29.92% and decreased the system energy consumption by 1.79%. Thus, this work provides a fast and stable multi-objective optimization method for the energy management strategy of HESS and lays the foundation for obtaining optimal system parameters.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2935188",
            "Date of Publication": "13 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanwei Liu",
                "labs": [
                    "School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Zhenye Li",
                "labs": [
                    "School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Ziyue Lin",
                "labs": [
                    "School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Kegang Zhao",
                "labs": [
                    "National Local Engineering Laboratory of Automobile Parts Technology, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Yunxue Zhu",
                "labs": [
                    "The Fifth Electronics Research Institute of the Ministry of Industry and Information Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Batteries",
                "Supercapacitors",
                "Energy management",
                "Optimization",
                "Discharges (electric)",
                "Resistance"
            ],
            "Author Keywords": [
                "Energy management strategy",
                "hybrid energy storage system",
                "multi-objective optimization",
                "Radau pseudospectral method"
            ]
        }
    },
    {
        "Title": "A Novel COVID-19 Data Set and an Effective Deep Learning Approach for the De-Identification of Italian Medical Records",
        "Link": "https://ieeexplore.ieee.org/document/9335570/",
        "Abstract": "In the last years, the need to de-identify privacy-sensitive information within Electronic Health Records (EHRs) has become increasingly felt and extremely relevant to encourage the sharing and publication of their content in accordance with the restrictions imposed by both national and supranational privacy authorities. In the field of Natural Language Processing (NLP), several deep learning techniques for Named Entity Recognition (NER) have been applied to face this issue, significantly improving the effectiveness in identifying sensitive information in EHRs written in English. However, the lack of data sets in other languages has strongly limited their applicability and performance evaluation. To this aim, a new de-identification data set in Italian has been developed in this work, starting from the 115 COVID-19 EHRs provided by the Italian Society of Radiology (SIRM): 65 were used for training and development, the remaining 50 were used for testing. The data set was labelled following the guidelines of the i2b2 2014 de-identification track. As additional contribution, combined with the best performing Bi-LSTM + CRF sequence labeling architecture, a stacked word representation form, not yet experimented for the Italian clinical de-identification scenario, has been tested, based both on a contextualized linguistic model to manage word polysemy and its morpho-syntactic variations and on sub-word embeddings to better capture latent syntactic and semantic similarities. Finally, other cutting-edge approaches were compared with the proposed model, which achieved the best performance highlighting the goodness of the promoted approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3054479",
            "Date of Publication": "25 January 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rosario Catelli",
                "labs": [
                    "Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy"
                ]
            },
            {
                "name": "Francesco Gargiulo",
                "labs": [
                    "Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy"
                ]
            },
            {
                "name": "Valentina Casola",
                "labs": [
                    "Department of Electrical Engineering and Information Technologies, University of Naples Federico II, Naples, Italy"
                ]
            },
            {
                "name": "Giuseppe De Pietro",
                "labs": [
                    "Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy"
                ]
            },
            {
                "name": "Hamido Fujita",
                "labs": [
                    "Faculty of Information Technology, Ho Chi Minh City University of Technology (HUTECH), Ho Chi Minh, Vietnam",
                    "Andalusian Research Institute in Data Science and Computational Intelligence (DaSCI), University of Granada, Granada, Spain",
                    "Faculty of Software and Information Science, Iwate Prefectural University, Iwate, Japan"
                ]
            },
            {
                "name": "Massimo Esposito",
                "labs": [
                    "Institute for High Performance Computing and Networking (ICAR), National Research Council, Naples, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "COVID-19",
                "Training",
                "Task analysis",
                "Natural language processing",
                "Labeling",
                "Bit error rate"
            ],
            "Author Keywords": [
                "Clinical de-identification",
                "contextualized embedding",
                "deep learning",
                "Italian language",
                "named entity recognition"
            ]
        }
    },
    {
        "Title": "Context Embedding Based on Bi-LSTM in Semi-Supervised Biomedical Word Sense Disambiguation",
        "Link": "https://ieeexplore.ieee.org/document/8712564/",
        "Abstract": "Word sense disambiguation (WSD) is a basic task of natural language processing (NLP) and its purpose to choose the correct sense of an ambiguous word according to its context. In biomedical WSD, recent research has used context embeddings built by concatenating or averaging word embeddings to represent the sense of a context. These simple linear operations on neighbor words ignore the information about the sequence and may cause their models to be flawed in semantic representation. In this paper, we present a novel language model based on Bi-LSTM to embed an entire sentential context in continuous space by taking account of word order. We demonstrate that our language model can generate high-quality context representations in an unsupervised manner. Unlike the previous work that directly predicts the word senses, our model classifies a word in a context by building sense embeddings and this helps us set a new state-of-the-art result (macro/micro average) on both MSH and NLM datasets. In addition, with the same language model, we propose semi-supervised learning based on label propagation (LP) to reduce the dependence on biomedical data. The results show that this method can nearly approach the state-of-the-art results produced by our Bi-LSTM when reducing the labeled training data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2912584",
            "Date of Publication": "10 May 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhi Li",
                "labs": [
                    "Key Laboratory of Wireless Power Transmission, Ministry of Education, University of Sichuan, Chengdu, China"
                ]
            },
            {
                "name": "Fan Yang",
                "labs": [
                    "Key Laboratory of Obstetric and Gynecologic and Pediatric Diseases and Birth Defects, Ministry of Education, West China Second Hospital, University of Sichuan, Chengdu, China"
                ]
            },
            {
                "name": "Yaoru Luo",
                "labs": [
                    "College of Electronics and Information Engineering, University of Sichuan, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Semantics",
                "Biological system modeling",
                "Context modeling",
                "Data models",
                "Classification algorithms",
                "Logic gates"
            ],
            "Author Keywords": [
                "Word sense disambiguation",
                "semi-supervised learning",
                "context embedding",
                "biomedical domain"
            ]
        }
    },
    {
        "Title": "Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10413447/",
        "Abstract": "Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3358206",
            "Date of Publication": "24 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hamideh Ghanadian",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Isar Nejadgholi",
                "labs": [
                    "National Research Council Canada, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Hussein Al Osman",
                "labs": [
                    "Department of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Synthetic data",
                "Task analysis",
                "Data models",
                "Chatbots",
                "Mental health",
                "Social networking (online)",
                "Social factors",
                "Artificial intelligence",
                "Deep learning",
                "Mental health",
                "Synthetic data"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "deep learning",
                "large language models",
                "suicide detection",
                "synthetic data generation",
                "transformer based models"
            ]
        }
    },
    {
        "Title": "Deep Learning Based Weighted Feature Fusion Approach for Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/8827512/",
        "Abstract": "Deep learning algorithms have achieved remarkable results in the natural language processing(NLP) and computer vision. Hence, a trend still going on to use these algorithms, such as convolution and recurrent neural networks, for text analytic task to extract useful information. Features extraction is one of the important reasons behind the success of these networks. Moreover passing features from one layer to another layer within the network and one network to another network have done. However multilevel and multitype features fusion remains unexplored in sentiment analysis. So, in this paper, we use three datasets to display the advantages of extracting and fusing multilevel as well as multitype features from different neural networks. Multilevel features are from different layers of the same network, and multitype features are from different network architectures. Experiment results demonstrate that the proposed model based on multilevel and multitype weighted features fusion outperforms than many exiting works with an accuracy of 80.2%, 48.2%, and 87.0% on MR, SST1, and SST2 datasets respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2940051",
            "Date of Publication": "09 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohd Usama",
                "labs": [
                    "Embedded and Pervasive Computing (EPIC) Laboratory, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"
                ]
            },
            {
                "name": "Wenjing Xiao",
                "labs": [
                    "Embedded and Pervasive Computing (EPIC) Laboratory, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"
                ]
            },
            {
                "name": "Belal Ahmad",
                "labs": [
                    "Embedded and Pervasive Computing (EPIC) Laboratory, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China"
                ]
            },
            {
                "name": "Jiafu Wan",
                "labs": [
                    "Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Mohammad Mehedi Hassan",
                "labs": [
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulhameed Alelaiwi",
                "labs": [
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Convolution",
                "Recurrent neural networks",
                "Deep learning",
                "Feature extraction",
                "Analytical models"
            ],
            "Author Keywords": [
                "Convolution neural network",
                "recurrent neural network",
                "feature fusion",
                "feature learning",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "The Recent Technologies to Curb the Second-Wave of COVID-19 Pandemic",
        "Link": "https://ieeexplore.ieee.org/document/9471880/",
        "Abstract": "Different epidemics, specially Coronavirus, have caused critical misfortunes in various fields like monetary deprivation, survival conditions, thus diminishing the overall individual fulfillment. Various worldwide associations and different hierarchies of government fraternity are endeavoring to offer the necessary assistance in eliminating the infection impacts but unfortunately standing up to the non-appearance of resources and expertise. In contrast to all other pandemics, Coronavirus has proven to exhibit numerous requirements such that curated appropriation and determination of innovations are required to deal with the vigorous undertakings, which include precaution, detection, and medication. Innovative advancements are essential for the subsequent pandemics where-in the forthcoming difficulties can indeed be approached to such a degree that it facilitates constructive solutions more comprehensively. In this study, futuristic and emerging innovations are analyzed, improving COVID-19 effects for the general public. Large data sets need to be advanced so that extensive models related to deep analysis can be used to combat Coronavirus infection, which can be done by applying Artificial intelligence techniques such as Natural Language Processing (NLP), Machine Learning (ML), and Computer vision to varying processing files. This article aims to furnish variation sets of innovations that can be utilized to eliminate COVID-19 and serve as a resource for the coming generations. At last, elaboration associated with future state-of-the-art technologies and the attainable sectors of AI methodologies has been mentioned concerning the post-COVID-19 world to enable the different ideas for dealing with the pandemic-based difficulties.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3094400",
            "Date of Publication": "02 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "M. Poongodi",
                "labs": [
                    "College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            },
            {
                "name": "Mohit Malviya",
                "labs": [
                    "Department of CTO 5G, Wipro Ltd., Bengaluru, India"
                ]
            },
            {
                "name": "Mounir Hamdi",
                "labs": [
                    "College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            },
            {
                "name": "Hafiz Tayyab Rauf",
                "labs": [
                    "Centre for Smart Systems, AI and Cybersecurity, Staffordshire University, Stoke-on-Trent, U.K."
                ]
            },
            {
                "name": "Seifedine Kadry",
                "labs": [
                    "Faculty of Applied Computing and Technology, Noroff University College, Kristiansand, Norway"
                ]
            },
            {
                "name": "Orawit Thinnukool",
                "labs": [
                    "Research Group of Embedded Systems and Mobile Application in Health Science, College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "COVID-19",
                "Pandemics",
                "Coronaviruses",
                "Technological innovation",
                "Diseases",
                "Artificial intelligence",
                "Medical diagnostic imaging"
            ],
            "Author Keywords": [
                "Epidemic",
                "coronavirus",
                "cloud",
                "5G",
                "drone",
                "X-Ray",
                "CT-scan",
                "telemedicine",
                "artificial intelligence"
            ]
        }
    },
    {
        "Title": "Interactive Rule Attention Network for Aspect-Level Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9037260/",
        "Abstract": "Aspect-level sentiment analysis is a fundamental task in NLP, and it aims to predict the sentiment polarity of each specific aspect term in a given sentence. Recent researches show that the fine-grained sentiment analysis for aspect-level has become a research hotspot. However, previous work did not consider the influence of grammatical rules on aspect-level sentiment analysis. In addition, attention mechanism is too simple to learn attention information from context and target interactively. Therefore, we propose an interactive rule attention network (IRAN) for aspect-level sentiment analysis. IRAN not only designs a grammar rule encoder, which simulates the grammatical functions at the sentence by standardizing the output of adjacent positions, but also constructs an interaction attention network to learn attention information from context and target. Experimental results on SemEval 2014 Dataset and ACL 2014 Twitter Dataset demonstrate IRAN can learn effective features and obtain superior performance over the baseline models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2981139",
            "Date of Publication": "16 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qiang Lu",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Shandong, China"
                ]
            },
            {
                "name": "Zhenfang Zhu",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Shandong, China"
                ]
            },
            {
                "name": "Dianyuan Zhang",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Shandong, China"
                ]
            },
            {
                "name": "Wenqing Wu",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Shandong, China"
                ]
            },
            {
                "name": "Qiangqiang Guo",
                "labs": [
                    "School of Information Science and Electrical Engineering, Shandong Jiaotong University, Shandong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Analytical models",
                "Task analysis",
                "Grammar",
                "Social sciences",
                "Twitter"
            ],
            "Author Keywords": [
                "Aspect-level sentiment analysis",
                "grammatical rules",
                "IRAN",
                "interaction attention network"
            ]
        }
    },
    {
        "Title": "Stacked Residual Recurrent Neural Networks With Cross-Layer Attention for Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9063530/",
        "Abstract": "Text classification is a fundamental task in natural language processing and is essential for many tasks like sentiment analysis and question classification etc. As we all know, different NLP tasks require different linguistic features. Tasks such as text classification requires more semantic features than other tasks such as dependency parsing requiring more syntactic features. Most existing methods focus on improving performance by mixing and calibrating features, without distinguishing the types of features and corresponding effects. In this paper, we propose a stacked residual recurrent neural networks with cross-layer attention model to filter more semantic features for text classification, which named SRCLA. Firstly, we build a stacked network structure to filter different types of linguistic features, and then propose a novel cross-layer attention mechanism that exploits higher-level features to supervise the lower-level features to refine the filtering process. Based on this, more semantic features can be selected for text classification. We conduct experiments on eight text classification tasks, including sentiment analysis, question classification and subjectivity classification and compare with a broad range of baselines. Experimental results show that the proposed approaches achieve the state-of-the-art results on 5 out of 8 tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2987101",
            "Date of Publication": "13 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yangyang Lan",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",
                    "Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Technology R&D, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Yazhou Hao",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",
                    "Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Technology R&D, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Kui Xia",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",
                    "Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Technology R&D, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Buyue Qian",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",
                    "National Engineering Laboratory for Big Data Analytics, Xi’an Jiaotong University, Xi’an, China"
                ]
            },
            {
                "name": "Chen Li",
                "labs": [
                    "School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China",
                    "Shaanxi Province Key Laboratory of Satellite and Terrestrial Network Technology R&D, Xi’an Jiaotong University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Recurrent neural networks",
                "Linguistics",
                "Semantics",
                "Mathematical model",
                "Syntactics"
            ],
            "Author Keywords": [
                "Cross-layer attention",
                "stacked residual neural network",
                "bidirectional long short-term memory",
                "feature filtering",
                "text classification"
            ]
        }
    },
    {
        "Title": "Syntactic Edge-Enhanced Graph Convolutional Networks for Aspect-Level Sentiment Classification With Interactive Attention",
        "Link": "https://ieeexplore.ieee.org/document/9177070/",
        "Abstract": "Aspect-level sentiment classification is a hot research topic in natural language processing (NLP). One of the key challenges is that how to develop effective algorithms to model the relationships between aspects and opinion words appeared in a sentence. Among the various methods proposed in the literature, the graph convolutional networks (GCNs) achieve the promising results due to their good ability to capture the long distance between the aspects and the opinion words. However, the existing methods cannot effectively leverage the edge information of dependency parsing tree, resulting in the sub-optimal results. In this article, we propose a syntactic edge-enhanced graph convolutional network (ASEGCN) for aspect-level sentiment classification with interactive attention. Our proposed method can effectively learn better representations of aspects and the opinion words by considering the different types of neighborhoods with the edge constraint. To evaluate the effectiveness of our proposed method, we conduct the experiments on five standard sentiment classification results. Our results demonstrate that our proposed method obtains the better performance than the state-of-the-art models on four datasets, and achieves a comparative performance on Rest16.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3019277",
            "Date of Publication": "25 August 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yao Xiao",
                "labs": [
                    "Central China Normal University Wollongong Joint Institute, Central China Normal University, Wuhan, China"
                ]
            },
            {
                "name": "Guangyou Zhou",
                "labs": [
                    "School of Computer Science, Central China Normal University, Wuhan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Syntactics",
                "Solid modeling",
                "Semantics",
                "Manganese",
                "Encoding",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Natural language processing",
                "sentiment analysis",
                "text mining",
                "graph convolutional networks"
            ]
        }
    },
    {
        "Title": "PHTI: Pashto Handwritten Text Imagebase for Deep Learning Applications",
        "Link": "https://ieeexplore.ieee.org/document/9928191/",
        "Abstract": "Document Image Analysis (DIA) is one of the research areas of Artificial Intelligence (AI) that converts document images into machine-readable codes. In DIA systems, Optical Character Recognition (OCR) plays a key role in digitizing document images. The output of an OCR system is further used in many applications including, Natural Language Processing (NLP), Sentiment Analysis, Speech Recognition, and Translation Services. However, standard datasets are an essential requirement for the development, evaluation and comparison of different text recognition techniques. Pashto is one of such low resource languages that lacks availability regarding standard dataset of handwritten text. This paper therefore, addresses the unavailability of standard dataset for the Pashto handwritten text by developing a dataset named Pashto Handwritten Text Imagebase (PHTI). The PHTI is created by collecting handwritten samples from diverse genre of the Pashto language including poetry, religion, short stories, articles, novels, sports, culture and news. The dataset consists of 4,000 scanned images, written by 400 writers including 200 males and 200 females. These 4,000 images are further segmented into 36,082 text-line images. Each text-line image is annotated/ transcribed with UTF-8 codecs. The dataset can be used for many deep learning-based applications including, text recognition, skew detection, gender classification and age-groups classification.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3216881",
            "Date of Publication": "25 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ibrar Hussain",
                "labs": [
                    "Department of Computer Science and Information Technology, University of Malakand, Khyber Pakhtunkhawa, Pakistan",
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Riaz Ahmad",
                "labs": [
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Siraj Muhammad",
                "labs": [
                    "Department of Computer Science, Shaheed Benazir Bhutto University (SBBU), Sheringal, Upper Dir, Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Khalil Ullah",
                "labs": [
                    "Department of Software Engineering, University of Malakand (UOM), Khyber Pakhtunkhawa, Pakistan"
                ]
            },
            {
                "name": "Habib Shah",
                "labs": [
                    "Department of Computer Science, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Abdallah Namoun",
                "labs": [
                    "Faculty of Computer Science and Information Systems, Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical character recognition",
                "Text recognition",
                "Handwriting recognition",
                "Artificial intelligence",
                "Writing",
                "Text analysis",
                "Image segmentation",
                "Natural language processing",
                "Speech recognition"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "document image analysis",
                "handwritten text",
                "natural language processing",
                "optical character recognition",
                "speech recognition",
                "Pashto",
                "standard dataset"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis of Public Social Media as a Tool for Health-Related Topics",
        "Link": "https://ieeexplore.ieee.org/document/9810923/",
        "Abstract": "For decades, researchers have experimented with the possibility that machines can equal human linguistic capabilities. Recently, advances in the field of natural language processing (NLP) as well as a substantial increase in available naturally occurring linguistic data on social media platforms have made more advanced methodologies such as sentiment analysis (SA) gain substantial momentum on contemporary applications. This document compiles what the authors consider to be some of the most important concepts related to SA, as well as techniques and processes necessary for the various stages of its implementation. Furthermore, specific applications related to the extraction and classification of social media data using novel SA techniques are presented and quantified, with an emphasis on those used for the identification of mental health degradation during the COVID-19 pandemic. Finally, the authors present several conclusions highlighting the most prominent benefits and drawbacks of the methods discussed, followed by a brief discussion of possible future applications of certain methods of interest.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3187406",
            "Date of Publication": "30 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fernando Arias",
                "labs": [
                    "Facultad de Ingeniería Eléctrica, Universidad Tecnológica de Panamá, Panama City, Panama",
                    "Centro de Estudios Multidisciplinarios en Ciencias, Ingenieria y Tecnologia, CEMCIT-AIP, Panama City, Panama",
                    "Centro de Investigación e Innovación Eléctrica, Mecánica y de la Industria (CINEMI), Universidad Tecnológica de Panamá, Panama City, Panama"
                ]
            },
            {
                "name": "Mayteé Zambrano Núñez",
                "labs": [
                    "Facultad de Ingeniería Eléctrica, Universidad Tecnológica de Panamá, Panama City, Panama",
                    "Centro de Estudios Multidisciplinarios en Ciencias, Ingenieria y Tecnologia, CEMCIT-AIP, Panama City, Panama"
                ]
            },
            {
                "name": "Ariel Guerra-Adames",
                "labs": [
                    "Facultad de Ingeniería Eléctrica, Universidad Tecnológica de Panamá, Panama City, Panama"
                ]
            },
            {
                "name": "Nathalia Tejedor-Flores",
                "labs": [
                    "Centro de Estudios Multidisciplinarios en Ciencias, Ingenieria y Tecnologia, CEMCIT-AIP, Panama City, Panama",
                    "Centro de Investigaciones Hidráulicas e Hidrotécnicas (CIHH), Universidad Tecnológica de Panamá, Panama City, Panama"
                ]
            },
            {
                "name": "Miguel Vargas-Lombardo",
                "labs": [
                    "Centro de Estudios Multidisciplinarios en Ciencias, Ingenieria y Tecnologia, CEMCIT-AIP, Panama City, Panama",
                    "Facultad de Ingeniería en Sistemas Computacionales (FISC), Universidad Tecnológica de Panamá, Panama City, Panama"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "COVID-19",
                "Sentiment analysis",
                "Data mining",
                "Pandemics",
                "Linguistics",
                "Mental health"
            ],
            "Author Keywords": [
                "COVID-19",
                "literature review",
                "public social media",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "The Application of Machine Learning to Consolidate Critical Success Factors of Lean Six Sigma",
        "Link": "https://ieeexplore.ieee.org/document/9511473/",
        "Abstract": "Lean six sigma (LSS) is a quality improvement phenomenon that has captured the attention of the industry. Aiming at a capability level of 3.4 defects per million opportunities (Six Sigma) and efficient (lean) processes, LSS has been shown to improve business efficiency and customer satisfaction by blending the best methods from Lean and Six Sigma (SS). Many businesses have attempted to implement LSS, but not everyone has succeeded in improving the business processes to achieve expected outcomes. Hence, understanding the cause and effect relationships of the enablers of LSS, while deriving deeper insights from the functioning of the LSS strategy will be of great value for effective execution of LSS. However, there is little research on the causal mechanisms that explain how expected outcomes are caused through LSS enablers, highlighting the need for comprehensive research on this topic. LSS literature is overwhelmed by the diverse range of Critical Success Factors (CSFs) prescribed by a plethora of conceptual papers, and very few attempts have been made to harness these CSFs to a coherent theory on LSS. We fill this gap through a novel method using artificial intelligence, more specifically Natural Language Processing (NLP), with particular emphasis on cross-domain knowledge utilization to develop a parsimonious set of constructs that explain the LSS phenomenon. This model is then reconciled against published models on SS to develop a final testable model that explains how LSS elements cause quality performance, customer satisfaction, and business performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3103931",
            "Date of Publication": "11 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Achinthya D. Perera",
                "labs": [
                    "School of Food and Advanced Technology, Massey University, Palmerston North, New Zealand"
                ]
            },
            {
                "name": "Nihal P. Jayamaha",
                "labs": [
                    "School of Food and Advanced Technology, Massey University, Palmerston North, New Zealand"
                ]
            },
            {
                "name": "Nigel P. Grigg",
                "labs": [
                    "School of Food and Advanced Technology, Massey University, Palmerston North, New Zealand"
                ]
            },
            {
                "name": "Mark Tunnicliffe",
                "labs": [
                    "School of Food and Advanced Technology, Massey University, Palmerston North, New Zealand"
                ]
            },
            {
                "name": "Amardeep Singh",
                "labs": [
                    "School of Fundamental Sciences, Massey University, Palmerston North, New Zealand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Six sigma",
                "Organizations",
                "Project management",
                "Natural language processing",
                "Deep learning",
                "Customer satisfaction",
                "Manufacturing"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "critical success factors (CSFs) of LSS",
                "lean",
                "lean six sigma (LSS)",
                "six sigma (SS)",
                "deep neural network",
                "word embedding",
                "classification model"
            ]
        }
    },
    {
        "Title": "A Multi-Layer Network for Aspect-Based Cross-Lingual Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/9550786/",
        "Abstract": "In the recent era, the advancement of communication technologies provides a valuable interaction source between people of different regions. Nowadays, many organizations adopt the latest approaches, i.e., sentiment analysis and aspect-oriented sentiment classification, to evaluate user reviews to improve the quality of their products. The processing of multi-lingual user reviews is a key challenge in Natural Language Processing (NLP). This paper proposes a multi-layer network with divided attention to perform aspect-based sentiment classification for cross-lingual data. It extracts the Part-of-Speech (POS) tagging information of the given reviews, preprocesses them, and converts them into tokens. Furthermore, bi-lingual dictionaries are leveraged to map the converted tokens from one language to another. Given the preprocessed and mapped reviews, vectors are generated by leveraging the multi-lingual BERT and passed to the proposed deep learning classifier. The 10351 restaurant reviews from SemEval-2016 Task 5 dataset are exploited for the prediction of aspect-based sentiment. The results of cross-lingual validation suggest that the proposed approach significantly outperforms the state-of-the-art approaches and improves the precision, recall, and F1 by more than 23%, 20%, and 22%, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3116053",
            "Date of Publication": "28 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kalim Sattar",
                "labs": [
                    "School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China"
                ]
            },
            {
                "name": "Qasim Umer",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Vehari, Pakistan"
                ]
            },
            {
                "name": "Dinara G. Vasbieva",
                "labs": [
                    "Department of English Language for Professional Communication, Financial University under the Government of the Russian Federation, Moscow, Russia"
                ]
            },
            {
                "name": "Sungwook Chung",
                "labs": [
                    "Department of Computer Engineering, Changwon National University, Changwon, South Korea"
                ]
            },
            {
                "name": "Zohaib Latif",
                "labs": [
                    "Department of Computer Science, Hanyang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Choonhwa Lee",
                "labs": [
                    "Department of Computer Science, Hanyang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Task analysis",
                "Data models",
                "Feature extraction",
                "Data mining",
                "Bit error rate",
                "Tagging"
            ],
            "Author Keywords": [
                "Natural language processing",
                "cross-lingual",
                "divided attention",
                "aspect-based sentiment classification"
            ]
        }
    },
    {
        "Title": "A Method for MBTI Classification Based on Impact of Class Components",
        "Link": "https://ieeexplore.ieee.org/document/9578983/",
        "Abstract": "Predicting the personality type of text authors has a well-known usage in psychology with practical applications in business. From the data science perspective, we can look at this problem as a text classification task that can be tackled using natural language processing (NLP) and deep learning. This paper proposes a method and a novel loss function for multiclass classification using the Myers–Briggs Type Indicator (MBTI) approach for predicting the author’s personality type. Furthermore, this paper proposes an approach that improves the current results of the MBTI multiclass classification because it considers components of compound class labels as supportive elements for better classification according to MBTI. As such, it also provides a new perspective on this classification problem. The experimental results on long short-term memory (LSTM) and convolutional neural network (CNN) models outperform baseline models for multiclass classification, related research on multiclass classification, and most research with four binary approaches to MBTI classification. Moreover, other classification problems that target compound class labels and label parts with binary mutually exclusive values can benefit from this approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3121137",
            "Date of Publication": "18 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ninoslav Cerkez",
                "labs": [
                    "College of Information Technologies (VSITE), Zagreb, Croatia"
                ]
            },
            {
                "name": "Boris Vrdoljak",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Sandro Skansi",
                "labs": [
                    "Faculty of Croatian Studies, University of Zagreb, Zagreb, Croatia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Compounds",
                "Instruments",
                "Encoding",
                "Psychology",
                "Natural language processing",
                "Standards",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Binary classification",
                "compound class labels",
                "cross-entropy loss",
                "custom loss function",
                "deep learning",
                "machine learning",
                "MBTI",
                "Myers-Briggs Type Indicator",
                "multiclass classification",
                "natural language processing",
                "personality computing"
            ]
        }
    },
    {
        "Title": "Make It Directly: Event Extraction Based on Tree-LSTM and Bi-GRU",
        "Link": "https://ieeexplore.ieee.org/document/8957160/",
        "Abstract": "Event extraction is an important research direction in the field of natural language processing (NLP) applications including information retrieval (IR). Traditional event extraction is realized with two methods: the pipeline and the joint extraction methods. The pipeline method determines the event by triggering word recognition to further implement event extraction and is prone to error cascading. The joint extraction method applies deep learning to implement the completion of the trigger word and the argument role classification task. Most studies with the joint extraction method adopt the CNN or RNN network structure. However, in the case of event extraction, deeper understanding of complex contexts is required. Existing studies do not make full use of syntactic relations. This paper proposes a novel event extraction model, which is built upon a Tree-LSTM network and a Bi-GRU network and carries syntactically related information. It is illustrated that this method simultaneously uses Tree-LSTM and Bi-GRU to obtain a representation of the candidate event sentence and identify the event type, which results in a better performance compared to the ones that use chain structured LSTM, CNN or only Tree-LSTM. Finally, the hidden state of each node is used in Tree-LSTM to predict a label for candidate arguments and identify/classify all arguments of an event. Lab results show that the proposed event extraction model achieves competitive results compared to previous works.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2965964",
            "Date of Publication": "13 January 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wentao Yu",
                "labs": [
                    "PLA Information Engineering University, Zhengzhou, China"
                ]
            },
            {
                "name": "Mianzhu Yi",
                "labs": [
                    "PLA Information Engineering University, Zhengzhou, China"
                ]
            },
            {
                "name": "Xiaohui Huang",
                "labs": [
                    "PLA Information Engineering University, Zhengzhou, China",
                    "University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Xiaoyu Yi",
                "labs": [
                    "PLA Information Engineering University, Zhengzhou, China",
                    "Henan Normal University, Xinxiang, China"
                ]
            },
            {
                "name": "Qingjun Yuan",
                "labs": [
                    "PLA Information Engineering University, Zhengzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Task analysis",
                "Hidden Markov models",
                "Feature extraction",
                "Information retrieval",
                "Semantics",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Event extraction",
                "Bi-GRU",
                "Tree-LSTM"
            ]
        }
    },
    {
        "Title": "AdaMoW: Multimodal Sentiment Analysis Based on Adaptive Modality-Specific Weight Fusion Network",
        "Link": "https://ieeexplore.ieee.org/document/10126108/",
        "Abstract": "Multimodal sentiment analysis (MSA) is a crucial task in the field of natural language processing (NLP), with a wide range of applications. This paper proposes an adaptive modality-specific weight fusion network (AdaMoW) to address issues in the process of multimodal data fusion. Specifically, we use different weight calculation methods at various stages of the model. In the model training stage, diverse weights are assigned to different modalities by calculating the correlation between the single-modal sentiment prediction value and the real multimodal sentiment labels, and a weight-mapping network is designed to learn this “data-weight” mapping relationship. In the testing and verification phase of the model, the trained weight-mapping network is used to obtain the weights of different modalities. In addition, in order to optimize the multimodal fusion data, we designed a generator, which reversely generates the unimodal feature vector through the multimodal fusion vector, and compares it with the original unimodal feature extraction obtained after unimodal feature extraction. The modal feature vectors are compared and optimized, so that the fusion results can maintain the uniqueness of the modality while obtaining the multimodal data interaction information. AdaMoW is verified on two benchmark MSA datasets CMU-MOSI and CMU-MOSEI. The experimental results show that the effectiveness of AdaMoW surpasses the previous baseline model and achieves state-of-the-art results.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3276932",
            "Date of Publication": "16 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junling Zhang",
                "labs": [
                    "Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Zhejiang, Jinhua, China"
                ]
            },
            {
                "name": "Xuemei Wu",
                "labs": [
                    "Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Zhejiang, Jinhua, China"
                ]
            },
            {
                "name": "Changqin Huang",
                "labs": [
                    "Key Laboratory of Intelligent Education Technology and Application of Zhejiang Province, Zhejiang Normal University, Zhejiang, Jinhua, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Feature extraction",
                "Visualization",
                "Analytical models",
                "Task analysis",
                "Transformers",
                "Tensors",
                "Neural networks",
                "Deep learning"
            ],
            "Author Keywords": [
                "Deep neural networks",
                "adaptive weight-based feature fusion",
                "modality-specific feature optimization",
                "multimodal sentiment analysis"
            ]
        }
    },
    {
        "Title": "Latent Personality Traits Assessment From Social Network Activity Using Contextual Language Embedding",
        "Link": "https://ieeexplore.ieee.org/document/9531972/",
        "Abstract": "Recognizing author identity from digital footprints without having a large corpus of documents from an individual is of keen interest to security researchers and government agencies. Users reveal aspects of their personality via the content they share with their social media followers and through the patterns in their interactions on online networking platforms. This study examines the potency of emerging natural language processing (NLP) methods in analyzing social network activity. A linguostylistic personality traits assessment (LPTA) system is developed to estimate Twitter users’ personality traits based on their tweets using the Myers-Briggs-type indicator (MBTI) and big-five personality scales. A novel input representation mechanism is proposed to process tweets by converting them into real-valued vectors using frequency, co-occurrence, and context (FCC) measures. Other prevalent text representation schemes, such as one-hot encoding, count-based vectorization, and pretrained language model representations are used as comparators. A genetic algorithm (GA) approach is proposed to reduce the feature set and increase the efficacy of the features extracted. The developed system outperforms the state-of-the-art research by reliably estimating the user’s latent personality traits while using 50 or fewer tweets per user.",
        "Details": {
            "DOI": "10.1109/TCSS.2021.3108810",
            "Date of Publication": "09 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Computational Social Systems"
        },
        "issn_info": {
            "Electronic ISSN": "2329-924X"
        },
        "authors_data": [
            {
                "name": "Pavan Kumar K. N.",
                "labs": [
                    "Department of Computer Science, University of Calgary, Calgary, Canada"
                ]
            },
            {
                "name": "Marina L. Gavrilova",
                "labs": [
                    "Department of Computer Science, University of Calgary, Calgary, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Linguistics",
                "Task analysis",
                "Reliability",
                "Computational modeling",
                "Predictive models"
            ],
            "Author Keywords": [
                "Contextual language embedding",
                "linguostylistic classification",
                "personality traits",
                "social behavior",
                "social network"
            ]
        }
    },
    {
        "Title": "Large Language Models are Not Models of Natural Language: They are Corpus Models",
        "Link": "https://ieeexplore.ieee.org/document/9794684/",
        "Abstract": "Natural Language Processing (NLP) has become one of the leading application areas in the current Artificial Intelligence boom. Transfer learning has enabled large deep learning neural networks trained on the language modeling task to vastly improve performance in almost all downstream language tasks. Interestingly, when the language models are trained with data that includes software code, they demonstrate remarkable abilities in generating functioning computer code from natural language specifications. We argue that this creates a conundrum for the claim that eliminative neural models are a radical restructuring in our understanding of cognition in that they eliminate the need for symbolic abstractions like generative phrase structure grammars. Because the syntax of programming languages is by design determined by phrase structure grammars, neural models that produce syntactic code are apparently uninformative about the theoretical foundations of programming languages. The demonstration that neural models perform well on tasks that involve clearly symbolic systems, proves that they cannot be used as an argument that language and other cognitive systems are not symbolic. Finally, we argue as a corollary that the term language model is misleading and propose the adoption of the working term corpus model instead, which better reflects the genesis and contents of the model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3182505",
            "Date of Publication": "13 June 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Csaba Veres",
                "labs": [
                    "Department of Information Science and Media Studies, University of Bergen, Bergen, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Grammar",
                "Linguistics",
                "Deep learning",
                "Computational modeling",
                "Syntactics",
                "Production",
                "Task analysis"
            ],
            "Author Keywords": [
                "Natural language processing",
                "deep learning",
                "syntax",
                "linguistics",
                "language model",
                "automatic programming",
                "neural networks"
            ]
        }
    },
    {
        "Title": "Transformer-Based Named Entity Recognition on Drone Flight Logs to Support Forensic Investigation",
        "Link": "https://ieeexplore.ieee.org/document/10007817/",
        "Abstract": "The increase in drone usage by the public brings the number of drone incident and attack up. Sophisticated preventive mechanisms, as well as post-incident procedures and frameworks, are needed. Forensic investigation is performed upon a drone incident, aiming to uncover the incident scenario, mitigate the risk and report the examination results. Generally, standard drone forensic procedure consists of three stages, i.e., evidence acquisition, evidence analysis, and reporting. Among the existing research, many attempts have been made in framework proposal and evaluation, study case, and tools proposal and evaluation. However, less research focuses on utilizing specific data artifacts from the drone forensic image, such as telemetry, dataflash, and flight log data. Therefore, this research aims to propose the use of log message data to discover and extract some incident-related information using a deep learning-based NLP technique, i.e., named entity recognition using the Transformer. Cosine similarity is proposed as a substitute for dot-product in the self-attention mechanism of the Transformer encoder layer. Additionally, we propose NER architecture built from a mix of several existing methods and report the performance evaluation. We extract the DJI drone forensic image from a publicly available dataset using Autopsy and DJI Phantom Help and collect the decrypted log messages. Six entity types are defined after carefully reading the log message. These entity types are used in the manual annotation process using the IOB2 scheme as the label. The constructed dataset is used to evaluate the proposed model along with several baseline models. The proposed method outperforms the previous baseline model with a 91.348% F1 score. Finally, we conclude the experiment and mention several future directions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3234605",
            "Date of Publication": "05 January 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Swardiantara Silalahi",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Tohari Ahmad",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            },
            {
                "name": "Hudan Studiawan",
                "labs": [
                    "Department of Informatics, Institut Teknologi Sepuluh Nopember, Surabaya, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Drones",
                "Digital forensics",
                "Transformers",
                "Performance evaluation",
                "Telemetry",
                "Object recognition",
                "Natural language processing",
                "Encoding",
                "Random processes"
            ],
            "Author Keywords": [
                "Digital forensics",
                "drone flight log",
                "drone forensics",
                "log mining",
                "named entity recognition",
                "transformer encoder",
                "conditional random fields",
                "infrastructure"
            ]
        }
    },
    {
        "Title": "Avoiding the Hook: Influential Factors of Phishing Awareness Training on Click-Rates and a Data-Driven Approach to Predict Email Difficulty Perception",
        "Link": "https://ieeexplore.ieee.org/document/9893815/",
        "Abstract": "Phishing attacks are still seen as a significant threat to cyber security, and large parts of the industry rely on anti-phishing simulations to minimize the risk imposed by such attacks. This study conducted a large-scale anti-phishing training with more than 31000 participants and 144 different simulated phishing attacks to develop a data-driven model to classify how users would perceive a phishing simulation. Furthermore, we analyze the results of our large-scale anti-phishing training and give novel insights into users’ click behavior. Analyzing our anti-phishing training data, we find out that 66% of users do not fall victim to credential-based phishing attacks even after being exposed to twelve weeks of phishing simulations. To further enhance the phishing awareness-training effectiveness, we developed a novel manifold learning-powered machine learning model that can predict how many people would fall for a phishing simulation using the several structural and state-of-the-art NLP features extracted from the emails. In this way, we present a systematic approach for the training implementers to estimate the average “convincing power” of the emails prior to rolling out. Moreover, we revealed the top-most vital factors in the classification. In addition, our model presents significant benefits over traditional rule-based approaches in classifying the difficulty of phishing simulations. Our results clearly show that anti-phishing training should focus on the training of individual users rather than on large user groups. Additionally, we present a promising generic machine learning model for predicting phishing susceptibility.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3207272",
            "Date of Publication": "16 September 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thomas Sutter",
                "labs": [
                    "Institute of Applied Information Technology, Zurich University of Applied Sciences, Winterthur, Switzerland"
                ]
            },
            {
                "name": "Ahmet Selman Bozkir",
                "labs": [
                    "Institute of Applied Information Technology, Zurich University of Applied Sciences, Winterthur, Switzerland"
                ]
            },
            {
                "name": "Benjamin Gehring",
                "labs": [
                    "Institute of Applied Information Technology, Zurich University of Applied Sciences, Winterthur, Switzerland"
                ]
            },
            {
                "name": "Peter Berlich",
                "labs": [
                    "Institute of Applied Information Technology, Zurich University of Applied Sciences, Winterthur, Switzerland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Phishing",
                "Training data",
                "Human factors",
                "Estimation",
                "Predictive models",
                "Machine learning",
                "Security",
                "Human computer interaction"
            ],
            "Author Keywords": [
                "Difficulty estimation",
                "human-centered",
                "machine learning",
                "phishing awareness",
                "susceptibility",
                "phishing attack simulations"
            ]
        }
    },
    {
        "Title": "Aspect Based Multi-Labeling Using SVM Based Ensembler",
        "Link": "https://ieeexplore.ieee.org/document/9343254/",
        "Abstract": "Sentiment analysis is one of the most prominent sub-areas of research in Natural Language Processing (NLP), where it is important to consider implicit or explicit emotions conveyed by review material. Researchers also recognized that the generic feelings derived from the textual material are insufficient, so the sentiment analysis aspect based was coined to extract the emotions from textual data. Multi-labeling based on aspects data can resolve the issue of extracting emotion aspect based. In this work, a novel approach namely: Evolutionary Ensembler (EEn) is proposed to effectively boost the accuracy and diversity of multi-label learners. Unlike traditional multi-label training methods, EEn emphasizes the accuracy and diversity of multi-label-based models. We have used seven datasets (medical, hotel, movies, automobiles, proteins, birds, emotions, news). At first, we applied a pre-processing step to gain the refined and clean data. Second, we have applied the Vader tool with Bag of Words (BoW) for the feature extraction. Third, the word2vec method is applied to draw an association between words. Moreover, the SVM model (tuned with GA) is trained and tested on the refined data. The accuracy of the aspect-based multi-labeling using the SVM-GA on medical, hotel, movies, automobiles, proteins, birds, emotions, news are 93.13%, 94.32%, 94.0%, 95.10%, 90.20%, 93.22%, 90.0%, and 94.0%, respectively. Our proposed model with different dimensions of multi-label datasets shows that EEn is vastly superior to other popular techniques. Experimental outcomes validate the success of the implemented approach among existing benchmark techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3055768",
            "Date of Publication": "01 February 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Khursheed Aurangzeb",
                "labs": [
                    "College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nasir Ayub",
                "labs": [
                    "Department of Computer Science, Federal Urdu University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Musaed Alhussein",
                "labs": [
                    "Computer Engineering Department, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Sentiment analysis",
                "Learning systems",
                "Labeling",
                "Videos",
                "Training",
                "Motion pictures"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "multi-labeling",
                "aspect based",
                "ML",
                "optimization techniques",
                "SVM"
            ]
        }
    },
    {
        "Title": "Fake News Detection Using Deep Learning: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/10614154/",
        "Abstract": "Nowadays, we witness rapid technological advancements in online communication platforms, with increasing volumes of people using a vast range of communication solutions. The fast flow of information and the enormous number of users opens the door to the publication of non-truthful news, which has the potential to reach many people. Disseminating this news through low- or no-cost channels resulted in a flood of fake news that is difficult to detect by humans. Social media networks are one of these channels that are used to quickly spread this fake news by manipulating it in ways that influence readers in many aspects. That influence appears in a recent example amid the COVID-19 pandemic and various political events such as the recent US presidential elections. Given how this phenomenon impacts society, it is crucial to understand it well and study mechanisms that allow its timely detection. Deep learning (DL) has proven its potential for multiple complex tasks in the last few years with outstanding results. In particular, multiple specialized solutions have been put forward for natural language processing (NLP) tasks. In this paper, we systematically review existing fake news detection (FND) strategies that use DL techniques. We systematically surveyed the existing research articles by investigating the DL algorithms used in the detection process. Our focus then shifts to the datasets utilized in previous research and the effectiveness of the different DL solutions. Special attention was given to the application of strategies for transfer learning and dealing with the class imbalance problem. The effect of these solutions on the detection accuracy is also discussed. Finally, our survey provides an overview of key challenges that remain unsolved in the context of FND.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3435497",
            "Date of Publication": "29 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Q. Alnabhan",
                "labs": [
                    "Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Paula Branco",
                "labs": [
                    "Electrical Engineering and Computer Science, University of Ottawa, Ottawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Deep learning",
                "Transfer learning",
                "Task analysis",
                "COVID-19",
                "Accuracy",
                "Classification algorithms",
                "Systematic literature review",
                "Fake news",
                "Social networking (online)",
                "Deep learning",
                "Transfer learning",
                "Task analysis",
                "COVID-19",
                "Accuracy",
                "Classification algorithms",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Classification",
                "deep learning",
                "fake news",
                "misinformation",
                "systematic literature review"
            ]
        }
    },
    {
        "Title": "Utilizing an Autoencoder-Generated Item Representation in Hybrid Recommendation System",
        "Link": "https://ieeexplore.ieee.org/document/9075162/",
        "Abstract": "While collaborative filtering (CF) is the most popular approach for recommendation systems, it only makes use of the ratings given to items by users and neglects side information about user attributes or item features. In this work, a natural language processing (NLP) technique is applied to generate a more consistent version of Tag Genome, a side information which is associated with each movie in the MovieLens 20M dataset. Subsequently, we propose a 3-layer autoencoder to create a more compact representation of these tags which improves the performance of the system both in accuracy and in computational complexity. Finally, the proposed representation and the well-known matrix factorization techniques are combined into a unified framework that outperforms the state-of-the-art models by at least 2.87% and 3.36% in terms of RMSE and MAE, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2989408",
            "Date of Publication": "21 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tan Nghia Duong",
                "labs": [
                    "School of Electronics and Telecommunications, Hanoi University of Science and Technology, Hanoi, Vietnam"
                ]
            },
            {
                "name": "Tuan Anh Vuong",
                "labs": [
                    "School of Electronics and Telecommunications, Hanoi University of Science and Technology, Hanoi, Vietnam"
                ]
            },
            {
                "name": "Duc Minh Nguyen",
                "labs": [
                    "School of Electronics and Telecommunications, Hanoi University of Science and Technology, Hanoi, Vietnam"
                ]
            },
            {
                "name": "Quang Hieu Dang",
                "labs": [
                    "School of Electronics and Telecommunications, Hanoi University of Science and Technology, Hanoi, Vietnam"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Motion pictures",
                "Predictive models",
                "Task analysis",
                "Collaboration",
                "Correlation",
                "Genomics",
                "Bioinformatics"
            ],
            "Author Keywords": [
                "Collaborative filtering",
                "matrix factorization",
                "neighborhood-based",
                "recommendation system",
                "similarity measure"
            ]
        }
    },
    {
        "Title": "A Study on 3D Human Pose Estimation Using Through-Wall IR-UWB Radar and Transformer",
        "Link": "https://ieeexplore.ieee.org/document/10041888/",
        "Abstract": "In this paper, we propose a human pose estimation algorithm for an impulse radio ultra-wideband (IR-UWB) radar based on the transformer-based deep learning model. We have built an IR-UWB radar system with an 8-by-8 multiple-input multiple-output (MIMO) antenna array. The IR-UWB radar system in our paper is advantageous for the through-wall detection application since it operates on a very low frequency range (i.e., 0.45 to 3.55 GHz) compared to other existing works on RF-based human pose estimation. Moreover, the human pose estimation by an IR-UWB radar has not been studied very well in other existing works since all existing works have used a frequency-modulated continuous wave (FMCW) radar or a WiFi device. We propose a 3D-TransPOSE algorithm for the 3D human pose estimation from the IR-UWB radar signals. The proposed algorithm is designed based on the transformer architecture. While the transformer has actively been studied in the natural language processing (NLP) or vision domains, no prior work has applied the transformer model to the RF-based human pose estimation problem. The attention mechanism of the proposed algorithm is able to focus on the relevant time segments of the IR-UWB radar signals for detecting the human pose, eliminating the needs of converting radar signals to a voxelized 3D image. We have gathered a large dataset of IR-UWB radar signals labeled with 3D human skeletons, and shown that the proposed algorithm is able to detect human skeletons with a high accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3244017",
            "Date of Publication": "10 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gon Woo Kim",
                "labs": [
                    "Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, South Korea"
                ]
            },
            {
                "name": "Sang Won Lee",
                "labs": [
                    "Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, South Korea"
                ]
            },
            {
                "name": "Ha Young Son",
                "labs": [
                    "Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, South Korea"
                ]
            },
            {
                "name": "Kae Won Choi",
                "labs": [
                    "Department of Electrical and Computer Engineering, Sungkyunkwan University (SKKU), Suwon, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ultrawideband technology",
                "Radar antennas",
                "Transformers",
                "Radar imaging",
                "Antenna arrays",
                "Pose estimation",
                "Three-dimensional displays"
            ],
            "Author Keywords": [
                "IR-UWB radar",
                "MIMO",
                "attention",
                "transformer",
                "keypoint detection",
                "pose estimation"
            ]
        }
    },
    {
        "Title": "Towards Knowledge Enhanced Language Model for Machine Reading Comprehension",
        "Link": "https://ieeexplore.ieee.org/document/9292918/",
        "Abstract": "Machine reading comprehension is a crucial and challenging task in natural language processing (NLP). Recently, knowledge graph (KG) embedding has gained massive attention as it can effectively provide side information for downstream tasks. However, most previous knowledge-based models do not take into account the structural characteristics of the triples in KGs, and only convert them into vector representations for direct accumulation, leading to deficiencies in knowledge extraction and knowledge fusion. In order to alleviate this problem, we propose a novel deep model KCF-NET, which incorporates knowledge graph representations with context as the basis for predicting answers by leveraging capsule network to encode the intrinsic spatial relationship in triples of KG. In KCF-NET, we fine-tune BERT, a highly performance contextual language representation model, to capture complex linguistic phenomena. Besides, a novel fusion structure based on multi-head attention mechanism is designed to balance the weight of knowledge and context. To evaluate the knowledge expression and reading comprehension ability of our model, we conducted extensive experiments on multiple public datasets such as WN11, FB13, SemEval-2010 Task 8 and SQuAD. Experimental results show that KCF-NET achieves state-of-the-art results in both link prediction and MRC tasks with negligible parameter increase compared to BERT-Base, and gets competitive results in triple classification task with significantly reduced model size.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3044308",
            "Date of Publication": "14 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Peizhu Gong",
                "labs": [
                    "College of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Jin Liu",
                "labs": [
                    "College of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Yihe Yang",
                "labs": [
                    "College of Information Engineering, Shanghai Maritime University, Shanghai, China"
                ]
            },
            {
                "name": "Huihua He",
                "labs": [
                    "College of Education, Shanghai Normal University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Semantics",
                "Knowledge engineering",
                "Knowledge based systems",
                "Bit error rate",
                "Encoding",
                "Syntactics"
            ],
            "Author Keywords": [
                "Machine reading comprehension",
                "knowledge graph embedding",
                "BERT",
                "capsule network"
            ]
        }
    },
    {
        "Title": "Tracking Flooding Phase Transitions and Establishing a Passive Hotline With AI-Enabled Social Media Data",
        "Link": "https://ieeexplore.ieee.org/document/9091866/",
        "Abstract": "Flooding management requires collecting real-time onsite information widely and rapidly. As an emerging data source, social media demonstrates an advantage of providing in-time, rich data in the format of texts and photos and can be used to improve flooding situation awareness. The present study shows that social media data, with additional information processed by Artificial Intelligence (AI) techniques, can be effectively used to track flooding phase transition and locate emergency incidents. To track phase transition, we train a computer vision model that can classify images embedded in social media data into four categories - preparedness, impact, response, and recovery - that can reflect the phases of disaster event development. To locate emergency incidents, we use a deep learning based natural language processing (NLP) model to recognize locations from textual content of tweets. The geographic coordinates of the recognized locations are assigned by searching through a dedicated local gazetteer rapidly compiled for the disaster affected region based on the GeoNames gazetteer and the US Census data. By combining image and text analysis, we filter the tweets that contain images of the “Impact” category and high-resolution locations to gain the most valuable situation information. We carry out a manual examination step to complement the automatic data processing and find that it can further strengthen the AI-processed results to support comprehensive situation awareness and to establish a passive hotline to inform rescue and search activities. The developed framework is applied to the flood of Hurricane Harvey in the Houston area.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2994187",
            "Date of Publication": "13 May 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ruo-Qian Wang",
                "labs": [
                    "Department of Civil and Environmental Engineering, Rutgers, The State University of New Jersey, New Brunswick, USA"
                ]
            },
            {
                "name": "Yingjie Hu",
                "labs": [
                    "Department of Geography, University at Buffalo, Buffalo, USA"
                ]
            },
            {
                "name": "Zikai Zhou",
                "labs": [
                    "Department of Civil and Environmental Engineering, Rutgers, The State University of New Jersey, New Brunswick, USA"
                ]
            },
            {
                "name": "Kevin Yang",
                "labs": [
                    "Union County Magnet High School, Scotch Plains, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social network services",
                "Machine learning",
                "Data mining",
                "Real-time systems",
                "Natural language processing",
                "Disaster management"
            ],
            "Author Keywords": [
                "Computer vision",
                "natural language processing",
                "convolutional neural networks",
                "pluvial flooding",
                "disaster management",
                "rescue and search",
                "resilience"
            ]
        }
    },
    {
        "Title": "A Graph Convolutional Network With Multiple Dependency Representations for Relation Extraction",
        "Link": "https://ieeexplore.ieee.org/document/9446853/",
        "Abstract": "Dependency analysis can assist neural networks to capture semantic features within a sentence for entity relation extraction (RE). Both hard and soft strategies of encoding dependency tree structure have been developed to balance the beneficial extra information against the unfavorable interference in the task of RE. A wide application of graph convolutional network (GCN) in the field of natural language processing (NLP) has demonstrated its effectiveness in encoding the input sentence with the dependency tree structure, as well as its efficiency in parallel computation. This study proposes a novel GCN-based model using multiple representations to depict the dependency tree from various perspectives, and combines those dependency representations afterward to obtain a better sentence representation for relation classification. This model can maximally draw from the sentence the semantic features relevant to the relationship between entities. Results show that our model achieves state-of-the-art performance in terms of the F1 score (68.0) on the Text Analysis Conference relation extraction dataset (TACRED). In addition, we verify that the renormalization parameter in the GCN operation should be carefully chosen to help GCN-based models achieve its best performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3086480",
            "Date of Publication": "04 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanfeng Hu",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Hong Shen",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Wuling Liu",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Fei Min",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Xue Qiao",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Kangrong Jin",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Computational modeling",
                "Semantics",
                "Analytical models",
                "Syntactics",
                "Natural language processing",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Graph convolutional network",
                "relation extraction",
                "syntactic dependency tree"
            ]
        }
    },
    {
        "Title": "An RFML Ecosystem: Considerations for the Application of Deep Learning to Spectrum Situational Awareness",
        "Link": "https://ieeexplore.ieee.org/document/9540909/",
        "Abstract": "While deep learning (DL) technologies are now pervasive in state-of-the-art Computer Vision (CV) and Natural Language Processing (NLP) applications, only in recent years have these technologies started to sufficiently mature in applications related to wireless communications, a field loosely termed Radio Frequency Machine Learning (RFML). In particular, recent research has shown DL to be an enabling technology for Cognitive Radio (CR) applications as well as a useful tool for supplementing expertly defined algorithms for spectrum awareness applications such as signal detection, estimation, and classification. A major driver for the usage of RFML is that little, to no, a priori knowledge of the intended spectral environment is required, given that there is an abundance of representative raw Radio Frequency (RF) data to facilitate training and evaluation. However, in addition to this fundamental need for sufficient data, there are other key considerations, such as trust, security, and hardware requirements, that must be taken into account before deploying RFML systems in real-world wireless communication applications that largely go unaddressed in the current literature. This paper examines the prior works related to these major research considerations, with focus on the dependencies between them and factors unique to the RFML space.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2021.3112939",
            "Date of Publication": "20 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Lauren J. Wong",
                "labs": [
                    "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "William H. Clark",
                "labs": [
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "Bryse Flowers",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California at San Diego, San Diego, CA, USA"
                ]
            },
            {
                "name": "R. Michael Buehrer",
                "labs": [
                    "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "William C. Headley",
                "labs": [
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA"
                ]
            },
            {
                "name": "Alan J. Michaels",
                "labs": [
                    "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Maximum likelihood estimation",
                "Radio frequency",
                "Cognitive radio",
                "Security",
                "Wireless sensor networks",
                "Routing",
                "Modulation"
            ],
            "Author Keywords": [
                "Survey",
                "deep learning",
                "neural networks",
                "radio frequency machine learning",
                "spectrum awareness",
                "dynamic spectrum access",
                "cognitive radio",
                "automatic modulation classification",
                "specific emitter identification",
                "signal detection"
            ]
        }
    },
    {
        "Title": "Utilizing Ensemble Learning for Detecting Multi-Modal Fake News",
        "Link": "https://ieeexplore.ieee.org/document/10412049/",
        "Abstract": "The spread of fake news has become a critical problem in recent years due extensive use of social media platforms. False stories can go viral quickly, reaching millions of people before they can be mocked, i.e., a false story claiming that a celebrity has died when he/she is still alive. Therefore, detecting fake news is essential for maintaining the integrity of information and controlling misinformation, social and political polarization, media ethics, and security threats. From this perspective, we propose an ensemble learning-based detection of multi-modal fake news. First, it exploits a publicly available dataset Fakeddit consisting of over 1 million samples of fake news. Next, it leverages Natural Language Processing (NLP) techniques for preprocessing textual information of news. Then, it gauges the sentiment from the text of each news. After that, it generates embeddings for text and images of the corresponding news by leveraging Visual Bidirectional Encoder Representations from Transformers (V-BERT), respectively. Finally, it passes the embeddings to the deep learning ensemble model for training and testing. The 10-fold evaluation technique is used to check the performance of the proposed approach. The evaluation results are significant and outperform the state-of-the-art approaches with the performance improvement of 12.57%, 9.70%, 18.15%, 12.58%, 0.10, and 3.07 in accuracy, precision, recall, F1-score, Matthews Correlation Coefficient (MCC), and Odds Ratio (OR), respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3357661",
            "Date of Publication": "23 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Luqman",
                "labs": [
                    "Department of Computer Science, Northwestern Polytechnical University, Xi’an, China"
                ]
            },
            {
                "name": "Muhammad Faheem",
                "labs": [
                    "School of Technology and Innovations, University of Vaasa, Vaasa, Finland"
                ]
            },
            {
                "name": "Waheed Yousuf Ramay",
                "labs": [
                    "Department of Computer Science, Air University, Multan, Pakistan"
                ]
            },
            {
                "name": "Malik Khizar Saeed",
                "labs": [
                    "Department of Computer Sciences, COMSATS University Islamabad, Vehari, Pakistan"
                ]
            },
            {
                "name": "Majid Bashir Ahmad",
                "labs": [
                    "School of Software and Microelectronics, Northwestern Polytechnical University, Xi’an, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Feature extraction",
                "Visualization",
                "Convolutional neural networks",
                "Social networking (online)",
                "Ensemble learning",
                "Electronic mail"
            ],
            "Author Keywords": [
                "Ensemble learning",
                "convolutional neural network",
                "multi-modal fake news",
                "classification",
                "boosted CNN",
                "bagged CNN"
            ]
        }
    },
    {
        "Title": "Vision Transformers for Vein Biometric Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10058202/",
        "Abstract": "In October 2020, Google researchers present a promising Deep Learning architecture paradigm for Computer Vision that outperforms the already standard Convolutional Neural Networks (CNNs) on multiple image recognition state-of-the-art datasets: Vision Transformers (ViTs). Based on the self-attention concept inherited from Natural Language Processing (NLP), this new structure surpasses the CNN image classification task on ImageNet, CIFAR-100, and VTAB, among others, when it is fine-tuned (Transfer Leaning) after a previous pre-training on larger datasets. In this work, we confirm this theory and move one step further over the CNN structures applied for Vascular Biometric Recognition (VBR): to the best of our knowledge, we introduce for the first time multiple pure pre-trained and fine-tuned Vision Transformers in this evolving biometric modality to address the challenge of the limited number of samples in VBR datasets. For this purpose, the ViTs have been trained to extract unique image features on the ImageNet-1k and ImageNet-21k and then fine-tuned for the four main existing VBR variants, i.e., finger, palm, hand dorsal, and wrist vein areas. Fourteen existing vascular datasets have been used to perform the vein identification task in the four previously mentioned modalities, based on the True-Positive Identification Rate (TPIR) and 75-25% train-test sets obtaining the following results: HKPU (99.52%), and FV-USM (99.1%); Vera (99.39%), and CASIA (96.00%); Bosphorus (99.86%); PUT-wrist (99.67%), and UC3M-CV1+CV2 (99.67%). Furthermore, we introduce UC3M-CV3: a hygienic contactless wrist database collected on smartphones and consisting of 4800 images from 100 different subjects. The promising results show the Vision Transformer’s versatility in VBR under Transfer Learning and reinforce this new Neural Network architecture paradigm.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3252009",
            "Date of Publication": "03 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Raul Garcia-Martin",
                "labs": [
                    "Electronic Technology Department, University Carlos III of Madrid, Leganés, Spain"
                ]
            },
            {
                "name": "Raul Sanchez-Reillo",
                "labs": [
                    "Electronic Technology Department, University Carlos III of Madrid, Leganés, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Machine learning",
                "Transformers",
                "Biometrics (access control)",
                "Databases",
                "Image recognition",
                "Convolutional neural networks",
                "Transfer learning"
            ],
            "Author Keywords": [
                "Vision transformers",
                "vein biometric recognition",
                "deep learning",
                "convolutional neural networks",
                "finger veins",
                "transfer learning",
                "machine learning",
                "artificial intelligence",
                "biometrics on mobile devices",
                "contactless wrist vascular database",
                "hand palm identification"
            ]
        }
    },
    {
        "Title": "Arabic Text Steganography Based on Deep Learning Methods",
        "Link": "https://ieeexplore.ieee.org/document/9864312/",
        "Abstract": "Steganography is one of the oldest methods for securely sending and transferring secret information between two people without raising suspicion. Recently, the use of Artificial Intelligence (AI) has become simpler and more widely used. Since the emergence of natural language processing (NLP), building language models using deep learning has become more. Furthermore, because of the importance of concealing secret information in delivered messages, Artificial Intelligence theories along with Natural Language Processing algorithms were employed to conceal secret information within the text cover. The Arabic language was used because of its large number of words, vocabulary, and linguistic meanings, and its most significant feature is Arabic poetry. This study discovered a new way to hide secret data inside newly formulated Arabic poetry based on previous Arabic poetic texts and a database of a number of Arab poets from the ancient and modern eras using Artificial Intelligence and Long Short-Term Memory (LSTM) theories to increase storage capacity by 45 percent. The linguistic accuracy and volume of secret data hidden within the formulated poetry were increased using a Baudot Code algorithm, where the secret data is hidden at the level of letters rather than words, and the linguistic accuracy and volume of secret data hidden within the formulated poetry were increased to eliminate the drawbacks found in previous studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3201019",
            "Date of Publication": "23 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Omer Farooq Ahmed Adeeb",
                "labs": [
                    "Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran"
                ]
            },
            {
                "name": "Seyed Jahanshah Kabudian",
                "labs": [
                    "Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Steganography",
                "Artificial intelligence",
                "Symbols",
                "Natural language processing",
                "Linguistics",
                "Codes",
                "Deep learning",
                "Text processing",
                "Information sharing"
            ],
            "Author Keywords": [
                "Text steganography",
                "hiding information",
                "letter frequency",
                "LSTM",
                "Baudot code"
            ]
        }
    },
    {
        "Title": "A Natural Language Processing Model on BERT and YAKE Technique for Keyword Extraction on Sustainability Reports",
        "Link": "https://ieeexplore.ieee.org/document/10388311/",
        "Abstract": "Sustainability has become the greatest aspiration on the planet, as every organization has begun reorienting itself to become one. To accomplish this, organizations must strike a balance between their Environmental, Social, and Governance (ESG) policies. It is essential to examine the organizations that currently exist. For this reason, the study conducts a thematic analysis of the sustainability reports of Forbes’ India’s top companies in 2021 in order to determine their current ESG focus using BERT tokenization and YAKE technique along with MLM and NSP methods of natural language processing (NLP). The experiment results in prediction with 98% accuracy. The study addresses the question, “What must organizations do to embark on the path towards sustainability?”",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3352742",
            "Date of Publication": "11 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Akriti Gupta",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, Uttar Pradesh, India"
                ]
            },
            {
                "name": "Aman Chadha",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, Uttar Pradesh, India"
                ]
            },
            {
                "name": "Vijaishri Tewari",
                "labs": [
                    "Indian Institute of Information Technology Allahabad, Allahabad, Uttar Pradesh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sustainable development",
                "Organizations",
                "Bidirectional control",
                "Encoding",
                "Stakeholders",
                "Investment",
                "Green products"
            ],
            "Author Keywords": [
                "BERT",
                "YAKE",
                "ESG",
                "sustainability",
                "organizations"
            ]
        }
    },
    {
        "Title": "Efficient Methods for Mapping Neural Machine Translator on FPGAs",
        "Link": "https://ieeexplore.ieee.org/document/9309170/",
        "Abstract": "Neural machine translation (NMT) is one of the most critical applications in natural language processing (NLP) with the main idea of converting text in one language to another using deep neural networks. In recent year, we have seen continuous development of NMT by integrating more emerging technologies, such as bidirectional gated recurrent units (GRU), attention mechanisms, and beam-search algorithms, for improved translation quality. However, with the increasing problem size, the real-life NMT models have become much more complicated and difficult to implement on hardware for acceleration opportunities. In this article, we aim to exploit the capability of FPGAs to deliver highly efficient implementations for real-life NMT applications. We map the inference of a large-scale NMT model with total computation of 172 GFLOP to a highly optimized high-level synthesis (HLS) IP and integrate the IP into Xilinx VCU118 FPGA platform. The model has widely used key features for NMTs, including the bidirectional GRU layer, attention mechanism, and beam search. We quantize the model to mixed-precision representation in which parameters and portions of calculations are in 16-bit half precision, and others remain as 32-bit floating-point. Compared to the float NMT implementation on FPGA, we achieve 13.1× speedup with an end-to-end performance of 22.0 GFLOPS without any accuracy degradation. Based on our knowledge, this is the first work that successfully implements a real-life end-to-end NMT model to an FPGA on board.",
        "Details": {
            "DOI": "10.1109/TPDS.2020.3047371",
            "Date of Publication": "25 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Parallel and Distributed Systems"
        },
        "issn_info": {
            "Print ISSN": "1045-9219",
            "Electronic ISSN": "1558-2183"
        },
        "authors_data": [
            {
                "name": "Qin Li",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Champaign, IL, USA"
                ]
            },
            {
                "name": "Xiaofan Zhang",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Champaign, IL, USA"
                ]
            },
            {
                "name": "Jinjun Xiong",
                "labs": [
                    "IBM T.J. Watson Research Center, NY, USA"
                ]
            },
            {
                "name": "Wen-Mei Hwu",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Champaign, IL, USA"
                ]
            },
            {
                "name": "Deming Chen",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Champaign, IL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Field programmable gate arrays",
                "Decoding",
                "Task analysis",
                "Hardware",
                "IP networks",
                "Dictionaries"
            ],
            "Author Keywords": [
                "Hardware-efficient inference",
                "neural machine translation",
                "FPGA",
                "high level synthesis"
            ]
        }
    },
    {
        "Title": "Power of Attention in MOOC Dropout Prediction",
        "Link": "https://ieeexplore.ieee.org/document/9248578/",
        "Abstract": "The dropout rate of massive open online courses (MOOC) has been significantly high, which makes its prediction an important problem. In this article, we try to transfer the knowledge gained in the field of Natural Language Processing into the field of MOOC dropout prediction, due to the high similarity between them. More specifically, we attempt to study and show the powerful use of attention and conditional random field, both of which have been very popular architectures when solving NLP problems. A novel neural network structure is designed as the combination of these techniques. Extensive experimental results demonstrate that the proposed approach is effective.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3035687",
            "Date of Publication": "04 November 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shengjun Yin",
                "labs": [
                    "Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Leqi Lei",
                "labs": [
                    "Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Hongzhi Wang",
                "labs": [
                    "Harbin Institute of Technology, Harbin, China"
                ]
            },
            {
                "name": "Wentao Chen",
                "labs": [
                    "Harbin Institute of Technology, Harbin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer aided instruction",
                "Electronic learning",
                "Semantics",
                "Predictive models",
                "Natural language processing",
                "Real-time systems",
                "Task analysis"
            ],
            "Author Keywords": [
                "Deep learning",
                "MOOC",
                "conditional random field"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis in Finance: From Transformers Back to eXplainable Lexicons (XLex)",
        "Link": "https://ieeexplore.ieee.org/document/10380556/",
        "Abstract": "Lexicon-based sentiment analysis in finance leverages specialized, manually annotated lexicons created by human experts to extract sentiment from financial texts effectively. Although lexicon-based methods are simple to implement and fast to operate on textual data, they require considerable manual annotation efforts to create, maintain, and update the lexicons. These methods are also considered inferior to the deep learning-based approaches, such as transformer models, which have become dominant in various natural language processing (NLP) tasks due to their remarkable performance. However, their efficacy comes at a cost: these models require extensive data and computational resources for both training and testing. Additionally, they involve significant prediction times, making them unsuitable for real-time production environments or systems with limited processing capabilities. In this paper, we introduce a novel methodology named eXplainable Lexicons (XLex) that combines the advantages of both lexicon-based methods and transformer models. We propose an approach that utilizes transformers and SHapley Additive exPlanations (SHAP) for explainability to automatically learn financial lexicons. Our study presents four main contributions. Firstly, we demonstrate that transformer-aided explainable lexicons can enhance the vocabulary coverage of the benchmark Loughran-McDonald (LM) lexicon. This enhancement leads to a significant reduction in the need for human involvement in the process of annotating, maintaining, and updating the lexicons. Secondly, we show that the resulting lexicon outperforms the standard LM lexicon in sentiment analysis of financial datasets. Our experiments show that XLex outperforms LM when applied to general financial texts, resulting in enhanced word coverage and an overall increase in classification accuracy by 0.431. Furthermore, by employing XLex to extend LM, we create a combined dictionary, XLex+LM, which achieves an even higher accuracy improvement of 0.450. Thirdly, we illustrate that the lexicon-based approach is significantly more efficient in terms of model speed and size compared to transformers. Lastly, the proposed XLex approach is inherently more interpretable than transformer models. This interpretability is advantageous as lexicon models rely on predefined rules, unlike transformers, which have complex inner workings. The interpretability of the models allows for better understanding and insights into the results of sentiment analysis, making the XLex approach a valuable tool for financial decision-making.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3349970",
            "Date of Publication": "04 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maryan Rizinski",
                "labs": [
                    "Department of Computer Science, Metropolitan College, Boston University, Boston, MA, USA",
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Hristijan Peshov",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Kostadin Mishev",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Milos Jovanovik",
                "labs": [
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Dimitar Trajanov",
                "labs": [
                    "Department of Computer Science, Metropolitan College, Boston University, Boston, MA, USA",
                    "Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, North Macedonia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Transformers",
                "Finance",
                "Dictionaries",
                "Computational modeling",
                "Analytical models",
                "Task analysis",
                "Machine learning",
                "Natural language processing",
                "Text categorization"
            ],
            "Author Keywords": [
                "Machine learning",
                "natural language processing",
                "text classification",
                "sentiment analysis",
                "finance",
                "lexicons",
                "lexicon learning",
                "transformers",
                "SHAP",
                "explainability"
            ]
        }
    },
    {
        "Title": "SimCSE for Encrypted Traffic Detection and Zero-Day Attack Detection",
        "Link": "https://ieeexplore.ieee.org/document/9780135/",
        "Abstract": "Traffic detection has attracted much attention in recent years, playing an essential role in intrusion detection systems (IDS). This paper proposes a new approach for traffic detection at the packet level, inspired by natural language processing (NLP), using simple contrastive learning of sentence embeddings (SimCSE) as an embedding model. The new approach can learn the features of traffic from raw packet data. Experiments were conducted on two well-known datasets to evaluate our approach. For detecting malicious activity, our model achieved an accuracy of 99.99% on the USTC-TFC2016 dataset, whereas for detecting virtual private network (VPN) activity, our model achieved an accuracy of 99.98% on the ISCXVPN2016 dataset. Furthermore, the resulting model was found to be robust based on zero-day attack detection, which shows the model’s ability to detect attacks that have not been seen before. Experiments show that our approach can effectively detect network traffic and outperforms many other state-of-the-art methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3177272",
            "Date of Publication": "23 May 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rotem Bar",
                "labs": [
                    "School of Software Engineering: Intelligent Systems, Afeka College of Engineering, Tel Aviv, Israel"
                ]
            },
            {
                "name": "Chen Hajaj",
                "labs": [
                    "Industrial Engineering and Management Department, Data Science and Artificial Intelligence Research Center, Ariel University, Ariel, Israel"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Convolutional neural networks",
                "Virtual private networks",
                "Telecommunication traffic",
                "Neural networks",
                "Integrated circuits",
                "Deep learning"
            ],
            "Author Keywords": [
                "Network traffic",
                "SimCSE",
                "packet capture",
                "Word2vec",
                "cyber security"
            ]
        }
    },
    {
        "Title": "Transformer-Based Named Entity Recognition in Construction Supply Chain Risk Management in Australia",
        "Link": "https://ieeexplore.ieee.org/document/10472528/",
        "Abstract": "In the Australian construction industry, effective supply chain risk management (SCRM) is critical due to its complex networks and susceptibility to various risks. This study explores the application of transformer models like BERT, RoBERTa, DistilBERT, ALBERT, and ELECTRA for Named Entity Recognition (NER) in this context. Utilizing these models, we analyzed news articles to identify and classify entities related to supply chain risks, providing insights into the vulnerabilities within this sector. Among the evaluated models, RoBERTa achieved the highest average F1 score of 0.8580, demonstrating its superior balance in precision and recall for NER in the Australian construction supply chain context. Our findings highlight the potential of NLP-driven solutions to revolutionize SCRM, particularly in geo-specific settings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3377232",
            "Date of Publication": "18 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Milad Baghalzadeh Shishehgarkhaneh",
                "labs": [
                    "Department of Civil Engineering, Faculty of Engineering, Monash University, Clayton, VIC, Australia"
                ]
            },
            {
                "name": "Robert C. Moehler",
                "labs": [
                    "Department of Civil Engineering, Faculty of Engineering, Monash University, Clayton, VIC, Australia",
                    "Department of Infrastructure Engineering, The University of Melbourne, Melbourne, VIC, Australia"
                ]
            },
            {
                "name": "Yihai Fang",
                "labs": [
                    "Department of Civil Engineering, Faculty of Engineering, Monash University, Clayton, VIC, Australia"
                ]
            },
            {
                "name": "Amer A. Hijazi",
                "labs": [
                    "Department of Civil Engineering, Al-Ahliyya Amman University, Amman, Jordan"
                ]
            },
            {
                "name": "Hamed Aboutorab",
                "labs": [
                    "School of Computing, Mathematics and Engineering, Charles Sturt University, Bathurst, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Transformers",
                "Data mining",
                "Data models",
                "Risk management",
                "Supply chain management",
                "Natural language processing",
                "Construction industry",
                "Risk management",
                "Geophysical measurements"
            ],
            "Author Keywords": [
                "Construction supply chain risk management",
                "named entity recognition",
                "transformers",
                "natural language processing",
                "BERT"
            ]
        }
    },
    {
        "Title": "Emotion Detection From Micro-Blogs Using Novel Input Representation",
        "Link": "https://ieeexplore.ieee.org/document/10050864/",
        "Abstract": "Emotion is a natural intrinsic state of mind that drives human behavior, social interaction, and decision-making. Due to the rapid expansion in the current era of the Internet, online social media (OSM) platforms have become popular means of expressing opinions and communicating emotions. With the emergence of natural language processing (NLP) techniques powered by artificial intelligence (AI) algorithms, emotion detection (ED) from user-generated OSM data has become a prolific research domain. However, it is challenging to extract meaningful features for identifying discernible patterns from the short, informal, and unstructured texts that are common on micro-blogging platforms like Twitter. In this paper, we introduce a novel representation of features extracted from user-generated Twitter data that can capture users’ emotional states. An advanced approach based on Genetic Algorithm (GA) is used to construct the input representation which is composed of stylistic, sentiment, and linguistic features extracted from tweets. A voting ensemble classifier with weights optimized by a GA is introduced to increase the accuracy of emotion detection using the novel feature representation. The proposed classifier is trained and tested on a benchmark Twitter emotion detection dataset where each sample is labeled with either of the six classes: sadness, joy, love, anger, fear, and surprise. The experimental results demonstrate that the proposed approach outperforms the state-of-the-art classical machine learning-based emotion detection techniques, achieving the highest level of precision (96.49%), recall (96.49%), F1-score (96.49%), and accuracy (96.49%).",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3248506",
            "Date of Publication": "23 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fahim Anzum",
                "labs": [
                    "Department of Computer Science, Biometric Technologies Laboratory, University of Calgary, Calgary, AB, Canada"
                ]
            },
            {
                "name": "Marina L. Gavrilova",
                "labs": [
                    "Department of Computer Science, Biometric Technologies Laboratory, University of Calgary, Calgary, AB, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Emotion recognition",
                "Social networking (online)",
                "Linguistics",
                "Genetic algorithms",
                "Blogs",
                "Predictive models",
                "Affective computing",
                "Machine learning",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Affective computing",
                "emotion detection",
                "ensemble classifier",
                "genetic algorithm",
                "machine learning",
                "natural language processing",
                "online social media",
                "social behavior"
            ]
        }
    },
    {
        "Title": "An Evaluation on Information Composition in Dementia Detection Based on Speech",
        "Link": "https://ieeexplore.ieee.org/document/9870792/",
        "Abstract": "In recent years, scientists are paying much attention to the research on automatic dementia detection that could be applied to the speech samples of dementia patients. In a related context, recent research has seen the fast development of Deep Learning (DL) and Natural Language Processing (NLP). The techniques developed for text classification or sentiment analysis have been applied to the field of early dementia detection by many researchers. However, text classification and sentiment analysis are different tasks from dementia detection, which makes us believe that for dementia detection, some adjustments would help improve the performance of the machine learning models. In this work, we implemented experiments with various language models including traditional\nn\n-gram language models, Average stochastic gradient descent Weight-Dropped Long Short-Term Memory (AWD-LSTM) models, and attention-based models to evaluate the speech data of dementia patients. Unlike traditional works where the text is stripped from stop words, we propose the idea of exploiting the stop words themselves, since they offer non-context information which helps to identify dementia. As a result, 3 different language models are prepared in this work: a model processing only context words, a model processing stop words and Part-of-Speech (PoS) tag sequences, and a model processing both of them. By performing the aforementioned experiments, we show that both grammar and vocabulary contribute equally to classification: The 3 models achieve an accuracy equal to 70.00%, 76.16%, and 81.54%, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3203068",
            "Date of Publication": "31 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chuheng Zheng",
                "labs": [
                    "Graduate School of Science and Technology, Keio University, Yokohama, Kanagawa, Japan"
                ]
            },
            {
                "name": "Mondher Bouazizi",
                "labs": [
                    "Faculty of Science and Technology, Keio University, Yokohama, Kanagawa, Japan"
                ]
            },
            {
                "name": "Tomoaki Ohtsuki",
                "labs": [
                    "Faculty of Science and Technology, Keio University, Yokohama, Kanagawa, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Dementia",
                "Data models",
                "Feature extraction",
                "Text categorization",
                "Natural language processing",
                "Sentiment analysis",
                "Deep learning",
                "Transfer learning"
            ],
            "Author Keywords": [
                "Dementia detection",
                "deep learning",
                "language models",
                "transfer learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "A Multi-Headed Transformer Approach for Predicting the Patient’s Clinical Time-Series Variables From Charted Vital Signs",
        "Link": "https://ieeexplore.ieee.org/document/9907018/",
        "Abstract": "Deep learning has progressively been the spotlight of innovations that aim to leverage the clinical time-series data that are longitudinally recorded in the Electronic Health Records(EHR) to forecast the patient’s survival and vital signs deterioration. However, their recording velocity, as well as their noisiness, hinder the proper adoption of the recently proposed benchmarks. The Recurrent Neural Networks (RNN) especially the Long-short Term Memory (LSTMs) have achieved better results in recent studies but they are hard to train and interpret and fail to properly capture the long-term dependencies. Moreover, the RNNs suffer greatly with clinical time series due to their sequential processing which cripples the prospect of parallel processing. Recently the Transformer approach was proposed for Natural Language Processing (NLP) tasks and achieved state-of-the-art results. Hence to tackle the drawbacks that are suffered by the RNNs we propose a clinical time series Multi-head Transformer (MHT), which is a transformer-based model that forecasts the patient’s future time series variables using the vitals signs. To prove the generalization of the model we use the same model for other critical tasks that describe the Intensive Care Unit (ICU) patient’s progression and the associated risks like the remaining Length Of Stay(LoS), the In-hospital Mortality as well as the 24 hours mortality. Our model achieves an Area Under The Curve-Receiver Operating Characteristics(AUC-ROC) of 0.98 and an Area Under the Curve, Precision-Recall (AUC-PR) of 0.424 for vital time series prediction, and an AUC-ROC of 0.875 in the mortality prediction. The model performs well for the frequently recorded variables like the Heart Rate (HR) and performs barely like the LSTM counterparts for the intermittently captured records such as the White Blood Count (WBC).",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3211334",
            "Date of Publication": "03 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gaspard Harerimana",
                "labs": [
                    "Department of Information Technology, Carnegie Mellon University, Kigali, Rwanda"
                ]
            },
            {
                "name": "Jong Wook Kim",
                "labs": [
                    "Department of Computer Science, Sangmyung University, Seoul, South Korea"
                ]
            },
            {
                "name": "Beakcheol Jang",
                "labs": [
                    "Graduate School of Information, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Time series analysis",
                "Predictive models",
                "Task analysis",
                "Decoding",
                "Convolutional neural networks",
                "Feature extraction",
                "Clinical diagnosis",
                "Natural language processing",
                "Heart rate",
                "Recurrent neural networks",
                "Parallel processing"
            ],
            "Author Keywords": [
                "Multi head transformer",
                "clinical time series",
                "natural language processing",
                "self-attention",
                "encoder-decoder attention",
                "interpolation"
            ]
        }
    },
    {
        "Title": "Extractive Summarization of Call Transcripts",
        "Link": "https://ieeexplore.ieee.org/document/9946852/",
        "Abstract": "Automatic text summarization is one of the most challenging and interesting problems in natural language processing (NLP). Text summarization is the process of extracting the most important information from the text and presenting it concisely in fewer sentences. Call transcript involves textual description of a phone conversation between a customer (caller) and agent(s) (customer representatives). Call transcripts pose unique challenges that are not adequately addressed by most open-source automatic text summarizers, which are developed to summarize continuous texts such as articles and stories. This paper presents an indigenously developed method that combines topic modeling and sentence selection with punctuation restoration in condensing ill-punctuated or un-punctuated call transcripts to produce more readable summaries. This unique combination is what distinguishes the proposed summarizer from other text summarizers. Extensive testing, evaluation and comparisons, with an open-source, state-of-the-art extractive summarizer using three different pre-trained language models, have demonstrated the efficacy of this summarizer for call transcript summarization. The summaries generated by the proposed summarizer are shown to be more compelling and useful based on multiple criteria.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3221404",
            "Date of Publication": "11 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pratik K. Biswas",
                "labs": [
                    "Artificial Intelligence and Data, Global Network and Technology (GNT), Verizon Communications, Basking Ridge, NJ, USA"
                ]
            },
            {
                "name": "Aleksandr Iakubovich",
                "labs": [
                    "Core Engineering and Operations, Global Network and Technology (GNT), Verizon Communications, Richardson, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Semantics",
                "Feature extraction",
                "Task analysis",
                "Hidden Markov models",
                "Bit error rate",
                "Transformers"
            ],
            "Author Keywords": [
                "Extractive summarization",
                "topic models",
                "transformers",
                "embedding",
                "punctuation restoration"
            ]
        }
    },
    {
        "Title": "Toward Intent-Based Network Automation for Smart Environments: A Healthcare 4.0 Use Case",
        "Link": "https://ieeexplore.ieee.org/document/10336815/",
        "Abstract": "Today’s organizations have been embracing digital transformation to boost the quality of living within IoT-based smart-sustainable environments (e.g., healthcare, factories, vehicles, etc.). At the same time, augmenting the network infrastructure surface with billions of new devices accommodating myriad applications creates the need for network automation through different technologies, such as Software-Defined Networking (SDN), Network Function Virtualization (NFV), and Big Data Analytics (BDA). However, to devise an end-to-end self-driving and autonomous network, the manual configuration of network parameters and devices should be limited or even vanished. The recently emerged Intent-based Networking (IBN) paradigm introduces an additional building block enabling the network to adapt its settings automatically according to high-level user demands (intents) while hiding low-level details of the underlying infrastructure (e.g., configurations in millions of network devices). This paper initiates a deeper discussion regarding service automation over a Hospital 4.0 environment, from translating user requests to service profiling (unstructured intent refinement), deployment, and assurance. First, we discuss the design challenges of joining an intent-based framework as a convenient plane to an SDN-based platform. Following, we focus on an intelligent intent refinement system based on the Named Entity Recognition (NER) approach, an application of Natural Language Processing (NLP). This IBN-NER system deploys an extensible network policy model and the pre-trained Google’s BERT (Bidirectional Encoder Representations from Transformers) algorithm, fine-tuned with a Healthcare 4.0 dataset. The proposed intent refinement framework is evaluated via extensive simulations with an incremental number of heterogeneous intents. Our simulation results show promising performance with only one epoch for all dataset sizes and all policy model entities tested. For example, with 5000 intents, our system provides the highest accuracy with 86%; meanwhile, the well-known benchmarks in the NER problem, namely BiLSTM-CRF, BiLSTM, and LSTM, with ten epochs, provide 57%, 31%, and 26%, respectively.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3338189",
            "Date of Publication": "30 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yosra Njah",
                "labs": [
                    "Department of Software and IT Engineering, École de Technologie Supérieure, Montreal, Canada"
                ]
            },
            {
                "name": "Aris Leivadeas",
                "labs": [
                    "Department of Software and IT Engineering, École de Technologie Supérieure, Montreal, Canada"
                ]
            },
            {
                "name": "John Violos",
                "labs": [
                    "Department of Software and IT Engineering, École de Technologie Supérieure, Montreal, Canada"
                ]
            },
            {
                "name": "Matthias Falkner",
                "labs": [
                    "Cisco’s SP Sales CTO Group, Cisco Systems Inc., Ottawa, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Automation",
                "Natural language processing",
                "Hospitals",
                "Network function virtualization",
                "Manuals",
                "Graphical user interfaces",
                "Autonomous networks"
            ],
            "Author Keywords": [
                "Healthcare 4.0",
                "intent-based networking",
                "network automation",
                "intent refinement",
                "service policy mapping",
                "named entity recognition"
            ]
        }
    },
    {
        "Title": "Multi-Encoder Transformer for Korean Abstractive Text Summarization",
        "Link": "https://ieeexplore.ieee.org/document/10129176/",
        "Abstract": "In this paper, we propose a Korean abstractive text summarization approach that uses a multi -encoder transformer. Recently, in many natural language processing (NLP) tasks, the use of the pre-trained language models (PLMs) for transfer learning has achieved remarkable performance. In particular, transformer-based models such as Bidirectional Encoder Representations from Transformers (BERT) are used for pre-training and applied to downstream tasks, showing state-of-the-art performance including abstractive text summarization. However, existing text summarization models usually use one pre-trained model per model architecture, meaning that it becomes necessary to choose one PLM at a time. For PLMs applicable to Korean abstractive text summarization, there are publicly available BERT-based pre-trained Korean models that offer different advantages such as Multilingual BERT, KoBERT, HanBERT, and KorBERT. We assume that if these PLMs could be leveraged simultaneously, better performance would be obtained. We propose a model that uses multiple encoders which are capable of leveraging multiple pre-trained models to create an abstractive summary. We evaluate our method using three benchmark Korean abstractive summarization datasets, each named Law (AI-Hub), News (AI-Hub), and News (NIKL) datasets. Experimental results show that the proposed multi-encoder model variations outperform single -encoder models. We find the empirically best summarization model by determining the optimal input combination when leveraging multiple PLMs with the multi-encoder method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3277754",
            "Date of Publication": "18 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Youhyun Shin",
                "labs": [
                    "Department of Computer Science and Engineering, Incheon National University, Incheon, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Transformers",
                "Natural language processing",
                "Bit error rate",
                "Encyclopedias",
                "Encoding",
                "Vocabulary",
                "Neural networks",
                "Text processing"
            ],
            "Author Keywords": [
                "Natural language processing",
                "abstractive text summarization",
                "bidirectional encoder representations from transformer",
                "neural networks",
                "natural language generation"
            ]
        }
    },
    {
        "Title": "MARSA: Multi-Domain Arabic Resources for Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/9576756/",
        "Abstract": "The Arabic language has many spoken dialects. However, until recently, it was primarily written in Modern Standard Arabic (MSA), which is the formal variant of Arabic. Social media platforms have changed the face of written Arabic where users converse freely in various dialects, thus offering a massive number of resources for the study of dialectal text. The Arabic dialects differ from MSA in morphology, syntax, and phonetics. Consequently, since the effectiveness of NLP tasks—like sentiment analysis—is dependent on the availability of representative resources, there is currently a great need for such resources in these dialects. In this paper, we present MARSA—the largest sentiment annotated corpus for Dialectal Arabic (DA) in the Gulf region, which consists of 61,353 manually labeled tweets that contain a total of 840 K tokens. The tweets were collected from trending hashtags in four domains: political, social, sports, and technology to create a multi-domain corpus. The importance of such a corpus is to facilitate the study of domain-dependent sentiment analysis in Arabic. In addition to this corpus, the annotators extracted indicator words to form affect lexicons for each domain. We draw insights from these lexicons regarding contextual polarity of certain words. Furthermore, we present benchmark experiments on the MARSA corpus in order to establish a baseline for further studies.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3120746",
            "Date of Publication": "15 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Areeb Alowisheq",
                "labs": [
                    "College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia",
                    "National Center for Artificial Intelligence (NCAI), Saudi Data and Artificial Intelligence Authority (SDAIA), Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nora Al-Twairesh",
                "labs": [
                    "National Center for Artificial Intelligence (NCAI), Saudi Data and Artificial Intelligence Authority (SDAIA), Riyadh, Saudi Arabia",
                    "Information Technology Department, STC’s Artificial Intelligence Chair, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mawaheb Altuwaijri",
                "labs": [
                    "General Directorate of Information Technology, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Afnan Almoammar",
                "labs": [
                    "College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Alhanouf Alsuwailem",
                "labs": [
                    "College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Tarfa Albuhairi",
                "labs": [
                    "Elm, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Wejdan Alahaideb",
                "labs": [
                    "General Directorate of Information Technology, Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sarah Alhumoud",
                "labs": [
                    "College of Computer and Information Sciences, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Sentiment analysis",
                "Blogs",
                "Annotations",
                "Sports",
                "Benchmark testing",
                "Task analysis"
            ],
            "Author Keywords": [
                "Corpus",
                "sentiment analysis",
                "dialectal Arabic"
            ]
        }
    },
    {
        "Title": "Achieving Peak Performance for Large Language Models: A Systematic Review",
        "Link": "https://ieeexplore.ieee.org/document/10589417/",
        "Abstract": "In recent years, large language models (LLMs) have achieved remarkable success in natural language processing (NLP). LLMs require an extreme amount of parameters to attain high performance. As models grow into the trillion-parameter range, computational and memory costs increase significantly. This makes it difficult for many researchers to access the resources needed to train or apply these models. Optimizing LLM performance involves two main approaches: fine-tuning pre-trained models for specific tasks to achieve state-of-the-art performance, and reducing costs or improving training time while maintaining similar performance. This paper presents a systematic literature review (SLR) following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement. We reviewed 65 publications out of 983 from 2017 to December 2023, retrieved from 5 databases. The study presents methods to optimize and accelerate LLMs while achieving cutting-edge results without sacrificing accuracy. We begin with an overview of the development of language modeling, followed by a detailed explanation of commonly used frameworks and libraries, and a taxonomy for improving and speeding up LLMs based on three classes: LLM training, LLM inference, and system serving. We then delve into recent optimization and acceleration strategies such as training optimization, hardware optimization, scalability and reliability, accompanied by the taxonomy and categorization of these strategies. Finally, we provide an in-depth comparison of each class and strategy, with two case studies on optimizing model training and enhancing inference efficiency. These case studies showcase practical approaches to address LLM resource limitations while maintaining performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3424945",
            "Date of Publication": "08 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhyar Rzgar K. Rostam",
                "labs": [
                    "Doctoral School of Applied Informatics and Applied Mathematics, Óbuda University, Budapest, Hungary"
                ]
            },
            {
                "name": "Sándor Szénási",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Faculty of Economics and Informatics, J. Selye University, Komárno, Slovakia"
                ]
            },
            {
                "name": "Gábor Kertész",
                "labs": [
                    "John von Neumann Faculty of Informatics, Óbuda University, Budapest, Hungary",
                    "Laboratory of Parallel and Distributed Systems, Institute for Computer Science and Control (SZTAKI), Hungarian Research Network (HUN-REN), Budapest, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optimization methods",
                "Training",
                "Parallel processing",
                "Computational modeling",
                "Scalability",
                "Libraries",
                "Taxonomy",
                "Distributed computing",
                "Graphics processing units",
                "Large language models"
            ],
            "Author Keywords": [
                "Distributed training",
                "GPU acceleration",
                "large language model",
                "LLM",
                "LLM acceleration",
                "LLM frameworks",
                "LLM optimization"
            ]
        }
    },
    {
        "Title": "Bi-LSTM-CRF Network for Clinical Event Extraction With Medical Knowledge Features",
        "Link": "https://ieeexplore.ieee.org/document/9915568/",
        "Abstract": "Extracting clinical event expressions and their types from clinical text is a fundamental task for many applications in clinical NLP. State-of-the-art systems need handcraft features and do not take into account the representation of the low-frequency words. To address these issues, a Bi-LSTM-CRF neural network architecture based on medical knowledge features is proposed. First, we employ convolutional neural networks (CNNs) to encode character-level information of a word and extract medical knowledge features from an open-source clinical knowledge system. Then, we concatenate character-level and word-level embedding and the medical knowledge features of words together, and feed them into bi-directional long short-term memory (Bi-LSTM) to build context information of each word. Finally, we jointly use a conditional random field (CRF) to decode labels for the whole sentence. We evaluate our model on two publicly available clinical datasets, namely THYME corpus and 2012 i2b2 dataset. Experimental results show that our model outperforms previous state-of-the-art systems with different methodologies, including machine learning-based methods, deep learning-based methods, and Bert-based methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3213676",
            "Date of Publication": "10 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shunli Zhang",
                "labs": [
                    "Department of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China"
                ]
            },
            {
                "name": "Yancui Li",
                "labs": [
                    "College of Computer and Information Engineering, Henan Normal University, Xinxiang, China"
                ]
            },
            {
                "name": "Shiyong Li",
                "labs": [
                    "Department of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China"
                ]
            },
            {
                "name": "Fang Yan",
                "labs": [
                    "Department of Information Engineering, Henan Institute of Science and Technology, Xinxiang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Unified modeling language",
                "Natural language processing",
                "Semantics",
                "Recurrent neural networks",
                "Medical diagnostic imaging",
                "Learning systems",
                "Clinical diagnosis",
                "Medical services"
            ],
            "Author Keywords": [
                "Clinical text",
                "entity recognition",
                "deep learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Reinforced Abstractive Text Summarization With Semantic Added Reward",
        "Link": "https://ieeexplore.ieee.org/document/9483920/",
        "Abstract": "Text summarization is an important task in natural language processing (NLP). Neural summary models summarize information by understanding and rewriting documents through the encoder-decoder structure. Recent studies have sought to overcome the bias that cross-entropy-based learning methods can have through reinforcement learning (RL)-based learning methods or the problem of failing to learn optimized for metrics. However, the ROUGE metric with only\nn\n-gram matching is not a perfect solution. The purpose of this study is to improve the quality of the summary statement by proposing a reward function used in text summarization based on RL. We propose ROUGE-SIM and ROUGE-WMD, modified functions of the ROUGE function. ROUGE-SIM enables meaningfully similar words, in contrast to ROUGE-L. ROUGE-WMD is a function adding semantic similarity to ROUGE-L. The semantic similarity between articles and summary text was computed using Word Mover’s Distance (WMD) methodology. Our model with two proposed reward functions demonstrated superior performance on ROUGE-1, ROUGE-2, and ROUGE_L than on ROUGE-L as a reward function. Our two models, ROUGE-SIM and ROUGE-WMD, scored 0.418 and 0.406 for ROUGE-L, respectively, for the Gigaword dataset. The two reward functions outperformed ROUGE-L even in the abstractiveness and grammatical aspects.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3097087",
            "Date of Publication": "14 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Heewon Jang",
                "labs": [
                    "Department of Industrial Engineering, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Wooju Kim",
                "labs": [
                    "Department of Industrial Engineering, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Measurement",
                "Task analysis",
                "Semantics",
                "Neural networks",
                "Vocabulary"
            ],
            "Author Keywords": [
                "Text summarization",
                "abstract summarization",
                "reinforcement learning",
                "semantic similarity"
            ]
        }
    },
    {
        "Title": "Neural Collaborative Embedding From Reviews for Recommendation",
        "Link": "https://ieeexplore.ieee.org/document/8782556/",
        "Abstract": "This paper mainly studies the personalized rating prediction task based on review texts for the recommendation. Recently, most of the related researches use convolutional neural networks to capture local context information, but it loses word frequency and global context information. In addition, they simply equate the user (item) embedding to review embedding, which brings some irrelevant information of the review text into user preference or item property. Moreover, they only consider the low-order interactions, which remain the fine-grained user-item interactions to be explored. To solve these problems, we propose a novel method neural collaborative embedding model (NCEM). We first adopt pre-trained BERT model, which has been proven to improve most of the downstream NLP tasks, to simultaneously capture the global context and word frequency information. In addition, a self-attention mechanism is introduced to learn the contribution of each review. Next, we develop a neural form of standard factorization machine, which can model first-order and second-order user-item interactions by stacking multiple layers. The extensive experiments on four public datasets showed that NCEM consistently outperforms the state-of-the-art recommendation approaches. Furthermore, the recommendation interpretability can be improved by showing users the high score reviews accompanied recommended item.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2931357",
            "Date of Publication": "31 July 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xingjie Feng",
                "labs": [
                    "College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China"
                ]
            },
            {
                "name": "Yunze Zeng",
                "labs": [
                    "College of Computer Science and Technology, Civil Aviation University of China, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Collaboration",
                "Predictive models",
                "Recommender systems",
                "Task analysis",
                "Bit error rate",
                "Context modeling"
            ],
            "Author Keywords": [
                "Recommender system",
                "collaborative filtering",
                "deep learning",
                "factorization machine"
            ]
        }
    },
    {
        "Title": "Fine Grained Named Entity Recognition via Seq2seq Framework",
        "Link": "https://ieeexplore.ieee.org/document/9034046/",
        "Abstract": "Fine-grained Named entity recognition (NER) is crucial to natural language processing (NLP) applications like relation extraction and knowledge graph construction. Most existing fine-grained NER systems suffer from inefficiency problem as they use manually annotated training datasets. To address such issue, our NER system could automatically generate datasets from Wikipedia in distant supervision paradigm through mapping hyperlinks in Wikipedia documents to Freebase. In addition, previous NER models can not effectively process fine-grained labels with more than 100 types. So we introduce a `BIO' tagging strategy which can identify the position and type attributes simultaneously. Such tagging scheme transfers NER problem into a sequence-to-sequence (seq2seq) based issue. We propose a seq2seq framework to comprehend the input sentence in a comprehensive way. Specifically, we adopt a Bi-LSTM as the encoder to equally process the past and future information of the input. Then we add a self-attention mechanism to handle the long-term dependency problem in a long sequence. When classifying the entity tags, we choose CRF model as it adds more constraints to avoid position logical problem. Experiments are performed on large-scale datasets for fine-grained NER tasks. Experimental results verify the effectiveness of FSeqC, and it outperforms other state-of-the-art alternatives consistently and significantly.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2980431",
            "Date of Publication": "12 March 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Huiming Zhu",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China",
                    "Department of Economics and Trade, Changsha Commerce and Tourism College, Changsha, China"
                ]
            },
            {
                "name": "Chunhui He",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Yang Fang",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Weidong Xiao",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tagging",
                "Encyclopedias",
                "Electronic publishing",
                "Internet",
                "Task analysis",
                "Decoding"
            ],
            "Author Keywords": [
                "Named entity recognition",
                "fine-grained",
                "seq2seq framework"
            ]
        }
    },
    {
        "Title": "CSM: A Chatbot Solution to Manage Student Questions About Payments and Enrollment in University",
        "Link": "https://ieeexplore.ieee.org/document/10536871/",
        "Abstract": "Students at the University of Guayaquil who are pursuing a degree in Software Engineering and who have difficulty obtaining information about enrollment and tuition payments are the target audience of the application developed in this study. For this purpose, a chatbot is proposed. It uses machine learning (ML) and natural language processing (NLP) to answer students’ questions. To evaluate the usability of the system from a quantitative point of view, the time taken by six students to complete user registration (T1), perform five searches (T2), and unsubscribe (T3) was measured in minutes, with an average duration of three minutes for each activity. To assess students’ perceptions of the use of the proposed chatbot, a sample of sixty students who had previously interacted with the proposed solution were surveyed. Aspects evaluated included: Ease of use of the system (A), Speed (B), Appropriate behavior (C), Confidence to use it again (D), and Quality of the answer provided (E). Each of the evaluated features (A-E) was rated above 3 out of 5 in most cases. Thus, the chatbot solution is well accepted by the students, even considering its use in future academic semesters.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3404008",
            "Date of Publication": "22 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Franklin Parrales-Bravo",
                "labs": [
                    "Facultad de Ciencias Matemáticas y Físicas, Universidad de Guayaquil, Guayaquil, Ecuador"
                ]
            },
            {
                "name": "Rosangela Caicedo-Quiroz",
                "labs": [
                    "Universidad Bolivariana del Ecuador, Durán, Ecuador"
                ]
            },
            {
                "name": "Julio Barzola-Monteses",
                "labs": [
                    "Facultad de Ciencias Matemáticas y Físicas, Universidad de Guayaquil, Guayaquil, Ecuador",
                    "Universidad Bolivariana del Ecuador, Durán, Ecuador"
                ]
            },
            {
                "name": "José Guillén-Mirabá",
                "labs": [
                    "Facultad de Ciencias Matemáticas y Físicas, Universidad de Guayaquil, Guayaquil, Ecuador"
                ]
            },
            {
                "name": "Otto Guzmán-Bedor",
                "labs": [
                    "Facultad de Ciencias Matemáticas y Físicas, Universidad de Guayaquil, Guayaquil, Ecuador"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Natural language processing",
                "Machine learning",
                "Social networking (online)",
                "Analytical models",
                "Software engineering",
                "Neural networks",
                "Education",
                "Software engineering",
                "Financial management"
            ],
            "Author Keywords": [
                "Chatbot",
                "cloud server",
                "natural language processing",
                "neural network",
                "machine learning"
            ]
        }
    },
    {
        "Title": "A Robust Intelligent System for Text-Based Traffic Signs Detection and Recognition in Challenging Weather Conditions",
        "Link": "https://ieeexplore.ieee.org/document/10530242/",
        "Abstract": "Traffic signs have great importance regarding smooth traffic flow and safe driving. However, due to many distractions and capricious factors, spotting and perceiving them may become hazardous. Traffic sign detection and recognition have gained popularity to put an end or to lessen the issue, and massive efforts have been realized in this regard. Despite considerable endeavors put together for traffic sign detection and recognition, there is a lack of attention in this area where these traffic signs contain text in them. A handful of studies may be found in state-of-the-art (SOTA) methods for text-based traffic sign detection, and particularly lesser for text recognition of detected text. The proposed method focuses on developing a robust semi-pipeline intelligent system to detect and understand text from traffic road signs boards in various weather conditions. For this purpose, a customized YOLOv5s is deployed for initial panel detection. Subsequently, MSER with preprocessing techniques is used for localization of text. Finally, OCR with NLP is utilized to recognize the text. The proposed method employed the ASAYAR dataset for training and different datasets for testing. The proposed approach produced satisfactory outcomes on them in contrast with SOTA approaches.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3401044",
            "Date of Publication": "14 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sara Khalid",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Wah Campus, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Jamal Hussain Shah",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Wah Campus, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Sharif",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Wah Campus, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Fadl Dahan",
                "labs": [
                    "Department of Management Information Systems, College of Business Administration Hawtat Bani Tamim, Prince Sattam Bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            },
            {
                "name": "Rabia Saleem",
                "labs": [
                    "Department of Information Technology, Government College University Faisalabad, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Anum Masood",
                "labs": [
                    "Department of Circulation and Medical Imaging, Norwegian University of Science and Technology, Trondheim, Norway"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text recognition",
                "Text detection",
                "Roads",
                "Deep learning",
                "Symbols",
                "Feature extraction",
                "Natural language processing",
                "YOLO"
            ],
            "Author Keywords": [
                "Text recognition",
                "deep learning",
                "natural language processing",
                "automated road signs/panels detection",
                "YOLOV5s",
                "MSER"
            ]
        }
    },
    {
        "Title": "User-Oriented Paraphrase Generation With Keywords Controlled Network",
        "Link": "https://ieeexplore.ieee.org/document/8736871/",
        "Abstract": "Paraphrase generation can help with both downstream tasks in natural language processing (NLP) and human writing in our daily life. Most of the prevalent neural models focus on the former usages and generate uncontrolled paraphrase while they ignore the subtleties of users' requirement. In addition, the existing tools for users are usually rule-based which is unnatural due to the complexity of the paraphrase nature. To this end, we propose a keyword controlled network (KCN) which can be used as an assistant paraphrase generation tool. The KCN works in an interactive manner and generates different paraphrases given different keywords. The model is based on a Sequence-to-Sequence (Seq2Seq) framework integrated with copy mechanism. Given the source sentence and the keywords, two encoders transform them into vector representations. Then, the representations are fused together and used for the decoder. The decoder with attention mechanism either copies the words from the keywords or generates words from the whole dictionary. In the training stage, as the source sentence and the target sentence are all valid paraphrases, the model is trained to generate each given different keywords, which simulates the behaviors of users. The extensive experiments on three datasets show that our method outperforms baselines in the automatic evaluation (0.06 absolute improvement in BLEU) and the generated paraphrases meet user expectation in the human evaluation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2923057",
            "Date of Publication": "14 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Daojian Zeng",
                "labs": [
                    "School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Haoran Zhang",
                "labs": [
                    "School of Information Science, University of Illinois Urbana–Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Lingyun Xiang",
                "labs": [
                    "School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Jin Wang",
                "labs": [
                    "School of Computer and Communication Engineering, Changsha University of Science and Technology, Changsha, China"
                ]
            },
            {
                "name": "Guoliang Ji",
                "labs": [
                    "China Three Gorges Corporation, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Writing",
                "Syntactics",
                "Decoding",
                "Task analysis",
                "Natural language processing",
                "Tools"
            ],
            "Author Keywords": [
                "Copy mechanism",
                "keyword",
                "paraphrase generation",
                "Seq2Seq"
            ]
        }
    },
    {
        "Title": "Interactive Self-Attentive Siamese Network for Biomedical Sentence Similarity",
        "Link": "https://ieeexplore.ieee.org/document/9057451/",
        "Abstract": "The determination of semantic similarity between sentences is an important component in natural language processing (NLP) tasks such as text retrieval and text summarization. Many approaches have been proposed for estimating sentence similarity, and Siamese neural networks (SNN) provide a better approach. However, the sentence semantic representation, generated by sharing weights in the SNN without any attention mechanism, ignores the different contributions of different words to the overall sentence semantics. Furthermore, the attention operation within only a single sentence neglects interactive semantic influence on similarity estimation. To address these issues, an interactive self-attention (ISA) mechanism is proposed in this paper and integrated with an SNN, named an interactive self-attentive Siamese neural network (ISA-SNN) which is used to verify the effectiveness of ISA. The proposed model obtains the weights of words in a single sentence by means of self-attention and extracts inherent interactive semantic information between sentences via interactive attention to enhance sentence semantic representation. It achieves better performances without feature engineering than other existing methods on three biomedical benchmark datasets (a Pearson correlation coefficient of 0.656 and 0.713/0.658 on DBMI and CDD-ful/-ref, respectively).",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2985685",
            "Date of Publication": "06 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhengguang Li",
                "labs": [
                    "College of Computer Science and Technology, Dalian University of Technology, Dalian, China",
                    "Software Institute, Dalian Jiaotong University, Dalian, China"
                ]
            },
            {
                "name": "Hongfei Lin",
                "labs": [
                    "College of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Wei Zheng",
                "labs": [
                    "Software Institute, Dalian Jiaotong University, Dalian, China"
                ]
            },
            {
                "name": "Michael M. Tadesse",
                "labs": [
                    "College of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Zhihao Yang",
                "labs": [
                    "College of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Jian Wang",
                "labs": [
                    "College of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Neural networks",
                "Logic gates",
                "Estimation",
                "Biological system modeling",
                "Data mining"
            ],
            "Author Keywords": [
                "Interactive self-attention",
                "Siamese network",
                "sentence pair",
                "semantic similarity"
            ]
        }
    },
    {
        "Title": "Improving Textual Emotion Recognition Based on Intra- and Inter-Class Variations",
        "Link": "https://ieeexplore.ieee.org/document/9513563/",
        "Abstract": "Textual Emotion Recognition (TER) is an important task in Natural Language Processing (NLP), due to its high impact in real-world applications. Prior research has tackled the automatic classification of emotion expressions in text by maximising the probability of the correct emotion class using cross-entropy loss. However, this approach does not account for intra- and inter-class variations within and between emotion classes. To overcome this problem, we introduce a variant of triplet centre loss as an auxiliary task to emotion classification. This allows TER models to learn compact and discriminative features. Furthermore, we introduce a method for evaluating the impact of intra- and inter-class variations on each emotion class. Experiments performed on three datasets demonstrate the effectiveness of our method when applied to each emotion class in comparison to previous approaches. Finally, we present analyses that illustrate the benefits of our method in terms of improving the prediction scores as well as producing discriminative features.",
        "Details": {
            "DOI": "10.1109/TAFFC.2021.3104720",
            "Date of Publication": "13 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Affective Computing"
        },
        "issn_info": {
            "Electronic ISSN": "1949-3045"
        },
        "authors_data": [
            {
                "name": "Hassan Alhuzali",
                "labs": [
                    "NaCTeM, University of Manchester, Manchester, U.K.",
                    "Department of Computer Science, The University of Manchester, Manchester, U.K."
                ]
            },
            {
                "name": "Sophia Ananiadou",
                "labs": [
                    "NaCTeM, University of Manchester, Manchester, U.K.",
                    "Department of Computer Science, The University of Manchester, Manchester, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Emotion recognition",
                "Training",
                "Task analysis",
                "Natural language processing",
                "Convolutional neural networks",
                "Computational modeling",
                "Predictive models"
            ],
            "Author Keywords": [
                "Textual emotion recognition",
                "emotion classification",
                "learning intra- and inter-class variation",
                "variant triplet centre loss"
            ]
        }
    },
    {
        "Title": "AnomalyAdapters: Parameter-Efficient Multi-Anomaly Task Detection",
        "Link": "https://ieeexplore.ieee.org/document/9673755/",
        "Abstract": "The emergence of technological innovations brings sophisticated threats. Cyberattacks are increasing day by day aligned with these innovations and entails rapid solutions for defense mechanisms. These attacks may hinder enterprise operations or more importantly, interrupt critical infrastructure systems, that are essential to safety, security, and well-being of a society. Anomaly detection, as a protection step, is significant for ensuring a system security. Logs, which are accepted sources universally, are utilized in system health monitoring and intrusion detection systems. Recent developments in Natural Language Processing (NLP) studies show that contextual information decreases false-positives yield in detecting anomalous behaviors. Transformers and their adaptations to various language understanding tasks exemplify the enhanced ability to extract this information. Deep network based anomaly detection solutions use generally feature-based transfer learning methods. This type of learning presents a new set of weights for each log type. It is unfeasible and a redundant way considering various log sources. Also, a vague representation of model decisions prevents learning from threat data and improving model capability. In this paper, we propose AnomalyAdapters (AAs) which is an extensible multi-anomaly task detection model. It uses pretrained transformers’ variant to encode a log sequences and utilizes adapters to learn a log structure and anomaly types. Adapter-based approach collects contextual information, eliminates information loss in learning, and learns anomaly detection tasks from different log sources without overuse of parameters. Lastly, our work elucidates the decision making process of the proposed model on different log datasets to emphasize extraction of threat data via explainability experiments.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3141161",
            "Date of Publication": "07 January 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Uğur Ünal",
                "labs": [
                    "Management Information Systems, Kadir Has University, Istanbul, Turkey"
                ]
            },
            {
                "name": "Hasan Dağ",
                "labs": [
                    "Management Information Systems, Kadir Has University, Istanbul, Turkey"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Anomaly detection",
                "Adaptation models",
                "Transformers",
                "Security",
                "Semantics",
                "Monitoring"
            ],
            "Author Keywords": [
                "Anomaly detection",
                "adapters",
                "cyber threat intelligence",
                "explainability",
                "log",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "A Novel Convolutional Neural Networks for Stock Trading Based on DDQN Algorithm",
        "Link": "https://ieeexplore.ieee.org/document/10077346/",
        "Abstract": "In deep learning based stock trading strategy models, most of the research just use simple convolutional neural networks (CNN) to process stock data. But task-specific neural network structures have been proposed extensively, and their effectiveness has been demonstrated in computer vision (CV) and natural language processing (NLP) tasks. In this paper, we proposed a multi-scale convolutional neural feature extraction network (MS-CNN) for stock data, which can better extract stock trend features and thus make better decisions. The network structure inspired by the human stock trading model: in human behavior, we do not only look at a single set of stock data, but rather combine all the stock data, such as opening, closing, and trading volume, to make a comprehensive judgment. And humans will consider the current stock trend on different time scales, such as 3-Day Line and 5-Day Line. This is consistent with the two-dimensional convolution kernels commonly used in CV tasks, so we used convolution kernels of\n3×3\nand\n5×5\nin the network with two-dimensional convolution size and constructed a novel network structure for stock data. With double deep Q networks (DDQN) algorithm, we get the best performance for our network. The experimental results show that we can obtain high yield on the datasets of Dow Jones (DJI), AAPLE (AAPL), and General Electric (GE).",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3259424",
            "Date of Publication": "20 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Kai Cui",
                "labs": [
                    "School of Computer Science and Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Ruizhe Hao",
                "labs": [
                    "Military Science Information Research Center, Academy of Military Science, Beijing, China"
                ]
            },
            {
                "name": "Yuling Huang",
                "labs": [
                    "School of Computer Science and Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Jianqing Li",
                "labs": [
                    "School of Computer Science and Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Yunlin Song",
                "labs": [
                    "School of Business, Macau University of Science and Technology, Macau, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Convolutional neural networks",
                "Task analysis",
                "Neural networks",
                "Stock markets",
                "Market research"
            ],
            "Author Keywords": [
                "DRL",
                "DDQN",
                "CNN",
                "stock",
                "feature extraction network"
            ]
        }
    },
    {
        "Title": "CCRO: Citation’s Context & Reasons Ontology",
        "Link": "https://ieeexplore.ieee.org/document/8664157/",
        "Abstract": "Research papers can be visualized as a networked information space that contains a collection of information entities, inter-connected by directed links, commonly known as citation graph. There is a possibility to enrich the citation graph with meaningful relations using semantic tags. We have discovered and evaluated more than 150 citations' reasons from the existing published literature to be represented as citation tags. Many of these reasons have overlapped and diffused meanings. Annotating such a large volume of citation graphs with citation's reasons manually is nearly impossible, giving rise to a need to discover the citation's reasons automatically with high accuracy. The first step towards this is developing a minimal set of citation's context and reasons that are disjoint in nature. It would be a great help to the reasoning system if these reasons are represented in a formal way in the form of an ontology. By adopting a well-defined scientific methodology to formulate an ontology of citation reasons, we have reduced 150 reasons into only eight disjoint reasons, using an iterative process of sentiment analysis, collaborative meanings, and experts' opinions. Based on our findings and experiments, we have proposed a citation's context and reasons ontology (CCRO) that provides abstract conceptualization required to organize citations' relations. CCRO has been verified, validated, and assessed by using the well-defined procedures and tools proposed in the literature for ontology evaluation. The results show that the proposed ontology is concise, complete, and consistent. For the instantiation and mapping of ontology classes on real data, we have developed a mapping graph among the verbs with predicative complements in the English Language, the verbs extracted from the selected corpus using the NLP and CCRO classes. Using this mapping graph, the mapping of ontology classes in each citation's sentiment is explained with a complete mapping on the selected dataset.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2903450",
            "Date of Publication": "11 March 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Imran Ihsan",
                "labs": [
                    "Department of Computer Science, Center for Research in Data Science, Semantics and Scientometrics, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Abdul Qadir",
                "labs": [
                    "Department of Computer Science, Center for Research in Data Science, Semantics and Scientometrics, Islamabad, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ontologies",
                "Semantics",
                "Metadata",
                "Tools",
                "Natural language processing",
                "Citation analysis"
            ],
            "Author Keywords": [
                "Citation ontology",
                "citation graphs",
                "citation analysis",
                "ontology development",
                "natural language processing",
                "computational linguistics"
            ]
        }
    },
    {
        "Title": "Arabic Text Processing Model: Verbs Roots and Conjugation Automation",
        "Link": "https://ieeexplore.ieee.org/document/9104997/",
        "Abstract": "The Natural Language Processing (NLP) is a process to automate the text or speech of Natural Languages. This automation is mainly conducted for Western languages. The Arabic Language got less focus in this area. This paper presents a Model to recognize an Arabic sentence. A new morphological model based on regular expressions is developed to recognize the Arabic verbs. A hash table containing all Arabic three-letters' root of verbs is implemented. The total number of Arabic verbs that are derived from three-letters' root size is 23090. The number of roots is 6104. A set of rules forming the Arabic grammar is used to derive and analyze the syntax of Arabic sentences. About 87% of the verbs represented in our regular expressions' engine are detected. Moreover, the sentences are also recognized. In several Surat of the Quran, only 9% of the detected verbs are false-positive (a non-verb declared as a verb), and 4% are considered false-negative (a verb is considered as a noun). This rate is mainly because we are not using vowels even that the Quran (our case study) is using them. The reason behind our decision is to be able to handle all Arabic texts, which mostly are not using vowels.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2999259",
            "Date of Publication": "01 June 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohamed Tahar Ben Othman",
                "labs": [
                    "Department of Computer Science, College of Computer, Qassim University, Buraydah, Saudi Arabia",
                    "BIND Research Group, College of Computer, Qassim University, Buraydah, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammed Abdullah Al-Hagery",
                "labs": [
                    "Department of Computer Science, College of Computer, Qassim University, Buraydah, Saudi Arabia",
                    "BIND Research Group, College of Computer, Qassim University, Buraydah, Saudi Arabia"
                ]
            },
            {
                "name": "Yahya Muhammad El Hashemi",
                "labs": [
                    "Department of Arabic Language and Literature, College of Arabic Language and Social Studies, Qassim University, Buraydah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Syntactics",
                "Automation",
                "Text processing",
                "Semantics",
                "Tools",
                "Grammar",
                "Complexity theory"
            ],
            "Author Keywords": [
                "Arabic text processing",
                "regular expression",
                "root extraction",
                "verbs root classification",
                "data mining"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis in Low-Resource Settings: A Comprehensive Review of Approaches, Languages, and Data Sources",
        "Link": "https://ieeexplore.ieee.org/document/10526251/",
        "Abstract": "The field of low-resource sentiment analysis has seen significant developments in recent years. This research review SLR evaluates the approaches and data sources utilized in low-resource sentiment analysis by deep learning. The primary aim is to discover suitable approaches for future sentiment analysis in low-resource. Our studies explore various languages, models, and data sources expressing a desire to create effective approaches. Our emphasis lies in the critical evaluation of the approaches and the datasets utilized, to identify areas where further research is needed. Our analysis study adds to the existing body of literature reviews, encompassing multilingual low-resource sentiment analysis research spanning from 2018 to 2023. The findings indicate that the transfer learning approach is the most frequently used, followed by word embedding learning and machine translation systems. Additionally, the study shows that social media is the most used platform for data collection, followed by product reviews, movies, and hotels. There has been a significant surge in the adoption of pre-trained transformers, indicating a growing interest in exploring the potential of these models for low-resource languages within the natural language processing (NLP) community. This trend is largely attributed to the novel nature of these models and their feature of being non-labour intensive. However, the scarcity of annotated datasets for such languages remains a major hurdle. finally, these research findings are relevant and informative for any researcher working in the field of low-resource multilingual sentiment analysis. The study introduces a conceptual framework for performing sentiment analysis in low-resource. The study provides a valuable resource for future researchers.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3398635",
            "Date of Publication": "08 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yusuf Aliyu",
                "labs": [
                    "Department of Computer and Information Science, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Aliza Sarlan",
                "labs": [
                    "Center for Foundation Studies, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Kamaluddeen Usman Danyaro",
                "labs": [
                    "Department of Computer and Information Science, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia",
                    "Centre for Cyber-Physical Systems (C2PS), Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Abdullahi Sani B. A. Rahman",
                "labs": [
                    "Department of Computer and Information Science, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Mujaheed Abdullahi",
                "labs": [
                    "Department of Computer and Information Science, Universiti Teknologi PETRONAS, Seri Iskandar, Perak, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Reviews",
                "Deep learning",
                "Analytical models",
                "Social networking (online)",
                "Encoding",
                "Data models",
                "Transfer learning",
                "Resource management"
            ],
            "Author Keywords": [
                "Word-embedding",
                "transfer learning",
                "transformer",
                "machine translation",
                "low-resource",
                "sentiment analysis",
                "multilingual"
            ]
        }
    },
    {
        "Title": "Nature-Based Prediction Model of Bug Reports Based on Ensemble Machine Learning Model",
        "Link": "https://ieeexplore.ieee.org/document/10158700/",
        "Abstract": "In software development systems, the maintenance process of software systems attracted the attention of researchers due to its importance in fixing the defects discovered in the software testing by using bug reports (BRs) which include detailed information like description, status, reporter, assignee, priority, and severity of the bug and other information. The main problem in this process is how to analyze these BRs to discover all defects in the system, which is a tedious and time-consuming task if done manually because the number of BRs increases dramatically. Thus, the automated solution is the best. Most of the current research focuses on automating this process from different aspects, such as detecting the severity or priority of the bug. However, they did not consider the nature of the bug, which is a multi-class classification problem. This paper solves this problem by proposing a new prediction model to analyze BRs and predict the nature of the bug. The proposed model constructs an ensemble machine learning algorithm using natural language processing (NLP) and machine learning techniques. We simulate the proposed model by using a publicly available dataset for two online software bug repositories (Mozilla and Eclipse), which includes six classes: Program Anomaly, GUI, Network or Security, Configuration, Performance, and Test-Code. The simulation results show that the proposed model can achieve better accuracy than most existing models, namely, 90.42% without text augmentation and 96.72% with text augmentation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3288156",
            "Date of Publication": "21 June 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shatha Abed Alsaedi",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia",
                    "Department of Computer Science, College of Computer Science and Engineering, Taibah University, Yanbu, Saudi Arabia"
                ]
            },
            {
                "name": "Amin Yousef Noaman",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed A. A. Gad-Elrab",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            },
            {
                "name": "Fathy Elbouraey Eassa",
                "labs": [
                    "Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Software maintenance",
                "Predictive models",
                "Machine learning",
                "Ensemble learning",
                "Maintenance engineering",
                "Support vector machines",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Software maintenance",
                "nature classification",
                "ensemble machine learning algorithm",
                "natural language processing",
                "bug reports",
                "machine learning"
            ]
        }
    },
    {
        "Title": "Meta Reinforcement Learning for UAV-Assisted Energy Harvesting IoT Devices in Disaster-Affected Areas",
        "Link": "https://ieeexplore.ieee.org/document/10473207/",
        "Abstract": "Over the past decade, Unmanned Aerial Vehicles (UAVs) have attracted significant attention due to their potential applications in emergency-response applications, including wireless power transfer (WPT) and data collection from Internet of Things (IoT) devices in disaster-affected areas. UAVs are more attractive than traditional techniques due to their maneuverability, flexibility, and low deployment costs. However, using UAVs for such critical tasks comes with challenges, including limited resources, energy constraints, and the need to complete missions within strict time frames. IoT devices in disaster areas have limited resources (e.g., computation, energy), so they depend on the UAVs’ resources to accomplish vital missions. To address these resource problems in a disaster scenario, we propose a meta-reinforcement learning (RL)-based energy harvesting (EH) framework. Our system model considers a swarm of UAVs that navigate an area, providing wireless power and collecting data from IoT devices on the ground. The primary objective is to enhance the quality of service for strategic locations while allowing UAVs to dynamically join and leave the swarm (e.g., for recharging). In this context, we formulate the problem as a non-linear programming (NLP) optimization problem aimed at maximizing the total EH IoT devices and determining the optimal trajectory paths for UAVs while adhering to the constraints related to the maximum time duration, the UAVs’ maximum energy consumption, and the minimum data rate to achieve a reliable transmission. Due to the complexity of the problem, the combinatorial nature of the formulated problem, and the difficulty of obtaining the optimal solution using conventional optimization problems, we propose a lightweight meta-RL solution capable of solving the problem by learning the system dynamics. We conducted extensive simulations and compared our approach with two state-of-the-art models using traditional RL algorithms represented by a deep Q-network algorithm, a Particle Swarm Optimization (PSO) algorithm, and one greedy solution. Our simulation results show that the proposed Meta-RL algorithm can outperform the IoT EH of the DQN, PSO algorithm, and the greedy solution by 25%, 32%, and 45%, respectively. The results of our simulations also demonstrate that our proposed approach outperforms the competitive solutions in terms of efficiently covering strategic locations with a high satisfaction rate and high accuracy.\nShow Less",
        "Details": {
            "DOI": "10.1109/OJCOMS.2024.3377706",
            "Date of Publication": "18 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Marwan Dhuheir",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            },
            {
                "name": "Aiman Erbad",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            },
            {
                "name": "Ala Al-Fuqaha",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            },
            {
                "name": "Abegaz Mohammed Seid",
                "labs": [
                    "Division of Information and Computing Technology, College of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Autonomous aerial vehicles",
                "Optimization",
                "Data collection",
                "Energy consumption",
                "Trajectory",
                "Disasters"
            ],
            "Author Keywords": [
                "Energy harvesting",
                "UAVs positions",
                "energy consumption",
                "meta-reinforcement learning",
                "UAVs",
                "strategic locations"
            ]
        }
    },
    {
        "Title": "Ensemble Learning With Tournament Selected Glowworm Swarm Optimization Algorithm for Cyberbullying Detection on Social Media",
        "Link": "https://ieeexplore.ieee.org/document/10292654/",
        "Abstract": "Online social network (OSN) plays a crucial role to facilitate social connections; but, this social networking media increases antisocial behaviors, like trolling, cyberbullying, and hate speech. Cyberbullying has often resulted in serious physical and mental distress, especially for children and women, and even sometimes forces them to commit suicide. Conventional techniques for detecting cyberbullying, such as relying on users to report the instance of bullying, are not always effective. Deep learning (DL) and Machine learning (ML) techniques are trained to automatically recognize and flag potential cyberbullying content, along with identifying behavior patterns that are indicative of cyberbullying. Therefore, this study concentrates on the design and development of ensemble deep learning with tournament-selected glowworm swarm optimization (EDL-TSGSO) algorithm for cyberbullying detection and classification on Twitter data. The goal of the study is to examine social media data through the use of natural language processing (NLP) and ensemble learning process. This EDL-TSGSO technique preprocesses the raw tweets and then employs the Glove word embedding technique. In addition, the presented EDL-TSGSO technique utilizes ensemble long short-term memory with Adaboost (ELSTM-AB) model for effective cyberbullying detection and classification. The ensemble ELSTM-AB classifier integrates the prediction of LSTM and Adaboost models to enhance the overall classification performance. To further develop the cyberbullying detection performance of the EDL-TSGSO algorithm, the TSGSO algorithm is applied as a hyperparameter optimizer. The experimental validation of the EDL-TSGSO algorithm on the Twitter dataset demonstrates its promising performance over other state of art approaches in terms of different measures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3326948",
            "Date of Publication": "23 October 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ravuri Daniel",
                "labs": [
                    "Department of Computer Science and Engineering, Prasad V. Potluri Siddhartha Institute of Technology, Vijayawada, India"
                ]
            },
            {
                "name": "T. Satyanarayana Murthy",
                "labs": [
                    "Department of Information Technology, Chaitanya Bharathi Institute of Technology, Hyderabad, India"
                ]
            },
            {
                "name": "Ch. D. V. P. Kumari",
                "labs": [
                    "Department of CSE, Aditya College of Engineering, Surampalem, India"
                ]
            },
            {
                "name": "E. Laxmi Lydia",
                "labs": [
                    "Department of Computer Science and Engineering, Vignan’s Institute of Information Technology, Visakhapatnam, India"
                ]
            },
            {
                "name": "Mohamad Khairi Ishak",
                "labs": [
                    "Department of Electrical and Computer Engineering, College of Engineering and Information Technology, Ajman University, Ajman, United Arab Emirates",
                    "School of Electrical and Electronic Engineering, Engineering Campus, Universiti Sains Malaysia, Nibong Tebal, Penang, Malaysia"
                ]
            },
            {
                "name": "Myriam Hadjouni",
                "labs": [
                    "Department of Computer Sciences, College of Computer and Information Science, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Samih M. Mostafa",
                "labs": [
                    "Computer Science Department, Faculty of Computers and Information, South Valley University, Qena, Egypt",
                    "Faculty of Industry and Energy Technology, New Assiut Technological University (NATU), New Assiut, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cyberbullying",
                "Blogs",
                "Classification algorithms",
                "Tokenization",
                "Prediction algorithms",
                "Particle swarm optimization",
                "Ensemble learning"
            ],
            "Author Keywords": [
                "Cyberbullying detection",
                "natural language processing",
                "social media",
                "ensemble learning",
                "hyperparameter tuning"
            ]
        }
    },
    {
        "Title": "Six-Granularity Based Chinese Short Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10097716/",
        "Abstract": "Short text classification is an important task in Natural Language Processing (NLP). The classification result for Chinese short text is always not ideal due to the sparsity problem of them. Most of the previous classification models for Chinese short text are based on word or character, considering that Chinese radical can also represent the meaning individually, so word, character and radical are all used to build a Chinese short text classification model in this paper, which solves the data sparsity problem of short text. In addition, in the process of segmenting sentences into words, considering that jieba will cause the loss of key information and ngram will generate noise words, both jieba and ngram are used to construct a six-granularity (i.e. word-jieba, word-jieba-radical, word-ngram, word-ngram-radical, character and character-radical) based Chinese short text classification (SGCSTC) model. Additionally, different weights are assigned to the six granularities and are automatically updated in the process of back-propagation using cross-entropy loss due to the different influence of them on the classification results. The classification Accuracy, Precision, Recall and F1 of SGCSTC in THUCNews-S dataset are 93.36%, 94.47%, 94.15% and 94.31% respectively, and that in CNT dataset are 92.67%, 92.38%, 93.15% and 92.76% respectively, and multiple comparative experiment results on THUCNews-S and CNT datasets show that SGCSTC outperforms the state-of-the-art text classification models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3265712",
            "Date of Publication": "10 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xinjie Sun",
                "labs": [
                    "Institute of Computer Science, Liupanshui Normal University, Liupanshui, China",
                    "Guizhou Xinjie Qianxun Software Service Company Ltd, Liupanshui, China"
                ]
            },
            {
                "name": "Zhifang Liu",
                "labs": [
                    "Institute of Computer Science, Liupanshui Normal University, Liupanshui, China"
                ]
            },
            {
                "name": "Xingying Huo",
                "labs": [
                    "Institute of Computer Science, Liupanshui Normal University, Liupanshui, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Optimization",
                "Deep learning",
                "Convolutional neural networks",
                "Support vector machines",
                "Text mining",
                "Machine learning algorithms",
                "China"
            ],
            "Author Keywords": [
                "Chinese short text",
                "six-granularity",
                "weights",
                "data sparsity"
            ]
        }
    },
    {
        "Title": "Moth Flame Optimization With Hybrid Deep Learning Based Sentiment Classification Toward ChatGPT on Twitter",
        "Link": "https://ieeexplore.ieee.org/document/10251500/",
        "Abstract": "ChatGPT, developed by OpenAI, is an advanced language model that excels at generating human-like text responses in conversational settings. As ChatGPT interacts with the user, it creates a range of sentiments from them, involving neutral, positive, or negative expressions. Sentiment analysis (SA), also called opinion mining, is a branch of natural language processing (NLP) that defines the emotional tone or sentiment conveyed in textual data. Sentiment analysis (SA) plays a major role in understanding how people respond and perceive different entities, involving services, products, brands, or artificial intelligence (AI) models GPT. Analyzing the sentiment toward ChatGPT gives valuable insight into, user experience, areas, and satisfaction for development. The study presents a moth flame optimization with hybrid deep learning-based sentiment analysis (MFOHDL-SA) on ChatGPT. The major aim of the MFOHDL-SA method is to design an automated AI model to properly classify the tweets as positive, negative, or neutral in sentiment towards ChatGPT. To accomplish this, the MFOHDL-SA technique initially pre-processes the tweets in different stages. Next, the TF-IDF model is used for the word embedding process. Moreover, the HDL method comprising a convolutional neural network with long short-term memory (CNN-LSTM) method was utilized for sentiment classification. To improve the classifier results of the HDL model, the MFO algorithm is used for hyperparameter tuning. The simulation results of the MFOHDL-SA technique are validated on the Twitter dataset from the Kaggle repository. The obtained experimental outcomes stated the betterment of the MFOHDL-SA approach over other existing techniques in terms of different measures. This provides a valued understanding of public sentiment towards ChatGPT on Twitter, allowing improved understanding and assessment of its impact and perception among users.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3315609",
            "Date of Publication": "14 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Aljebreen",
                "labs": [
                    "Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Bayan Alabduallah",
                "labs": [
                    "Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mashael M. Asiri",
                "labs": [
                    "Department of Computer Science, College of Science and Art at Mahayil, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed S. Salama",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering and Technology, Future University in Egypt, New Cairo, Egypt"
                ]
            },
            {
                "name": "Mohammed Assiri",
                "labs": [
                    "Department of Computer Science, College of Sciences and Humanities-Aflaj, Prince Sattam bin Abdulaziz University, Al-Kharj, Al-Aflaj, Saudi Arabia"
                ]
            },
            {
                "name": "Sara Saadeldeen Ibrahim",
                "labs": [
                    "Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Social networking (online)",
                "Artificial intelligence",
                "Blogs",
                "Feature extraction",
                "Sentiment analysis",
                "Emojis"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "ChatGPT",
                "sentiment analysis",
                "deep learning",
                "machine learning",
                "data classification"
            ]
        }
    },
    {
        "Title": "POAT-Net: Parallel Offset-Attention Assisted Transformer for 3D Object Detection for Autonomous Driving",
        "Link": "https://ieeexplore.ieee.org/document/9611257/",
        "Abstract": "3D object detection is playing a key role in the perception process of autonomous driving and industrial robots automation. Inherent characteristics of point cloud raise an enormous challenge to both spatial representation and association analysis. Unordered point cloud spatial data structure and density variations caused by gradually varying distances to LiDAR make accurate and robust 3D object detection even more difficult. In this paper, we present a novel transformer network POAT-Net for 3D point cloud object detection. Transformer is credited with the great success in Natural Language Processing (NLP) and exhibiting inspiring potentials in point cloud processing. Our method POAT-Net is inherently insensitive to element permutations within the unordered point cloud. The associations between local points contribute significantly to 3D object detection or other 3D tasks. Parallel offset-attention is leveraged to highlight and capture subtle associations between local points. To overcome the non-uniform density distribution of different objects, we exploit Normalized multi-resolution Grouping (NMRG) strategy to enhance the non-uniform density adaptive ability for POAT-Net. Quantitative experimental results on KITTI3D dataset demonstrate our method achieves the state-of-the-art performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3127234",
            "Date of Publication": "10 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jinyang Wang",
                "labs": [
                    "Rhinoceros Intelligent Robots Technology Company Ltd., Shanghai, China"
                ]
            },
            {
                "name": "Xiao Lin",
                "labs": [
                    "Department of Computer Science, Shanghai Normal University (SHNU), Shanghai, China"
                ]
            },
            {
                "name": "Hongying Yu",
                "labs": [
                    "Department of Electrical and Control Engineering, North University of China (NUC), Taiyuan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Three-dimensional displays",
                "Feature extraction",
                "Object detection",
                "Natural language processing",
                "Autonomous vehicles",
                "Laser radar"
            ],
            "Author Keywords": [
                "3D object detection",
                "non-uniform density",
                "parallel offset-attention",
                "point cloud",
                "transformer"
            ]
        }
    },
    {
        "Title": "Opinion Mining from Online Travel Reviews: An Exploratory Investigation on Pakistan Major Online Travel Services Using Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10077573/",
        "Abstract": "Online tourism evaluations are a valuable origin of data for traveler organizations, defining as they could be excellently recognized critically prompting traveler opinion-designing using opinion mining. As technology advanced, online review forums of any organization become an attractive source of communication with them, where people can share their views in the form of comments. The main determination of this research article is to recognize normal topics and connect them to contrasts in web-based travel reviews. Online millions of reviews, got from two significant web-based travel organizations (Uber, and Careem) in Pakistan, and a semantic affiliation examination was utilized to extract thematic words and construct a semantic affiliation organization. In the Python programming language, we use natural language processing (NLP), which includes data cleansing and tokenization. The results of network visualization are able to evidently recognize main topics and thematic words with social network associations. The proposed logical system extends our grip on the strategic complications and gives new points of view on the best way to dig popular assessments to assist vacationers, inns, and travel industry organizations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3260114",
            "Date of Publication": "21 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bushra Kanwal",
                "labs": [
                    "School of Software Engineering, Beijing University of Technology, Beijing, China",
                    "University Institute of Information Technology (UIIT), Arid Agriculture University, Rawalpindi, Pakistan"
                ]
            },
            {
                "name": "Saif Ur Rehman",
                "labs": [
                    "University Institute of Information Technology (UIIT), Arid Agriculture University, Rawalpindi, Pakistan"
                ]
            },
            {
                "name": "Azhar Imran",
                "labs": [
                    "Department of Creative Technologies, Faculty of Computing and AI, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Rana Saud Shaukat",
                "labs": [
                    "University Institute of Information Technology (UIIT), Arid Agriculture University, Rawalpindi, Pakistan"
                ]
            },
            {
                "name": "Jianqiang Li",
                "labs": [
                    "School of Software Engineering, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Abdulkareem Alzahrani",
                "labs": [
                    "Faculty of Computer Science and Information Technology, Al Baha University, Al Baha, Saudi Arabia"
                ]
            },
            {
                "name": "Ans D. Alghamdi",
                "labs": [
                    "Faculty of Computer Science and Information Technology, Al Baha University, Al Baha, Saudi Arabia"
                ]
            },
            {
                "name": "Fawaz Khaled Alarfaj",
                "labs": [
                    "College of Computer Sciences and Information Technology, King Faisal University, Al-Ahsa, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Social networking (online)",
                "Sentiment analysis",
                "Companies",
                "Information technology",
                "Technological innovation",
                "Online services",
                "Tourism industry",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Opinion mining",
                "online travel reviews",
                "social network association",
                "thematic words",
                "natural language processing",
                "sentiment analysis"
            ]
        }
    },
    {
        "Title": "Methodology for Code Synthesis Evaluation of LLMs Presented by a Case Study of ChatGPT and Copilot",
        "Link": "https://ieeexplore.ieee.org/document/10535504/",
        "Abstract": "Large Language Models (LLMs) have grown in popularity in recent years and are now employed in a variety of software engineering domains thanks to their Natural Language Processing (NLP) capabilities, which include source code generation, understanding, and documentation. Selecting the appropriate model for source code generation presents a problem to developers as more and more powerful LLMs become available. While some studies have evaluated Copilot or ChatGPT, there is a lack of research on how developers can choose from available LLMs, which is a key factor in the growing set of available models and services. It is crucial to know if a model is capable of generating useful source code that meets the quality requirements and if the developers will be able to use the generated code. Regarding these factors, one has to decide which model to utilize during everyday tasks. This paper shows a methodology to compare such models by demonstrating an actual comparison of two models. Subsequently, we investigated the functional and non-functional qualities of the code synthesized by the models on a program synthesis benchmark containing 25 tasks. On average, the functional testing shows that ChatGPT generated 17 perfect solutions, while Copilot could only solve 13. The non-functional analysis reflected that both models generated good quality code, however, both have characteristic code smells. Our evaluation shows that ChatGPT performs better using this methodology, which is supported by human reviewers who evaluated the generated code by hand.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3403858",
            "Date of Publication": "21 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zoltán Ságodi",
                "labs": [
                    "Department of Software Engineering, University of Szeged, Szeged, Hungary",
                    "FrontEndART Software Ltd., Szeged, Hungary"
                ]
            },
            {
                "name": "István Siket",
                "labs": [
                    "Department of Software Engineering, University of Szeged, Szeged, Hungary",
                    "FrontEndART Software Ltd., Szeged, Hungary"
                ]
            },
            {
                "name": "Rudolf Ferenc",
                "labs": [
                    "Department of Software Engineering, University of Szeged, Szeged, Hungary"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Codes",
                "Source coding",
                "Chatbots",
                "Task analysis",
                "Static analysis",
                "C++ languages",
                "Analytical models",
                "Artificial intelligence",
                "Large language models"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "copilot",
                "ChatGPT",
                "code-synthesis",
                "code quality",
                "large language models",
                "model selection"
            ]
        }
    },
    {
        "Title": "Jointly Detecting and Extracting Social Events From Twitter Using Gated BiLSTM-CRF",
        "Link": "https://ieeexplore.ieee.org/document/8866717/",
        "Abstract": "In this article, we focus on the problem of social event extraction from Twitter, in which event detection, i.e., to identify which messages truly mention events of interest, is an indispensable step due to the fact that most Twitter messages, viz. tweets, are not related to any real-world event. Existing approaches to this problem often use pipelined architectures relying on some hand-crafted features derived using off-the-shelf natural language processing (NLP) tools, which may cause error propagation from the upstream component (event detection) to the downstream one (element extraction) and fail to leverage the interdependencies between them. To overcome these limitations, we propose a deep neural network based framework to Jointly Detect and Extract Events from Twitter (JDEET), which learns, as well as conducts, detection and extraction simultaneously by defining a joint loss function, a bidirectional long short-term memory (LSTM) based common representation layer, and a control gate. A conditional random field (CRF) layer is further employed to capture the strong dependencies among output labels. Experimental results show that the proposed approach outperforms the state-of-the-art ones considerably on a real-world dataset from Twitter.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2947027",
            "Date of Publication": "11 October 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Meng Xu",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Xin Zhang",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            },
            {
                "name": "Lixiang Guo",
                "labs": [
                    "Science and Technology on Information Systems Engineering Laboratory, National University of Defense Technology, Changsha, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Event detection",
                "Blogs",
                "Neural networks",
                "Semantics",
                "Logic gates",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Event extraction",
                "social events",
                "Twitter",
                "joint models",
                "a control gate",
                "deep neural networks"
            ]
        }
    },
    {
        "Title": "Jointly Extract Entities and Their Relations From Biomedical Text",
        "Link": "https://ieeexplore.ieee.org/document/8893999/",
        "Abstract": "Entity recognition and relation extraction have become an important part of knowledge acquisition, and which have been widely applied in various fields, such as Bioinformatics. However, prior state-of-the-art extraction models heavily rely on the external features obtained from hand-craft or natural language processing (NLP) tools. As a result, the performance of models depends directly on the accuracy of the obtained features. Moreover, current joint extraction approaches cannot effectively tackle the multi-head problem (i.e. an entity is related to multiple entities). In this paper, we firstly present a novel tagging scheme and then propose a joint approach based deep neural network for producing unique tagging sequences. Our approach can not only simultaneously perform entity resolution and relation extraction without any external features, but also effectively solve the multi-head problem. Besides, since arbitrary tokens may provide important cues for two components, we exploit self-attention to explicitly capture long-range dependencies among them and character embeddings to learn the features of lexical morphology, which make our method less susceptible to cascading errors. The results demonstrate that the joint method proposed outperforms the other state-of-the-art joint models. Our work is beneficial for biomedical text mining, and the construction of the biomedical knowledge base.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2952154",
            "Date of Publication": "07 November 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jizhi Chen",
                "labs": [
                    "Computer Science and Technology, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Junzhong Gu",
                "labs": [
                    "Computer Science and Technology, East China Normal University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Tagging",
                "Drugs",
                "Biological system modeling",
                "Neural networks",
                "Data mining"
            ],
            "Author Keywords": [
                "Bioinformatics",
                "entity recognition",
                "knowledge acquisition",
                "neural networks",
                "relation extraction",
                "text mining"
            ]
        }
    },
    {
        "Title": "Automated Smell Detection and Recommendation in Natural Language Requirements",
        "Link": "https://ieeexplore.ieee.org/document/10418899/",
        "Abstract": "Requirement specifications are typically written in natural language (NL) due to its usability across multiple domains and understandability by all stakeholders. However, unstructured NL is prone to quality problems (e.g., ambiguity) when writing requirements, which can result in project failures. To address this issue, we present a tool, named Paska, that takes as input any NL requirements, automatically detects quality problems as smells in the requirements, and offers recommendations to improve their quality. Our approach relies on natural language processing (NLP) techniques and a state-of-the-art controlled natural language (CNL) for requirements (Rimay), to detect smells and suggest recommendations using patterns defined in Rimay to improve requirement quality. We evaluated Paska through an industrial case study in the financial domain involving 13 systems and 2725 annotated requirements. The results show that our tool is accurate in detecting smells (89% precision and recall) and suggesting appropriate Rimay pattern recommendations (96% precision and 94% recall).",
        "Details": {
            "DOI": "10.1109/TSE.2024.3361033",
            "Date of Publication": "01 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Software Engineering"
        },
        "issn_info": {
            "Print ISSN": "0098-5589",
            "Electronic ISSN": "1939-3520"
        },
        "authors_data": [
            {
                "name": "Alvaro Veizaga",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Luxembourg, Luxembourg"
                ]
            },
            {
                "name": "Seung Yeob Shin",
                "labs": [
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Luxembourg, Luxembourg"
                ]
            },
            {
                "name": "Lionel C. Briand",
                "labs": [
                    "Lero SFI Centre for Software Research, University of Limerick, Limerick, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Syntactics",
                "Grammar",
                "Software",
                "Information systems",
                "Stakeholders",
                "Ear",
                "Usability"
            ],
            "Author Keywords": [
                "Requirement smells",
                "requirement quality",
                "smell detection and recommendation",
                "natural language processing",
                "and controlled natural language"
            ]
        }
    },
    {
        "Title": "Emotion Processing by Applying a Fuzzy-Based Vader Lexicon and a Parallel Deep Belief Network Over Massive Data",
        "Link": "https://ieeexplore.ieee.org/document/9863839/",
        "Abstract": "Emotion processing has been a very intense domain of investigation in data analysis and NLP during the previous few years. Currently, the algorithms of the deep neural networks have been applied for opinion mining tasks with good results. Among various neuronal models applied for opinion mining a deep belief network (DBN) model has gained more attention. In this proposal, we have developed a combined classifier based on fuzzy Vader lexicon and a parallel deep belief network for emotion analysis. We have implemented multiple pretreatment techniques to improve the quality and soundness of the data and eliminate disturbing data. Afterward, we have performed a semi-automatic dataset labeling using a combination of two different methods: Mamdani’s fuzzy system and Vader lexicon. As well, we have applied four feature extractors, which are: GloVe, TFIDF (Trigram), TFIDF (Bigram), TFIDF (Unigram) with the aim of transforming each incoming tweet into a digital value vector. In addition, we have integrated three feature selectors, namely: The ANOVA method, the chi-square approach and the mutual information technique with the objective of selecting the most relevant features. Further, we have implemented the DBN as classifier for classifying each inputted tweet into three categories: neutral, positive or negative. At the end, we have deployed our proposed approach in parallel way employing both Hadoop and Spark framework with the purpose of overcoming the problem of long runtime of massive data. Furthermore, we have carried out a comparison between our newly suggested hybrid approach and alternative hybrid models available in the literature. From the experimental findings, it was found that our suggested vague parallel approach is more powerful than the baseline patterns in terms of false negative rate (1.33%), recall (99.75%), runtime (32.95s), convergence, stability, F1 score (99.53%), accuracy (98.96%), error rate (1.04%), kappa-Static (99.1%), complexity, false positive rate (0.25%), precision rate (97.59%) and specificity rate (98.67%). As a conclusion, our vague parallel approach outperforms baseline and deep learning models, as well as certain other approaches chosen from the literature.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3200389",
            "Date of Publication": "19 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatima Es-Sabery",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Ibrahim Es-Sabery",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Abdellatif Hair",
                "labs": [
                    "Department of Computer Science, Faculty of Sciences and Technology, Sultan Moulay Slimane University, Beni Mellal, Morocco"
                ]
            },
            {
                "name": "Beatriz Sainz-De-Abajo",
                "labs": [
                    "Department of Signal Theory, Communications and Telematics Engineering, University of Valladolid, Valladolid, Spain"
                ]
            },
            {
                "name": "Begonya Garcia-Zapirain",
                "labs": [
                    "EVIDA Research Group, University of Deusto, Bilbao, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Social networking (online)",
                "Blogs",
                "Runtime",
                "Proposals",
                "Sentiment analysis",
                "Fuzzy systems",
                "Neural networks",
                "Deep learning"
            ],
            "Author Keywords": [
                "Hadoop",
                "sentiment analysis",
                "extractors of features",
                "HDFS",
                "selectors of features",
                "MapReduce",
                "fuzzy logic",
                "deep belief neural network"
            ]
        }
    },
    {
        "Title": "Ensemble Transfer Learning on Augmented Domain Resources for Oncological Named Entity Recognition in Chinese Clinical Records",
        "Link": "https://ieeexplore.ieee.org/document/10196443/",
        "Abstract": "Biomedical Named Entity Recognition (NER) is a crucial task in Natural Language Processing (NLP) and can help mine knowledge from massive clinical and diagnostic records. However, the biomedical NER task often undergoes a low-resource training setting due to the high cost of human annotation, limiting the capability of traditional NER models. In this study, we propose a two-stage learning pipeline to tackle the oncological NER task in Chinese language, which is a typical task lacking training resources. In the first stage, two base models pre-trained by Word to Vector (Word2Vec) and Bidirectional Embeddings Representations from Transformer (BERT) are fine tuned to obtain domains-specific word embeddings that serve as the input for the downstream NER task. In the second stage, we feed the word embeddings into a neural network that consists of a Bidirectional Long and Short Time Memory Recurrent Neural Network (BiLSTM) and Linear-chain Conditional Random Field (CRF) for end task training. Meanwhile, we utilize a substitution-based generative model for data augmentation (DA), aiming to enhance the quantity and diversity of the training data. Experiments show that our proposed learning pipeline demonstrates superior performance compared to other model alternatives under a low-resource setting. Specifically, results show that the proposed fine-tuning strategy, when conducted on an augmented domain resource, can effectively incorporate rich domain knowledge into the final NER model, presenting a great potential in boosting a model’s predictive power with limited training data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3299824",
            "Date of Publication": "28 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Meifeng Zhou",
                "labs": [
                    "Department of Oncology, Hainan General Hospital (Hainan Affiliated Hospital of Hainan Medical University), Hainan, Haikou, China"
                ]
            },
            {
                "name": "Jindian Tan",
                "labs": [
                    "Department of Orthopaedic Surgery, Hainan General Hospital (Hainan Affiliated Hospital of Hainan Medical University), Hainan, Haikou, China"
                ]
            },
            {
                "name": "Song Yang",
                "labs": [
                    "Department of Orthopaedic Surgery, Hainan General Hospital (Hainan Affiliated Hospital of Hainan Medical University), Hainan, Haikou, China"
                ]
            },
            {
                "name": "Haixia Wang",
                "labs": [
                    "Department of Oncology, Hainan General Hospital (Hainan Affiliated Hospital of Hainan Medical University), Hainan, Haikou, China"
                ]
            },
            {
                "name": "Lin Wang",
                "labs": [
                    "Department of Oncology, Hainan General Hospital (Hainan Affiliated Hospital of Hainan Medical University), Hainan, Haikou, China"
                ]
            },
            {
                "name": "Zhifeng Xiao",
                "labs": [
                    "School of Engineering, Penn State Erie, The Behrend College, Erie, PA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Context modeling",
                "Computational modeling",
                "Diseases",
                "Surgery",
                "Semantics",
                "Bit error rate",
                "Cancer detection",
                "Deep learning",
                "Oncology",
                "Bone diseases"
            ],
            "Author Keywords": [
                "BERT",
                "cancer",
                "deep learning",
                "named entity recognition",
                "oncology",
                "osteosarcoma",
                "Word2Vec"
            ]
        }
    },
    {
        "Title": "Conspiracy or Not? A Deep Learning Approach to Spot It on Twitter",
        "Link": "https://ieeexplore.ieee.org/document/9750122/",
        "Abstract": "Sentiment analysis is an active topic in Natural Language Processing (NLP). It has attracted a significant interest of research community due to the wide range of applications, including social-media, fake news spotting and interactive applications. In this paper, we present a novel approach for semi-automatic background creation and conspiracy classification. For this purpose, a complete framework including novel recurrent models is proposed. The BORJIS: Best algorithm foR Joint conspiracy and sarcasm detection has been tested on twitter-crawled data and It is composed by:\n(a)\nthe crawler and labelling module,\n(b)\nthe features vector extraction and\n(c)\nthe conspiracy classifier. BORJIS was compared with up-to-date techniques and it showed a significant improvement (≥ 10% accuracy) when applied to diverse datasets.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3165226",
            "Date of Publication": "06 April 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Borja Arroyo Galende",
                "labs": [
                    "Visual Telecommunications Application Group, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Gustavo Hernández-Peñaloza",
                "labs": [
                    "Visual Telecommunications Application Group, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Silvia Uribe",
                "labs": [
                    "Visual Telecommunications Application Group, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            },
            {
                "name": "Federico Álvarez García",
                "labs": [
                    "Visual Telecommunications Application Group, Universidad Politécnica de Madrid, Madrid, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Fake news",
                "Feature extraction",
                "Deep learning",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Fake news detection",
                "natural language processing",
                "sentiment analysis",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Crowdsourced Test Report Prioritization Based on Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/9617598/",
        "Abstract": "In crowdsourced testing, crowd workers from different places help developers conduct testing and submit test reports for the observed abnormal behaviors. Developers manually inspect each test report and make an initial decision for the potential bug. However, due to the poor quality, test reports are handled extremely slowly. Meanwhile, due to the limitation of resources, some test reports are not handled at all. Therefore, some researchers attempt to resolve the problem of test report prioritization and have proposed many methods. However, these methods do not consider the impact of duplicate test reports. In this paper, we focus on the problem of test report prioritization and present a new method named DivClass by combining a diversity strategy and a classification strategy. First, we leverage Natural Language Processing (NLP) techniques to preprocess crowdsourced test reports. Then, we build a similarity matrix by introducing an asymmetric similarity computation strategy. Finally, we combine the diversity strategy and the classification strategy to determine the inspection order of test reports. To validate the effectiveness of DivClass, experiments are conducted on five crowdsourced test report datasets. Experimental results show that DivClass achieves 0.8887 in terms of APFD (Average Percentage of Fault Detected) and improves the state-of-the-art technique DivRisk by 14.12% on average. The asymmetric similarity computation strategy can improve DivClass by 4.82% in terms of APFD on average. In addition, empirical results show that DivClass can greatly reduce the number of inspected test reports.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3128726",
            "Date of Publication": "16 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yuxuan Yang",
                "labs": [
                    "School of Computer Science, Hangzhou Dianzi University, Hangzhou, China"
                ]
            },
            {
                "name": "Xin Chen",
                "labs": [
                    "School of Computer Science, Hangzhou Dianzi University, Hangzhou, China",
                    "Key Laboratory of Safety-Critical Software, Nanjing University of Aeronautics and Astronautics, Ministry of Industry and Information Technology, Nanjing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Diversity reception",
                "Software",
                "Inspection",
                "Task analysis",
                "Software testing",
                "Smart phones"
            ],
            "Author Keywords": [
                "Crowdsourced testing",
                "test report prioritization",
                "text classification",
                "diversity strategy",
                "asymmetric similarity"
            ]
        }
    },
    {
        "Title": "MSnet: Multi-Head Self-Attention Network for Distantly Supervised Relation Extraction",
        "Link": "https://ieeexplore.ieee.org/document/8698900/",
        "Abstract": "Distant supervision for relation extraction is a task of recognizing semantic relations between entities in a large amount of plain text weakly supervised by external knowledge bases, which can benefit many NLP applications, such as knowledge graph completion and question answering. While it significantly alleviates the expensive cost for data labeling, it severely suffers from noisy labels. In this paper, we propose a Multi-head Self-attention Network (MSNet)-based label denoising method for relation extraction. More specifically, we encode the words, entities and their positions information into contextual embeddings via a multi-head self-attention mechanism, then extract the discriminative sentence features with max pooling operation. MSNet can capture the inherent structure of a sentence and model the relatedness between two words without regard to their distance. Moreover, we adopt a novel label confidence learning method to correct the noisy labels. A latent label is predicted step by step during training as the ground-truth according to a curriculum function of label confidence. This label denoising mechanism gradually incorporates the obtained latent label of easy relation patterns into later latent label prediction of hard patterns, which makes latent label consistent learning more reliable. To verify the effectiveness of our proposed method, in addition to the widely used PCNN-based architecture, we also perform the experiment on BiLSTM model as a comparison. The results demonstrate that our approach can outperform the state-of-the-art systems on the popular evaluation dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2913316",
            "Date of Publication": "25 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tingting Sun",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Chunhong Zhang",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yang Ji",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Zheng Hu",
                "labs": [
                    "State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Noise reduction",
                "Noise measurement",
                "Task analysis",
                "Training",
                "Labeling",
                "Learning systems"
            ],
            "Author Keywords": [
                "Relation extraction",
                "distant supervision",
                "multi-head self-attention",
                "label denoising"
            ]
        }
    },
    {
        "Title": "Artificial Intelligence for Quality of Life Study: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/10510439/",
        "Abstract": "The concept of “quality of life” (QoL) encompasses all aspects of people’s standard of living, including economic, social, or health-related factors, as well as their perceptions of their own lives. Although the growing application of Artificial Intelligence (AI) and Machine Learning (ML) techniques in processing and modeling the diverse datasets associated with these domains, there remains a significant challenge in addressing different issues in QoL area of research and in fully harnessing these technologies to improve QoL research outcomes. Despite the technological advancements, current research endeavors often overlook the complex, multifaceted nature of QoL study. This oversight results in fragmented insights and leaves significant areas underexplored. In this work, we conducted a systematic literature review (SLR) to investigate the contribution of AI to QoL studies. For this, we collected 68 research works published between 2008 and 2022. This review covers a range of research questions about the objectives and methods of studies on QoL, the sources and types of data utilized, and the advancements made through the application of natural language processing (NLP), ML, deep learning (DL), statistical models, and semantic approaches. The goal of this review is to tackle the prevalent ambiguity in QoL dimensions, synthesize the research findings, and highlight the contributions, advancements, and most innovative approaches in the field. Moreover, we identify gaps and limitations in the current literature and suggest potential areas for future research, aiming to inspire more cohesive and comprehensive approaches to studying QoL using AI and ML techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3395369",
            "Date of Publication": "30 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ayoub Jannani",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Nawal Sael",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Faouzia Benabbou",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Reviews",
                "Social networking (online)",
                "Systematics",
                "Correlation",
                "Prediction algorithms",
                "Data models",
                "Machine learning",
                "Deep learning",
                "Natural language processing",
                "Ontologies",
                "Quality assessment",
                "Behavioral sciences",
                "Psychology"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "machine learning",
                "deep learning",
                "natural language processing",
                "ontology",
                "quality of life",
                "well-being",
                "happiness"
            ]
        }
    },
    {
        "Title": "An Incremental Approach to Corpus Design and Construction: Application to a Large Contemporary Saudi Corpus",
        "Link": "https://ieeexplore.ieee.org/document/9458313/",
        "Abstract": "Due to the rapid developments in technology and the sudden expansion of social media use, Dialect Arabic has become an important source of data that needs to be addressed when building Arabic corpora. In this paper, thirty-three Arabic corpora are surveyed to show that despite all of the developments in the literature, Saudi dialect (SD) corpora still need further expansion. This paper contributes to the literature on SD corpora by creating the largest Saudi corpus - the King Saud University Saudi Corpus (KSUSC) - with +1B total words, including +119M SD words. The KSUSC not only is the newest and largest SD corpus but is also diverse, covering 26 domains in text collected from five different sources. This paper also contributes to the literature by developing a new incremental preprocessing system that is used to create relevant lexicons that are then used to clean and normalize the collected data. This incremental system is scalable and can be adapted for different resources and dialects. Moreover, the collection process for building the KSUSC is discussed in detail, and the challenges in collecting SD text with respect to each platform are highlighted. By the end of this paper, different design criteria are proposed and used with the KSUSC to conclude that the resulting corpus can be of great benefit to researchers who are interested in integrating the corpus with their own work or using its resulting lexicons with Saudi-based NLP tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3089924",
            "Date of Publication": "17 June 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hebah Elgibreen",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Information Technology, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammed Faisal",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "College of Applied Computer Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mansour Al Sulaiman",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Sherif Abdou",
                "labs": [
                    "Department of Information Technology, Faculty of Computers and Artificial Intelligence, Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Mohamed Amine Mekhtiche",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdullah M. Moussa",
                "labs": [
                    "Department of Information Technology, Faculty of Computers and Artificial Intelligence, Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Yousef A. Alohali",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Wadood Abdul",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ghulam Muhammad",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohsen Rashwan",
                "labs": [
                    "Department of Electronics and Electrical Communications, Faculty of Engineering, Cairo University, Giza, Egypt"
                ]
            },
            {
                "name": "Mohammed Algabri",
                "labs": [
                    "Center of Smart Robotics Research, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Information science",
                "Task analysis",
                "Tools",
                "Standards",
                "Sentiment analysis"
            ],
            "Author Keywords": [
                "Saudi dialect",
                "corpus",
                "natural language processing",
                "data preprocessing"
            ]
        }
    },
    {
        "Title": "Using a Language Model to Generate Music in Its Symbolic Domain While Controlling Its Perceived Emotion",
        "Link": "https://ieeexplore.ieee.org/document/10138187/",
        "Abstract": "This work proposes a transformer-based model capable of generating music in its symbolic domain, in a controllable fashion. The ultimate goal of this is to build a system with which people can compose music collaboratively with a computer. Using an NLP model as a base (GPT-2), we take advantage of the similarities across symbolic music representation and written language to build a model capable of conditionally predicting musical sequences. Controllability is achieved without explicit programming for it, and does not require extensive retraining of the model. A study with 939 participants was performed to evaluate this controllability. The results of this suggest the proposed method is indeed effective and can be used to control the generation of music in its symbolic domain. The method itself is flexible to any desired “control”, but this work focuses specifically on the emotion conveyed when one listens to a piece of music.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3280603",
            "Date of Publication": "29 May 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Naomi Imasato",
                "labs": [
                    "Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            },
            {
                "name": "Kazuki Miyazawa",
                "labs": [
                    "Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            },
            {
                "name": "Caitlin Duncan",
                "labs": [
                    "Graduate School of Engineering Science, Osaka University, Osaka, Japan"
                ]
            },
            {
                "name": "Takayuki Nagai",
                "labs": [
                    "Graduate School of Engineering Science, Osaka University, Osaka, Japan",
                    "Artificial Intelligence Exploration Research Center, The University of Electro-Communications, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Deep learning",
                "Predictive models",
                "Data models",
                "Computational modeling",
                "Artificial intelligence",
                "Computer generated music",
                "Music"
            ],
            "Author Keywords": [
                "AI music composition",
                "controlled music generation",
                "deep learning",
                "language model",
                "autoregressive model"
            ]
        }
    },
    {
        "Title": "Bandwidth Allocation and Power Control Optimization for Multi-UAVs Enabled 6G Network",
        "Link": "https://ieeexplore.ieee.org/document/10520245/",
        "Abstract": "In this paper, we undertake an examination of the complicated challenges associated with bandwidth allocation and power control in multi- unmanned aerial vehicles (UAVs) network. The focal point of our investigation is the formulation and subsequent proposition of a novel algorithm aimed at optimizing bandwidth utilization and energy efficiency across multiple UAVs. The intricate joint optimization problem is cast as a nontrivial nonlinear programming (NLP) challenge; thus, to efficiently address it, we split it into two subproblems. In the first sub-problem, UAVs bandwidth resources are being optimized while considering that they are operating at their maximum transmit powers. In the second sub-problem and after optimizing bandwidth allocations, UAVs transmit powers are optimized based on their inter-links speed. Sequential quadratic programing (SQP) based on coloring graph representation is proposed to address the first sub-problem, while\nM\n- matrix theory is employed to address the second one. Rigorous numerical simulations are conducted to prove the effectiveness of the proposed scheme against other benchmarks in maximizing both data rate and energy efficiency of the proposed multi-UAV network.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3397165",
            "Date of Publication": "06 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Ahmed Alnakhli",
                "labs": [
                    "Department of Electrical Engineering, College of Engineering in Wadi Addwasir, Prince Sattam bin Abdulaziz University, Wadi ad-Dawasir, Saudi Arabia"
                ]
            },
            {
                "name": "Ehab Mahmoud Mohamed",
                "labs": [
                    "Department of Electrical Engineering, College of Engineering in Wadi Addwasir, Prince Sattam bin Abdulaziz University, Wadi ad-Dawasir, Saudi Arabia"
                ]
            },
            {
                "name": "Mostafa M. Fouda",
                "labs": [
                    "Department of Electrical and Computer Engineering, Idaho State University, Pocatello, ID, USA",
                    "Center for Advanced Energy Studies (CAES), Idaho Falls, ID, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autonomous aerial vehicles",
                "Power control",
                "Optimization",
                "Channel allocation",
                "6G mobile communication",
                "Resource management",
                "Three-dimensional displays",
                "Energy efficiency"
            ],
            "Author Keywords": [
                "6G",
                "multi-UAVs",
                "spectrum efficiency",
                "energy efficiency",
                "SQP",
                "M-matrix"
            ]
        }
    },
    {
        "Title": "Automated Image Captioning Using Sparrow Search Algorithm With Improved Deep Learning Model",
        "Link": "https://ieeexplore.ieee.org/document/10256186/",
        "Abstract": "Image captioning is a deep learning technique that intends to create and generate textual descriptions or captions for images. It integrates computer vision and natural language processing (NLP) to comprehend the visual content of an image and generate human-like descriptions. Deep learning (DL) based image captioning models can be trained on large-scale datasets, allowing them to generalize various types of images and generate captions that apply to a wide range of visual scenarios. By combining computer vision and natural language processing, DL-enabled image captioning models can understand both visual and textual information, which enables them to generate captions that not only describe the visual content but also incorporate contextual and semantic information. This study develops an Automated Image Captioning using Sparrow Search Algorithm with Improved Deep Learning (AIC-SSAIDL) technique. The major intention of the AIC-SSAIDL technique lies in the automated generation of textual captions for the input images. To accomplish this, the AIC-SSAIDL technique utilizes the MobileNetv2 model to generate feature descriptors of the input images and its hyperparameter tuning process takes place using SSA. For the image captioning process, the AIC-SSAIDL technique utilizes an attention mechanism with long short-term memory (AM-LSTM) network. Finally, the hyperparameter selection of the AM-LSTM model is performed by the fruit fly optimization (FFO) algorithm. A wide range of experiments has been conducted on benchmark data to depict the better performance of the AIC-SSAIDL method. The comprehensive result analysis highlighted the enhanced captioning results of the AIC-SSAIDL method with maximum CIDEr of 46.12, 61.89, and 137.45 on Flickr8k, Flickr30k, and MSCOCO datasets, respectively.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3317276",
            "Date of Publication": "20 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Munya A. Arasi",
                "labs": [
                    "Department of Computer Science, College of Science and Arts in Rijal Almaa, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Haya Mesfer Alshahrani",
                "labs": [
                    "Department of Information Systems, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Nuha Alruwais",
                "labs": [
                    "Department of Computer Science and Engineering, College of Applied Studies and Community Services, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdelwahed Motwakel",
                "labs": [
                    "Department of Management Information Systems, College of Business Administration Hawtat Bani Tamim, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            },
            {
                "name": "Noura Abdelaziz Ahmed",
                "labs": [
                    "Department of Computer and Self Development, Preparatory Year Deanship, Prince Sattam bin Abdulaziz University, Al-Kharj, Saudi Arabia"
                ]
            },
            {
                "name": "Abdullah Mohamed",
                "labs": [
                    "Research Centre, Future University in Egypt, New Cairo, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Convolutional neural networks",
                "Visualization",
                "Feature extraction",
                "Convolution",
                "Deep learning",
                "Natural language processing",
                "Computational modeling",
                "Image capture",
                "Search methods"
            ],
            "Author Keywords": [
                "Image captioning",
                "deep learning",
                "natural language processing",
                "sparrow search algorithm",
                "computer vision"
            ]
        }
    },
    {
        "Title": "An Experimental Analysis of Deep Neural Network Based Classifiers for Sentiment Analysis Task",
        "Link": "https://ieeexplore.ieee.org/document/10100712/",
        "Abstract": "The application of natural language processing (NLP) in sentiment analysis task by using textual data has wide scale application across various domains in plethora of industries. We have methodically studied pre-existing models and proposed new models for examining sentiment analysis task. The models proposed were analysed with three widely popular word embeddings separately and in combined approach using all embeddings as unique channels. We combined deep neural network models such as Bidirectional Long Short-Term Memory (BiLSTM) and Convolutional Neural Network (CNN) so that integrated models complement each other with their unique architectures. The word embeddings used had profound impact in accuracy of models owing to performative changes. The best word embedding was Word2Vec giving highest accuracy in almost all implemented models, followed by GloVe. FastText embedding performed consistently worse, giving much lower accuracy than other embeddings. We also observed that adding transformer encoder layers with CNN improves accuracy by 2% when compared to CNN without any transformer layers. An accuracy improvement of 2-3% over CNN-BiLSTM model was also observed by utilizing transformer encoder layer in conjunction with both BiLSTM and CNN. The proposed model achieved an accuracy of 89.04% on SST-2 dataset. We also compared larger pretrained language model used in sentiment analysis task with our proposed approach. The accuracy values obtained through combination of embeddings and models can be useful for other researchers when selecting word embeddings for their models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3266640",
            "Date of Publication": "12 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mrigank Shukla",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Akhil Kumar",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Convolutional neural networks",
                "Sentiment analysis",
                "Analytical models",
                "Task analysis",
                "Transformers",
                "Computational modeling",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "deep learning",
                "natural language processing",
                "word embeddings",
                "text classification"
            ]
        }
    },
    {
        "Title": "Trajectory Optimization and Finite-Time Control for Unmanned Helicopters Formation",
        "Link": "https://ieeexplore.ieee.org/document/8758819/",
        "Abstract": "A safe and rapid formation generation is of great importance for the cooperation performance of the multiple unmanned helicopters. The trajectory optimization and control is the key problem in the process of the formation generation. To achieve this goal, a novel safe formation generation strategy is proposed through trajectory optimization and tracking control. First, the rapidly-exploring random tree (RRT) algorithm is applied to obtain the initial guess to satisfy the requirement of rapid solution. Then, the Gauss pseudospectral method is used to transform the optimal control problem to the nonlinear programming (NLP) problem and the sequence quadratic programming (SQP) method is utilized to gain the optimal trajectory combined with the initial guess. Second, a finite-time sliding mode controller is proposed to ensure the finite time trajectory tracking in the presence of model parameter uncertainties and unknown external disturbances. Finally, the numerical simulation is provided to show the effectiveness of the proposed formation generation strategy for unmanned helicopters formation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2927817",
            "Date of Publication": "10 July 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Boyuan Zhang",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Qun Zong",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Liqian Dou",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Bailing Tian",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Dandan Wang",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            },
            {
                "name": "Xinyi Zhao",
                "labs": [
                    "School of Electrical Automation and Information Engineering, Tianjin University, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical switches",
                "Optical waveguides",
                "Wavelength division multiplexing",
                "Optical network units",
                "Optical crosstalk",
                "Optical interconnections"
            ],
            "Author Keywords": [
                "Trajectory optimization",
                "finite-time sliding mode controller",
                "unmanned helicopters formation"
            ]
        }
    },
    {
        "Title": "Word Similarity Datasets for Thai: Construction and Evaluation",
        "Link": "https://ieeexplore.ieee.org/document/8851127/",
        "Abstract": "Distributional semantics in the form of word embeddings are an essential ingredient to many modern natural language processing systems. The quantification of semantic similarity between words can be used to evaluate the ability of a system to perform semantic interpretation. To this end, a number of word similarity datasets have been created for the English language over the last decades. For Thai language few such resources are available. In this work, we create three Thai word similarity datasets by translating and re-rating the popular WordSim-353, SimLex-999 and SemEval-2017-Task-2 datasets. The three datasets contain 1852 word pairs in total and have different characteristics in terms of difficulty, domain coverage, and notion of similarity (relatedness vs. similarity). These features help to gain a broader picture of the properties of an evaluated word embedding model. We include baseline evaluations with existing Thai embedding models, and identify the high ratio of out-of-vocabulary words as one of the biggest challenges in the evaluation process. All datasets, evaluation results, and a tool for easy evaluation of new Thai embedding models are available to the NLP community online.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2944151",
            "Date of Publication": "27 September 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ponrudee Netisopakul",
                "labs": [
                    "Faculty of Information Technology, King Mongkut’s Institute of Technology Ladkrabang (KMITL), Bangkok, Thailand"
                ]
            },
            {
                "name": "Gerhard Wohlgenannt",
                "labs": [
                    "Faculty of Software Engineering and Computer Systems, ITMO University, St. Petersburg, Russia"
                ]
            },
            {
                "name": "Aleksei Pulich",
                "labs": [
                    "Faculty of Software Engineering and Computer Systems, ITMO University, St. Petersburg, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Predictive models",
                "Tools",
                "Software engineering",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Dataset creation",
                "distributional semantics",
                "Thai language",
                "word embeddings",
                "word similarity"
            ]
        }
    },
    {
        "Title": "Effective Natural Language Processing and Interpretable Machine Learning for Structuring CT Liver-Tumor Reports",
        "Link": "https://ieeexplore.ieee.org/document/9933737/",
        "Abstract": "In the past, the liver tumors were reported manually in an unstructured format. There actually exists much valuable knowledge in these reports for further disease risk assessment, disease recognition and treatment recommendation. Yet, it is not easy to read and mine knowledge from the unstructured reports. Hence, how to extract the knowledge from these biomedical reports effectively and efficiently has been a challenging issue in the past decades. Although a set of Natural Language Processing techniques were proposed for Bio-medical information retrieval, few related works were made on transforming the unstructured CT liver-tumor reports into structured ones. To aim at this issue, in this paper, we propose a two-stage report structuring method by integrating effective Natural Language Processing (NLP) and interpretable machine learning. For the first stage, the candidate keywords in unstructured reports are extracted. Next, the feature keywords are determined by the feature-selection technique. For the second stage, the well-known multi-classifiers are performed, and finally the reports are labeled in a refined structure format. Further, the factor keywords in the classification model are filtered to interpret the performance. In overall, the proposed report structuring method generates a hierarchical data structure, including the common features and refined features in the\n1\nst\nand\n2\nnd\nlevels/stages, respectively. To reveal the performance of proposed method, a set of evaluations were conducted and the results show that, the proposed method is more promising than the fashion neural networks such as Bert (Bidirectional Encoder Representations from Transformers) in terms of effectiveness and efficiency.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3218646",
            "Date of Publication": "01 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yi-Hsuan Chuang",
                "labs": [
                    "Liver Transplantation Program, Department of Diagnostic Radiology and Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung University College of Medicine, Niao-Sung, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Ja-Hwung Su",
                "labs": [
                    "Department of Computer Science and Information Engineering, National University of Kaohsiung, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Ding-Hong Han",
                "labs": [
                    "Department of Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Yi-Wen Liao",
                "labs": [
                    "Department of Intelligent Commerce, National Kaohsiung University of Science and Technology, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Yeong-Chyi Lee",
                "labs": [
                    "Department of Information Management, Cheng Shiu University, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Yu-Fan Cheng",
                "labs": [
                    "Liver Transplantation Program, Department of Diagnostic Radiology and Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung University College of Medicine, Niao-Sung, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Tzung-Pei Hong",
                "labs": [
                    "Department of Computer Science and Information Engineering, National University of Kaohsiung, Kaohsiung, Taiwan",
                    "Department of Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Katherine Shu-Min Li",
                "labs": [
                    "Department of Computer Science and Engineering, National Sun Yat-sen University, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Hsin-You Ou",
                "labs": [
                    "Liver Transplantation Program, Department of Diagnostic Radiology and Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung University College of Medicine, Niao-Sung, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Yi Lu",
                "labs": [
                    "Liver Transplantation Program, Department of Diagnostic Radiology and Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung University College of Medicine, Niao-Sung, Kaohsiung, Taiwan"
                ]
            },
            {
                "name": "Chih-Chi Wang",
                "labs": [
                    "Liver Transplantation Center and Department of Surgery, Kaohsiung Chang Gung Memorial Hospital, Niao-Sung, Kaohsiung, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Computed tomography",
                "Information retrieval",
                "Tumors",
                "Machine learning",
                "Visualization",
                "Biomedical imaging",
                "Liver cancer"
            ],
            "Author Keywords": [
                "Structured reports",
                "natural language processing",
                "interpretable machine learning",
                "CT liver-tumors",
                "biomedical science"
            ]
        }
    },
    {
        "Title": "Enhance the Photosynthetic and Color Performances of Multi-Primary White Light-Emitting Diodes for the Indoor Farming",
        "Link": "https://ieeexplore.ieee.org/document/9979797/",
        "Abstract": "The GaN-based white light-emitting diodes (LEDs) increase the possibility of realizing an ideal spectrum for the growth of plants. At the same time, high photosynthetic action of white LEDs is very crucial for the plant lighting to increase the crops productivity in the indoor artificial lighting plant factory. In this paper, via designing a non-linear program (NLP) based on the common genetic algorithm (GA), we are capable of conducting the comprehensive spectral optimization for realizing high photosynthetic action of multi-primary white LEDs (from three-primary to five-primary) under three different correlated color temperatures (CCTs, 2700 K, 4500 K, and 6500 K, respectively) while taking the color rendering performances, such as Commission Internationale de l'Eclairage (CIE) color rendering index (CRI, Ra), two special color rendering indices (R9 and R12) and Illuminating Engineering Society of North America (IES) TM-30 (Rf and Rg), and color quality scale (CQS, Qa) into account. In addition, these mentioned performances are compared among different primary numbers, CCTs, and spectral bandwidths in the multi-primary LEDs. Finally, we believe that the obtained relevant results presented here could provide a useful guidance for the achievement of high photosynthetic and excellent color performance lighting for the indoor farming.",
        "Details": {
            "DOI": "10.1109/JPHOT.2022.3228232",
            "Date of Publication": "12 December 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "Mengxiao Zhuo",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Qiyao Li",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Bingui Lv",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Mingkai Huang",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Xiaoting Xue",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Xiao Zheng",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Yi Lin",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Bijing Liu",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Xinqin Liao",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Ziquan Guo",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            },
            {
                "name": "Zhong Chen",
                "labs": [
                    "Fujian Engineering Research Center for Solid-state Lighting, Department of Electronic Science, School of Electronic Science and Engineering (National Model Microelectronics College), Xiamen University, Xiamen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Light emitting diodes",
                "Color",
                "Rendering (computer graphics)",
                "Genetic algorithms",
                "Optimization",
                "Visualization",
                "Light sources"
            ],
            "Author Keywords": [
                "Genetic algorithm",
                "indoor farming",
                "light-emitting diodes",
                "photosynthetic"
            ]
        }
    },
    {
        "Title": "Emotion Analysis Using Multilayered Networks for Graphical Representation of Tweets",
        "Link": "https://ieeexplore.ieee.org/document/9893783/",
        "Abstract": "Anticipating audience reaction towards a certain piece of text is integral to several facets of society ranging from politics, research, and commercial industries. Sentiment analysis (SA) is a useful natural language processing (NLP) technique that utilizes both lexical/statistical and deep learning methods to determine whether different sized texts exhibit a positive, negative, or neutral emotion. However, there is currently a lack of tools that can be used to analyze groups of independent texts and extract the primary emotion from the whole set. Therefore, the current paper proposes a novel algorithm referred to as the Multi-Layered Tweet Analyzer (MLTA) that graphically models social media text using multi-layered networks (MLNs) in order to better encode relationships across independent sets of tweets. Graph structures are capable of capturing meaningful relationships in complex ecosystems compared to other representation methods. State of the art Graph Neural Networks (GNNs) are used to extract information from the Tweet-MLN and make predictions based on the extracted graph features. Results show that not only does the MLTA predict from a larger set of possible emotions, delivering a more accurate sentiment compared to the standard positive, negative or neutral, it also allows for accurate group-level predictions of Twitter data.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3207161",
            "Date of Publication": "16 September 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Anna Nguyen",
                "labs": [
                    "Pulse.io, London, U.K."
                ]
            },
            {
                "name": "Antonio Longa",
                "labs": [
                    "Fondazione Bruno Kessler, Trento, Italy",
                    "Department of Information Engineering and Computer Science, University of Trento, Trento, Italy"
                ]
            },
            {
                "name": "Massimiliano Luca",
                "labs": [
                    "Pulse.io, London, U.K.",
                    "Fondazione Bruno Kessler, Trento, Italy",
                    "Faculty of Computer Science, Free University of Bolzano, Bolzano, Italy"
                ]
            },
            {
                "name": "Joe Kaul",
                "labs": [
                    "Pulse.io, London, U.K."
                ]
            },
            {
                "name": "Gabriel Lopez",
                "labs": [
                    "Pulse.io, London, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Feature extraction",
                "Blogs",
                "Task analysis",
                "Sentiment analysis",
                "Image edge detection",
                "Data mining",
                "Graph neural networks"
            ],
            "Author Keywords": [
                "Graph neural network",
                "sentiment analysis",
                "graph classification",
                "multi-layer network",
                "twitter"
            ]
        }
    },
    {
        "Title": "Toward a Low-Resource Non-Latin-Complete Baseline: An Exploration of Khmer Optical Character Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10316307/",
        "Abstract": "Many existing text recognition methods rely on the structure of Latin characters and words. Such methods may not be able to deal with non-Latin scripts that have highly complex features, such as character stacking, diacritics, ligatures, non-uniform character widths, and writing without explicit word boundaries. In addition, from a natural language processing (NLP) perspective, most non-Latin languages are considered low-resource due to the scarcity of large-scale data. This paper presents a convolutional Transformer-based text recognition method for low-resource non-Latin scripts, which uses local two-dimensional (2D) feature maps. The proposed method can handle images of arbitrarily long textlines, which may occur with non-Latin writing without explicit word boundaries, without resizing them to a fixed size by using an improved image chunking and merging strategy. It has a low time complexity in self-attention layers and allows efficient training. The Khmer script is used as the representative of non-Latin scripts because it shares many features with other non-Latin scripts, which makes the construction of an optical character recognition (OCR) method for Khmer as hard as that for other non-Latin scripts. Thus, by analogy with the AI-complete concept, a Khmer OCR method can be considered as one of the non-Latin-complete methods and can be used as a low-resource non-Latin baseline method. The proposed 2D method was trained on synthetic datasets and outperformed the baseline models on both synthetic and real datasets. Fine-tuning experiments using Khmer handwritten palm leaf manuscripts and other non-Latin scripts demonstrated the feasibility of transfer learning from the Khmer OCR method. To contribute to the low-resource language community, the training and evaluation datasets will be made publicly available.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3332361",
            "Date of Publication": "13 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rina Buoy",
                "labs": [
                    "Department of Core Informatics, Graduate School of Informatics, Osaka Metropolitan University, Sakai, Osaka, Japan"
                ]
            },
            {
                "name": "Masakazu Iwamura",
                "labs": [
                    "Department of Core Informatics, Graduate School of Informatics, Osaka Metropolitan University, Sakai, Osaka, Japan"
                ]
            },
            {
                "name": "Sovila Srun",
                "labs": [
                    "Department of Information Technology Engineering, Faculty of Engineering, Royal University of Phnom Penh, Phnom Penh, Cambodia"
                ]
            },
            {
                "name": "Koichi Kise",
                "labs": [
                    "Department of Core Informatics, Graduate School of Informatics, Osaka Metropolitan University, Sakai, Osaka, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text recognition",
                "Optical character recognition",
                "Transformers",
                "Stacking",
                "Feature extraction",
                "Decoding",
                "Character recognition"
            ],
            "Author Keywords": [
                "Khmer script",
                "non-Latin scripts",
                "character stacking",
                "no explicit word boundaries",
                "text recognition",
                "image chunking"
            ]
        }
    },
    {
        "Title": "A Quantum Entanglement-Based Approach for Computing Sentence Similarity",
        "Link": "https://ieeexplore.ieee.org/document/9204644/",
        "Abstract": "It is important to learn directly from original texts in natural language processing (NLP). Many deep learning (DP) models needing a large number of manually annotated data are not effective in deriving much information from corpora with few annotated labels. Existing methods using unlabeled language information to provide valuable messages consume considerable time and cost. Our provided sentence representation based on quantum computation (called Model I) needs no prior knowledge except word2vec. To reduce some semantic noise caused by the tensor product on the entangled words vector, two improved models (called Model II and Model III) are proposed to reduce the dimensions of the sentence embedding stimulated by Model I. The provided models are evaluated in the STS tasks of 2012, 2014, 2015 and 2016, for a total of 21 corpora. Experimental results show that using quantum entanglement and dimensionality reduction in sentence embedding yields state-of-the-art performances on semantic relations and syntactic structures. Compared to the Pearson correlation coefficient (Pcc) and mean squared error (MSE), the results of 16 out of 16 corpora are better than the results of the comparative methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3025958",
            "Date of Publication": "23 September 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yan Yu",
                "labs": [
                    "School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China",
                    "College of Mobile Telecommunications, Chongqing University of Posts and Telecom, Chongqing, China"
                ]
            },
            {
                "name": "Dong Qiu",
                "labs": [
                    "School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China"
                ]
            },
            {
                "name": "Ruiteng Yan",
                "labs": [
                    "School of Computer Science and Technology, Chongqing University of Posts and Telecommunications, Chongqing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Semantics",
                "Quantum computing",
                "Quantum entanglement",
                "Tensile stress",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Quantum computation",
                "text representation",
                "sentence similarity",
                "tensor product",
                "dimensionality reduction"
            ]
        }
    },
    {
        "Title": "Scalable Decentralized Multi-Robot Trajectory Optimization in Continuous-Time",
        "Link": "https://ieeexplore.ieee.org/document/9199826/",
        "Abstract": "This article presents a decentralized algorithm that generates continuous-time trajectory online for a swarm of robots based upon model predictive control. To generate collision-free trajectory, temporally distinct safe regions are formed such that the robots are confined to move within these safe regions to avoid collisions with one another. The distinct safe regions are temporally linked by generating a B-spline. Additionally, to ensure that collisions are avoided, collision-regions that the robots have to stay outside are also generated distinctly. A non linear program (NLP) with an objective to make the robots stay outside the collision-regions and stay within the safe regions is formulated. The algorithm was tested in simulations on Gazebo with aerial robots. The simulated results suggest that the proposed algorithm is computationally efficient and can be used for online planning in moderate sized multi-robot systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3024685",
            "Date of Publication": "18 September 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sivanathan Kandhasamy",
                "labs": [
                    "Autonomous Systems Laboratory, Department of Mechatronics Engineering, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Kanchipuram, India"
                ]
            },
            {
                "name": "Vinayagam Babu Kuppusamy",
                "labs": [
                    "Department of Mechatronics Engineering, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Kanchipuram, India"
                ]
            },
            {
                "name": "Shravan Krishnan",
                "labs": [
                    "Autonomous Systems Laboratory, Department of Mechatronics Engineering, Faculty of Engineering and Technology, SRM Institute of Science and Technology, Kanchipuram, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Collision avoidance",
                "Planning",
                "Prediction algorithms",
                "Trajectory optimization",
                "Robot sensing systems"
            ],
            "Author Keywords": [
                "Multi-robot system",
                "trajectory optimization",
                "obstacle avoidance",
                "model predictive control"
            ]
        }
    },
    {
        "Title": "B-NER: A Novel Bangla Named Entity Recognition Dataset With Largest Entities and Its Baseline Evaluation",
        "Link": "https://ieeexplore.ieee.org/document/10103464/",
        "Abstract": "Within the Natural Language Processing (NLP) framework, Named Entity Recognition (NER) is regarded as the basis for extracting key information to understand texts in any language. As Bangla is a highly inflectional, morphologically rich, and resource-scarce language, building a balanced NER corpus with large and diverse entities is a demanding task. However, previously developed Bangla NER systems are limited to recognizing only three familiar entities: person, location, and organization. To address this significant limitation, we introduce a novel Bangla NER dataset B-NER, which was created using 22,144 manually annotated Bangla sentences collected from Bangla newspapers and Bangla Wikipedia. This dataset includes a total of 9,895 unique words which were manually categorized into eight different entity types, such as a person, organization, event, artifact, time indicator, natural phenomenon, geopolitical entity, and geographical location. Inter-annotator agreement experiments were conducted to validate the quality of annotations performed by three annotators, resulting in a Kappa score of 0.82. In this paper, we provide an outline of the annotation guideline illustrated with examples, discuss the B-NER dataset properties, and present benchmark evaluations of the dataset. To establish that B-NER is more comprehensive and balanced in comparison to other publicly accessible datasets, we conducted cross-dataset modeling and validation, i.e. trained NER model on one dataset while tested on another, and found that the model trained on B-NER performed the best in that settings. Furthermore, we performed exhaustive benchmark evaluations based on Bidirectional LSTM with fastText embeddings and sentence transformer models. Among these models, fine-tuned NR/IndicbnBERT achieved noticeable results with a Macro-F1 of 86%. This dataset and baseline results will be publicly available under a CC-BY 4.0 license in the CoNLL-2002 format to facilitate further research on Bangla NER.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3267746",
            "Date of Publication": "17 April 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md. Zahidul Haque",
                "labs": [
                    "Department of Computer Science and Engineering, Sylhet Engineering College, Tilagarh, Sylhet, Bangladesh"
                ]
            },
            {
                "name": "Sakib Zaman",
                "labs": [
                    "Department of Computer Science and Engineering, Sylhet Engineering College, Tilagarh, Sylhet, Bangladesh"
                ]
            },
            {
                "name": "Jillur Rahman Saurav",
                "labs": [
                    "Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA"
                ]
            },
            {
                "name": "Summit Haque",
                "labs": [
                    "Department of Computer Science and Engineering, Shahjalal University of Science and Technology, Sylhet, Bangladesh"
                ]
            },
            {
                "name": "Md. Saiful Islam",
                "labs": [
                    "Department of Computing Science, University of Alberta, Edmonton, AB, Canada"
                ]
            },
            {
                "name": "Mohammad Ruhul Amin",
                "labs": [
                    "Department of Computer and Information Science, Fordham University, Bronx, NY, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hidden Markov models",
                "Annotations",
                "Tagging",
                "Organizations",
                "Benchmark testing",
                "Data mining",
                "Bit error rate"
            ],
            "Author Keywords": [
                "Named entity recognition (NER)",
                "natural language processing",
                "bangla NER dataset",
                "information extraction",
                "B-NER"
            ]
        }
    },
    {
        "Title": "TOP-Rank: A Novel Unsupervised Approach for Topic Prediction Using Keyphrase Extraction for Urdu Documents",
        "Link": "https://ieeexplore.ieee.org/document/9265205/",
        "Abstract": "In Natural Language Processing (NLP), topic modeling is the technique to extract abstract information from documents with huge amount of text. This abstract information leads towards the identification of the topics in the document. One way to retrieve topics from documents is keyphrase extraction. Keyphrases are a set of terms which represent high level description of a document. Different techniques of keyphrase extraction for topic prediction have been proposed for multiple languages i.e. English, Arabic, etc. However, this area needs to be explored for other languages e.g. Urdu. Therefore, in this paper, a novel unsupervised approach for topic prediction for Urdu language has been introduced which is able to extract more significant information from the documents. For this purpose, the proposed TOP-Rank system extracts keywords from the document and ranks them according to their position in a sentence. These keywords along with their ranking scores are utilized to generate keyphrases by applying syntactic rules to extracts more meaningful topics. These keyphrases are ranked according to the keywords scores and re-ranked with respect to their positions in the document. Finally, our proposed model identifies top-ranked keyphrases as topical significance and keyphrase with the highest score is selected as the topic of the document. Experiments are performed on two different datasets and performance of the proposed system is compared with existing state-of-the-art techniques. Results have shown that our proposed system outperforms existing techniques and holds the ability to produce more meaningful topics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3039548",
            "Date of Publication": "20 November 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ahmad Amin",
                "labs": [
                    "Department of Computer Science and IT, The University of Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Toqir A. Rana",
                "labs": [
                    "Department of Computer Science and IT, The University of Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Natash Ali Mian",
                "labs": [
                    "School of Computer and Information Technology, Beaconhouse National University, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muhammad Waseem Iqbal",
                "labs": [
                    "Department of Computer Science and IT, The Superior College (University Campus), Lahore, Pakistan"
                ]
            },
            {
                "name": "Abbas Khalid",
                "labs": [
                    "Department of Computer Science and IT, The University of Lahore, Lahore, Pakistan"
                ]
            },
            {
                "name": "Tahir Alyas",
                "labs": [
                    "Department of Computer Science, Lahore Garrison University, Lahore, Pakistan"
                ]
            },
            {
                "name": "Mohammad Tubishat",
                "labs": [
                    "School of Technology and Computing, Asia Pacific University of Technology and Innovation, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Clustering algorithms",
                "Syntactics",
                "Probabilistic logic",
                "Prediction algorithms",
                "Feature extraction",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Topic extraction",
                "top-rank",
                "keyphrase extraction",
                "topic prediction",
                "Urdu positional ranking"
            ]
        }
    },
    {
        "Title": "Time-Series Large Language Models: A Systematic Review of State-of-the-Art",
        "Link": "https://ieeexplore.ieee.org/document/10856008/",
        "Abstract": "Large Language Models (LLMs) have transformed Natural Language Processing (NLP) and Software Engineering by fostering innovation, streamlining processes, and enabling data-driven decision-making. Recently, the adoption of LLMs in time-series analysis has catalyzed the emergence of time-series LLMs, a rapidly evolving research area. Existing reviews provide foundational insights into time-series LLMs but lack a comprehensive examination of recent advancements and do not adequately address critical challenges in this domain. This Systematic Literature Review (SLR) bridges these gaps by analysing state-of-the-art contributions in time-series LLMs, focusing on architectural innovations, tokenisation strategies, tasks, datasets, evaluation metrics, and unresolved challenges. Using a rigorous methodology based on PRISMA guidelines, over 700 studies from 2020 to 2024 were reviewed, with 59 relevant studies selected from journals, conferences, and workshops. Key findings reveal advancements in architectures and novel tokenization strategies tailored for temporal data. Forecasting dominates the identified tasks with 79.66% of the selected studies, while classification and anomaly detection remain underexplored. Furthermore, the analysis reveals a strong reliance on datasets from the energy and transportation domains, highlighting the need for more diverse datasets. Despite these advancements, significant challenges persist, including tokenization inefficiencies, prediction hallucinations, and difficulties in modelling long-term dependencies. These issues hinder the robustness, scalability, and adaptability of time-series LLMs across diverse applications. To address these challenges, this SLR outlines a research roadmap emphasizing the improvement of tokenization methods, the development of mechanisms for capturing long-term dependencies, the mitigation of hallucination effects, and the design of scalable, interpretable models for diverse time-series tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3535782",
            "Date of Publication": "28 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shamsu Abdullahi",
                "labs": [
                    "Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia",
                    "Department of Computer Science, Hassan Usman Katsina Polytechnic, Katsina, Katsina State, Nigeria"
                ]
            },
            {
                "name": "Kamaluddeen Usman Danyaro",
                "labs": [
                    "Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Abubakar Zakari",
                "labs": [
                    "Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia",
                    "Department of Computer Science, Aliko Dangote University of Science and Technology, Wudil, Kano, Nigeria"
                ]
            },
            {
                "name": "Izzatdin Abdul Aziz",
                "labs": [
                    "Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Noor Amila Wan Abdullah Zawawi",
                "labs": [
                    "Civil and Environmental Engineering Department, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia"
                ]
            },
            {
                "name": "Shamsuddeen Adamu",
                "labs": [
                    "Department of Computer and Information Sciences, Universiti Teknologi PETRONAS, SeriIskandar, Perak, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Time series analysis",
                "Forecasting",
                "Measurement",
                "Tokenization",
                "Systematic literature review",
                "Systematics",
                "Databases",
                "Transformers",
                "Search problems",
                "Anomaly detection"
            ],
            "Author Keywords": [
                "Time-series",
                "large language models",
                "forecasting",
                "tokenization",
                "time-series LLMs"
            ]
        }
    },
    {
        "Title": "Injecting User Identity Into Pretrained Language Models for Document-Level Sentiment Classification",
        "Link": "https://ieeexplore.ieee.org/document/9733377/",
        "Abstract": "This paper mainly studies the combination of pre-trained language models and user identity information for document-level sentiment classification. In recent years, pre-trained language models (PLMs) such as BERT have achieved state-of-the-art results on many NLP applications, including document-level sentiment classification. On the other hand, a collection of works introduce additional information such as user identity for better text modeling. However, most of them inject user identity into traditional models, while few studies have been conducted to study the combination of pre-trained language models and user identity for even better performance. To address this issue, in this paper, we propose to unite user identity and PLMs and formulate User-enhanced Pre-trained Language Models (U-PLMs). Specifically, we demonstrate two simple yet effective attempts, i.e. embedding-based and attention-based personalization, which inject user identity into different parts of a pre-trained language model and provide personalization from different perspectives. Experiments in three datasets with two backbone PLMs show that our proposed methods outperform the best state-of-the-art baseline method with an absolute improvement of up to 3%, 2.8%, and 2.2% on accuracy. In addition, our methods encode user identity with plugin modules, which are fully compatible with most auto-encoding pre-trained language models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3158975",
            "Date of Publication": "11 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xinlei Cao",
                "labs": [
                    "School of Computer Science and Technology, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Jinyang Yu",
                "labs": [
                    "Center for ADR Monitoring of Guangdong, Guangzhou, China"
                ]
            },
            {
                "name": "Yan Zhuang",
                "labs": [
                    "National Engineering Laboratory for Medical Big Data Application Technology, Chinese PLA General Hospital, Beijing, China",
                    "Medical Innovation Research Division, Medical Big Data Research Center, Chinese PLA General Hospital, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Predictive models",
                "Transformers",
                "Context modeling",
                "Electronic mail",
                "Data models"
            ],
            "Author Keywords": [
                "Representation learning",
                "document-level sentiment classification",
                "personalized sentiment classification",
                "pre-trained language models",
                "attention mechanism"
            ]
        }
    },
    {
        "Title": "Improving BERT With Self-Supervised Attention",
        "Link": "https://ieeexplore.ieee.org/document/9584911/",
        "Abstract": "One of the most popular paradigms of applying large pre-trained NLP models such as BERT is to fine-tune it on a smaller dataset. However, one challenge remains as the fine-tuned model often overfits on smaller datasets. A symptom of this phenomenon is that irrelevant or misleading words in the sentence, which are easy to understand for human beings, can substantially degrade the performance of these fine-tuned BERT models. In this paper, we propose a novel technique, called Self-Supervised Attention (SSA) to help facilitate this generalization challenge. Specifically, SSA automatically generates weak, token-level attention labels iteratively by probing the fine-tuned model from the previous iteration. We investigate two different ways of integrating SSA into BERT and propose a hybrid approach to combine their benefits. Empirically, through a variety of public datasets, we illustrate significant performance improvement using our SSA-enhanced BERT model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3122273",
            "Date of Publication": "22 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yiren Chen",
                "labs": [
                    "Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Xiaoyu Kou",
                "labs": [
                    "Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Jiangang Bai",
                "labs": [
                    "Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University, Beijing, China"
                ]
            },
            {
                "name": "Yunhai Tong",
                "labs": [
                    "Key Laboratory of Machine Perception (MOE), School of Electronics Engineering and Computer Science, Peking University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Bit error rate",
                "Predictive models",
                "Data models",
                "Training",
                "Training data"
            ],
            "Author Keywords": [
                "Natural language processing",
                "attention model",
                "text classification",
                "BERT",
                "pre-trained model"
            ]
        }
    },
    {
        "Title": "AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization",
        "Link": "https://ieeexplore.ieee.org/document/10804767/",
        "Abstract": "Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model’s strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3519423",
            "Date of Publication": "17 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nuruzzaman Faruqui",
                "labs": [
                    "Department of Software Engineering, Daffodil International University, Daffodil Smart City, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Priyabrata Thatoi",
                "labs": [
                    "Amazon, Chicago, IL, USA"
                ]
            },
            {
                "name": "Rohit Choudhary",
                "labs": [
                    "Amazon, Dallas, TX, USA"
                ]
            },
            {
                "name": "Ivana Roncevic",
                "labs": [
                    "Department of Linguistics and Translation, Applied Linguistics Research Laboratory, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Hamed Alqahtani",
                "labs": [
                    "Informatics and Computer Systems Department, Center of Artificial Intelligence, College of Computer Science, King Khalid University, Abha, Saudi Arabia"
                ]
            },
            {
                "name": "Iqbal H. Sarker",
                "labs": [
                    "Centre for Securing Digital Futures, School of Science, Edith Cowan University, Perth, WA, Australia"
                ]
            },
            {
                "name": "Shapla Khanam",
                "labs": [
                    "Faculty of Computing and Digital Technology, HELP University, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Mathematical models",
                "Transformers",
                "Costs",
                "Vectors",
                "Business",
                "Unified modeling language",
                "Training",
                "Optimization",
                "Testing",
                "Systematic literature review"
            ],
            "Author Keywords": [
                "Transformer model",
                "large language model",
                "system development lifecycle",
                "transfer learning",
                "artificial intelligence",
                "business cost optimization",
                "project management automation",
                "system analyst",
                "LLM",
                "SDLC",
                "AI",
                "PMP"
            ]
        }
    },
    {
        "Title": "End to End Urdu Abstractive Text Summarization With Dataset and Improvement in Evaluation Metric",
        "Link": "https://ieeexplore.ieee.org/document/10472483/",
        "Abstract": "Urdu, being a common language in South Asia, has not received significant attention in terms of language processing compared to more advanced languages. In the field of Natural Language Processing (NLP), the task of text summarization holds great importance due to its ability to comprehend textual content and generate concise summaries. Text summarization can be either extractive or abstractive in nature. While considerable efforts have been made to advance extractive summarization techniques, the limitations associated with it have been extensively explored and explained in the paper. However, the domain of abstractive summarization for the Urdu language remains largely unexplored. The challenges and underlying factors that have impeded progress in this domain have also been addressed. This paper specifically focuses on abstractive summarization of the Urdu language using supervised learning. To accomplish this, a labeled dataset consisting of Urdu text and its abstractive summaries is required. A dataset of Urdu text and its corresponding abstractive summaries has been prepared for the purpose of supervised learning. Additionally, the paper presents the results of summary generation, measured in terms of a rough score. Transformer’s encoder-decoder network was employed to generate abstractive summaries in Urdu, yielding a ROUGE-1 score of 25.18 in Urdu text summarization. Moreover, a novel evaluation metric called the “disconnection rate” has been introduced as a context-aware evaluation metric to enhance the assessment of a summary, known as the Context Aware RoBERTa Score.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3377463",
            "Date of Publication": "13 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hassan Raza",
                "labs": [
                    "FAST School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Waseem Shahzad",
                "labs": [
                    "FAST School of Computing, National University of Computer and Emerging Sciences, Islamabad, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Transformers",
                "Supervised learning",
                "Databases",
                "Artificial neural networks",
                "Standards",
                "Data mining",
                "Data models",
                "Neural networks",
                "Text categorization",
                "Natural language processing",
                "Performance evaluation"
            ],
            "Author Keywords": [
                "Datasets",
                "neural networks",
                "CA-RoBERTa score",
                "text summarization"
            ]
        }
    },
    {
        "Title": "A Suicidal Ideation Detection Framework on Social Media Using Machine Learning and Genetic Algorithms",
        "Link": "https://ieeexplore.ieee.org/document/10666498/",
        "Abstract": "Suicide is a serious problem that affects modern societies all over the world, and its prevention is critical. Suicidal ideas are influenced by a variety of risk factors, such as depression, anxiety, hopelessness, and social isolation. Early detection of these risk factors can significantly reduce or prevent suicide attempts. Online platforms, particularly social media, have become a popular outlet for young people to express suicidal ideation. However, detecting and responding to such ideation effectively poses significant challenges in natural language processing (NLP) and psychology. To improve the efficiency of detecting suicidal ideation, this study proposes a novel framework that overcomes prior research limitations, such as feature redundancy and limited relevance to the target class. The framework addresses these issues by extracting meaningful and context-related features from posts that capture contextual and semantic aspects. Furthermore, a genetic algorithm is used to select the most important and relevant features that are strongly associated with the target class while excluding those that are redundant or irrelevant. To evaluate the effectiveness of the proposed framework, the following machine learning classifiers were used to determine whether a post indicates suicidal ideation or not: Random Forest (RF), Naive Bayes (NB), gradient boost classification tree (GBDT), and XGBoost. The proposed framework’s results outperformed previous research, demonstrating the framework’s high efficiency. The best performance in our study was achieved using the Random Forest (RF) classifier, which was applied to the features selected by the Genetic Algorithm (GA) from the linguistic feature set. When evaluated using 5-fold cross-validation, this approach yielded an impressive accuracy rate of 98.92% and an F1-score of 98.92%. These outstanding performance metrics demonstrate the framework’s effectiveness in accurately detecting suicidal ideation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3454796",
            "Date of Publication": "05 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdallah Basyouni",
                "labs": [
                    "Information Systems Department, Faculty of Computers and Information, Menoufia University, Shebeen El-Kom, Egypt"
                ]
            },
            {
                "name": "Hatem Abdulkader",
                "labs": [
                    "Information Systems Department, Faculty of Computers and Information, Menoufia University, Shebeen El-Kom, Egypt"
                ]
            },
            {
                "name": "Wail S. Elkilani",
                "labs": [
                    "College of Applied Computer Science, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdullah Alharbi",
                "labs": [
                    "Department of Computer Science, Community College, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Yulong Xiao",
                "labs": [
                    "School of Communication and Information Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China"
                ]
            },
            {
                "name": "Asmaa H. Ali",
                "labs": [
                    "Information Systems Department, Faculty of Computers and Information, Menoufia University, Shebeen El-Kom, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Feature extraction",
                "Blogs",
                "Text categorization",
                "Natural language processing",
                "Machine learning",
                "Deep learning",
                "Mental health"
            ],
            "Author Keywords": [
                "Mental health",
                "suicide detection",
                "Reddit social media",
                "feature selection",
                "genetic algorithm"
            ]
        }
    },
    {
        "Title": "Empowering Few-Shot Recommender Systems With Large Language Models-Enhanced Representations",
        "Link": "https://ieeexplore.ieee.org/document/10440582/",
        "Abstract": "Recommender systems utilizing explicit feedback have witnessed significant advancements and widespread applications over the past years. However, generating recommendations in few-shot scenarios remains a persistent challenge. Recently, large language models (LLMs) have emerged as a promising solution for addressing natural language processing (NLP) tasks, thereby offering novel insights into tackling the few-shot scenarios encountered by explicit feedback-based recommender systems. To bridge recommender systems and LLMs, we devise a prompting template that generates user and item representations based on explicit feedback. Subsequently, we integrate these LLM-processed representations into various recommendation models to evaluate their significance across diverse recommendation tasks. Our ablation experiments and case study analysis collectively demonstrate the effectiveness of LLMs in processing explicit feedback, highlighting that LLMs equipped with generative and logical reasoning capabilities can effectively serve as a component of recommender systems to enhance their performance in few-shot scenarios. Furthermore, the broad adaptability of LLMs augments the generalization potential of recommender models, despite certain inherent constraints. We anticipate that our study can inspire researchers to delve deeper into the multifaceted dimensions of LLMs’ involvement in recommender systems and contribute to the advancement of the explicit feedback-based recommender systems field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3368027",
            "Date of Publication": "20 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhoumeng Wang",
                "labs": [
                    "Marketing Programme, The Chinese University of Hong Kong Business School, Hong Kong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Recommender systems",
                "Task analysis",
                "Reviews",
                "Predictive models",
                "Motion pictures",
                "Training",
                "Large language models",
                "Representation learning"
            ],
            "Author Keywords": [
                "Large language models",
                "recommender systems",
                "ChatGPT",
                "representations"
            ]
        }
    },
    {
        "Title": "Sentiment Analysis Based on Hybrid Neural Network Techniques Using Binary Coordinate Ascent Algorithm",
        "Link": "https://ieeexplore.ieee.org/document/10323318/",
        "Abstract": "Sentiment analysis is a technique for determining whether data is positive, negative, or neutral using Natural Language Processing (NLP). The particular challenge in classifying huge amounts of data is that it takes a long time and requires the employment of specialist human resources. Various deep learning techniques have been employed by different researchers to train and classify different datasets with varying outcomes. However, the results are not satisfactory. To address this challenge, this paper proposes a novel Sentiment Analysis approach based on Hybrid Neural Network Techniques. The preprocessing step is first applied to the Amazon Fine Food Reviews dataset in our architecture, which includes a number of data cleaning and text normalization techniques. The word embedding technique is then used to capture the semantics of the input by clustering semantically related inputs in the embedding space on the cleaned dataset. Finally, generated features were classified using three different deep learning techniques, including Recurrent Neural Network (RNN), Convolutional Neural Network (CNN), and Hybrid CNN-RNN models, in two different ways, with each technique as follows: classification on the original feature set and classification on the reduced feature set based on Binary Coordinate Ascent (BCA) and Optimal Coordinate Ascent (OCA). The experimental results show that a hybrid CNN-RNN with the BCA and OCA algorithms outperforms state-of-the-art methods with 97.91% accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3334980",
            "Date of Publication": "20 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammed Hussein Abdalla",
                "labs": [
                    "Department of Computer Science, University of Raparin, Rania, Iraq"
                ]
            },
            {
                "name": "Jafar Majidpour",
                "labs": [
                    "Department of Computer Science, University of Raparin, Rania, Iraq"
                ]
            },
            {
                "name": "Rahela Aziz Rasul",
                "labs": [
                    "Department of Mathematics, University of Raparin, Rania, Iraq"
                ]
            },
            {
                "name": "Abdulrahman A. Alsewari",
                "labs": [
                    "College of Computing, Faculty of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, U.K."
                ]
            },
            {
                "name": "Tarik Ahmed Rashid",
                "labs": [
                    "Department of Computer Science and Engineering, University of Kurdistan Hewlêr, Erbil, Iraq"
                ]
            },
            {
                "name": "Aram Mahmood Ahmed",
                "labs": [
                    "Department of Computer Science, College of Science, Charmo University, Sulaimani, Iraq",
                    "Department of Information Technology, University of Human Development, Sulaimani, Iraq"
                ]
            },
            {
                "name": "Bryar A. Hassan",
                "labs": [
                    "Department of Computer Science, College of Science, Charmo University, Sulaimani, Iraq"
                ]
            },
            {
                "name": "Noor Bahjat Tayfor",
                "labs": [
                    "Department of Information Technology, Kurdistan Technical Institute, Sulaimani, Iraq"
                ]
            },
            {
                "name": "Shko Muhammed Qader",
                "labs": [
                    "Department of Information Technology, University College of Goizha, Sulaimani, Iraq",
                    "Information Technology Department, Computer Science Institute, Sulaimani Polytechnic University, Sulaimani, Iraq"
                ]
            },
            {
                "name": "Sinan Q. Salih",
                "labs": [
                    "Technical College of Engineering, Al-Bayan University, Baghdad, Iraq"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Social networking (online)",
                "Feature extraction",
                "Convolutional neural networks",
                "Analytical models",
                "Blogs",
                "Deep learning",
                "Deep learning",
                "Recurrent neural networks",
                "Natural language processing",
                "Clustering methods"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "deep learning",
                "BCA algorithm",
                "OCA",
                "RNN",
                "CNN"
            ]
        }
    },
    {
        "Title": "Integrating Large Language Model, EEG, and Eye-Tracking for Word-Level Neural State Classification in Reading Comprehension",
        "Link": "https://ieeexplore.ieee.org/document/10636286/",
        "Abstract": "With the recent proliferation of large language models (LLMs), such as Generative Pre-trained Transformers (GPT), there has been a significant shift in exploring human and machine comprehension of semantic language meaning. This shift calls for interdisciplinary research that bridges cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals’ neural states during a semantic inference reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use feature engineering to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60% across 12 subjects. Words highly relevant to the inference keyword received significantly more eye fixations per word: 1.0584 compared to 0.6576, including words with no fixations. This study represents the first attempt to classify brain states at a word level using LLM-generated labels. It provides valuable insights into human cognitive abilities and Artificial General Intelligence (AGI), and offers guidance for developing potential reading-assisted technologies.",
        "Details": {
            "DOI": "10.1109/TNSRE.2024.3435460",
            "Date of Publication": "14 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
        },
        "issn_info": {
            "Print ISSN": "1534-4320",
            "Electronic ISSN": "1558-0210"
        },
        "authors_data": [
            {
                "name": "Yuhong Zhang",
                "labs": [
                    "Shu Chien-Gene Lay Department of Bioengineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Qin Li",
                "labs": [
                    "Department of Bioengineering, University of California at Los Angeles, Los Angeles, CA, USA"
                ]
            },
            {
                "name": "Sujal Nahata",
                "labs": [
                    "Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Tasnia Jamal",
                "labs": [
                    "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Shih-Kuen Cheng",
                "labs": [
                    "Institute of Cognitive Neuroscience, National Central University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "Gert Cauwenberghs",
                "labs": [
                    "Shu Chien-Gene Lay Department of Bioengineering and the Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA"
                ]
            },
            {
                "name": "Tzyy-Ping Jung",
                "labs": [
                    "Institute for Neural Computation, University of California San Diego, La Jolla, CA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electroencephalography",
                "Task analysis",
                "Brain modeling",
                "Semantics",
                "Gaze tracking",
                "Electronic mail",
                "Accuracy"
            ],
            "Author Keywords": [
                "Large language model",
                "brain-computer interface",
                "human-computer interface",
                "EEG",
                "eye-fixation",
                "cognitive computing",
                "pattern recognition",
                "reading comprehension",
                "computational linguistics"
            ]
        }
    },
    {
        "Title": "Transformer-Based Deep Learning Strategies for Lithium-Ion Batteries SOX Estimation Using Regular and Inverted Embedding",
        "Link": "https://ieeexplore.ieee.org/document/10749810/",
        "Abstract": "The accurate estimation of Li-ion battery (LIB) states such as State of Charge (SOC), State of Health (SOH), and State of Power (SOP) plays a pivotal role in the efficient operation of Electric Vehicles (EVs). These parameters can impact the battery’s health, driving range, and overall vehicle performance. Transformer-based artificial neural networks have shown impressive results in natural language processing (NLP) and estimation problems of many other domains. This paper presents an intensive study on the capabilities of various Transformer-based models in estimating the SOC and SOH of LIBs, the SOP is obtained based on the estimated SOC. This paper provides the following key original contributions: 1) the application of the Informer and Reformer variants of the Transformer model for the first time for SOH estimation of LIBs in EVs, 2) studying the effect of inverted embedding of iTransformers, a modified architecture of the transformers, on SOC and SOH estimation, inversion is performed on the Informer and Reformer as well; 3) applying a simple feature extraction method using partial discharge cycles for SOH estimation with Transformer-based models; 4) a new robust method is proposed for SOC estimation based on a 2-Encoder-Transformer with a one-dimensional convolutional neural network (1D-CNN) architecture; 5) the various architectures are trained, validated and tested on two real-world datasets comprising various driving scenarios and battery conditions. Comparative analysis with various deep learning architectures show impressive accuracy for estimating the SOC and SOH, leading to better SOP calculation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3495560",
            "Date of Publication": "11 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "John Guirguis",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            },
            {
                "name": "Ahmed Abdulmaksoud",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            },
            {
                "name": "Mohanad Ismail",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            },
            {
                "name": "Phillip J. Kollmeyer",
                "labs": [
                    "Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            },
            {
                "name": "Ryan Ahmed",
                "labs": [
                    "Department of Mechanical Engineering, McMaster University, Hamilton, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Estimation",
                "State of charge",
                "Computer architecture",
                "Computational modeling",
                "Artificial intelligence",
                "Predictive models",
                "Long short term memory",
                "Face recognition",
                "Decoding"
            ],
            "Author Keywords": [
                "Convolutional neural networks",
                "deep learning",
                "electric vehicles",
                "iTransformers",
                "li-ion batteries",
                "state estimation",
                "state of charge",
                "state of health",
                "state of power",
                "transformers"
            ]
        }
    },
    {
        "Title": "A Non-Exclusive Multi-Class Convolutional Neural Network for the Classification of Functional Requirements in AUTOSAR Software Requirement Specification Text",
        "Link": "https://ieeexplore.ieee.org/document/9931679/",
        "Abstract": "Software Requirement Specification (SRS) describes a software system to be developed that captures the functional, non-functional, and technical aspects of the stakeholder’s requirements. Retrieval and extraction of software information from SRS are essential to the development of software product line (SPL). Albeit Natural Language Processing (NLP) techniques, such as information retrieval and standard machine learning, have been advocated in the recent past as a semi-automatic means of optimising requirements specifications, they have not been widely embraced. The complexity in the organization’s information makes requirement analysis intricately a challenging task. The interdependence of subsystems and within an organisation drives this complexity. A plain multi-class classification framework may not address this issue. Hence, this paper propounds an automated non-exclusive approach for classification of functional requirements from SRS, using a deep learning framework. Specifically, Word2Vec and FastText word embeddings are utilised for document representation for training a convolutional neural network (CNN). The study was carried out by the compilation of manually categorised relevant enterprise data (AUTomotive Open System ARchitecture (AUTOSAR)), which were also employed for model training. Over a convolutional neural network, the impact of data trained with Word2Vec and FastText word embeddings from SRS documentation were compared to pre-trained word embeddings models, available online.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3217752",
            "Date of Publication": "28 October 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sanjanasri Jp",
                "labs": [
                    "Center for Computational Engineering and Networking, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India"
                ]
            },
            {
                "name": "Vijay Krishna Menon",
                "labs": [
                    "KeepFlying, 5 Tampines Central 6, Singapore"
                ]
            },
            {
                "name": "KP Soman",
                "labs": [
                    "Center for Computational Engineering and Networking, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India"
                ]
            },
            {
                "name": "Atul K. R. Ojha",
                "labs": [
                    "Data Science Institute, National University of Ireland Galway, Galway, Ireland",
                    "Panlingua Language Processing LLP, New Delhi, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Software engineering",
                "Convolutional neural networks",
                "Documentation",
                "Support vector machines",
                "Semantics",
                "Automotive engineering",
                "Embedded systems"
            ],
            "Author Keywords": [
                "Functional requirement",
                "software requirement specification",
                "convolutional neural network",
                "multi-layer perceptron",
                "word embedding"
            ]
        }
    },
    {
        "Title": "A Machine Learning Approach for the Automatic Classification of Schizophrenic Discourse",
        "Link": "https://ieeexplore.ieee.org/document/8678636/",
        "Abstract": "Schizophrenia is a chronic neurobiological disorder whose early detection has attracted significant attention from the clinical, psychiatric, and also artificial intelligence communities. This latter approach has been mainly focused on the analysis of neuroimaging and genetic data. A less explored strategy consists in exploiting the power of natural language processing (NLP) algorithms applied over narrative texts produced by schizophrenic subjects. In this paper, a novel dataset collected from a proper field study is presented. Also, grammatical traits discovered in narrative documents are used to build computational representations of texts, allowing an automatic classification of discourses generated by schizophrenic and non-schizophrenic subjects. The attained results showed that the use of the proposed computational representations along with machine learning techniques enables a novel and precise strategy to automatically detect texts produced by schizophrenic subjects.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2908620",
            "Date of Publication": "01 April 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Héctor Allende-Cid",
                "labs": [
                    "Escuela de Ingeniería Informática, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Juan Zamora",
                "labs": [
                    "Instituto de Estadística, Pontificia Universidad Católica de Valparaíso, Valparaíso, Chile"
                ]
            },
            {
                "name": "Pedro Alfaro-Faccio",
                "labs": [
                    "Instituto de Literatura y Ciencias del Lenguaje, Pontificia Universidad Católica de Valparaíso, Viña del Mar, Chile"
                ]
            },
            {
                "name": "María Francisca Alonso-Sánchez",
                "labs": [
                    "Centro de Investigación del Desarrollo en Cognición y Lenguaje, Universidad de Valparaíso, Viña del Mar, Chile"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Machine learning",
                "Feature extraction",
                "Task analysis",
                "Brain modeling",
                "Electroencephalography",
                "Natural language processing",
                "Machine learning algorithms"
            ],
            "Author Keywords": [
                "Applied machine learning",
                "natural language processing",
                "schizophrenia"
            ]
        }
    },
    {
        "Title": "Summarizing Students’ Free Responses for an Introductory Algebra-Based Physics Course Survey Using Cluster and Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10220088/",
        "Abstract": "In Physics Higher Education (PHE), Student Evaluation of Teaching (SET) surveys are widely used to collect students’ feedback on courses and instructions. In our research, we propose a more efficient way to summarize students’ free responses from the Student Assessment of their Learning Gains (SALG) survey, a form of the SET survey, of an algebra-based introductory physics course at a large Canadian research university. Specifically, we use cluster and sentiment analysis methods such as K-means and Valence Aware Dictionary for sEntiment Reasoning (VADER) to summarize students’ free responses. For cluster analysis, we extract popular keywords and summaries of responses in different clusters that reflect students’ dominant opinions toward each aspect of the course. Notably, we obtain an average silhouette coefficient of 0.480. In addition, we analyze sentiments in students’ free responses that are determined through applying VADER. Intriguingly, we see that VADER (micro F1 = 0.57, macro F1 = 0.55) can better classify responses with positive (F1 = 0.62) and neutral sentiment (F1 = 0.59). However, evident disagreements arise with negative sentiment responses (F1 = 0.42). In addition, our research suggests that some Likert-scale summaries deviate from the sentiment of free response summaries due to the limitations of Likert-scale responses. By creating various visualizations, we discover that Natural Language Processing (NLP) methods, such as cluster and sentiment analysis, effectively summarize students’ free responses, with several limitations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3305260",
            "Date of Publication": "15 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hongzip Kim",
                "labs": [
                    "Department of Computer Science, University of Toronto, Toronto, Canada"
                ]
            },
            {
                "name": "Geting Qin",
                "labs": [
                    "Department of Physics, University of Toronto, Toronto, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Education",
                "Physics",
                "Sentiment analysis",
                "Machine learning",
                "Text mining",
                "Standards",
                "Clustering methods",
                "Sentiment analysis",
                "Educational courses"
            ],
            "Author Keywords": [
                "Cluster analysis",
                "education",
                "free responses",
                "sentiment analysis",
                "summaries",
                "survey"
            ]
        }
    },
    {
        "Title": "Inferring Multilingual Domain-Specific Word Embeddings From Large Document Corpora",
        "Link": "https://ieeexplore.ieee.org/document/9559966/",
        "Abstract": "The use of distributed vector representations of words in Natural Language Processing has become established. To tailor general-purpose vector spaces to the context under analysis, several domain adaptation techniques have been proposed. They all require sufficiently large document corpora tailored to the target domains. However, in several cross-lingual NLP domains both large enough domain-specific document corpora and pre-trained domain-specific word vectors are hard to find for languages other than English. This paper aims at tackling the aforesaid issue. It proposes a new methodology to automatically infer aligned domain-specific word embeddings for a target language on the basis of the general-purpose and domain-specific models available for a source language (typically, English). The proposed inference method relies on a two-step process, which first automatically identifies domain-specific words and then opportunistically reuses the non-linear space transformations applied to the word vectors of the source language in order to learn how to tailor the vector space of the target language to the domain of interest. The performance of the proposed method was validated via extrinsic evaluation by addressing the established word retrieval task. To this aim, a new benchmark multilingual dataset, derived from Wikipedia, has been released. The results confirmed the effectiveness and usability of the proposed approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3118093",
            "Date of Publication": "05 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Luca Cagliero",
                "labs": [
                    "Dipartimento di Automatica e Informatica, Politecnico di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Moreno La Quatra",
                "labs": [
                    "Dipartimento di Automatica e Informatica, Politecnico di Torino, Turin, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Adaptation models",
                "Data models",
                "Natural language processing",
                "Context modeling",
                "Semantics",
                "Online services"
            ],
            "Author Keywords": [
                "Cross-lingual models",
                "domain adaptation",
                "natural language processing",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "Simulation for Generation of Several Types of Pulses in an Yb-Doped Mode-Locked Fiber Laser",
        "Link": "https://ieeexplore.ieee.org/document/9222498/",
        "Abstract": "Impact Statement:\nA better understanding of the influence of cavity parameters on pulse characteristics could help one to better design fiber lasers. In this paper, we numerically demonstr...Show More\nWe numerically demonstrated six types of pulses in an Yb-doped fiber laser, including dissipative soliton (DS), dissipative soliton resonance (DSR), multipulse, noise-like pulse (NLP), breathing soliton and soliton explosion. The influence of cavity conditions on DSR pulse properties is discussed systematically. It is found that the change of the saturation power of saturable absorber (SA) could transform DSR into various types of pulses. Saturation power of SA and injected signal affect the number and shape of multipulse. Furthermore, the influence of the saturation power of SA and intra-cavity dispersion on pulse type is diagrammed intuitively. By properly adjusting the transmission curve of SA, breathing soliton and soliton explosion can be obtained as well.",
        "Details": {
            "DOI": "10.1109/JPHOT.2020.3030272",
            "Date of Publication": "13 October 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "Youshuo Cui",
                "labs": [
                    "College of Applied Sciences, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Jinrong Tian",
                "labs": [
                    "College of Applied Sciences, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Zikai Dong",
                "labs": [
                    "College of Applied Sciences, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Runqin Xu",
                "labs": [
                    "Institute of Automation, Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Zexin Zhang",
                "labs": [
                    "College of Applied Sciences, Beijing University of Technology, Beijing, China"
                ]
            },
            {
                "name": "Yanrong Song",
                "labs": [
                    "College of Applied Sciences, Beijing University of Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical fiber dispersion",
                "Solitons",
                "Fiber lasers",
                "Laser mode locking",
                "Optical fiber couplers",
                "Laser theory"
            ],
            "Author Keywords": [
                "Fiber laser",
                "mode-locked laser",
                "dissipative soliton resonance"
            ]
        }
    },
    {
        "Title": "Fine-Tuning of Distil-BERT for Continual Learning in Text Classification: An Experimental Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10614170/",
        "Abstract": "Continual learning (CL) with bidirectional encoder representation from transformer (BERT) and its variant Distil-BERT, have shown remarkable performance in various natural language processing (NLP) tasks, such as text classification (TC). However, the model degrading factors like catastrophic forgetting (CF), accuracy, task dependent architecture ruined its popularity for complex and intelligent tasks. This research article proposes an innovative approach to address the challenges of CL in TC tasks. The objectives are to enable the model to learn continuously without forgetting previously acquired knowledge and perfectly avoid CF. To achieve this, a task-independent model architecture is introduced, allowing training of multiple tasks on the same model, thereby improving overall performance in CL scenarios. The framework incorporates two auxiliary tasks, namely next sentence prediction and task identifier prediction, to capture both the task-generic and task-specific contextual information. The Distil-BERT model, enhanced with two linear layers, categorizes the output representation into a task-generic space and a task-specific space. The proposed methodology is evaluated on diverse sets of TC tasks, including Yahoo, Yelp, Amazon, DB-Pedia, and AG-News. The experimental results demonstrate impressive performance across multiple tasks in terms of F1 score, model accuracy, model evaluation loss, learning rate, and training loss of the model. For the Yahoo task, the proposed model achieved an F1 score of 96.84 %, accuracy of 95.85 %, evaluation loss of 0.06, learning rate of 0.00003144. In the Yelp task, our model achieved an F1 score of 96.66 %, accuracy of 97.66 %, evaluation loss of 0.06, and similarly minimized training losses by achieving the learning rate of 0.00003189. For the Amazon task, the F1 score was 95.82 %, the observed accuracy is 97.83 %, evaluation loss was 0.06, and training losses were effectively minimized by securing the learning rate of 0.00003144. In the DB-Pedia task, we achieved an F1 score of 96.20 %, accuracy of 95.21 %, evaluation loss of 0.08, with learning rate 0.0001972 and rapidly minimized training losses due to the limited number of epochs and instances. In the AG-News task, our model obtained an F1 score of 94.78 %, accuracy of 92.76 %, evaluation loss of 0.06, and fixed the learning rate to 0.0001511. These results highlight the exceptional performance of our model in various TC tasks, with gradual reduction in training losses over time, indicating effective learning and retention of knowledge.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3435537",
            "Date of Publication": "29 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sahar Shah",
                "labs": [
                    "Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan, Italy"
                ]
            },
            {
                "name": "Sara Lucia Manzoni",
                "labs": [
                    "Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan, Italy"
                ]
            },
            {
                "name": "Farooq Zaman",
                "labs": [
                    "Department of Computer Science, University of Information Technology, Lahore, Pakistan"
                ]
            },
            {
                "name": "Fatima Es Sabery",
                "labs": [
                    "Department of Economics and Management Sciences, Faculty of Law, Economics and Social Sciences, Hassan II University of Casablanca, Mohammedia, Morocco"
                ]
            },
            {
                "name": "Francesco Epifania",
                "labs": [
                    "Social Things srl, Milan, Italy"
                ]
            },
            {
                "name": "Italo Francesco Zoppis",
                "labs": [
                    "Department of Informatics, Systems and Communication, University of Milano-Bicocca, Milan, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Training",
                "Adaptation models",
                "Data models",
                "Accuracy",
                "Computational modeling",
                "Transformers",
                "Natural language processing",
                "Text categorization",
                "Continuing education"
            ],
            "Author Keywords": [
                "Continual learning",
                "natural language processing",
                "text classification",
                "fine-tuning",
                "Distil-BERT"
            ]
        }
    },
    {
        "Title": "Toward Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal Cross- and Self-Attention Large Language Model Approach",
        "Link": "https://ieeexplore.ieee.org/document/10438452/",
        "Abstract": "This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL’s performance with state-of-the-art LLM-based models and traditional time sequence models, demonstrating its superiority in accuracy and robustness, achieving an accuracy of 95.94% and an AUC of 0.98. This NLP-based approach enables, for the first time, the creation of exploits directly from design documents, making remarkable progress in scalable system verification and validation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3366803",
            "Date of Publication": "16 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jingda Yang",
                "labs": [
                    "School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            },
            {
                "name": "Ying Wang",
                "labs": [
                    "School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Protocols",
                "Formal verification",
                "5G mobile communication",
                "Natural languages",
                "Iterative methods",
                "Transformers",
                "Complexity theory",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Formal verification",
                "cross-attention",
                "self-attention",
                "natural language protocol",
                "formal flow graph"
            ]
        }
    },
    {
        "Title": "A Neural Relation Extraction Model for Distant Supervision in Counter-Terrorism Scenario",
        "Link": "https://ieeexplore.ieee.org/document/9281299/",
        "Abstract": "Natural language processing (NLP) is the best solution to extensive, unstructured, complex, and diverse network big data for counter-terrorism. Through the text analysis, it is the basis and the most critical step to quickly extract the relationship between the relevant entities pairs in terrorism. Relation extraction lays a foundation for constructing a knowledge graph (KG) of terrorism and provides technical support for intelligence analysis and prediction. This paper takes the distant-supervised relation extraction as the starting point, breaks the limitation of artificial data annotation. Combining the Bidirectional Encoder Representation from Transformers (BERT) pre-training model and the sentence-level attention over multiple instances, we proposed the relation extraction model named BERT-att. Experiments show that our model is more efficient and better than the current leading baseline model over each evaluative metrics. Our model applied to the construction of anti-terrorism knowledge map, it used in regional security risk assessment, terrorist event prediction and other scenarios.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3042672",
            "Date of Publication": "04 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jiaqi Hou",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Xin Li",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Rongchen Zhu",
                "labs": [
                    "School of Information Technology and Cyber Security, People’s Public Security University of China, Beijing, China"
                ]
            },
            {
                "name": "Chongqiang Zhu",
                "labs": [
                    "Technical Investigation Detachment, Lianyungang Public Security Bureau, Lianyungang, China"
                ]
            },
            {
                "name": "Zeyu Wei",
                "labs": [
                    "Patrol Special Police Brigade of Keqiao, Shaoxing Public Security Bureau, Shaoxing, China"
                ]
            },
            {
                "name": "Chao Zhang",
                "labs": [
                    "Network Security Detachment, Lianyungang Public Security Bureau, Lianyungang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bit error rate",
                "Data mining",
                "Encoding",
                "Feature extraction",
                "Data models",
                "Big Data",
                "Training"
            ],
            "Author Keywords": [
                "BERT",
                "relation extraction",
                "distant supervision",
                "selective attention mechanism",
                "BERT entity encoding"
            ]
        }
    },
    {
        "Title": "A Hybrid Transformer Architecture for Multiclass Mental Illness Prediction Using Social Media Text",
        "Link": "https://ieeexplore.ieee.org/document/10804794/",
        "Abstract": "Mental illness prediction through text involves employing natural language processing (NLP) techniques and deep learning algorithms to analyze textual data for the identification of mental disorders. Therefore, machine learning and deep learning algorithms have been utilized in the existing literature for the detection of mental illness. However, current systems exhibit suboptimal performance primarily due to their reliance on traditional embedding techniques and generic language models to generate text embeddings. To address this limitation, there is a requirement for domain-specific pretrained language models that comprehensively understand the context found in posts of person with a psychiatric disability patients. Posts from individuals with mental illness often contain metaphorical expressions, posing a challenge for existing models in understanding such figurative language. In this study, we propose a hybrid transformer architecture, comprising MentalBERT and MelBERT pretrained language models, cascaded with CNN models to generate and concatenate deep features. MentalBERT is pretrained on an extensive corpus of text data specifically related to the mental health domain, while MelBERT is trained on a large corpus of metaphorical data for improved understanding of metaphorical expressions. The results reveal outstanding performance of the proposed architecture with an overall accuracy of 92% and an F1-score of 92%, surpassing state-of-the-art models in comparison. This study underscores the necessity for further research in this field and illustrates the potential of advanced technologies to address mental health issues in contemporary society.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3519308",
            "Date of Publication": "17 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Adnan Karamat",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Imran",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan"
                ]
            },
            {
                "name": "Muhammad Usman Yaseen",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan"
                ]
            },
            {
                "name": "Rasool Bukhsh",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad (CUI), Islamabad, Pakistan"
                ]
            },
            {
                "name": "Sheraz Aslam",
                "labs": [
                    "Department of Electrical Engineering, Computer Engineering and Informatics, Cyprus University of Technology, Limassol, Cyprus",
                    "Department of Computer Science, CTL Eurocollege, Limassol, Cyprus"
                ]
            },
            {
                "name": "Nouman Ashraf",
                "labs": [
                    "School of Electrical and Electronic Engineering, Technological University Dublin, Dublin, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Depression",
                "Social networking (online)",
                "Mental health",
                "Anxiety disorders",
                "Predictive models",
                "Feature extraction",
                "Deep learning",
                "Data models",
                "Transformers",
                "Linguistics"
            ],
            "Author Keywords": [
                "Convolutional neural network",
                "deep learning",
                "mental illness",
                "MentalBERT",
                "melBERT",
                "social media",
                "transformer"
            ]
        }
    },
    {
        "Title": "A Place Recommendation Approach Using Word Embeddings in Conceptual Spaces",
        "Link": "https://ieeexplore.ieee.org/document/10035007/",
        "Abstract": "The way that computing systems digest geographic space is fundamentally different from people’s understanding of space. In human discourse, a geographic space is referred to by a place name, and the reasoning about a place are based on its characteristics. This is in contrast with computing systems where geographical spaces are handled by the definition of coordinate systems. Hence, when recommending places, a recommendation method that leverages textual content, as a medium of communication among people, can be better understood. In this paper, we use elements of Natural Language Processing (NLP), such as Positive Point-wise Mutual Information (PPMI), Term Frequency - Inverse Document Frequency (TF-IDF), and Multi-Dimensional Scaling (MDS), to infer a conceptual space of the items of a place-based recommender system. By applying a Support Vector Machine (SVM) classifier on the resulting conceptual space, some meaningful directions are extracted. Shannon entropy is used as a measure to identify the directions that imply a valid geographic region. We apply the method on a dataset of advertisement descriptions of rental properties and a dataset of Persian Wikipedia articles. The results showed the proposed method is able to measure the similarity of items in the inferred conceptual space with 88% of accuracy. A comparison with BERT algorithm demonstrates the superiority of the proposed method over the baseline models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3241806",
            "Date of Publication": "01 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Omid R. Abbasi",
                "labs": [
                    "Department of GIS, K. N. Toosi University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Ali A. Alesheikh",
                "labs": [
                    "Department of GIS, K. N. Toosi University of Technology, Tehran, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Recommender systems",
                "Ontologies",
                "Geographic information systems",
                "Content management",
                "Support vector machines",
                "Social networking (online)"
            ],
            "Author Keywords": [
                "Conceptual spaces",
                "place",
                "recommender systems",
                "semantic similarity",
                "textual content",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "A Short Text Classification Method Based on N-Gram and CNN",
        "Link": "https://ieeexplore.ieee.org/document/10848243/",
        "Abstract": "Text classification is a fundamental task in Nature language process (NLP) application. Most existing research work relied on either explicate or implicit text representation to settle this kind of problems, while these techniques work well for sentence and can not simply apply to short text because of its shortness and sparseness feature. Given these facts that obtaining the simple word vector feature and ignoring the important feature by utilizing the traditional multi-size filter Convolution neural network (CNN) during the course of text classification task, we offer a kind of short text classification model by CNN, which can obtain the abundant text feature by adopting none linear sliding method and N-gram language model, and picks out the key features by using the concentration mechanism, in addition employing the pooling operation can preserve the text features at the most certain as far as possible. The experiment shows that this method we offered, comparing the traditional machine learning algorithm and convolutional neural network, can markedly improve the classification result during the short text classification.",
        "Details": {
            "DOI": "10.1049/cje.2020.01.001",
            "Date of Publication": "March 2020",
            "Publisher": "CIE",
            "Published In": "Chinese Journal of Electronics"
        },
        "issn_info": {
            "Electronic ISSN": "2075-5597",
            "Print ISSN": "1022-4653"
        },
        "authors_data": [
            {
                "name": "Haitao Wang",
                "labs": [
                    "College of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China"
                ]
            },
            {
                "name": "Jie He",
                "labs": [
                    "College of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China"
                ]
            },
            {
                "name": "Xiaohong Zhang",
                "labs": [
                    "College of Computer Science and Technology, Henan Polytechnic University, Jiaozuo, China"
                ]
            },
            {
                "name": "Shufen Liu",
                "labs": [
                    "College of Computer Science and Technology, Jilin University, Changchun, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Maximum likelihood detection",
                "Machine learning algorithms",
                "Convolution",
                "Text categorization",
                "Neural networks",
                "Nonlinear filters",
                "Vectors",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Short text",
                "Classification",
                "Convolution neural network",
                "N-gram",
                "Concentration mechanism"
            ]
        }
    },
    {
        "Title": "Clustering APT Groups Through Cyber Threat Intelligence by Weighted Similarity Measurement",
        "Link": "https://ieeexplore.ieee.org/document/10697172/",
        "Abstract": "Advanced Persistent Threat (APT) groups pose significant cybersecurity threats due to their sophisticated and persistent nature. This study introduces a novel methodology to understand their collaborative patterns and shared objectives, which is crucial for developing robust defense mechanisms. We utilize MITRE ATT&CK Techniques, software, target nations, and industries as our primary features to understand the characteristics of APT groups. Since essential information is often buried within the unstructured data of Cyber Threat Intelligence (CTI) reports, we employ Natural Language Processing (NLP) and Named Entity Recognition (NER) to extract relevant data. To analyze and interpret the complex relationships between APT groups, we compute similarity among the features using weighted cosine similarity metrics and Machine Learning (ML) models, enhanced by feature crosses and feature selection strategies. Subsequently, hierarchical clustering is used to group APTs based on their similarity scores, helping to identify common behaviors and uncover deeper relationships. Our methodology demonstrates notable clustering performance, with a silhouette coefficient of 0.76, indicating strong intra-cluster similarity. The Adjusted Rand Index (ARI) of 0.63, though moderate, effectively measures agreement between our clustering and the ground truth. These metrics provide robust validation, surpassing commonly recognized benchmarks for effective clustering in cybersecurity. Our methodology successfully classifies 23 distinct APT groups into six clusters, highlighting the importance of techniques and industry features in the clustering process. Notably, techniques such as T1059 (Command and Scripting Interpreter) and T1036 (Masquerading) are prevalently deployed, observed in 18 out of 23 APT groups across all six clusters.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3469552",
            "Date of Publication": "27 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zheng-Shao Chen",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "R. Vaitheeshwari",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "Eric Hsiao-Kuang Wu",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Central University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "Ying-Dar Lin",
                "labs": [
                    "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan"
                ]
            },
            {
                "name": "Ren-Hung Hwang",
                "labs": [
                    "College of Artificial Intelligence, National Yang Ming Chiao Tung University, Tainan, Taiwan"
                ]
            },
            {
                "name": "Po-Ching Lin",
                "labs": [
                    "Department of Computer Science and Information Engineering, National Chung Cheng University, Chiayi, Taiwan"
                ]
            },
            {
                "name": "Yuan-Cheng Lai",
                "labs": [
                    "Department of Information Management, National Taiwan University of Science and Technology, Taipei, Taiwan"
                ]
            },
            {
                "name": "Asad Ali",
                "labs": [
                    "National Institute of Cyber Security, Ministry of Digital Affairs, Taipei, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Software",
                "Industries",
                "Cyber threat intelligence",
                "Accuracy",
                "Computer security",
                "Organizations",
                "Market research",
                "Named entity recognition",
                "Encoding"
            ],
            "Author Keywords": [
                "Advanced persistent threat (APT) groups",
                "cyber threat intelligence (CTI) report",
                "feature engineering",
                "hierarchical clustering",
                "named entity recognition",
                "weighted similarity measurement"
            ]
        }
    },
    {
        "Title": "DCNN: Deep Convolutional Neural Network With XAI for Efficient Detection of Specific Language Impairment in Children",
        "Link": "https://ieeexplore.ieee.org/document/10605817/",
        "Abstract": "Assessing children for specific language impairment (SLI) or other communication impairments can be challenging for doctors due to the extensive battery of tests and examinations required. Artificial intelligence and computer-aided diagnostics have aided medical professionals in conducting rapid, reliable assessments of children’s neurodevelopmental conditions concerning language comprehension and output. Previous research has shown differences between the vocal characteristics of typically developing (TD) children and those with SLI. This study aims to develop a natural language processing (NLP) system that can identify children’s early impairments using specific conditions. Our dataset contains examples of disorders, and this study seeks to (1) demonstrate the effectiveness of several classifiers in this regard and (2) select the most effective model from the classifiers. We utilized various machine learning (ML), deep learning (DL), and transformer models to achieve our objective. Our deep convolutional neural network (DCNN) model yielded excellent results, outperforming the competition with an accuracy of 90.47%, making it the top-performing model overall. To increase the accuracy and credibility of our most likely output, we have incorporated explainable AI approaches like SHAP and LIME. These approaches aid in interpreting and explaining model predictions, considering the significance and sensitivity of the topic. Additionally, we believe that our work can contribute to developing more accessible, effective methods for diagnosing language impairments in young children.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3431933",
            "Date of Publication": "22 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Khan Md Hasib",
                "labs": [
                    "Department of Computer Science and Engineering, Bangladesh University of Business and Technology, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "M. F. Mridha",
                "labs": [
                    "Department of Computer Science, American International University-Bangladesh, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md Humaion Kabir Mehedi",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Kazi Omar Faruk",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Rabeya Khatun Muna",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Shahriar Iqbal",
                "labs": [
                    "Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md Rashedul Islam",
                "labs": [
                    "Department of Computer Science and Engineering, University of Asia Pacific, Dhaka, Bangladesh",
                    "Department of RD, Chowagiken Corporation, Sapporo, Japan"
                ]
            },
            {
                "name": "Yutaka Watanobe",
                "labs": [
                    "Department of Computer Science and Engineering, The University of Aizu, Aizuwakamatsu, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Explainable AI",
                "Predictive models",
                "Pediatrics",
                "Accuracy",
                "Deep learning",
                "Reliability",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Natural language processing",
                "language impairment",
                "child",
                "DCNN",
                "XAI",
                "LIME",
                "SHAP"
            ]
        }
    },
    {
        "Title": "A Hybrid Approach for Automated Short Answer Grading",
        "Link": "https://ieeexplore.ieee.org/document/10577980/",
        "Abstract": "With the widespread use of distance learning, technological developments have also been applied in the field of education. The need for accurate and efficient assessment methods for online exams has become even more apparent, especially with remote learning taking place during the pandemic. For a more efficient evaluation process, we propose a hybrid model of the Automatic Short Answer Grading (ASAG) system based on Bidirectional Encoder Representation of Transformers (BERT). The usage of novel state-of-the-art natural language processing (NLP) techniques in our model enhances the comprehension of text. Specifically, we employ a customized multi-head attention mechanism adapted with BERT, which enables reliable identification of semantic dependencies among words within a sentence and therefore contributes to the effectiveness and trustworthiness of the scoring system. We use a parallel connection of CNN layers in our proposed BERT based ASAG system instead of their serial connection and this usage improves the performance of the system. The proposed model is assessed using common datasets frequently used for ASAG related research projects. In this evaluation process, our model produces much better results compared to other systems available in the literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3420890",
            "Date of Publication": "01 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mustafa Kaya",
                "labs": [
                    "Department of Computer Engineering, Hacettepe University, Beytepe Campus, Ankara, Türkiye"
                ]
            },
            {
                "name": "Ilyas Cicekli",
                "labs": [
                    "Department of Computer Engineering, Hacettepe University, Beytepe Campus, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bidirectional control",
                "Encoding",
                "Task analysis",
                "Transformers",
                "Semantics",
                "Natural language processing",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Automated short answer grading",
                "BERT",
                "CNN",
                "LSTM"
            ]
        }
    },
    {
        "Title": "Target-Aspect-Sentiment Joint Detection: Uncovering Explicit and Implicit Targets Through Aspect-Target-Context-Aware Detection",
        "Link": "https://ieeexplore.ieee.org/document/10600682/",
        "Abstract": "Target Aspect Sentiment Detection (TASD) is challenging because it involves various Natural Language Processing (NLP) subtasks including opinion target detection and sentiment polarity classification. Despite significant advancements in this area, most studies have neglected the interrelation between opinion elements and contexts, primarily when a target opinion is expressed implicitly. This study proposes Aspect-Target-Context-Aware Detection for Target Aspect Sentiment Detection, which is a joint learning neural-based framework. The Aspect-Target-Context-Aware Detection model incorporates opinion context syntactic information by utilizing dependency relations associated with opinion terms, and considers head nodes as a primary element for identifying relevant opinion contexts. The Target Aspect Sentiment Detection task was divided into aspect sentiment classification and opinion target extraction tasks. For aspect sentiment, multiclass classification was employed for aspect-sentiment pairs. A BIO tag inference scheme is adopted to detect the opinion target and determine its type (implicit or explicit) for opinion target extraction. The approach was evaluated using two restaurant datasets: Task-5 of SemEval-2016 and Task-12 of SemEval-2015. The proposed approach demonstrated cutting-edge performance when extracting multi-opinion elements from the TASD task, with notable improvements in Macro-F1 values: 3.28% for SemEval 2015 and 5.97% for SemEval 2016. The model also identifies various opinion types and offers valuable insights for future developments, particularly for implicit opinion detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3430092",
            "Date of Publication": "18 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Radi",
                "labs": [
                    "Center for Artificial Intelligence Technology (CAIT), Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia",
                    "Abu Dhabi Polytechnic, Abu Dhabi, United Arab Emirates"
                ]
            },
            {
                "name": "Nazlia Omar",
                "labs": [
                    "Center for Artificial Intelligence Technology (CAIT), Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia"
                ]
            },
            {
                "name": "Wandeep Kaur",
                "labs": [
                    "Center for Artificial Intelligence Technology (CAIT), Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Sentiment analysis",
                "Syntactics",
                "Natural language processing",
                "Predictive models",
                "Labeling",
                "Context modeling"
            ],
            "Author Keywords": [
                "Aspect-based sentiment analysis (ABSA)",
                "dependency relations",
                "explicit opinion",
                "implicit opinion",
                "target-aspect-sentiment (TASD)"
            ]
        }
    },
    {
        "Title": "Exploring Transformer-Based Learning for Negation Detection in Biomedical Texts",
        "Link": "https://ieeexplore.ieee.org/document/9853208/",
        "Abstract": "NLP techniques have been widely adopted in the biomedical domain to perform various text-analytics tasks, such as searching biomedical literature and extracting and deriving new knowledge from biomedical data. One type of biomedical data is clinical texts (e.g., clinical cases and medical records), which typically contain physicians’ notes about a patient’s health, including previous medical history (symptoms, diseases, lab exams, treatments, etc.), as every visit to the hospital leads to the addition of more information to the patient’s record. Another type of biomedical data is biological articles, which typically discuss and explore a certain phenomenon, such as the behavior of biological entities (e.g., genetic relations and interactions among them) and the roles of specific biological processes in causing diseases (e.g., how genetic amplification can cause tumorous diseases). For both types of biomedical data, negation detection is an essential analytics task that can be applied to identify negated contexts in biomedical text (e.g., detecting the presence of a statement establishing that a patient does not have/fit a certain clinical condition or detecting statements that indicate the nonexistence of certain relations among biological entities). This task has been addressed in prior work by considering a variety of approaches such as rule-based systems, conventional machine-learning classifiers, and deep learning approaches. In this work, we propose applying transformer-based learning for negation detection in biomedical texts. We use pre-trained BERT and other similar models (such as ALBERT, XLNet, and ELECTRA) to address two negation-detection subtasks: negation sentence identification and negation scope recognition. We evaluated our approach using the BioScope corpus and relying on measures such as accuracy, precision, recall, F1, and percentage of correct scopes (PCS). Our findings show the potential of transformer-based learning for negation detection, reaching an accuracy of 99% for negation identification and a PCS of 95% for negation scope recognition.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3197772",
            "Date of Publication": "10 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ghadeer Althari",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammad Alsulmi",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Bit error rate",
                "Transformers",
                "Medical services",
                "Natural language processing",
                "Medical diagnostic imaging",
                "Diseases",
                "Bioinformatics",
                "Machine learning",
                "Informatics"
            ],
            "Author Keywords": [
                "Health informatics",
                "biomedical text analytics",
                "machine learning",
                "natural language processing",
                "text classification"
            ]
        }
    },
    {
        "Title": "Enhanced Sentiment Intensity Regression Through LoRA Fine-Tuning on Llama 3",
        "Link": "https://ieeexplore.ieee.org/document/10623139/",
        "Abstract": "Sentiment analysis and emotion detection are critical research areas in natural language processing (NLP), offering benefits to numerous downstream tasks. Despite the widespread application of pre-trained models and large language models (LLMs) in sentiment analysis, most previous works have focused on sentiment polarity or emotion classification, neglecting the finer-grained task of sentiment intensity regression, which prevents the precise capture of sentiment intensity and hindering model performance in complex scenarios and diverse applications. To address this issue, we enhance the Roberta model with an efficient additive attention mechanism and an adaptive weighted Huber loss function, notably improving its performance in sentiment intensity regression. Based on the SemEval 2017 and 2018 datasets, we employ prompt engineering to construct fine-tuned datasets, which are further enriched with outputs from the enhanced Roberta model. We then fine-tune the Llama 3 model using Low-Rank Adaptation (LoRA) within the Unsloth framework. Experimental results demonstrate that our enhanced RoBERTa model significantly outperforms baseline models. Furthermore, the enriched and LoRA fine-tuned Llama 3-8B model outperforms other LLMs with similar parameter scales. Our method improves MAE by 0.015 and MSE by 0.0054 on the SemEval 2018 dataset, achieving a Pearson correlation coefficient of 0.8441. On the SemEval 2017 dataset, it improves MAE by 0.0416 and MSE by 0.043, with a Pearson correlation coefficient increased to 0.8268, which demonstrates the superior predictive power and robustness of our approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3438353",
            "Date of Publication": "05 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Diefan Lin",
                "labs": [
                    "Faculty of Arts and Sciences, Beijing Normal University, Zhuhai, China"
                ]
            },
            {
                "name": "Yi Wen",
                "labs": [
                    "Faculty of Arts and Sciences, Beijing Normal University, Zhuhai, China"
                ]
            },
            {
                "name": "Weishi Wang",
                "labs": [
                    "Faculty of Arts and Sciences, Beijing Normal University, Zhuhai, China"
                ]
            },
            {
                "name": "Yan Su",
                "labs": [
                    "Faculty of Arts and Sciences, Beijing Normal University, Zhuhai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Adaptation models",
                "Sentiment analysis",
                "Analytical models",
                "Biological system modeling",
                "Predictive models",
                "Training"
            ],
            "Author Keywords": [
                "LoRA",
                "sentiment analysis",
                "Llama 3",
                "RoBERTa",
                "adaptive weighted Huber loss function"
            ]
        }
    },
    {
        "Title": "Bridging the Kuwaiti Dialect Gap in Natural Language Processing",
        "Link": "https://ieeexplore.ieee.org/document/10430151/",
        "Abstract": "The available dialectal Arabic linguistic resources are very limited in their coverage of Arabic dialects, particularly the Kuwaiti dialect. This shortage of linguistic resources creates struggles for researchers in the Natural Language Processing (NLP) field and limits the development of advanced linguistic analytical and processing tools for the Kuwaiti dialect. Many other low-resource Arabic dialects are still not explored in research due to the challenges faced during the annotators’ recruitment process for dataset labeling. This paper proposes a weak supervised classification system to solve the problem of recruiting human annotators called “q8SentiLabeler”. In addition, we developed a large dataset consisting of over 16.6k posts serving sentiment analysis in the Kuwaiti dialect. This dataset covers several themes and timeframes to remove any bias that might affect its content. Furthermore, we evaluated our dataset using multiple traditional machine-learning classifiers and advanced deep-learning language models to test its performance. Results demonstrate the positive potential of “q8SentiLabeler” to replace human annotators with a 93% for pairwise percent agreement and 0.87 for Cohen’s Kappa coefficient. Using the ARBERT model on our dataset, we achieved 89% accuracy in the system’s performance.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3364367",
            "Date of Publication": "08 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatemah Husain",
                "labs": [
                    "Information Science Department, College of Life Sciences, Sabah AlSalem University City (Alshadadiya), Kuwait University, Safat, Kuwait"
                ]
            },
            {
                "name": "Hana Alostad",
                "labs": [
                    "Computer Science Department, College of Arts and Sciences, Gulf University for Science and Technology, Hawally, Kuwait"
                ]
            },
            {
                "name": "Halima Omar",
                "labs": [
                    "Communication Disorders Science Department, College of Life Sciences, Sabah AlSalem University City (Alshadadiya), Kuwait University, Safat, Kuwait"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Sentiment analysis",
                "Labeling",
                "Linguistics",
                "Annotations",
                "Cleaning",
                "Text categorization",
                "Zero-shot learning",
                "Machine learning"
            ],
            "Author Keywords": [
                "Natural language processing",
                "weak supervision",
                "zero-shot language model",
                "sentiment analysis",
                "Arabic language",
                "machine learning",
                "Kuwaiti dialect"
            ]
        }
    },
    {
        "Title": "INF-NDN IoT: An Intelligent Naming and Forwarding in Name Data Networking for Internet of Things",
        "Link": "https://ieeexplore.ieee.org/document/10638459/",
        "Abstract": "Internet of things (IoT) has emerged as a quintessential paradigm of communication systems. Current literature introduces notion of a named data network for IoT (NDN-IoT), optimizing IoT communication by employing name-based networking. However, the advancements introduced by this approach are inadequate when dealing with URL-based naming and forwarding. For instance, length and ambiguities in content names are still open challenges. In addition, the intelligent exploration of content names to discern a forwarding clue is a significant research gap. To achieve intelligent communication, understanding the interest name and acquiring a forwarding clue is crucial. Focusing on this gap, an intelligent naming scheme called INF-NDN IoT is proposed that correlates with a forwarding mechanism as well. The proposed INF-NDN IoT improves the NDN naming schemas by utilizing natural language processing (NLP) techniques and selecting supernodes and ordinary nodes in the network. INF-NDN IoT assigns (forwarding clue) semantic tags to content names as well as to supernodes that in turn perform the semantic forwarding. Experimental results have shown that INF-NDN IoT outperformed existing work, and has better results in terms of name length, name memory utilization, interest satisfaction rate, retrieval time, hop count, and energy consumption.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3444903",
            "Date of Publication": "19 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ghulam Musa Raza",
                "labs": [
                    "Department of Software and Communications Engineering, Hongik University, Sejong-si, South Korea"
                ]
            },
            {
                "name": "Ihsan Ullah",
                "labs": [
                    "Department of Software and Communications Engineering, Hongik University, Sejong-si, South Korea"
                ]
            },
            {
                "name": "Muhammad Salah Ud Din",
                "labs": [
                    "Department of Software and Communications Engineering, Hongik University, Sejong-si, South Korea"
                ]
            },
            {
                "name": "Muhammad Atif Ur Rehman",
                "labs": [
                    "Department of Computing and Mathematics, Manchester Metropolitan University, Manchester, U.K."
                ]
            },
            {
                "name": "Byung-Seo Kim",
                "labs": [
                    "Department of Software and Communications Engineering, Hongik University, Sejong-si, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Internet of Things",
                "Natural language processing",
                "Databases",
                "Routing",
                "Monitoring",
                "Tagging"
            ],
            "Author Keywords": [
                "Named data network",
                "Internet of Things",
                "natural language processing",
                "supernodes",
                "naming",
                "forwarding",
                "semantic tag"
            ]
        }
    },
    {
        "Title": "Multi-Level Cross-Lingual Transfer Learning With Language Shared and Specific Knowledge for Spoken Language Understanding",
        "Link": "https://ieeexplore.ieee.org/document/8990095/",
        "Abstract": "Recently conversational agents effectively improve their understanding capabilities by neural networks. Such deep neural models, however, do not apply to most human languages due to the lack of annotated training data for various NLP tasks. In this paper, we propose a multi-level cross-lingual transfer model with language shared and specific knowledge to improve the spoken language understanding of low-resource languages. Our method explicitly separates the model into the language-shared part and language-specific part to transfer cross-lingual knowledge and improve the monolingual slot tagging, especially for low-resource languages. To refine the shared knowledge, we add a language discriminator and employ adversarial training to reinforce information separation. Besides, we adopt novel multi-level knowledge transfer in an incremental and progressive way to acquire multi-granularity shared knowledge rather than a single layer. To mitigate the discrepancies between the feature distributions of language specific and shared knowledge, we propose the neural adapters to fuse knowledge automatically. Experiments show that our proposed model consistently outperforms monolingual baseline with a statistically significant margin up to 2.09%, even higher improvement of 12.21% in the zero-shot setting.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2972925",
            "Date of Publication": "10 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Keqing He",
                "labs": [
                    "Department of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Weiran Xu",
                "labs": [
                    "Department of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            },
            {
                "name": "Yuanmeng Yan",
                "labs": [
                    "Department of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tagging",
                "Hidden Markov models",
                "Feature extraction",
                "Task analysis",
                "Training",
                "Adaptation models",
                "Semantics"
            ],
            "Author Keywords": [
                "Spoken language understanding",
                "cross-lingual learning",
                "linguistic knowledge transfer",
                "adversarial learning",
                "multi-level knowledge representation"
            ]
        }
    },
    {
        "Title": "Entity Disambiguation Leveraging Multi-Perspective Attention",
        "Link": "https://ieeexplore.ieee.org/document/8790727/",
        "Abstract": "Entity disambiguation aims to map mentions in text to the corresponding entities in a knowledge base, which is a basic task in natural language processing (NLP). The major challenge in entity disambiguation is how to extract key information in mention context and entity description that is discriminative for disambiguation. State-of-the-art entity disambiguation systems apply attention mechanism to identify the informative components, but most of the methods only focus on mention context, and neglect entity side. Besides, attention mechanism is employed in a single aspect, which may not be effective in difficult circumstances. In this work, we propose a neural network with multi-perspective attention to enrich the representation of mentions and entities in different perspectives. Specifically, we utilize intra-attention to aggregate internal pivotal information in mention context and entity description separately, and utilize inter-attention to interact their latent semantics in multiple directions and highlight the interrelated information, so as to capture more informative features and improve the disambiguation performance. The experimental results show that our proposed model outperforms other state-of-the-art entity disambiguation models and attain more improvements on hard datasets, which validates the effectiveness and superiority of our model, especially in complex situations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2933644",
            "Date of Publication": "07 August 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chengzhi Wang",
                "labs": [
                    "School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Xian Sun",
                "labs": [
                    "Key Laboratory of Network Information System Technology (NIST), Institute of Electronics, Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Hongfeng Yu",
                "labs": [
                    "Key Laboratory of Network Information System Technology (NIST), Institute of Electronics, Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Wenkai Zhang",
                "labs": [
                    "Key Laboratory of Network Information System Technology (NIST), Institute of Electronics, Chinese Academy of Sciences, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Neural networks",
                "Urban areas",
                "Task analysis",
                "Knowledge based systems",
                "Aggregates",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Entity disambiguation",
                "neural network",
                "attention mechanism",
                "multi-perspective attention"
            ]
        }
    },
    {
        "Title": "A Parallel Two-Channel Emotion Classification Method for Chinese Text",
        "Link": "https://ieeexplore.ieee.org/document/10381688/",
        "Abstract": "The complex structure of Chinese, including the dual-granularity feature of words and phrases, poses unique challenges for sentiment analysis, which is significantly different from the alphabetic word formation mechanism of English text. To capture Chinese semantics more accurately, an advanced parallel channel sentiment classification strategy is designed. In this study, the advanced pre-training model ERNIE with Word2vec is first adopted to enrich the embedding of Chinese text at word granularity. Following that, fine-grained features at the word level are extracted by a multi-window convolutional strategy, and the word vector sequences are deeply learnt using BiGRU network to ensure the comprehensive capture of contextual information in both directions. To further optimise the model, an Attention mechanism is introduced to ensure effective delivery of information and improve computational efficiency. After this series of innovative designs, the microblog comment dataset is used as an experimental case, and the hyperparameters are adjusted to determine the optimal parameters. Six comparison models are selected to verify the effectiveness of MsCBA on three datasets. The classification accuracies of the proposed model on the three datasets are 93.64%, 90.00% and 92.61%, respectively, which are better than the comparison models. This study provides an efficient and innovative approach for Chinese sentiment analysis, which sheds new light on the field of NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3350190",
            "Date of Publication": "05 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Liu Na",
                "labs": [
                    "School of Information Science and Engineering, Dalian Polytechnic University, Dalian, China"
                ]
            },
            {
                "name": "Tao Cao",
                "labs": [
                    "School of Information Science and Engineering, Dalian Polytechnic University, Dalian, China"
                ]
            },
            {
                "name": "Shuchen Bai",
                "labs": [
                    "School of Information Science and Engineering, Dalian Polytechnic University, Dalian, China"
                ]
            },
            {
                "name": "Danqing Li",
                "labs": [
                    "School of Information Science and Engineering, Dalian Polytechnic University, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Computational modeling",
                "Data mining",
                "Context modeling",
                "Analytical models",
                "Task analysis"
            ],
            "Author Keywords": [
                "Attention model",
                "Chinese text classification",
                "deep neural networks",
                "dual-channel model",
                "Ernie"
            ]
        }
    },
    {
        "Title": "Enhanced Image Captioning Using Bahdanau Attention Mechanism and Heuristic Beam Search Algorithm",
        "Link": "https://ieeexplore.ieee.org/document/10604872/",
        "Abstract": "Captioning images is a challenging task at the intersection of Computer Vision (CV) and Natural Language Processing (NLP), that involves generating descriptive text to depict the content of an image. Existing methodologies typically employ Convolutional Neural Networks (CNNs) for feature extraction and Recurrent Neural Networks (RNNs) for generating captions. However, these approaches often suffer from a lack of contextual understanding, inability to capture fine-grained details, and to generate generic captions. This study proposes VisualCaptionNet (VCN), a novel image captioning model that leverages ResNet50 for rich visual feature extraction and a Long Short-Term Memory (LSTM) network for sequential caption generation while retaining context. By incorporating the Bahdanau attention mechanism to focus on relevant image regions and integrating beam search for coherent and contextually relevant descriptions, VCN addresses the limitations of previous methodologies. Extensive experimentation on benchmark datasets such as Flickr30K and Flickr8K demonstrates VCN’s notable improvements of 10% and 12% over baseline models in terms of caption quality, coherence, and relevance. These enhancements emphasize VCN’s effectiveness in advancing image captioning tasks, promising more accurate and contextually relevant descriptions for images.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3431091",
            "Date of Publication": "19 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "S. Abinaya",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "Mandava Deepak",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "A. Sherly Alphonse",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Long short term memory",
                "Feature extraction",
                "Residual neural networks",
                "Visualization",
                "Vectors",
                "Decoding",
                "Attention mechanisms",
                "Image capture"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "Bahdanau attention",
                "beam search",
                "BLEU score",
                "image captioning",
                "LSTM",
                "ResNet50",
                "VisualCaptionNet (VCN)"
            ]
        }
    },
    {
        "Title": "Nonlinear Absorbing-Loop Mirror Mode-Locked all-Polarization-Maintaining Yb-Doped Fiber Laser",
        "Link": "https://ieeexplore.ieee.org/document/9497747/",
        "Abstract": "In this paper, a nonlinear absorbing-loop mirror (NAbLM) is constructed in a polarization-maintaining (PM) version and applied in the all-normal dispersion (ANDi) regime, for the first time to our best knowledge. To investigate the properties of NAbLM in contrast with typical nonlinear optical loop mirror (NOLM), an asymmetric optical coupler is used in the NAbLM. In experiment, both the NAbLM and NOLM can be used to mode-lock a Yb-doped fiber (YDF) laser and enable a type of noise-like pulse (NLP) generation. Noticeably, however, it is further found that, in comparison to NOLM, NAbLM evidently enables both temporal and radio frequency (RF) noise suppressions, as well as elimination of RF variations. Further calculations show that the saturable property of the incorporated absorber plays a vital role in differing the NAbLM from typical NOLM. Our results demonstrate some new features of NAbLM, especially in respect to temporal pulse shaping, indicating that NAbLM can be a useful type of fiber loop mirror in nonlinear fiber optics.",
        "Details": {
            "DOI": "10.1109/JPHOT.2021.3100075",
            "Date of Publication": "27 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Photonics Journal"
        },
        "issn_info": {
            "Electronic ISSN": "1943-0655"
        },
        "authors_data": [
            {
                "name": "Yewang Chen",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Junqing Zhao",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Deqin Ouyang",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Meng Wang",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Minqiu Liu",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Xu Wu",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            },
            {
                "name": "Shuangchen Ruan",
                "labs": [
                    "Key Laboratory of Advanced Optical Precision Manufacturing Technology of Guangdong Higher Education Institutes, Shenzhen Technology University, Shenzhen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Radio frequency",
                "Optical fiber dispersion",
                "Optical fiber couplers",
                "Fiber lasers",
                "Optical fiber polarization",
                "Mirrors",
                "Absorption"
            ],
            "Author Keywords": [
                "Fiber laser",
                "nonlinear loop mirror",
                "polarization maintaining"
            ]
        }
    },
    {
        "Title": "BlazePose-Seq2Seq: Leveraging Regular RGB Cameras for Robust Gait Assessment",
        "Link": "https://ieeexplore.ieee.org/document/10506662/",
        "Abstract": "Evaluation of human gait through smartphone-based pose estimation algorithms provides an attractive alternative to costly lab-bound instrumented assessment and offers a paradigm shift with real time gait capture for clinical assessment. Systems based on smart phones, such as OpenPose and BlazePose have demonstrated potential for virtual motion assessment but still lack the accuracy and repeatability standards required for clinical viability. Seq2seq architecture offers an alternative solution to conventional deep learning techniques for predicting joint kinematics during gait. This study introduces a novel enhancement to the low-powered BlazePose algorithm by incorporating a Seq2seq autoencoder deep learning model. To ensure data accuracy and reliability, synchronized motion capture involving an RGB camera and ten Vicon cameras were employed across three distinct self-selected walking speeds. This investigation presents a groundbreaking avenue for remote gait assessment, harnessing the potential of Seq2seq architectures inspired by natural language processing (NLP) to enhance pose estimation accuracy. When comparing BlazePose alone to the combination of BlazePose and 1D convolution Long Short-term Memory Network (1D-LSTM), Gated Recurrent Unit (GRU) and Long Short-Term Memory (LSTM), the average mean absolute errors decreased from 13.4° to 5.3° for fast gait, from 16.3° to 7.5° for normal gait, and from 15.5° to 7.5° for slow gait at the left ankle joint angle respectively. The strategic utilization of synchronized data and rigorous testing methodologies further bolsters the robustness and credibility of these findings.",
        "Details": {
            "DOI": "10.1109/TNSRE.2024.3391908",
            "Date of Publication": "22 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Neural Systems and Rehabilitation Engineering"
        },
        "issn_info": {
            "Print ISSN": "1534-4320",
            "Electronic ISSN": "1558-0210"
        },
        "authors_data": [
            {
                "name": "Abdul Aziz Hulleck",
                "labs": [
                    "Department of Mechanical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Aamna AlShehhi",
                "labs": [
                    "Department of Biomedical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Marwan El Rich",
                "labs": [
                    "Department of Mechanical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Raviha Khan",
                "labs": [
                    "Department of Electrical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Rateb Katmah",
                "labs": [
                    "Department of Biomedical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            },
            {
                "name": "Mahdi Mohseni",
                "labs": [
                    "Department of Mechanical Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Navid Arjmand",
                "labs": [
                    "Department of Mechanical Engineering, Sharif University of Technology, Tehran, Iran"
                ]
            },
            {
                "name": "Kinda Khalaf",
                "labs": [
                    "Department of Biomedical Engineering, Khalifa University, Abu Dhabi, UAE"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Pose estimation",
                "Legged locomotion",
                "Cameras",
                "Vectors",
                "Knee",
                "Data models",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Remote gait assessment",
                "Seq2Seq",
                "BlazePose",
                "artificial intelligence",
                "deep learning"
            ]
        }
    },
    {
        "Title": "Naïve Bayes Approach for Word Sense Disambiguation System With a Focus on Parts-of-Speech Ambiguity Resolution",
        "Link": "https://ieeexplore.ieee.org/document/10663552/",
        "Abstract": "Natural languages are written and spoken languages, and NLP (Natural Language Processing) is the ability of a computer program to recognize both written and spoken languages. Word Sense Disambiguation (WSD) is identified as a challenging area of research in Artificial Intelligence (AI), and Machine Translation (MT). WSD is the procedure for selecting the exact meaning of a word that has more than one meaning. This is an essential application for all-natural language processing applications. There are various knowledge-based, supervised, and unsupervised approaches to WSD process. The Naïve Bayes classifier as an example of approach supervised and unsupervised approaches is the most important method. In this paper, we emphasize on the use of the Naïve Bayes approach for text classification in WSD techniques. Bayes’ hypothesis is a probabilistic model and a reliable approach for text classification. Bayes’ hypothesis acknowledges that the occurrence of some other features is not dependent on the presence of a particular element in a class. This calculation can be used to solve multi-class prediction problems. This classifier performs better compared to the other methods of different approaches. This paper gives an itemized investigation of Naïve Bayes algorithms, which depicts its ideas, covering up Naïve Bayes,’ text characterization, traditional innocent Bayes,’ and machine learning. We have used the collocation method of feature extraction for the WSD of English sentences. Using this model we have disambiguate ambiguous English words by predicting part-of-speech inclusive of “noun,” “verb,” “adverb,” and “adjective.” This disambiguation module is an enhancement in machine translation. The system reported the performance measure of seventy-eight (78%) percent of the scale on F1-measure.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3453912",
            "Date of Publication": "03 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ajith Abraham",
                "labs": [
                    "School of Artificial Intelligence, Bennett University, Greater Noida, Uttar Pradesh, India"
                ]
            },
            {
                "name": "Bineet Kumar Gupta",
                "labs": [
                    "Machine Intelligence Research Laboratories, Scientific Network for Innovation and Research Excellence, Auburn, WA, USA"
                ]
            },
            {
                "name": "Archana Sachindeo Maurya",
                "labs": [
                    "Shri Ramswaroop Memorial University, Barabanki, India"
                ]
            },
            {
                "name": "Satya Bhushan Verma",
                "labs": [
                    "Shri Ramswaroop Memorial University, Barabanki, India"
                ]
            },
            {
                "name": "Mohammad Husain",
                "labs": [
                    "Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Arshad Ali",
                "labs": [
                    "Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Sami Alshmrany",
                "labs": [
                    "Islamic University of Madinah, Madinah, Saudi Arabia"
                ]
            },
            {
                "name": "Sanjay Gupta",
                "labs": [
                    "Shri Ramswaroop Memorial University, Barabanki, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Bayes methods",
                "Text categorization",
                "Natural language processing",
                "Machine translation",
                "Feature extraction",
                "Accuracy",
                "Knowledge based systems",
                "Machine learning",
                "Translation"
            ],
            "Author Keywords": [
                "Bayes theorem",
                "machine learning",
                "machine translation",
                "Naïve Bayes classification",
                "supervised approach",
                "unsupervised approach",
                "word sense disambiguation (WSD)"
            ]
        }
    },
    {
        "Title": "SPECIL: Spell Error Corpus for the Indonesian Language",
        "Link": "https://ieeexplore.ieee.org/document/10227254/",
        "Abstract": "In this study, we present the first spell error corpus for the Indonesian Language (SPECIL). This corpus provides a comprehensive resource for researchers and practitioners to detect and correct spelling errors in Bahasa Indonesia (Indonesian). It should be emphasized that currently, there is no recognized corpus for identifying spelling mistakes in the Indonesian language that has been officially released or made accessible. This study also provides a systematic literature review to identify resources and methodologies for building a corpus for spelling error detection and correction in Indonesia. A corpus was created using a combination of manual and automatic methods. The results of this study are a review of publications relating to corpora and spelling, the novel algorithm of six types of spelling errors, and the production of a corpus comprising over 180,000 tokens in 21,500 sentences, including non-word, real-word, and punctuation errors. Using the developed corpus, various Natural Language Processing (NLP) models, including spell checkers and language models, can be trained and tested to enhance their accuracy and effectiveness in identifying and rectifying errors in Indonesian texts.Moreover, the corpus can be used to develop and evaluate new algorithms and techniques for spelling error detection and correction in Indonesia. The SPECIL corpus is publicly available and accessible.It is expected that SPECIL will inspire further research in this area and facilitate the development of more accurate and effective spelling error detection and correction tools in Indonesian language.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3307712",
            "Date of Publication": "23 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanfi Yanfi",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program—Doctor of Computer Science Program, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Reina Setiawan",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program—Doctor of Computer Science Program, Bina Nusantara University, Jakarta, Indonesia",
                    "Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Haryono Soeparno",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program—Doctor of Computer Science Program, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Widodo Budiharto",
                "labs": [
                    "Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Computer science",
                "Bibliographies",
                "Syntactics",
                "Semantics",
                "Systematics"
            ],
            "Author Keywords": [
                "Corpus",
                "Indonesian language",
                "natural language processing",
                "spell"
            ]
        }
    },
    {
        "Title": "A Multiscale Interactive Attention Short Text Classification Model Based on BERT",
        "Link": "https://ieeexplore.ieee.org/document/10714399/",
        "Abstract": "Text classification tasks aim to comprehend and classify text content into specific classifications. This task is crucial for interpreting unstructured text, making it a foundational task in the field of Natural Language Processing(NLP). Despite advancements in large language models, lightweight text classification via these models still demands substantial computational resources. Therefore, this paper presents a multiscale interactive attention short text classification model based on BERT, which is designed to address the short text classification problem with limited resources. A corpus containing news articles, Chinese comments, and English sentiment classifications is employed for text classification. The model uses BERT pre-trained word vectors as embedding layers, connects to a multilevel feature extraction network, and further extracts contextual features after feature fusion. The experimental results on the THUCNews, Today’s headline news corpus, the SST-2 dataset, and the Touhou 38 W dataset demonstrate that our method outperforms all existing algorithms in the literature.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3478781",
            "Date of Publication": "11 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lu Zhou",
                "labs": [
                    "Digital Silk Road Xinjiang Industry Investment Group Company, Ürümqi, China"
                ]
            },
            {
                "name": "Peng Wang",
                "labs": [
                    "Digital Silk Road Xinjiang Industry Investment Group Company, Ürümqi, China"
                ]
            },
            {
                "name": "Huijun Zhang",
                "labs": [
                    "Digital Silk Road Xinjiang Industry Investment Group Company, Ürümqi, China"
                ]
            },
            {
                "name": "Shengbo Wu",
                "labs": [
                    "School of Software, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Tao Zhang",
                "labs": [
                    "School of Software, Xinjiang University, Ürümqi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Feature extraction",
                "Vectors",
                "Semantics",
                "Encoding",
                "Bidirectional control",
                "Convolutional neural networks",
                "Transformers",
                "Natural language processing",
                "Training data",
                "Interactive systems"
            ],
            "Author Keywords": [
                "BERT",
                "RNN",
                "CNN",
                "multiscale interactive attention",
                "pre-training models"
            ]
        }
    },
    {
        "Title": "Exploring Character Trigrams for Robust Arabic Text Classification: A Comparative Analysis in the Face of Vocabulary Expansion and Misspelled Words",
        "Link": "https://ieeexplore.ieee.org/document/10504278/",
        "Abstract": "Tokenization is an important early step in natural language processing (NLP) tasks. The idea is to split the input sentence into smaller units, called tokens, for further processing. Words are the most commonly used tokens in text classification tasks but other tokenization ideas are also popular such as subword and character tokens. The increasing availability of training corpora has posed challenges for the word tokenization technique, primarily due to vocabulary size expansion. This has underscored the importance of exploring alternative tokenization, especially for morphologically rich languages like Arabic. In this study, we assess the efficacy of character trigrams for Arabic sentiment analysis and text classification, particularly their robustness against misspelled words. We compare character trigrams with word and WordPiece tokenization across five datasets, encompassing tweets sentiment analysis, reviews sentiment analysis, and news classification. These datasets, which range from small to large in vocabulary size, facilitate a comparative examination of vocabulary and Out-Of-Vocabulary (OOV) sizes for word and character trigram embeddings. The word and character trigram embeddings are integrated into a deep learning (DL) model featuring a dense layer connected to a Bidirectional Gated Recurrent Unit (BiGRU) for classification purposes. Meanwhile, WordPiece embeddings serve to fine-tune the AraBert model. Our findings reveal that the word embedding approach, when applied to extensive corpora, leads to a significant increase in vocabulary and OOV rates, whereas character trigram embedding maintains manageable sizes for both. On test sets devoid of spelling mistakes, the AraBert model surpasses the other models in performance. However, both word and character trigram embedding models exhibit similar levels of performance. In contrast, datasets with misspellings reveal a performance degradation for the WordPiece and word embedding models, with decline rates ranging between 2%-14% and 5%-19%, respectively. Meanwhile, the character trigram models exhibit stable performances, with a drop rate of 0%-8%. Notably, the performance of WordPiece and word embedding models suffers due to their inability to recognize misspelled words.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3390048",
            "Date of Publication": "17 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dorieh Alomari",
                "labs": [
                    "Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia"
                ]
            },
            {
                "name": "Irfan Ahmad",
                "labs": [
                    "Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Saudi Arabia",
                    "SDAIA–KFUPM Joint Research Center for AI, Dhahran, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Tokenization",
                "Text categorization",
                "Vocabulary",
                "Sentiment analysis",
                "Vectors",
                "Training"
            ],
            "Author Keywords": [
                "Character trigrams",
                "tokenization",
                "embedding",
                "misspellings",
                "sentiment analysis",
                "robust text classification"
            ]
        }
    },
    {
        "Title": "Influence of Narrative Strategies on Fundraising Outcome: An Exploratory Study of Online Medical Crowdfunding",
        "Link": "https://ieeexplore.ieee.org/document/10054636/",
        "Abstract": "Online medical crowdfunding (OMC) has attracted massive attention and participation in China. Despite its goal to lift the financial burden caused by expensive medical expenditure, little has been done to evaluate its impact on healthcare inequality. We examine the social consequences of OMC based on a large random sample extracted from one of the most widely-used OMC platforms in China. Our analysis shows that a disproportionally high percentage of fundraising campaigns are launched for patients with low socioeconomic status suffering from various illnesses, including many rare diseases. These findings suggest that OMC plays a positive role in providing an alternative channel for disadvantaged patients under the current health insurance system. We further examine whether and the extent to which the narrative style of solicitation text—fundraising campaign description—influences fundraising outcomes using natural language processing (NLP). The results show that expressions conveying optimism tend to result in a higher completion ratio, whereas descriptions engaging in moral mobilization or focusing on financial burden tend to have a negative impact on fundraising outcomes.",
        "Details": {
            "DOI": "10.23919/JSC.2022.0015",
            "Date of Publication": "December 2022",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Lu Zheng",
                "labs": [
                    "Department of Sociology, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Lihui Jiang",
                "labs": [
                    "Department of Sociology, Tsinghua University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social computing",
                "Ethics",
                "Insurance",
                "Focusing",
                "Medical services",
                "Natural language processing",
                "Diseases"
            ],
            "Author Keywords": [
                "online medical crowdfunding (OMC)",
                "narrative",
                "fundraising outcome",
                "healthcare inequality"
            ]
        }
    },
    {
        "Title": "Re-Ranking System with BERT for Biomedical Concept Normalization",
        "Link": "https://ieeexplore.ieee.org/document/9524621/",
        "Abstract": "In recent years, various neural network architectures have been successfully applied to natural language processing (NLP) tasks such as named entity normalization. Named entity normalization is a fundamental task for extracting information in free text, which aims to map entity mentions in a text to gold standard entities in a given domain-specific ontology; however, the normalization task in the biomedical domain is still challenging because of multiple synonyms, various acronyms, and numerous lexical variations. In this study, we regard the task of biomedical entity normalization as a ranking problem and propose an approach to rank normalized concepts. We additionally employ two factors that can notably affect the performance of normalization, such as task-specific pre-training (Task-PT) and calibration approach. Among five different biomedical benchmark corpora, our experimental results show that our proposed model achieved significant improvements over the previous methods and advanced the state-of-the-art performance for biomedical entity normalization, with up to 0.5% increase in accuracy and 1.2% increase in F-score.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3108445",
            "Date of Publication": "27 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyejin Cho",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "Dongha Choi",
                "labs": [
                    "AI Graduated School, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            },
            {
                "name": "Hyunju Lee",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea",
                    "AI Graduated School, Gwangju Institute of Science and Technology, Gwangju, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Biological system modeling",
                "Bit error rate",
                "Unified modeling language",
                "Dictionaries",
                "Conferences",
                "Context modeling"
            ],
            "Author Keywords": [
                "Named entity normalization",
                "natural language processing",
                "text mining",
                "text recognition"
            ]
        }
    },
    {
        "Title": "An Analysis of Machine Learning-Based Semantic Matchmaking",
        "Link": "https://ieeexplore.ieee.org/document/10076794/",
        "Abstract": "Interoperability remains to be one of the main challenges in the Internet of Things. The increasing number of IoT data sources from various vendors augments the complexity of integrating different sensors and actuators on the existing platforms, requiring human involvement and becoming error prone. To improve this situation, devices are usually coupled with a semantic description of their attributes. Such semantic descriptions, Things Descriptions, TD, are therefore an abstraction of devices, that is helpful to achieve a smoother integration of devices into IoT platforms. However, TD are usually vendor-based, so for large-scale IoT infrastructures, the integration complexity increases, as there will be different descriptions of similar sensors, provided by different vendors to be interconnected into IoT platforms. In this context, the paper assesses different ML-based semantic matchmaking approaches, against a sentence-based statistical similarity approach. For the ML approaches, the paper focuses on clustering and Natural Language Processing. The three approaches have been implemented on a realistic testbed, and experiments carried out show that the best performance achieved in terms of accuracy, time to completion of a matchmaking request, and memory usage is the NLP-based approach.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3259360",
            "Date of Publication": "20 March 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Erkan Karabulut",
                "labs": [
                    "Informatics Institute, University of Amsterdam, Amsterdam, XH, The Netherlands"
                ]
            },
            {
                "name": "Rute C. Sofia",
                "labs": [
                    "Fortiss GmbH, Munich, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Internet of Things",
                "Semantics",
                "Ontologies",
                "Sensors",
                "Temperature sensors",
                "Mashups",
                "Data models"
            ],
            "Author Keywords": [
                "IoT",
                "machine learning",
                "semantics",
                "matchmaking",
                "interoperability"
            ]
        }
    },
    {
        "Title": "ContextMiner: Mining Contextual Features for Conceptualizing Knowledge in Security Texts",
        "Link": "https://ieeexplore.ieee.org/document/9857853/",
        "Abstract": "This paper presents ContextMiner, a novel natural language processing (NLP) framework to automatically capture contextual features for the purpose of extracting meaningful context-aware phrases from cybersecurity unstructured textual data. The framework utilizes basic attributes such as part-of-speech tagging, dependency parsing, and a domain-specific grammar to extract the contextual features. The effectiveness and applications of ContextMiner are evaluated and presented from two different perspectives: qualitative and quantitative. As for the qualitative analysis, our case studies show that the proposed framework is capable of retrieving additional contents from the given texts, both in a labeled and unlabeled setting, and thus building context-aware phrases in comparison with existing approaches. From a quantitative point of view, we evaluate ContextMiner as a pre-processing step to perform named entity recognition (NER). Our results show that ContextMiner reduces the corpus up to 70% while maintaining 85% of its relevant entities, with a small drop in the classification metrics. Finally, we explored the utilization of ContextMiner in the construction and reasoning of knowledge graphs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3198944",
            "Date of Publication": "16 August 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Luis Felipe Gutiérrez",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            },
            {
                "name": "Akbar Namin",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Computer security",
                "Data mining",
                "Syntactics",
                "Natural language processing",
                "Machine learning",
                "Tagging"
            ],
            "Author Keywords": [
                "Dependency parsing",
                "feature extraction",
                "machine learning",
                "natural language processing",
                "word embeddings"
            ]
        }
    },
    {
        "Title": "Generating and Measuring Similar Sentences Using Long Short-Term Memory and Generative Adversarial Networks",
        "Link": "https://ieeexplore.ieee.org/document/9509434/",
        "Abstract": "The two problems of measuring the semantic similarity (MSS) between two sentences and generating a similar sentence (GSS) for a given one are particularly challenging. Since these two problems naturally have logical connections, this article proposes algorithms to deal with them together. The main contributions of this article are in four aspects. 1) We propose a new algorithm called the syntactic and semantic long short-term memory (SSLSTM) for computing sentence similarity. The sentence model used by SSLSTM computes a representation vector of a given sentence by merging the results of separately running two LSTM networks, one with the given sentence and the other with a related sentence that is generated based on the semantic features of the words and syntactic features of the given sentence. The semantic similarity score of two sentences is calculated based on the distance between the two representations vectors. 2) A new GAN framework is proposed called the sentence similarity generative adversarial network (SSGAN). A GSS algorithm and an MSS algorithm are incorporated as modules in the generator and discriminator of SSGAN. A unique design of SSGAN is that, with one input triple to the GAN, the generator will produce three additional items, and the discriminator will process them. Three versions of SSGAN are proposed: the classic SSGAN (C-SSGAN), the hybrid SSGAN (H-SSGAN), and the black-box SSGAN (B-SSGAN). 3) Two new paradigms of GAN emerge from the design patterns of the black-box SSGAN and hybrid SSGAN, called the black-box GAN (B-GAN) and the hybrid GAN (H-GAN), respectively, which have the potentials to be generally applied to other NLP problems. 4) A series of experiments of different settings are designed to test the effects of B-SSGAN, and the results show that B-SSGAN has considerable boosting effects on both the chosen MSS and GSS algorithms. Several experiments are executed to compare SSLSTM with some representative and state-of-the-art MSS algorithms. The results show that SSLSTM has advantages in terms of the amount of error and the overall performance. There are new design features in these experiments. The performances of a GSS algorithm are measured by using an MSS algorithm. Multiple performance measures are considered to describe the algorithms’ performance holistically, including the efficiency of achieved performance relative to training time, which indicates that a CNN-based algorithm (SSCNN) is the most training-efficient in the comparison.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3103669",
            "Date of Publication": "09 August 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhiyao Liang",
                "labs": [
                    "Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macau"
                ]
            },
            {
                "name": "Shiru Zhang",
                "labs": [
                    "Faculty of Information Technology, Macau University of Science and Technology, Taipa, Macau"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Generative adversarial networks",
                "Task analysis",
                "Syntactics",
                "Generators",
                "Natural language processing",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Long short-term memory",
                "generative adversarial networks",
                "semantics",
                "syntax",
                "deep learning",
                "neural network",
                "generating similar sentence",
                "measuring sentence similarity",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Multi-Head Attention Based Bidirectional LSTM for Spelling Error Detection in the Indonesian Language",
        "Link": "https://ieeexplore.ieee.org/document/10580948/",
        "Abstract": "Spelling errors in textual content may significantly hinder communication and comprehension, particularly in formal writing, such as news or reports. Thus, it becomes considerably more important to identify and fix spelling mistakes in the Indonesian language. Despite its significance, there has not been much progress toward developing efficient systems for identifying spelling errors in Indonesian texts. The solutions that are now available frequently fall short of meeting all spelling needs, including nonword, real-word, and punctuation errors. This study aims to address this gap by presenting a novel algorithm to improve spelling mistake detection within the Indonesian language context. We found gaps in the current methodologies through a thorough, systematic literature study, which helped us develop our innovative solution. Our proposed algorithm starts processing data by gathering and preparing the dataset, merging correct and incorrect sentences, labeling, and preprocessing the data. Furthermore, deep learning techniques were integrated, which combined Bidirectional Long Short-Term Memory (Bi-LSTM) networks to effectively capture the intricacies of sequential data and Multi-Head Attention (MHA) mechanisms to emphasize pertinent segments of input sequences, thereby improving the prediction accuracy. We conducted comprehensive experiments to benchmark the performance of our model against existing models. The findings are interesting, with our model reaching a peak accuracy of 92.26% and greatly exceeding the baseline models, which had the lowest accuracy of 65.72%. This study makes a significant contribution to the Natural Language Processing (NLP) field by demonstrating the efficacy of combining Bi-LSTM with MHA in fixing spelling errors in the Indonesian language.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3422318",
            "Date of Publication": "02 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanfi Yanfi",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program-Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Haryono Soeparno",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program-Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Reina Setiawan",
                "labs": [
                    "Computer Science Department, BINUS Graduate Program-Doctor of Computer Science, Bina Nusantara University, Jakarta, Indonesia",
                    "Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            },
            {
                "name": "Widodo Budiharto",
                "labs": [
                    "Computer Science Department, School of Computer Science, Bina Nusantara University, Jakarta, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vectors",
                "Natural language processing",
                "Long short term memory",
                "Mathematical models",
                "Accuracy",
                "Training",
                "Logic gates",
                "Long short term memory",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Bidirectional long short-term memory",
                "Indonesian language",
                "multi-head attention mechanism",
                "natural language processing",
                "spell error detection"
            ]
        }
    },
    {
        "Title": "Solving Data Imbalance in Text Classification With Constructing Contrastive Samples",
        "Link": "https://ieeexplore.ieee.org/document/10225302/",
        "Abstract": "Contrastive learning (CL) has been successfully applied in Natural Language Processing (NLP) as a powerful representation learning method and has shown promising results in various downstream tasks. Recent research has highlighted the importance of constructing effective contrastive samples through data augmentation. However, current data augmentation methods primarily rely on random word deletion, substitution, and cropping, which may introduce noisy samples and hinder representation learning. In this article, we propose a novel approach to address data imbalance in text classification by constructing contrastive samples. Our method involves the use of a Label-indicative Component to generate high-quality positive samples for the minority class, along with the introduction of a Hard Negative Mixing strategy to synthesize challenging negative samples at the feature level. By applying supervised contrastive learning to these samples, we are able to obtain superior text representations, which significantly benefit text classification tasks with imbalanced data. Our approach effectively mitigates distributional biases and promotes noise-resistant representation learning. To validate the effectiveness of our method, we conducted experiments on benchmark datasets (THUCNews, AG’s News, 20NG) as well as the imbalanced FDCNews dataset. The code for our method is publicly available at the following GitHub repository: https://github.com/hanggun/CLDMTC.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3306805",
            "Date of Publication": "21 August 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xi Chen",
                "labs": [
                    "Advanced Institution of Information Technology, Peking University, Hangzhou, China"
                ]
            },
            {
                "name": "Wei Zhang",
                "labs": [
                    "Advanced Institution of Information Technology, Peking University, Hangzhou, China"
                ]
            },
            {
                "name": "Shuai Pan",
                "labs": [
                    "Advanced Institution of Information Technology, Peking University, Hangzhou, China"
                ]
            },
            {
                "name": "Jiayin Chen",
                "labs": [
                    "Advanced Institution of Information Technology, Peking University, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Data augmentation",
                "Task analysis",
                "Data models",
                "Representation learning",
                "Training",
                "Semantics"
            ],
            "Author Keywords": [
                "Data imbalance",
                "contrastive learning",
                "data augmentation",
                "hard negative samples",
                "text classification"
            ]
        }
    },
    {
        "Title": "A Cross-Lingual Sentence Similarity Calculation Method With Multifeature Fusion",
        "Link": "https://ieeexplore.ieee.org/document/9734036/",
        "Abstract": "Cross-language sentence similarity computation is among the focuses of research in natural language processing (NLP). At present, some researchers have introduced fine-grained word and character features to help models understand sentence meanings, but they do not consider coarse-grained prior knowledge at the sentence level. Even if two cross-linguistic sentence pairs have the same meaning, the sentence representations extracted by the baseline approach may have language-specific biases. Considering the above problems, in this paper, we construct a Chinese–Uyghur cross-lingual sentence similarity dataset and propose a method to compute cross-lingual sentence similarity by fusing multiple features. The method is based on the cross-lingual pretraining model XLM-RoBERTa and assists the model in similarity calculation by introducing two coarse-grained prior knowledge features, i.e., sentence sentiment and length features. At the same time, to eliminate possible language-specific biases in the vectors, we whitened the sentence vectors of different languages to ensure that they were all represented under the standard orthogonal basis. Considering that the combination of different vectors has different effects on the final performance of the model, we introduce different vector features for comparison experiments based on the basic feature splicing method. The results show that the absolute value feature of the difference between two vectors can reflect the similarity of two sentences well. The final F1 value of our method reaches 98.97%, which is 19.81% higher than that of the baseline.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3159692",
            "Date of Publication": "14 March 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Lingxin Wang",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Shengquan Liu",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Longye Qiao",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Weiwei Sun",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Qi Sun",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            },
            {
                "name": "Huaqing Cheng",
                "labs": [
                    "College of Information Science and Engineering, Xinjiang University, Ürümqi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Computational modeling",
                "Feature extraction",
                "Training",
                "Syntactics",
                "Bit error rate",
                "Task analysis"
            ],
            "Author Keywords": [
                "Cross-language",
                "pre-trained model",
                "sentence similarity",
                "feature fusion"
            ]
        }
    },
    {
        "Title": "Novel Curriculum Learning Strategy Using Class-Based TF-IDF for Enhancing Personality Detection in Text",
        "Link": "https://ieeexplore.ieee.org/document/10568139/",
        "Abstract": "Personality detection plays a pivotal role in social interactions, machine learning (ML), and natural language processing (NLP). Its goal is to discern an individual’s traits from their behavior and expressions. The prevalence of text-based communication has sparked interest in inferring personality from written content. However, challenges persist in accurately interpreting traits like the Big-Five or Myers-Briggs Type Indicator. These challenges stem from the reliance on self-reported surveys for labeling, which introduces uncertainties as individual assessments may not consistently align with their actual personality. In this paper, we propose novel curriculum strategies that employ class-based term frequency-inverse document frequency (c-TF-IDF) to enhance personality detection performance. By leveraging a curriculum approach that mirrors human learning progression, starting from simpler tasks and moving toward more complex ones, these strategies aim to train models on progressively challenging scenarios. Our experimental results demonstrate that these proposed curriculum-based strategies improve the accuracy of personality detection compared to previously suggested methods. This study contributes to advance understanding of text-based cues for personality inference. It has the potential to enrich various fields, including human-computer interaction, personalized recommendations, and targeted marketing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3417180",
            "Date of Publication": "21 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Naae Kwon",
                "labs": [
                    "Department of Electronic Engineering, Seoul National University of Science and Technology, Seoul, South Korea"
                ]
            },
            {
                "name": "Yuenkyung Yoo",
                "labs": [
                    "Department of Electronic Engineering, Seoul National University of Science and Technology, Seoul, South Korea"
                ]
            },
            {
                "name": "Byunghan Lee",
                "labs": [
                    "Department of Electronic Engineering, Seoul National University of Science and Technology, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Support vector machines",
                "Emotion recognition",
                "Training",
                "Natural language processing",
                "Social networking (online)",
                "Curriculum development",
                "Machine learning",
                "Human computer interaction"
            ],
            "Author Keywords": [
                "Personality detection",
                "curriculum strategy",
                "c-TF-IDF",
                "language models",
                "big-five personality"
            ]
        }
    },
    {
        "Title": "Topic-Document Inference With the Gumbel-Softmax Distribution",
        "Link": "https://ieeexplore.ieee.org/document/9305202/",
        "Abstract": "Topic modeling is an important application of natural language processing (NLP) that can automatically identify the set of main topics of a given, typically large, collection of documents. In addition to identifying the main topics in the given collection, topic modeling infers which combination of topics is addressed by each individual document (the so-called topic-document inference), which can be useful for their classification and organization. However, the distributional assumptions for this inference are typically restricted to the Dirichlet family which can limit the performance of the model. For this reason, in this paper we propose modeling the topic-document inference with the Gumbel-Softmax distribution, a distribution recently introduced to expand differentiability in deep networks. To set up a performing system, the proposed approach integrates Gumbel-Softmax topic-document inference in a state-of-the-art topic model based on a deep variational autoencoder. Experimental results over two probing datasets show that the proposed approach has been able to outperform the original deep variational autoencoder and other popular topic models in terms of test-set perplexity and two topic coherence measures.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3046607",
            "Date of Publication": "23 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amit Kumar",
                "labs": [
                    "School of Electrical and Data Engineering, FEIT, University of Technology Sydney, Sydney, NSW, Australia",
                    "Food Agility CRC Ltd., Ultimo, NSW, Australia"
                ]
            },
            {
                "name": "Nazanin Esmaili",
                "labs": [
                    "School of Electrical and Data Engineering, FEIT, University of Technology Sydney, Sydney, NSW, Australia"
                ]
            },
            {
                "name": "Massimo Piccardi",
                "labs": [
                    "School of Electrical and Data Engineering, FEIT, University of Technology Sydney, Sydney, NSW, Australia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Analytical models",
                "Natural language processing",
                "Matrix decomposition",
                "Large scale integration",
                "Vocabulary",
                "Resource management"
            ],
            "Author Keywords": [
                "Topic models",
                "topic-document inference",
                "variational autoencoders",
                "Gumbel-Softmax distribution",
                "deep neural networks"
            ]
        }
    },
    {
        "Title": "Ensemble BiLSTM: A Novel Approach for Aspect Extraction From Online Text",
        "Link": "https://ieeexplore.ieee.org/document/10379619/",
        "Abstract": "Aspect extraction poses a significant challenge in Natural Language Processing (NLP). Extracting explicit and implicit aspects from online text data remains an ongoing challenge despite significant research efforts. Enhancing the accuracy and effectiveness of aspect extraction is an important area for improvement. This research introduces Ensemble BiLSTM, a novel approach to aspect extraction that addresses these challenges. Ensemble BiLSTM leverages the syntactic, semantic, and contextual properties of unstructured texts present in BERT word embeddings, along with their sequential properties captured using an ensemble of Bidirectional Long Short-Term Memory (BiLSTM) models. The proposed Ensemble BiLSTM model was evaluated extensively using the SemEval-2014 Restaurant, SemEval-2015 Restaurant, SemEval-2016 Laptop, and Financial Opinion Mining and Question Answering (FiQA) datasets. The experimental results demonstrate its efficacy in extracting aspects from text, achieving 91.28%, 87.39%, 95.85%, and 94.59% accuracy on the respective datasets. These promising results highlight the effectiveness of the ensemble approach and the incorporation of sequential models combined with BERT embeddings. The contributions of this research lie in the aspect category features extracted by the proposed Ensemble BiLSTM model, which can be expanded upon to generate accurate aspect-level sentiment features in future work.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3349203",
            "Date of Publication": "02 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mikail Muhammad Azman Busst",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Kalaiarasi Sonai Muthu Anbananthen",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Subarmaniam Kannan",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Jayakumar Krishnan",
                "labs": [
                    "Faculty of Information Science and Technology, Multimedia University, Melaka, Malaysia"
                ]
            },
            {
                "name": "Sridevi Subbiah",
                "labs": [
                    "Department of Information Technology, Thiagarajar College of Engineering, Madurai, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Data mining",
                "Encoding",
                "Sentiment analysis",
                "Data models",
                "Semantics",
                "Context modeling"
            ],
            "Author Keywords": [
                "Aspect extraction",
                "aspect-oriented features",
                "ensemble BiLSTM",
                "BERT embeddings"
            ]
        }
    },
    {
        "Title": "ZDDR: A Zero-Shot Defender for Adversarial Samples Detection and Restoration",
        "Link": "https://ieeexplore.ieee.org/document/10410848/",
        "Abstract": "Natural language processing (NLP) models find extensive applications but face vulnerabilities against adversarial inputs. Traditional defenses lean heavily on supervised detection techniques, which makes them vulnerable to issues arising from training data quality, inherent biases, noise, or adversarial inputs. This study observed common compromises in sentence fluency during aggression. On this basis, the Zero Sample Defender (ZDDR) is introduced for adversarial sample detection and recovery without relying on prior knowledge. ZDDR combines the log probability calculated by the model and the syntactic normative score of a large language model (LLM) to detect adversarial examples. Furthermore, using strategic prompts, ZDDR guides LLM in rephrasing adversarial content, maintaining clarity, structure, and meaning, thereby restoring the sentence from the attack. Benchmarking reveals a 9% improvement in area under receiver operating characteristic curve (AUROC) for adversarial detection over existing techniques. Post-restoration, model classification efficacy surges by 45% compared to the offensive inputs, setting new performance standards against other restoration techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3356568",
            "Date of Publication": "22 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Musheng Chen",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            },
            {
                "name": "Guowei He",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            },
            {
                "name": "Junhua Wu",
                "labs": [
                    "School of Software Engineering, Jiangxi University of Science and Technology, Nanchang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Robustness",
                "Computational modeling",
                "Perturbation methods",
                "Semantics",
                "Natural language processing",
                "Data models",
                "Adversarial machine learning",
                "Detection algorithms"
            ],
            "Author Keywords": [
                "Adversarial defense",
                "large language model",
                "natural language processing",
                "model security",
                "prompt engineering"
            ]
        }
    },
    {
        "Title": "Smart Stacking of Deep Learning Models for Granular Joint Intent-Slot Extraction for Multi-Intent SLU",
        "Link": "https://ieeexplore.ieee.org/document/9475978/",
        "Abstract": "These days' multi-intent utterances have become very important for the spoken language understanding (SLU). The multi-intent systems and algorithms add more complexity (Compare to the single-intent-based system) to the SLU. As, it requires an accurate system, which can identify intents and slots at fine-grain (i.e., word/token) level and also able to handle the relation between intents and slots locally at utterance level. In this case, intents may belong to multiple domains and multiple different classes. Similarly, slots may also belong to multiple different classes, and slots of the same class may be related to multiple different intent classes. Unfortunately, very few works have been done till now to address these issues at the fine-grain level. To solve this problem, we propose a smart stacking-ensemble strategy. The first stage of this system uses a combination of three different types of powerful multitasking NLP models, developed on top of pre-trained BERT, XLNet, and Elmo. Finally, a stacking ensemble layer learns to predict the best possible results. We have evaluated our model on four publicly available datasets. The evaluation results on the state-of-the-art public datasets show that our devised system outperforms the existing multi-intent-based systems at token-level and sentence-level.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3095416",
            "Date of Publication": "07 July 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Niraj Kumar",
                "labs": [
                    "Samsung Research Institute, Bengaluru, India"
                ]
            },
            {
                "name": "Bhiman Kumar Baghel",
                "labs": [
                    "Samsung Research Institute, Bengaluru, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Stacking",
                "Task analysis",
                "Annotations",
                "Training",
                "Filling",
                "Bit error rate",
                "Multitasking"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "artificial neural networks",
                "machine learning",
                "natural language processing",
                "pattern analysis",
                "pattern recognition"
            ]
        }
    },
    {
        "Title": "Knowledge Based Deep Inception Model for Web Page Classification",
        "Link": "https://ieeexplore.ieee.org/document/10246785/",
        "Abstract": "Web Page Classification is decisive for information retrieval and management task and plays an imperative role for natural language processing (NLP) problems in web engineering. Traditional machine learning algorithms excerpt covet features from web pages whereas deep leaning algorithms crave features as the network goes deeper. Pre-trained models such as BERT attains remarkable achievement for text classification and continue to show state-of-the-art results. Knowledge Graphs can provide rich structured factual information for better language modelling and representation. In this study, we proposed an ensemble Knowledge Based Deep Inception (KBDI) approach for web page classification by learning bidirectional contextual representation using pre-trained BERT incorporating Knowledge Graph embeddings and fine-tune the target task by applying Deep Inception network utilizing parallel multi-scale semantics. Proposed ensemble evaluates the efficacy of fusing domain specific knowledge embeddings with the pre-trained BERT model. Experimental interpretation exhibit that the proposed BERT fused KBDI model outperforms benchmark baselines and achieve better performance in contrast to other conventional approaches evaluated on web page classification datasets.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2075",
            "Date of Publication": "October 2021",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Amit Gupta",
                "labs": [
                    "Department of Computer Science and Engineering, Punjab Engineering College (Deemed to be University), Chandigarh, India"
                ]
            },
            {
                "name": "Rajesh Bhatia",
                "labs": [
                    "Department of Computer Science and Engineering, Punjab Engineering College (Deemed to be University), Chandigarh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Machine learning algorithms",
                "Knowledge based systems",
                "Text categorization",
                "Semantics",
                "Web pages",
                "Knowledge graphs",
                "Information retrieval"
            ],
            "Author Keywords": [
                "Web page classification",
                "transfer learning",
                "knowledge graph embedding",
                "pre-trained model"
            ]
        }
    },
    {
        "Title": "Quantifying Raw RF Dataset Similarity for Transfer Learning Applications",
        "Link": "https://ieeexplore.ieee.org/document/9939171/",
        "Abstract": "Transfer learning (TL) has proven to be a transformative technology for computer vision (CV) and natural language processing (NLP) applications, offering improved generalization, state-of-the-art performance, and faster training time with less labelled data. As a result, TL has been identified as a key research area in the budding field of radio frequency machine learning (RFML), where deployed environments are constantly changing, data is hard to label, and applications are often safety-critical. TL literature and theory shows that TL is generally successful when the source and target domains and tasks are similar, but the term similar is not sufficiently defined. Therefore, quantifying dataset similarity is of importance for analyzing and potentially predicting TL performance, and also has further application in RFML dataset design. This work offers a dataset similarity metric, specifically designed for raw RF datasets, based on expert-defined features and\nχ\n2\ntests, and systematically evaluates the proposed metric using synthetic datasets with carefully curated signal-to-noise ratios (SNRs), frequency offsets (FOs), and modulation types. Results show that the proposed dataset similarity metric intuitively quantifies the notion of similar signal sets, so long as the expert-features used to construct the metric are well suited to the application.",
        "Details": {
            "DOI": "10.1109/OJCOMS.2022.3218502",
            "Date of Publication": "04 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Communications Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-125X"
        },
        "authors_data": [
            {
                "name": "Lauren J. Wong",
                "labs": [
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA",
                    "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
                    "AI Lab, Intel Corporation, Santa Clara, CA, USA"
                ]
            },
            {
                "name": "Sean McPherson",
                "labs": [
                    "AI Lab, Intel Corporation, Santa Clara, CA, USA"
                ]
            },
            {
                "name": "Alan J. Michaels",
                "labs": [
                    "Hume Center for National Security and Technology, Virginia Tech, Blacksburg, VA, USA",
                    "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Measurement",
                "Task analysis",
                "Radio frequency",
                "Signal to noise ratio",
                "Transfer learning",
                "Histograms",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Dataset similarity",
                "deep learning (DL)",
                "machine learning (ML)",
                "radio frequency machine learning (RFML)",
                "transferability",
                "transfer learning (TL)"
            ]
        }
    },
    {
        "Title": "TransDoubleU-Net: Dual Scale Swin Transformer With Dual Level Decoder for 3D Multimodal Brain Tumor Segmentation",
        "Link": "https://ieeexplore.ieee.org/document/10311598/",
        "Abstract": "Segmenting brain tumors in MR modalities is an important step in treatment planning. Recently, the majority of methods rely on Fully Convolutional Neural Networks (FCNNs) that have acceptable results for this task. Among various networks, the U-shaped architecture known as U-Net, has gained enormous success in medical image segmentation. However, absence of long-range association and the locality of convolutional layers in FCNNs can create issues in tumor segmentation with different tumor sizes. Due to the success of Transformers in natural language processing (NLP) as a result of using self-attention mechanism to model global information, some studies designed different variations of vision based U-Shaped Transformers. So, to get the effectiveness of U-Net we proposed TransDoubleU-Net which consists of double U-shaped nets for 3D MR Modality segmentation of brain images based on dual scale Swin Transformer for the encoder part and dual level decoder based on CNN and Transformers for better localization of features. The model’s core uses the shifted windows multi-head self-attention of Swin Transformer and skip connections to CNN based decoder. The outputs are evaluated on BraTS2019 and BraTS2020 datasets and showed promising results in segmentation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3330958",
            "Date of Publication": "08 November 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Marjan Vatanpour",
                "labs": [
                    "Department of Biomedical Engineering, Hakim Sabzevari University, Sabzevar, Iran"
                ]
            },
            {
                "name": "Javad Haddadnia",
                "labs": [
                    "Department of Biomedical Engineering, Hakim Sabzevari University, Sabzevar, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Image segmentation",
                "Tumors",
                "Decoding",
                "Three-dimensional displays",
                "Training",
                "Convolutional neural networks"
            ],
            "Author Keywords": [
                "Brain tumor segmentation",
                "vision transformer",
                "Swin transformer",
                "dual scale",
                "U-Net",
                "BraTS"
            ]
        }
    },
    {
        "Title": "Reducing Wrong Labels for Distantly Supervised Relation Extraction With Reinforcement Learning",
        "Link": "https://ieeexplore.ieee.org/document/9079540/",
        "Abstract": "Relation extraction (RE) aims to mine semantic relations between entity pairs from plain texts, which plays an important role in various natural language processing (NLP) tasks. However, the existing methods in distant supervision (DS) are sensitive to bags and fail to handle sentence-level relation prediction. In particular, few methods focus on the sentence-level label denoising. In this paper, the sentence-level label denoising model based on reinforcement learning (RL) and the express-only-one assumption is proposed for distantly supervised RE. First, unlike removing the noisy sentences in previous studies, this paper designs Deep Q Network (DQN), a value-based RL algorithm, as a label denoiser to select the most reliable labels from the multiple relations that sentences are labeled. Second, the relation extractor applies the typical neural network model to predict relations between the data before and after the label denoiser cleans. The rewards in label denoiser are measured by the differences of prediction scores. Finally, the two modules between label denoiser and relation extractor are trained jointly to obtain correct labels and improve the extraction performance at the sentence level. The experimental results show that the proposed denoiser can deal with the noise labels of data effectively and the proposed model outperforms previous state-of-the-art baselines on both the Riedel dataset and human-annotated dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2990680",
            "Date of Publication": "27 April 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tiantian Chen",
                "labs": [
                    "School of Computer Science and Technology, Harbin Engineering University, Harbin, China"
                ]
            },
            {
                "name": "Nianbin Wang",
                "labs": [
                    "School of Computer Science and Technology, Harbin Engineering University, Harbin, China"
                ]
            },
            {
                "name": "Ming He",
                "labs": [
                    "School of Computer and Information Engineering, Heilongjiang University of Science and Technology, Harbin, China"
                ]
            },
            {
                "name": "Liu Sun",
                "labs": [
                    "School of Computer Science and Technology, Harbin Engineering University, Harbin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Noise reduction",
                "Noise measurement",
                "Training data",
                "Data mining",
                "Reliability",
                "Training"
            ],
            "Author Keywords": [
                "Relation extraction",
                "distant supervision",
                "reinforcement learning",
                "label denoising"
            ]
        }
    },
    {
        "Title": "Research on Scattering Transform of Urban Sound Events Detection Based on Self-Attention Mechanism",
        "Link": "https://ieeexplore.ieee.org/document/9953082/",
        "Abstract": "Urban sound event detection can automatically preload relevant information for a robot to ensure that it can be applied to various scene-activity tasks. To address the limitations of timbre similarity and scene recognition by audio collection devices, a fusion model based on the self-attention mechanism is proposed in this paper. The model consists of scattering transform and self-attention model. The scattering transform computes modulation spectrum coefficients of multiple orders through cascades of wavelet convolutions and modulus operators. It is learnable compared with Mel-scale Frequency Cepstral Coefficients (MFCC), and can be used to better restore the semantic features of some sound scenes with similar timbres. The transformer has an outstanding effect on Natural Language Processing (NLP) owing to its self-attention mechanism. In this paper, the self-attention mechanism in its encoder was used in the model, mainly to make the feature granularity consistent to refine the features. In addition, Focal Loss function was adopted in the model to curb the sample distribution imbalance. The Google Command and ESC-50 were used to supplement the scene categories of dataset UrbanSound8K. The model parameters of the learnable filters that performed well on the dataset UrbanSound8K were preserved to fine-tune the other two datasets with insufficient data volume and more target categories. The length of slice duration was further explored the in the model. The experimental results show that the model can achieve better performance in a large range of scene models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3222495",
            "Date of Publication": "16 November 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shen Song",
                "labs": [
                    "School of Mathematics and Computer, Wuhan Polytechnic University, Wuhan, China"
                ]
            },
            {
                "name": "Cong Zhang",
                "labs": [
                    "School of Electrical and Electronic Engineering, Wuhan Polytechnic University, Wuhan, China"
                ]
            },
            {
                "name": "Zhihui Wei",
                "labs": [
                    "School of Mathematics and Computer, Wuhan Polytechnic University, Wuhan, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Mel frequency cepstral coefficient",
                "Spectrogram",
                "Band-pass filters",
                "Scattering",
                "Task analysis",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Preload information",
                "scattering transform",
                "feature granularity consistency",
                "self-attention mechanism",
                "focal loss"
            ]
        }
    },
    {
        "Title": "Energy-Aware Successor Tree Consistent EDF Scheduling for PCTGs on MPSoCs",
        "Link": "https://ieeexplore.ieee.org/document/10535184/",
        "Abstract": "Multiprocessor System-on-Chips (MPSoCs) computing architectures are gaining popularity due to their high-performance capabilities and exceptional Quality-of-Service (QoS), making them a particularly well-suited computing platform for computationally intensive workloads and applications. Nonetheless, The scheduling and allocation of a single task set with precedence restrictions on MPSoCs have presented a persistent research challenge in acquiring energy-efficient solutions. The complexity of this scheduling problem escalates when subject to conditional precedence constraints between the tasks, creating what is known as a Conditional Task Graph (CTG). Scheduling sets of Periodic Conditional Task Graphs (PCTGs) on MPSoC platforms poses even more challenges. This paper focuses on tackling the scheduling challenge for a group of PCTGs on MPSoCs equipped with shared memory. The primary goal is to minimize the overall anticipated energy usage, considering two distinct power models: dynamic and static power models. To address this challenge, this paper introduces an innovative scheduling method named Energy Efficient Successor Tree Consistent Earliest Deadline First (EESEDF). The EESEDF approach is primarily designed to maximize the worst-case processor utilization. Once the tasks are assigned to processors, it leverages the earliest successor tree consistent deadline-first strategy to arrange tasks on each processor. To minimize the overall expected energy consumption, EESEDF solves a convex Non-Linear Program (NLP) to determine the optimal speed for each task. Additionally, the paper presents a highly efficient online Dynamic Voltage Scaling (DVS) heuristic, which operates in O(1) time complexity and dynamically adjusts the task speeds in real-time. We achieved the average improvement, maximum improvement, and minimum improvement of EESEDF+Online-DVS 15%, 17%, and 12%, respectively compared to EESEDF alone. Furthermore, in the second set of experiments, we compared EESEDF against state-of-the-art techniques LESA and NCM. The results showed that EESEDF+Online-DVS outperformed these existing approaches, achieving notable energy efficiency improvements of 25% and 20% over LESA and NCM, respectively. Our proposed scheduler, EESEDF+Online-DVS, also achieves significant energy efficiency gains compared to existing methods. It outperforms IOETCS-Heuristic by approximately 13% while surpassing BESS and CAP-Online by impressive margins of 25% and 35%, respectively.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3403418",
            "Date of Publication": "20 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Umair Ullah Tariq",
                "labs": [
                    "School of Engineering and Technology, Central Queensland University, Rockhampton, QLD, Australia"
                ]
            },
            {
                "name": "Haider Ali",
                "labs": [
                    "School of Computing, University of Derby, Derby, U.K."
                ]
            },
            {
                "name": "Muhammad Shahroz Nadeem",
                "labs": [
                    "School of Engineering and Arts, Science and Technology, University of Suffolk, Ipswich, U.K."
                ]
            },
            {
                "name": "Syed Roohullah Jan",
                "labs": [
                    "School of Engineering and Arts, Science and Technology, University of Suffolk, Ipswich, U.K."
                ]
            },
            {
                "name": "Fariza Sabrina",
                "labs": [
                    "School of Engineering and Technology, Central Queensland University, Rockhampton, QLD, Australia"
                ]
            },
            {
                "name": "Srimannarayana Grandhi",
                "labs": [
                    "School of Engineering and Technology, Central Queensland University, Rockhampton, QLD, Australia"
                ]
            },
            {
                "name": "Zhenglin Wang",
                "labs": [
                    "School of Engineering and Technology, Central Queensland University, Rockhampton, QLD, Australia"
                ]
            },
            {
                "name": "Lu Liu",
                "labs": [
                    "School of Computing and Mathematic Sciences, University of Leicester, Leicester, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Energy efficiency",
                "Energy consumption",
                "Computer architecture",
                "Voltage control",
                "Resource management",
                "Schedules",
                "Green computing",
                "Multiprocessing systems",
                "System-on-chip"
            ],
            "Author Keywords": [
                "PCTGs",
                "scheduling",
                "shared memory",
                "MPSoCs",
                "conditional precedence constraints",
                "DVS",
                "green computing"
            ]
        }
    },
    {
        "Title": "Joint Representations of Texts and Labels with Compositional Loss for Short Text Classification",
        "Link": "https://ieeexplore.ieee.org/document/10246201/",
        "Abstract": "Short text classification is an important foundation for natural language processing (NLP) tasks. Though, the text classification based on deep language models (DLMs) has made a significant headway, in practical applications however, some texts are ambiguous and hard to classify in multi-class classification especially, for short texts whose context length is limited. The mainstream method improves the distinction of ambiguous text by adding context information. However, these methods rely only the text representation, and ignore that the categories overlap and are not completely independent of each other. In this paper, we establish a new general method to solve the problem of ambiguous text classification by introducing label embedding to represent each category, which makes measurable difference between the categories. Further, a new compositional loss function is proposed to train the model, which makes the text representation closer to the ground-truth label and farther away from others. Finally, a constraint is obtained by calculating the similarity between the text representation and label embedding. Errors caused by ambiguous text can be corrected by adding constraints to the output layer of the model. We apply the method to three classical models and conduct experiments on six public datasets. Experiments show that our method can effectively improve the classification accuracy of the ambiguous texts. In addition, combining our method with BERT, we obtain the state-of-the-art results on the CNT dataset.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2035",
            "Date of Publication": "May 2021",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Ming Hao",
                "labs": [
                    "School of computer and communication engineering, University of science and technology Beijing, Beijing, China"
                ]
            },
            {
                "name": "Weijing Wang",
                "labs": [
                    "Department of bioengineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA"
                ]
            },
            {
                "name": "Fang Zhou",
                "labs": [
                    "School of computer and communication engineering, University of science and technology Beijing, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Natural language processing",
                "Task analysis",
                "Context modeling"
            ],
            "Author Keywords": [
                "Ambiguous text",
                "deep language models",
                "label embedding",
                "text classification",
                "triplet loss"
            ]
        }
    },
    {
        "Title": "Outdoor Free Space Optical Systems: Motivations, Challenges, Contributions in Environmental Conditions, and Future Directions—A Systematic Survey",
        "Link": "https://ieeexplore.ieee.org/document/10918944/",
        "Abstract": "This paper presents a new systematic survey of the free-space optical (FSO) system, highlighting its operations and applications in outdoor optical communication underlying its interaction with the environment. As the application portfolio of FSO technology grows, so does the need for a clear classification for FSO link configurations. Most existing surveys and classifications are single-level classifications using traditional survey methods, and thus not inclusive enough to accommodate recent and emerging changes and developments of different FSO link configurations and systems. To that end, this paper adopts a novel methodology based on statistical analysis using a natural language processing approach (NLP) to analyze, visualize, and interpret the researchers’ trends of 5075 relevant literature published documents (journal papers, conference papers, books, etc.) from 2017 to Feb-2024. The process of summarizing and analyzing is encompassed by adopting hierarchal multi-level classifications for the key performance evaluations, motivations, challenges, and contributions related to FSO systems. The survey is started by understanding the key performance of FSO such as matrices models and mathematical models. Then, the survey process is followed by investigating the outdoor FSO applications (urban, satellite, smart city, military, healthcare, disasters, and sensing applications). We have relied on listing and dividing the outdoor FSO networks into sub-networks based on the FSO’s architectural structures (point-to-multipoint, mobile network, long-range transmission and heterogeneous). In turn, outdoor impairments are classified into two categories: 1) environmental factors (weather and atmospheric conditions) and 2) component systems (source types and mechanical issues). We demonstrate the impact of these impairments in terms of the optical phenomena (effects), such as scattering, reflection, refraction, absorption, shadowing, and consequences (outcomes), such as pointing error, misalignments, beam divergence, etc. Finally, multi-technical solutions are listed and analyzed based on the researchers’ contributions, such as modulation, detection techniques, relay, array, and retroflectors. This paper is the first paper that adopts the statistical analysis approach for studying the FSO in outdoor applications, making this approach a good choice for future researchers to prioritize their decisions about future trends and target their improvements.INDEX TERMS Statistical analysis, free space optics (FSO), mobility, outdoor optical communication, point-to-multipoint coverage, subnetwork, weather conditions.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3549776",
            "Date of Publication": "10 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Amjaad T. Altakhaineh",
                "labs": [
                    "Department of Electrical Engineering, Mutah University, Al-Karak, Jordan"
                ]
            },
            {
                "name": "Sarah A. Alsarayreh",
                "labs": [
                    "Department of Electrical Engineering, Mutah University, Al-Karak, Jordan"
                ]
            },
            {
                "name": "Rula Alrawashdeh",
                "labs": [
                    "Department of Electrical Engineering, Mutah University, Al-Karak, Jordan"
                ]
            },
            {
                "name": "Ahed Aleid",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Fatima Alsharari",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Rowida Alodat",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Amal Alhasanat",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Abdullah Alhasanat",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Moath Alsafasfeh",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan",
                    "Department of Electrical and Computer Engineering, Tuskegee University, Tuskegee, AL, USA"
                ]
            },
            {
                "name": "Mohanad Alhasanat",
                "labs": [
                    "Department of Computer Engineering, Al-Hussein Bin Talal University, Ma’an, Jordan"
                ]
            },
            {
                "name": "Kaled Rabie",
                "labs": [
                    "Computer Engineering Department, King Fahd University of Petroleum and Minerals (KFUPM), Dhahran, Saudi Arabia",
                    "Interdisciplinary Research Center for Communication Systems and Sensing, King Fahd University of Petroleum and Minerals (KFUPM), Dhahran, Saudi Arabia"
                ]
            },
            {
                "name": "Mustapha Benjillali",
                "labs": [
                    "Communications Systems Department, National Institute of Posts and Telecommunications, Rabat, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Surveys",
                "Radio frequency",
                "Statistical analysis",
                "Market research",
                "Wireless communication",
                "Optical beams",
                "Meteorology",
                "Free-space optical communication",
                "Wireless sensor networks",
                "Optical sensors"
            ],
            "Author Keywords": [
                "Statistical analysis",
                "free space optics (FSO)",
                "mobility",
                "outdoor optical communication",
                "point-to-multipoint coverage",
                "subnetwork",
                "weather conditions"
            ]
        }
    },
    {
        "Title": "Extractive Question Answering Over Ancient Scriptures Texts Using Generative AI and Natural Language Processing Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10604866/",
        "Abstract": "Generative AI (GenAI) and Natural Language Processing (NLP) are transforming the landscape of question-answering systems, shifting from traditional methods to more advanced, automated solutions. This study explores into applying these technologies using a unique dataset derived from the ancient Hindu scriptures, specifically the Atharv Ved. Employing a combination of vector embedding transformations and a novel question-answering model integrating BERT embeddings, attention mechanisms, and Gated Recurrent Unit (GRU) layers, we have developed a system capable of understanding and generating semantically rich questions and answers. Our model was rigorously evaluated against the Atharv Ved and SQuAD datasets, demonstrating high accuracy rates of 94% and 95%, respectively. These results underscore the model’s capability to handle complex, context-heavy textual data effectively. The study concludes with the model’s potential applications in digital humanities, preserving cultural heritage, and enhancing the accessibility of ancient texts through modern technology.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3431282",
            "Date of Publication": "19 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abhishek Kumar Pandey",
                "labs": [
                    "Vellore Institute of Technology, Vellore, India"
                ]
            },
            {
                "name": "Sanjiban Sekhar Roy",
                "labs": [
                    "Vellore Institute of Technology, Vellore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Bidirectional control",
                "Question answering (information retrieval)",
                "Data models",
                "Context modeling",
                "Attention mechanisms",
                "Task analysis",
                "Natural language processing",
                "Question answering (information retrieval)",
                "Large language models"
            ],
            "Author Keywords": [
                "Natural language processing",
                "BERT embedding",
                "question answering",
                "attention mechanism",
                "large language model"
            ]
        }
    },
    {
        "Title": "Toward Supporting CS1 Instructors and Learners With Fine-Grained Topic Detection in Online Judges",
        "Link": "https://ieeexplore.ieee.org/document/10049440/",
        "Abstract": "Online judges (OJ) are a popular tool to support programming learning. However, one major issue with OJs is that problems are often put together without any associated meta-information that could, for example, be used to help classify problems. This meta-information could be extremely valuable to help users quickly find what types of problems they need most. To face this problem, several OJ administrators have recently begun manually annotating the topics of problems based on computer science-related subjects, such as dynamic programming, graphs, and data structures. Initially, these topics were used to support programming competitions and experienced learners. However, with OJs being increasingly used to support CS1 classes, such topic annotation needs to be extended to suit CS1 learners and instructors. In this work, for the first time, to the best of our knowledge, we propose and validate a predictive model that can automatically detect fine-grained topics of problems based on the CS1 syllabus. After experimenting with many shallow and deep learning models with different word representations based on cutting-edge NLP techniques, our best model is a CNN, achieving an F1-score of 88.9%. We then present how our model can be used for various applications, including (i) facilitating the search process of problems for CS1 learners and instructors and (ii) how it can be integrated into a system to recommend problems in OJs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3247189",
            "Date of Publication": "22 February 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Filipe Dwan Pereira",
                "labs": [
                    "Department of Computer Science, Federal University of Roraima, Boa Vista, Brazil"
                ]
            },
            {
                "name": "Samuel C. Fonseca",
                "labs": [
                    "Institute of Computing, Federal University of Amazonas, Manaus, Brazil"
                ]
            },
            {
                "name": "Sandra Wiktor",
                "labs": [
                    "Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA"
                ]
            },
            {
                "name": "David B. F. Oliveira",
                "labs": [
                    "Institute of Computing, Federal University of Amazonas, Manaus, Brazil"
                ]
            },
            {
                "name": "Alexandra I. Cristea",
                "labs": [
                    "Department of Computer Science, Durham University, Durham, U.K"
                ]
            },
            {
                "name": "Aileen Benedict",
                "labs": [
                    "Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA"
                ]
            },
            {
                "name": "Mohammadali Fallahian",
                "labs": [
                    "Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA"
                ]
            },
            {
                "name": "Mohsen Dorodchi",
                "labs": [
                    "Department of Computer Science, University of North Carolina at Charlotte, Charlotte, NC, USA"
                ]
            },
            {
                "name": "Leandro S. G. Carvalho",
                "labs": [
                    "Institute of Computing, Federal University of Amazonas, Manaus, Brazil"
                ]
            },
            {
                "name": "Rafael Ferreira Mello",
                "labs": [
                    "CESAR School, Centro de Estudos e Sistemas Avançados do Recife, Recife, Brazil"
                ]
            },
            {
                "name": "Elaine H. T. Oliveira",
                "labs": [
                    "Institute of Computing, Federal University of Amazonas, Manaus, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Annotations",
                "Natural language processing",
                "Codes",
                "Search problems",
                "Machine learning algorithms",
                "Data structures",
                "Dynamic programming"
            ],
            "Author Keywords": [
                "CS1 syllabus",
                "natural language processing",
                "topic detection",
                "deep learning",
                "programming autograder"
            ]
        }
    },
    {
        "Title": "Low-Resource POS Tagging With Deep Affix Representation and Multi-Head Attention",
        "Link": "https://ieeexplore.ieee.org/document/10510387/",
        "Abstract": "Part-of-speech (POS) tagging is a challenging and foundational task in the field of natural language processing (NLP), which commonly leverages the learned representations of individual word and character encodings within those words. However, neither of these representations explicitly leverage the profound semantics of sub-word units, such as roots, stems, and affixes, particularly in languages characterized by rich morphology and low resources. For this reason, this becomes a major limitation that leads to numerous unknown words and ambiguities in POS tagging task for agglutinative languages. In this work, a deep representation approach for word prefixes and suffixes is introduced using character n-grams approximation method to further augment features at both word and character levels. Then, a multi-head attention mechanism is applied to attain contextual dependencies among words, which can effectively resolve POS tag ambiguity. Finally, the customized dataset named MultiPOS_ukg is created for Uyghur, Uzbek, and Kyrgyz languages according to the uniform tag sets. Empirically, the proposed method is tested on both the customized dataset and the METU Turkish Treebank dataset. The overall performance demonstrated a significant improvement in POS tagging accuracy, with increases of up to 5.36%, 4.13%, and 2.1% across three MRLs. This improvement is achieved through the incorporation of affix-based word representation and multi-head attention, surpassing all other word and character-based models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3395454",
            "Date of Publication": "30 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alim Murat",
                "labs": [
                    "Department of Computer Science and Technology, Xinjiang Normal University, Ürümqi, Xinjiang, China"
                ]
            },
            {
                "name": "Samat Ali",
                "labs": [
                    "Department of Computer Science and Technology, Xinjiang Normal University, Ürümqi, Xinjiang, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Tagging",
                "Task analysis",
                "Natural language processing",
                "Hidden Markov models",
                "Semantics",
                "Long short term memory",
                "Computer architecture",
                "Speech recognition"
            ],
            "Author Keywords": [
                "POS tagging",
                "affix representation",
                "multi-head attention",
                "morphologically rich language (MRL)",
                "low resource"
            ]
        }
    },
    {
        "Title": "Improving Distantly Supervised Relation Classification With Attention and Semantic Weight",
        "Link": "https://ieeexplore.ieee.org/document/8747447/",
        "Abstract": "Distantly supervised relation classification aims at identifying the relationship between two given entities and plays an essential part in natural language processing (NLP). Although distant supervision is able to generate labeled data automatically, it is facing with the problem of noisy data due to the wrong labeling problems. The attention mechanism is one of the most popular methods to reduce the influence of mislabeled data. However, regardless of the correlation among relations, the most existing methods treat all relationships as independent classes. In general, the definitions of relations contain rich semantic information, which improves the performance of the model, especially when classifying long-tail relations which lacks training data. Based on this idea, we propose a novel neural network architecture with an attention mechanism in this paper. First, we use bidirectional GRU to encode relation definitions as the context representations of relations. Then, we use the merge attention mechanism to make full use of the hidden states obtained by the GRU. To help the model make full use of the context of the entities, we also introduce semantic weights, calculated by the length of the shortest path between entities and words in the dependency tree. We conduct experiments on the widely used New York Times relation extraction corpus, and the results demonstrate that our model outperforms most of the state-of-the-art models.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2925502",
            "Date of Publication": "27 June 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zhangdong Zhu",
                "labs": [
                    "College of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Jindian Su",
                "labs": [
                    "College of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
                ]
            },
            {
                "name": "Yang Zhou",
                "labs": [
                    "College of Computer Science and Engineering, South China University of Technology, Guangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Neural networks",
                "Correlation",
                "Natural language processing",
                "Data models",
                "Training data",
                "Task analysis"
            ],
            "Author Keywords": [
                "Attention mechanism",
                "bidirectional gated recurrent unit",
                "distant supervision",
                "natural language processing",
                "relation classification"
            ]
        }
    },
    {
        "Title": "English and Chinese Neural Metonymy Recognition Based on Semantic Priority Interruption Theory",
        "Link": "https://ieeexplore.ieee.org/document/8986607/",
        "Abstract": "Metonymy is one of the types of common figurative languages and often used in human conversation without any difficulties. However, metonymy recognition in NLP requires a deep semantic/contextual processing to interpretation because it is highly related to the discourse of the contexts. Moreover, the fact that few available datasets of figurative languages make it more problematic. Motivated by the shortcomings of metonymy recognition, we develop several new data sets, including the Chinese version of the data, and design an end-to-end neural network metonymy recognizer. Our framework is based on the semantic priority interrupt theory and additional knowledge is introduced which makes to learn contexts effectively. Through a series of experiments, we show that our method is comparable to the state-of-the-art metonymy recognition method, especially we verified that metonymy trigger words information contributes to performance improvement in our model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.2972379",
            "Date of Publication": "07 February 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chuandong Su",
                "labs": [
                    "College of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China"
                ]
            },
            {
                "name": "Xiaoxi Huang",
                "labs": [
                    "College of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China"
                ]
            },
            {
                "name": "Fumiyo Fukumoto",
                "labs": [
                    "Department of Computer Science and Engineering, University of Yamanashi, Yamanashi, Japan"
                ]
            },
            {
                "name": "Jiyi Li",
                "labs": [
                    "Department of Computer Science and Engineering, University of Yamanashi, Yamanashi, Japan"
                ]
            },
            {
                "name": "Rongbo Wang",
                "labs": [
                    "College of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China"
                ]
            },
            {
                "name": "Zhiqun Chen",
                "labs": [
                    "College of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Deep learning",
                "Neural networks",
                "Feature extraction",
                "Linguistics",
                "Knowledge based systems"
            ],
            "Author Keywords": [
                "Metonymy recognition",
                "neural network",
                "semantic priority interrupt theory"
            ]
        }
    },
    {
        "Title": "A Systematic Review of AI-Enabled Frameworks in Requirements Elicitation",
        "Link": "https://ieeexplore.ieee.org/document/10706210/",
        "Abstract": "Employing Artificial Intelligence techniques to address challenges in requirements elicitation is gaining traction. Although nine systematic literature reviews have been published on AI-based solutions in the requirements elicitation domain, to our knowledge, these studies do not cover a broad spectrum of elicitation tasks, data sources used for training, the performance of these algorithms, nor do they pinpoint the strengths and limitations of the algorithms used. This study contributes to the field by presenting a systematic literature review that explores the use of machine learning and NLP techniques in the elicitation phase of requirements engineering. The following research questions are addressed: 1) What elicitation tasks are supported by AI and what AI algorithms were employed? 2) What data sources have been used to construct AI-based solutions? 3) What performance outcomes were achieved? 4) What are the strengths and limitations of the current AI methods? Initially, 665 papers were retrieved from six data sources, and ultimately, 122 articles were selected for the review. This literature review identifies fifteen elicitation tasks currently supported by artificial intelligence and presents twelve publicly available data sources used for training these approaches. Furthermore, the study uncovers common limitations in current studies and suggests potential research directions. Overall, this systematic literature review provides insights into future research prospects for applying AI techniques to problems in the requirements elicitation domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3475293",
            "Date of Publication": "07 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vaishali Siddeshwar",
                "labs": [
                    "Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            },
            {
                "name": "Sanaa Alwidian",
                "labs": [
                    "Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            },
            {
                "name": "Masoud Makrehchi",
                "labs": [
                    "Department of Electrical, Computer and Software Engineering, Ontario Tech University, Oshawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Soft sensors",
                "Software",
                "Data models",
                "Natural language processing",
                "Machine learning algorithms",
                "Bibliographies",
                "Requirements engineering",
                "Training",
                "Software algorithms"
            ],
            "Author Keywords": [
                "Requirement engineering",
                "requirement elicitation",
                "machine learning",
                "deep learning",
                "natural language processing",
                "neural networks",
                "large language models"
            ]
        }
    },
    {
        "Title": "SpaceTransformers: Language Modeling for Space Systems",
        "Link": "https://ieeexplore.ieee.org/document/9548078/",
        "Abstract": "The transformers architecture and transfer learning have radically modified the Natural Language Processing (NLP) landscape, enabling new applications in fields where open source labelled datasets are scarce. Space systems engineering is a field with limited access to large labelled corpora and a need for enhanced knowledge reuse of accumulated design data. Transformers models such as the Bidirectional Encoder Representations from Transformers (BERT) and the Robustly Optimised BERT Pretraining Approach (RoBERTa) are however trained on general corpora. To answer the need for domain-specific contextualised word embedding in the space field, we propose SpaceTransformers, a novel family of three models, SpaceBERT, SpaceRoBERTa and SpaceSciBERT, respectively further pre-trained from BERT, RoBERTa and SciBERT on our domain-specific corpus. We collect and label a new dataset of space systems concepts based on space standards. We fine-tune and compare our domain-specific models to their general counterparts on a domain-specific Concept Recognition (CR) task. Our study rightly demonstrates that the models further pre-trained on a space corpus outperform their respective baseline models in the Concept Recognition task, with SpaceRoBERTa achieving significant higher ranking overall.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3115659",
            "Date of Publication": "24 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Audrey Berquand",
                "labs": [
                    "Department of Mechanical and Aerospace, Intelligent Computational Engineering Laboratory, University of Strathclyde, Glasgow G1 1XQ, U.K"
                ]
            },
            {
                "name": "Paul Darm",
                "labs": [
                    "Department of Mechanical and Aerospace, Intelligent Computational Engineering Laboratory, University of Strathclyde, Glasgow G1 1XQ, U.K"
                ]
            },
            {
                "name": "Annalisa Riccardi",
                "labs": [
                    "Department of Mechanical and Aerospace, Intelligent Computational Engineering Laboratory, University of Strathclyde, Glasgow G1 1XQ, U.K"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Modeling",
                "Task analysis",
                "Bit error rate",
                "Training",
                "Data models",
                "Transfer learning",
                "Transformers"
            ],
            "Author Keywords": [
                "Language model",
                "transformers",
                "space systems",
                "concept recognition",
                "requirements"
            ]
        }
    },
    {
        "Title": "The Evolution of Generative AI: Trends and Applications",
        "Link": "https://ieeexplore.ieee.org/document/11016906/",
        "Abstract": "Generative artificial intelligence (AI) has revolutionized AI by enabling high-fidelity content creation across text, images, audio, and structured data. This survey explores the core methodologies, advancements, applications, and ongoing challenges of generative AI, covering key models such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), Diffusion Models, and Transformer-based architectures. These innovations have driven breakthroughs in healthcare, scientific computing, Natural Language Processing (NLP), computer vision, and autonomous systems. Despite its progress, generative AI faces challenges in bias mitigation, interpretability, computational efficiency, and ethical governance, necessitating research into scalable architectures, explainability, and AI safety mechanisms. Integrating Reinforcement Learning (RL), multi-modal learning, and self-supervised techniques enhances controllability and adaptability in generative models. Additionally, as AI reshapes industrial automation, digital media, and scientific discovery, its societal and economic implications demand robust policy frameworks. This survey provides a comprehensive analysis of generative AI’s current state and future directions, highlighting innovations in efficient generative modelling, AI-driven scientific reasoning, adversarial robustness, and ethical deployment. By consolidating theoretical insights and real-world applications, it offers a structured foundation for researchers, industry professionals, and policymakers to navigate the evolving landscape of generative AI.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574660",
            "Date of Publication": "28 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maria Trigka",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica at Egaleo Park, Athens, Greece"
                ]
            },
            {
                "name": "Elias Dritsas",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica at Egaleo Park, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Generative AI",
                "Biological system modeling",
                "Computer architecture",
                "Computational modeling",
                "Ethics",
                "Economics",
                "Transformers",
                "Surveys",
                "Natural language processing",
                "Image synthesis"
            ],
            "Author Keywords": [
                "Generative AI",
                "multi-modal learning",
                "ethical AI and governance",
                "multi-modal AI"
            ]
        }
    },
    {
        "Title": "Debugging Debug Information With Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/9779237/",
        "Abstract": "The correctness of debug information included in optimized binaries has been the subject of recent attention by the research community. Indeed, it represents a practically important problem, as most of the software running in production is produced by an optimizing compiler. Current solutions rely on invariants, human-defined rules that embed the desired behavior, whose violation may indicate the presence of a bug. Although this approach proved to be effective in discovering several bugs, it is unable to identify bugs that do not trigger invariants. In this paper, we investigate the feasibility of using Deep Neural Networks (DNNs) to discover incorrect debug information. We trained a set of different models borrowed from the NLP community in an unsupervised way on a large dataset of debug traces and tested their performance on two novel datasets that we propose. Our results are positive and show that DNNs are capable of discovering bugs in both synthetic and real datasets. More interestingly, we performed a live analysis of our models by using them as bug detectors in a fuzzing system. We show that they were able to report 12 unknown bugs in the latest version of the widely used LLVM toolchain, 2 of which have been confirmed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2022.3176617",
            "Date of Publication": "20 May 2022",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fiorella Artuso",
                "labs": [
                    "Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy"
                ]
            },
            {
                "name": "Giuseppe Antonio Di Luna",
                "labs": [
                    "Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy"
                ]
            },
            {
                "name": "Leonardo Querzoni",
                "labs": [
                    "Department of Computer, Control, and Management Engineering Antonio Ruberti, Sapienza University of Rome, Rome, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Testing",
                "Codes",
                "Optimization",
                "Behavioral sciences",
                "Software",
                "Debugging"
            ],
            "Author Keywords": [
                "Bugs",
                "compilers",
                "debug information",
                "neural networks",
                "software engineering"
            ]
        }
    },
    {
        "Title": "Integrating Topic-Aware Heterogeneous Graph Neural Network With Transformer Model for Medical Scientific Document Abstractive Summarization",
        "Link": "https://ieeexplore.ieee.org/document/10637403/",
        "Abstract": "The development of abstractive summarization methods is a crucial task in Natural Language Processing (NLP) that presents challenges, which require the creation of intelligent systems that are capable of extracting the main idea from text effectively and generate coherent summary. Numerous existing abstractive approaches do not take into account the importance of the broader context or fail to capture the global semantics in identifying salient content for summary. Moreover, there is lack of studies that extensively evaluated abstractive summarization models for specific domains, such as medical scientific document summarization. With this motivation behind, this paper developed an integrated framework for abstractive summarization of medical scientific documents that integrates topic-aware Heterogeneous Graph Neural Network with a Transformer model. The suggested framework uses Latent Dirichlet Allocation (LDA) for topic modeling to uncover latent topics and global information, thus preserving document-level attributes important for creation of effective summaries. In addition to topic modeling, the framework utilized a Heterogeneous Graph Neural Network (HGNN), capable of capturing the relationship between sentences through graph-based document representation, and allows for the concurrent updating of both local and global information. Finally, the framework is integrated with a Transformer decoder, which greatly enhances the ability of model to produce accurate and informative abstractive summaries. The performance of proposed framework is evaluated on publicly available PubMed dataset related to medical scientific papers. Experimental results illustrate that the suggested framework for abstractive summarization showed superior performance as compared to the state-of-the-art models, achieving high F1-Scores: 46.03 for Rouge-1, 21.42 for Rouge-2, and 39.71 for Rouge-L. Our research makes a significant contribution to the field of natural language processing, particularly in the area of medical scientific document summarization. It demonstrates superior performance and provides a deeper understanding of document structure, and has the potential to impact various applications by offering efficient access to information.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3443730",
            "Date of Publication": "16 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ayesha Khaliq",
                "labs": [
                    "Department of Computer Science, University of Agriculture Faisalabad, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Atif Khan",
                "labs": [
                    "Department of Computer Science, Islamia College Peshawar, Peshawar, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Salman Afsar Awan",
                "labs": [
                    "Department of Computer Science, University of Agriculture Faisalabad, Faisalabad, Pakistan"
                ]
            },
            {
                "name": "Salman Jan",
                "labs": [
                    "Department of Information Technology, Al Buraimi University College, Al Buraimi, Oman"
                ]
            },
            {
                "name": "Muhammad Umair",
                "labs": [
                    "Department of Computer Science, City University of Science and Information Technology, Peshawar, Pakistan"
                ]
            },
            {
                "name": "Megat F. Zuhairi",
                "labs": [
                    "Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Text summarization",
                "Task analysis",
                "Semantics",
                "Encoding",
                "Graph neural networks",
                "Bidirectional control",
                "Graph neural networks",
                "Heterogeneous networks"
            ],
            "Author Keywords": [
                "BERT",
                "LDA",
                "GAT",
                "TF-IDF",
                "transformer",
                "medical documents",
                "abstractive summarization"
            ]
        }
    },
    {
        "Title": "Data-Driven Intelligence System for General Recommendations of Deep Learning Architectures",
        "Link": "https://ieeexplore.ieee.org/document/9597522/",
        "Abstract": "Choosing optimal Deep Learning (DL) architecture and hyperparameters for a particular problem is still not a trivial task among researchers. The most common approach relies on popular architectures proven to work on specific problem domains led on the same experiment environment and setup. However, this limits the opportunity to choose or invent novel DL networks that could lead to better results. This paper proposes a novel approach for providing general recommendations of an appropriate DL architecture and its hyperparameters based on different configurations presented in thousands of published research papers that examine various problem domains. This architecture can further serve as a starting point of investigating DL architecture for a concrete data set. Natural language processing (NLP) methods are used to create structured data from unstructured scientific papers upon which intelligent models are learned to propose optimal DL architecture, layer type, and activation functions. The advantage of the proposed methodology is multifold. The first is the ability to eventually use the knowledge and experience from thousands of DL papers published through the years. The second is the contribution to the forthcoming novel researches by aiding the process of choosing optimal DL setup based on the particular problem to be analyzed. The third advantage is the scalability and flexibility of the model, meaning that it can be easily retrained as new papers are published in the future, and therefore to be constantly improved.",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3124633",
            "Date of Publication": "01 November 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gjorgji Noveski",
                "labs": [
                    "Department of Intelligent Systems, Jožef Stefan Institute, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Tome Eftimov",
                "labs": [
                    "Computer Systems Department, Jožef Stefan Institute, Ljubljana, Slovenia"
                ]
            },
            {
                "name": "Kostadin Mishev",
                "labs": [
                    "Faculty of Computer Science and Engineering, Saints Cyril and Methodius University in Skopje, Skopje, North Macedonia"
                ]
            },
            {
                "name": "Monika Simjanoska",
                "labs": [
                    "Faculty of Computer Science and Engineering, Saints Cyril and Methodius University in Skopje, Skopje, North Macedonia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Training",
                "Architecture",
                "Deep learning",
                "Computer architecture",
                "Adaptation models",
                "Intelligent systems"
            ],
            "Author Keywords": [
                "Deep learning",
                "intelligent system",
                "hyperparameters selection",
                "DL architecture selection",
                "multi-label classification"
            ]
        }
    },
    {
        "Title": "Building a Multilevel Inflection Handling Stemmer to Improve Search Effectiveness for Urdu Language",
        "Link": "https://ieeexplore.ieee.org/document/10460562/",
        "Abstract": "Stemming is an essential step in various Natural Language Processing (NLP) applications and is used to reduce different variants of the query words to a standard form to avoid the vocabulary mismatch issue in Information Retrieval (IR) systems. Due to specific grammatical rules and complex morphological structures, finding an effective stemming algorithm in Urdu is a challenging task. Although, several stemming algorithms have been proposed for the Urdu text stemming; however, none of them extract the stem from multilevel inflected forms. In this context, according to the best of our knowledge, this is a first effort towards the proposition and evaluation of a novel Urdu Text Stemmer (UTS) that can deal with multi-level inflection forms in Urdu text. The experimental evaluation of the proposed scheme has been conducted on the text-based and word-based custom-developed corpus. The proposed stemming technique is rigorously evaluated and compared with state-of-the-art stemming algorithms. Experimental results demonstrate that UTS outperforms existing Urdu stemmers and achieves an accuracy of 94.92% and 91.8% on word corpus and text corpus, respectively. We also evaluated our proposed system in an Information Retrieval application for Urdu, using the Collection for Urdu Retrieval Evaluation (CURE) dataset. Our approach for information retrieval outperformed and improved both recall and precision metrics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3373714",
            "Date of Publication": "08 March 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Abdul Jabbar",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Main Campus, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Sajid Iqbal",
                "labs": [
                    "Department of Information Systems, College of Computer Science and Information Technology, King Faisal University, Hofuf, Saudi Arabia",
                    "Department of Computer Science, Bahauddin Zakariya University, Multan, Pakistan"
                ]
            },
            {
                "name": "Abdullah Abdulrhman Alaulamie",
                "labs": [
                    "Department of Information Systems, College of Computer Science and Information Technology, King Faisal University, Hofuf, Saudi Arabia"
                ]
            },
            {
                "name": "Manzoor Ilahi",
                "labs": [
                    "Department of Computer Science, COMSATS University Islamabad, Main Campus, Islamabad, Pakistan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Information retrieval",
                "Natural language processing",
                "Text mining",
                "Vocabulary",
                "Measurement techniques",
                "Data models",
                "Information analysis"
            ],
            "Author Keywords": [
                "Stemmer",
                "information retrieval",
                "Urdu stemmer",
                "lemmatizer",
                "natural language processing",
                "text mining"
            ]
        }
    },
    {
        "Title": "Embedding Imputation With Self-Supervised Graph Neural Networks",
        "Link": "https://ieeexplore.ieee.org/document/10173511/",
        "Abstract": "Embedding learning is essential in various research areas, especially in natural language processing (NLP). However, given the nature of unstructured data and word frequency distribution, general pre-trained embeddings, such as word2vec and GloVe, are often inferior in language tasks for specific domains because of missing or unreliable embedding. In many domain-specific language tasks, pre-existing side information can often be converted to a graph to depict the pair-wise relationship between words. Previous methods use kernel tricks to pre-compute a fixed graph for propagating information across different words and imputing missing representations. These methods require predefining the optimal graph construction strategy before any model training, resulting in an inflexible two-step process. In this paper, we leverage the recent advances in graph neural networks and self-supervision strategy to simultaneously learn a similarity graph and impute missing embeddings in an end-to-end fashion with the overall time complexity well controlled. We undertake extensive experiments to show that the integrated approach performs better than several baseline methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3292314",
            "Date of Publication": "05 July 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Uras Varolgunes",
                "labs": [
                    "New Jersey Institute of Technology, Newark, NJ, USA"
                ]
            },
            {
                "name": "Shibo Yao",
                "labs": [
                    "New Jersey Institute of Technology, Newark, NJ, USA"
                ]
            },
            {
                "name": "Yao Ma",
                "labs": [
                    "New Jersey Institute of Technology, Newark, NJ, USA"
                ]
            },
            {
                "name": "Dantong Yu",
                "labs": [
                    "New Jersey Institute of Technology, Newark, NJ, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Embedded systems",
                "Graph neural networks",
                "Natural language processing",
                "Embedded systems",
                "Self-supervised learning"
            ],
            "Author Keywords": [
                "Embedding imputation",
                "graph neural networks",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Deep Text Understanding Model for Similar Case Matching",
        "Link": "https://ieeexplore.ieee.org/document/10630503/",
        "Abstract": "Natural Language Processing (NLP) technology is rapidly evolving, and various large language models have been widely applied in Legal Artificial Intelligence (AI). However, low accuracy in Similar Case Matching (SCM) persists in the most popular case recommendation systems. It hinders the practical application of case recommendations in Legal Judgment Prediction (LJP). Developing effective methods to extract features from long texts and improve the accuracy of SCM is an urgent matter that requires attention. Therefore, the paper proposes a SCM method based on deep text comprehension. A fine-tuned BERT model is used to extract text information, and a combination of global attention and self-attention is employed to represent the features of long texts deeply. A dual-channel similar text-matching approach is used after candidate texts are pre-encoded to reduce the SCM model’s training time and improve accuracy. Experiments on the China AI and Law (CAIL) competition dataset show that the proposed method achieves the highest accuracy in SCM compared to the recent methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3439775",
            "Date of Publication": "07 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jie Xiong",
                "labs": [
                    "School of Economics and Management, Xiamen University of Technology, Xiamen, China"
                ]
            },
            {
                "name": "Yihui Qiu",
                "labs": [
                    "School of Economics and Management, Xiamen University of Technology, Xiamen, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Law",
                "Accuracy",
                "Artificial intelligence",
                "Data mining",
                "Vectors",
                "Semantics"
            ],
            "Author Keywords": [
                "Similar case matching",
                "text mining",
                "similarity analysis",
                "attention mechanism",
                "feature extraction"
            ]
        }
    },
    {
        "Title": "Enhancing Moroccan Dialect Sentiment Analysis Through Optimized Preprocessing and Transfer Learning Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10788699/",
        "Abstract": "This work investigates the challenges of sentiment analysis for Moroccan Arabic dialect (MD), where the lack of dialect-specific preprocessing methods complicates natural language processing tasks and affects sentiment classification performance. The research evaluates various preprocessing techniques, including stemming and feature extraction, using two main transfer learning approaches: feature extraction with deep learning models and fine-tuning pre-trained models. Experimentations were conducted on four MD datasets to assess combinations of stemmers, feature extractors, and architectures. In the feature extraction approach, omitting stemming and employing the QARiB feature extractor with a BiGRU model yielded the highest accuracy on the FB and MAC datasets, reaching 90.45% and 75.50%, respectively. In the fine-tuning approach, DarijaBERT excelled on the FB dataset with an accuracy of 93.37% and an F1-score of 88.55%, while QaRIB and AraBERT performed comparably well on the MAC and MSAC datasets. Results suggest that excluding base form reduction methods, such as stemming and lemmatization, during fine-tuning enhances sentiment analysis performance in MD, highlighting the limitations of Modern Standard Arabic techniques for MD processing. This study provides valuable insights for improving Natural language processing (NLP) applications in Arabic dialects, particularly in sentiment analysis, by optimizing model performance without relying on standard preprocessing methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3514934",
            "Date of Publication": "11 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yassir Matrane",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Faouzia Benabbou",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            },
            {
                "name": "Zineb Ellaky",
                "labs": [
                    "Laboratory of Information Technology and Modeling, Faculty of Sciences Ben M’Sick, Hassan II University of Casablanca, Casablanca, Morocco"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Sentiment analysis",
                "Accuracy",
                "Natural language processing",
                "Linguistics",
                "Transfer learning",
                "Analytical models",
                "Text categorization",
                "Complexity theory",
                "Tuning"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "Arabic dialect",
                "Moroccan dialect",
                "preprocessing",
                "deep learning",
                "fine-tuning"
            ]
        }
    },
    {
        "Title": "VisionTwinNet: Gated Clarity Enhancement Paired With Light-Robust CD Transformers",
        "Link": "https://ieeexplore.ieee.org/document/10381684/",
        "Abstract": "Deep learning has shown superiority in change detection (CD) tasks, notably the Transformer architecture with its self-attention mechanism, capturing long-range dependencies and outperforming traditional models. This capability provides the Transformer with significant advantages in capturing global-level features of complex changes in objects within high-resolution remote sensing images. Though Transformers are mature in Natural Language Processing (NLP), their application in computer vision, particularly CD tasks, is nascent. Current research on leveraging Transformers for CD reveals limitations, especially under varied lighting and seasonal changes. To address this, we propose VisionTwinNet, a two-stage strategy. First, our Gated EnhanceClearNet, a specially designed deep network reduces image noise and enhances brightness, preserving shadows and correcting color distortions. With its unique gating mechanism, this network can adaptively adjust the importance of features, thereby exhibiting superior performance in various remote sensing image degradation issues. Secondly, we have developed Hybrid Light-Robust CDNet, a hybrid robust lightweight network custom-designed for CD in remote sensing images. This module deeply integrates the advantages of CNN and Transformer and introduces an innovative attention mechanism design, optimizing the key/value dimensions separately, instead of adopting traditional single linear transformations, ensuring efficient detection. Specifically, the LR-Transformer Block employs a lightweight multi-head self-attention mechanism, optimizing computational efficiency while providing richer feature representations. Comparative studies with six CD methods on three public datasets validate VisionTwinNet’s robustness and efficacy. Our approach notably reduces algorithmic complexity and enhances the efficiency of the model.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3350173",
            "Date of Publication": "05 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tianao Chen",
                "labs": [
                    "Electrical Engineering and Computer Science Department, University of Michigan, Ann Arbor, MI, USA"
                ]
            },
            {
                "name": "Aotian Chen",
                "labs": [
                    "Electrical and Computer Engineering Department, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Lighting",
                "Remote sensing",
                "Task analysis",
                "Logic gates",
                "Computational modeling",
                "Feature extraction",
                "Deep learning"
            ],
            "Author Keywords": [
                "Automatically adjustable framework",
                "change detection",
                "deep learning",
                "multi-scale feature extraction",
                "transformer"
            ]
        }
    },
    {
        "Title": "LEST: Large-Scale LiDAR Semantic Segmentation With Deployment-Friendly Transformer Architecture",
        "Link": "https://ieeexplore.ieee.org/document/10904146/",
        "Abstract": "Large-scale LiDAR-based point cloud semantic segmentation is a critical challenge for autonomous driving perception. Most state-of-the-art LiDAR semantic segmentation methods rely on complex operators, such as sparse 3D convolutions or KdTree structures, which hinder their deployment on modern embedded devices. While transformer architectures have gained prominence in natural language processing (NLP) and 2D computer vision, their application to large-scale point cloud semantic segmentation remains limited. In this paper, we introduce LEST (LiDAR sEmantic Segmentation architecture with Transformer), a novel framework built entirely on simple operators. LEST incorporates two key innovations: a Space Filling Curve (SFC) grouping strategy and a DIStance-based COsine (DISCO) linear transformer. Experimental results demonstrate that our model achieves competitive performance on the nuScenes semantic segmentation validation set and the SemanticKITTI test set, while maintaining a deployment-friendly design.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3545957",
            "Date of Publication": "26 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chuanyu Luo",
                "labs": [
                    "Process Optimization Group, Ilmenau University of Technology, Ilmenau, Germany"
                ]
            },
            {
                "name": "Nuo Cheng",
                "labs": [
                    "Process Optimization Group, Ilmenau University of Technology, Ilmenau, Germany"
                ]
            },
            {
                "name": "Sikun Ma",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Han Li",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Xiaohan Li",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Shengguang Lei",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Pu Li",
                "labs": [
                    "Process Optimization Group, Ilmenau University of Technology, Ilmenau, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Three-dimensional displays",
                "Point cloud compression",
                "Complexity theory",
                "Nearest neighbor methods",
                "Convolution",
                "Solid modeling",
                "Semantic segmentation",
                "Aggregates",
                "Semantics"
            ],
            "Author Keywords": [
                "Point cloud semantic segmentation",
                "representation learning",
                "long sequence modeling",
                "linear transformer",
                "model deployment"
            ]
        }
    },
    {
        "Title": "Efficient Method for Robust Backdoor Detection and Removal in Feature Space Using Clean Data",
        "Link": "https://ieeexplore.ieee.org/document/10845767/",
        "Abstract": "The steady increase of proposed backdoor attacks on deep neural networks highlights the need for robust defense methods for their detection and removal. A backdoor attack is a type of attack where hidden triggers are added to the input data during training, with the goal of changing the behavior of the model during inference. These attacks pose a significant security threat in critical applications, such as street sign or pedestrian recognition for autonomous vehicles, biometric authentication, image retrieval, semantic labeling, etc. To combat these threats, many defense mechanisms have been proposed. These methods target different areas, such as computer vision (CV), natural language processing (NLP), and thus utilize different assumptions about the nature of the input data and the type of backdoor trigger used in the attack. However, the attacker can exploit these assumptions, which reduces their successfulness in real-world scenarios. Thus, a robust method for backdoor detection needs to have broad and simple assumptions. Furthermore, detection methods that rely on the input data suffer from the fact that they are constrained to the modality of the input and cannot apply to different modalities. In this work, a novel method for backdoor detection and removal for classification tasks using features extracted by the attacked model called FEAT-IN is proposed. This method can detect and reconstruct the feature representation of the possible triggers used in attacking the neural network. Using these reconstructed trigger features, the method can be used to efficiently mitigate the effects of an attack. Extensive experiments on multiple datasets and attack methods demonstrate that, when compared to state-of-the-art methods such as Neural Cleanse, Neural Attention Distillation, I-BAU, BTI-DBF etc. the FEAT-IN method provides several benefits. It can more consistently detect and mitigate backdoor attacks than similar trigger inversion defense methods that conduct the defense in the input space instead of feature space (where, on average, it achieves approx. 10% higher decrease in attack success rate during mitigation compared to the second-best method). Secondly, it reduces the memory footprint and the computation time by at least an order of magnitude compared to other methods, which allows FEAT-IN to be used practically in real-world scenarios. Finally, it is not constrained to only computer vision tasks, as this assumption holds for feature spaces of different problems, which is demonstrated by applying it without any change to semantic analysis on the SST-2 dataset.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3531716",
            "Date of Publication": "20 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Donik Vršnak",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Marko Subašić",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            },
            {
                "name": "Sven Lončarić",
                "labs": [
                    "Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Training",
                "Prevention and mitigation",
                "Optimization",
                "Data models",
                "Image reconstruction",
                "Computer vision",
                "Computational modeling",
                "Visualization",
                "Vectors"
            ],
            "Author Keywords": [
                "Backdoor attack",
                "backdoor defense",
                "image classification",
                "neural cleanse"
            ]
        }
    },
    {
        "Title": "Knowledge Graph Generation and Application for Unstructured Data Using Data Processing Pipeline",
        "Link": "https://ieeexplore.ieee.org/document/10681407/",
        "Abstract": "With the rapid advancement of technology and the vast volume of unstructured data available on the Internet, there is a pressing need to extract information from diverse data formats effectively. This is essential as valuable pieces of information may be lost. To address this issue, researchers are using Machine Learning (ML) and Natural Language Processing (NLP) techniques to extract information from unstructured text, including the utilization of Knowledge Graphs (KGs). This paper demonstrates end-to-end experimental studies of KG construction from unstructured text using open-source techniques and concrete real-world examples in different problem domains. The unstructured data underwent a text processing pipeline consisting of coreference resolution, named entity linking, and relationship extraction. The pipeline is designed to support automatic data storage in a graph database known as Neo4j. This storage includes the extracted entities and their relationships. Experiments were conducted on a real-world unstructured BBC News Dataset to analyze the outcome obtained from the pipeline. The experience can facilitate the adoption of KG creation for practitioners to capture valuable information from a large volume of unstructured text. The results from the relationship extraction step using two techniques were evaluated, including extracted entities, relationship types, accuracies of 61.4% with OpenNRE and 87% with REBEL, and processing time. Further, the data processing pipeline was applied to analyze the unstructured dataset from the Transportation Safety Board’s (TSB) Findings for aviation safety analysis. The results showed that structured relationships identified through the pipeline provided valuable indicators, as they captured critical aviation safety information, such as the flight, aircraft type, event, etc. This pipeline can be fine-tuned with a domain-specific knowledge base to provide higher accuracy and better entity detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3462635",
            "Date of Publication": "17 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sushmi Thushara Sukumar",
                "labs": [
                    "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Chung-Horng Lung",
                "labs": [
                    "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Marzia Zaman",
                "labs": [
                    "Cistel Technology, Research and Development, Ottawa, ON, Canada"
                ]
            },
            {
                "name": "Ritesh Panday",
                "labs": [
                    "Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Data processing",
                "Natural language processing",
                "Knowledge graphs",
                "Machine learning",
                "Named entity recognition",
                "Buffer storage"
            ],
            "Author Keywords": [
                "Coreference resolution graph database",
                "knowledge graph",
                "machine learning",
                "named entity linking",
                "natural language processing",
                "Neo4j",
                "relationship extraction",
                "unstructured data"
            ]
        }
    },
    {
        "Title": "Computer Vision-Based Framework for Data Extraction From Heterogeneous Financial Tables: A Comprehensive Approach to Unlocking Financial Insights",
        "Link": "https://ieeexplore.ieee.org/document/10813363/",
        "Abstract": "Information extraction from financial document images is crucial in computer vision and NLP, as financial data often exists in image or PDF format, enabling organizations to analyze and make informed business decisions using OCR advancements. The table contents of financial document images are one of the prominent structures to confine important portions of data of the document and many Deep learning-based methods have been proposed to detect Table regions inside document images. The shortcomings of the current approach are that it is bounded within the detection of the table region and struggles in cases such as handling different layouts and preserving the relation among the different attributes of the table. Therefore, in this work, we proposed an end-to-end architecture to extract information from Financial table images while preserving the column row structures of the attributes within the table. We divided the task into four modules and generated synthesized data with different augmentation techniques to overcome data scarcity challenges and boost the performance of the pipeline modules. In terms of information extraction, the proposed method acquired 85% accuracy in the target invoice dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3522141",
            "Date of Publication": "24 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Iftakhar Ali Khandokar",
                "labs": [
                    "Department of Electrical and Computer Engineering (EECE), Marquette University, Milwaukee, WI, USA"
                ]
            },
            {
                "name": "Priya Deshpande",
                "labs": [
                    "Department of Electrical and Computer Engineering (EECE), Marquette University, Milwaukee, WI, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Hidden Markov models",
                "Optical character recognition",
                "Information retrieval",
                "Feature extraction",
                "Layout",
                "Accuracy",
                "Text recognition",
                "Support vector machines",
                "Pipelines"
            ],
            "Author Keywords": [
                "Computer vision",
                "deep learning",
                "information extraction",
                "transformer model"
            ]
        }
    },
    {
        "Title": "On-Road Trajectory Planning of Connected and Automated Vehicles in Complex Traffic Settings: A Hierarchical Framework of Trajectory Refinement",
        "Link": "https://ieeexplore.ieee.org/document/10388357/",
        "Abstract": "This paper presents a hierarchical framework for on-road trajectory planning in complex traffic environments. Firstly, the processing of sparse coarse trajectories involves the utilization of DP (Dynamic Programming) generation and interpolation techniques. Then, for the waypoints with collision risk in the smoothed trajectory, the spiral search method is used to find some safe alternate waypoints. The alternate waypoints and the previous ones without collision risk form the amended trajectory. Concurrently, safety tunnels are constructed along the amended trajectory for the ego vehicle. Furthermore, with the constraint conditions of vehicle kinematics model and safety tunnels, nonlinear program (NLP) optimization is carried out for the amended trajectory of ego vehicle to obtain smooth and safe trajectories. For typical cases, simulation experiments demonstrate that the ego vehicle can ensure collision safety in dynamic traffic scenarios, while maintaining smooth vehicle velocity and small jitter of the front wheel angle. The proposed trajectory planning framework provides a novel decision-making method for connected and automated vehicles (CAVs).",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3352919",
            "Date of Publication": "11 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fuzhou Zhao",
                "labs": [
                    "School of Automotive Engineering, Changshu Institute of Technology, Suzhou, China",
                    "The State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Ling Han",
                "labs": [
                    "School of Mechanical and Electrical Engineering, Changchun University of Technology, Changchun, China"
                ]
            },
            {
                "name": "Mingyang Cui",
                "labs": [
                    "The State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Heye Huang",
                "labs": [
                    "The State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China"
                ]
            },
            {
                "name": "Shan Zhong",
                "labs": [
                    "Changshu Institute of Technology, Suzhou, China"
                ]
            },
            {
                "name": "Feifei Su",
                "labs": [
                    "Baidu Technology (Beijing) Company Ltd., Beijing, China"
                ]
            },
            {
                "name": "Lei Wang",
                "labs": [
                    "Ziqing Intelligent Driving Technology (Beijing) Company Ltd., Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Trajectory planning",
                "Roads",
                "Optimization",
                "Vehicle-to-everything",
                "Mathematical models",
                "Interpolation"
            ],
            "Author Keywords": [
                "Trajectory planning",
                "nonlinear program optimization",
                "connected and automated vehicles"
            ]
        }
    },
    {
        "Title": "Optimal Coordinated Operation of Distributed Static Series Compensators for Wide-area Network Congestion Relief",
        "Link": "https://ieeexplore.ieee.org/document/9594777/",
        "Abstract": "Relieving network congestions is a critical goal for the safe and flexible operation of modern power systems, especially in the presence of intermittent renewables or distributed generation. This paper deals with the real-time coordinated operation of distributed static series compensators (DSSCs) to remove network congestions by suitable modifications of the branch reactance. Several objective functions are considered and discussed to minimize the number of the devices involved in the control actions, the total losses or the total reactive power exchanged, leading to a non-convex mixed-integer non-linear programming problem. Then, a heuristic methodology combining the solution of a regular NLP with k-means clustering algorithm is proposed to get rid of the binary variables, in an attempt to reduce the computational cost. The proposed coordinated operation strategy of the DSSCs is tested on several benchmark systems, providing feasible and sufficiently optimal solutions in a reasonable time frame for practical systems.",
        "Details": {
            "DOI": "10.35833/MPCE.2021.000265",
            "Date of Publication": "29 October 2021",
            "Publisher": "SGEPRI",
            "Published In": "Journal of Modern Power Systems and Clean Energy"
        },
        "issn_info": {
            "Print ISSN": "2196-5625",
            "Electronic ISSN": "2196-5420"
        },
        "authors_data": [
            {
                "name": "Camilo Andrés Ordóñez M",
                "labs": [
                    "Smart Wires, Union City, USA"
                ]
            },
            {
                "name": "Antonio Gómez-Expósito",
                "labs": [
                    "Department of Electrical Engineering, University of Seville, Sevilla, Spain"
                ]
            },
            {
                "name": "Guillermo E. Vinasco M",
                "labs": [
                    "Interconexión Eléctrica SA Intercolombia, Sevilla, Spain"
                ]
            },
            {
                "name": "José María Maza-Ortega",
                "labs": [
                    "Department of Electrical Engineering, University of Seville, Sevilla, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Linear programming",
                "Real-time systems",
                "Power systems",
                "Optimization",
                "Mathematical models",
                "Renewable energy sources",
                "Flexible AC transmission systems"
            ],
            "Author Keywords": [
                "Distributed static series compensation (DSSC)",
                "flexible AC transmission system (FACTS)",
                "mixed-integer nonlinear programming (MINLP)",
                "wide-area network control"
            ]
        }
    },
    {
        "Title": "Majority or Minority: Data Imbalance Learning Method for Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10816423/",
        "Abstract": "Data imbalance presents a significant challenge in various machine learning (ML) tasks, particularly named entity recognition (NER) within natural language processing (NLP). NER exhibits a data imbalance with a long-tail distribution, featuring numerous minority classes (i.e., entity classes) and a single majority class (i.e.,\nO\n-class). This imbalance leads to misclassifications of the entity classes as the\nO\n-class. To tackle this issue, we propose a simple and effective learning method named majority or minority (MoM) learning. MoM learning incorporates the loss computed only for samples whose ground truth is the majority class into the loss of the conventional ML model. Evaluation experiments on four NER datasets (Japanese and English) showed that MoM learning improves the prediction performance of the minority classes without sacrificing the performance of the majority class and is more effective than widely known and state-of-the-art methods. We also evaluated MoM learning using frameworks such as sequential labeling and machine reading comprehension, which are commonly used in NER. Furthermore, MoM learning has achieved consistent performance improvements regardless of language, model, framework, or data size.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3522972",
            "Date of Publication": "25 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sota Nemoto",
                "labs": [
                    "Department of Applied Informatics, Graduate School of Science and Engineering, Hosei University, Tokyo, Japan"
                ]
            },
            {
                "name": "Shunsuke Kitada",
                "labs": [
                    "Department of Applied Informatics, Graduate School of Science and Engineering, Hosei University, Tokyo, Japan"
                ]
            },
            {
                "name": "Hitoshi Iyatomi",
                "labs": [
                    "Department of Applied Informatics, Graduate School of Science and Engineering, Hosei University, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Method of moments",
                "Training",
                "Named entity recognition",
                "Learning systems",
                "Labeling",
                "Predictive models",
                "Data models",
                "Standards",
                "Measurement",
                "Internet"
            ],
            "Author Keywords": [
                "Natural language processing",
                "named entity recognition",
                "data imbalance",
                "cost-sensitive learning"
            ]
        }
    },
    {
        "Title": "End-to-End Personalized Humorous Response Generation in Untrimmed Multi-Role Dialogue System",
        "Link": "https://ieeexplore.ieee.org/document/8755858/",
        "Abstract": "Multi-role dialogue is challenging in natural language processing (NLP), which needs not only to understand sentences but also to simulate interaction among roles. However, the existing methods assume that only two speakers are present in a conversation. In real life, this assumption is not always valid. More often, there are multiple speakers involved. To address this issue, we propose a multi-role interposition dialogue system (MIDS) that generates reasonable responses based on the dialogue context and next speaker prediction. The MIDS employs multiply role-defined encoders to understand each speaker and an independent sequence model to predict the next speaker. The independent sequence model also works as a controller to integrate encoders with weights. Then, an attention-enhanced decoder generates responses based on the dialogue context, speaker prediction, and integrated encoders. Moreover, with the help of unique speaker prediction, the MIDS is able to generate diverse responses and allow itself to join (interpose) the conversation when appropriate. Furthermore, a novel reward function and an updating policy of reinforcement learning (RL) are applied to the MIDS, which further enable MIDS the ability to write drama scripts. The experimental results demonstrate that the MIDS offers a significant improvement to the accuracy of speaker prediction and the reduction of response generation perplexity. It is also able to interact with users without cues during real-life online conversations and avoid meaningless conversation loops while generating scripts. This paper marks the first step toward multi-role humorous dialogue generation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2019.2926830",
            "Date of Publication": "04 July 2019",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qichuan Yang",
                "labs": [
                    "School of Computer Science and Engineering, Beihang University, Beijing, China"
                ]
            },
            {
                "name": "Zhiqiang He",
                "labs": [
                    "Chinese Academy of Sciences, Institute of Computing Technology, Beijing, China"
                ]
            },
            {
                "name": "Zhiqiang Zhan",
                "labs": [
                    "Chinese Academy of Sciences, Institute of Computing Technology, Beijing, China"
                ]
            },
            {
                "name": "Rang Li",
                "labs": [
                    "Research and Development, Lenovo Ltd., 100094, China"
                ]
            },
            {
                "name": "Yanwei Lee",
                "labs": [
                    "Research and Development, Lenovo Ltd., 100094, China"
                ]
            },
            {
                "name": "Yang Zhang",
                "labs": [
                    "Research and Development, Lenovo Ltd., 100094, China"
                ]
            },
            {
                "name": "Changjian Hu",
                "labs": [
                    "Research and Development, Lenovo Ltd., 100094, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Decoding",
                "Reinforcement learning",
                "Task analysis",
                "Predictive models",
                "Context modeling",
                "Writing",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Dialogue generation",
                "multi-role conversation",
                "neural network",
                "reinforcement learning",
                "speaker prediction"
            ]
        }
    },
    {
        "Title": "Microbubble Contrast Agents Improve Detection of Active Hemorrhage",
        "Link": "https://ieeexplore.ieee.org/document/10561886/",
        "Abstract": "Impact Statement:\nWe show in vitro that ultrasound contrast agents and tailored post-processing techniques to visualize them can enhance detection and characterization of active hemorrhage...Show More\nAssessment of trauma-induced hemorrhage with ultrasound is particularly challenging outside of the clinic, where its detection is crucial. The current clinical standard for hematoma detection – the focused assessment with sonography of trauma (FAST) exam – does not aim to detect ongoing blood loss, and thus is unable to detect injuries of increasing severity. To enhance detection of active bleeding, we propose the use of ultrasound contrast agents (UCAs), together with a novel flow phantom and contrast-sensitive processing techniques, to facilitate efficient, practical characterization of internal bleeding. Within a the custom phantom, UCAs and processing techniques enabled a significant enhancement of the hemorrhage visualization (mean increase in generalized contrast-to-noise ratio of 17%) compared to the contrast-free case over a range of flow rates up to 40 ml/min. Moreover, we have shown that the use of UCAs improves the probability of detection: the area under the receiver operating characteristic curve for a flow rate of 40 ml/min was 0.99, compared to 0.72 without contrast. We also demonstrate how additional processing of the spatial and temporal information further localizes the bleeding site. UCAs also enhanced Doppler signals over the non-contrast case. These results show that specialized nonlinear processing (NLP) pipelines together with UCAs may offer an efficient means to improve substantially the detection of slower hemorrhages and increase survival rates for trauma-induced injury in pre-hospital settings.",
        "Details": {
            "DOI": "10.1109/OJEMB.2024.3414974",
            "Date of Publication": "18 June 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of Engineering in Medicine and Biology"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1276"
        },
        "authors_data": [
            {
                "name": "Scott Schoen Jr",
                "labs": [
                    "Center for Ultrasound Research and Translation, Harvard Medical School and Massachusetts General Hospital, Boston, MA, USA"
                ]
            },
            {
                "name": "Alexis Prasov",
                "labs": [
                    "MIT Lincoln Laboratory, Lexington, MA, USA"
                ]
            },
            {
                "name": "Ion Candel",
                "labs": [
                    "Center for Ultrasound Research and Translation, Harvard Medical School and Massachusetts General Hospital, Boston, MA, USA"
                ]
            },
            {
                "name": "Saaid Arshad",
                "labs": [
                    "MIT Lincoln Laboratory, Lexington, MA, USA"
                ]
            },
            {
                "name": "Mark Ottensmeyer",
                "labs": [
                    "Center for Ultrasound Research and Translation, Harvard Medical School and Massachusetts General Hospital, Boston, MA, USA"
                ]
            },
            {
                "name": "Theodore T. Pierce",
                "labs": [
                    "Center for Ultrasound Research and Translation, Harvard Medical School and Massachusetts General Hospital, Boston, MA, USA"
                ]
            },
            {
                "name": "Laura J. Brattain",
                "labs": [
                    "University of Central Florida, Orlando, FL, USA"
                ]
            },
            {
                "name": "Brian A. Telfer",
                "labs": [
                    "MIT Lincoln Laboratory, Lexington, MA, USA"
                ]
            },
            {
                "name": "Anthony E. Samir",
                "labs": [
                    "Center for Ultrasound Research and Translation, Harvard Medical School and Massachusetts General Hospital, Boston, MA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Hemorrhaging",
                "Ultrasonic imaging",
                "Injuries",
                "Sensitivity",
                "Phantoms",
                "Blood",
                "Fluids"
            ],
            "Author Keywords": [
                "Trauma",
                "hemorrhage",
                "contrast agents",
                "ultrasound",
                "doppler"
            ]
        }
    },
    {
        "Title": "Quantifying Gender Bias in Arabic Pre-Trained Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10537164/",
        "Abstract": "The current renaissance in the development of Arabic Pre-trained Language models (APLMs) has yielded significant advancement across many fields. Nevertheless, no study has explored the dimensions of gender bias in these models. It is argued that the bias is influenced by the resources used during the models’ pre-training process. Thus, in this study, we conducted a comprehensive analysis to qualitatively assess the representation of different genders by tracing the bias signals from the training corpus. Through applying several Natural Language Processing (NLP) techniques, including Named Entity Recognition (NER), Part of Speech Tagging (POS), and Dependency Parsing (DP), the results indicated an imbalanced corpus in terms of gender nouns and reveal verbs’ patterns associated with each gender. The second phase of this study aimed to examine the impact of the results that emerged from the corpus analysis on the recent APLMs. Leveraging Bidirectional Encoder Representations (BERT)’s ability to predict the missing tokens in quantifying gender bias, we introduce the first template-based Arabic benchmark designed to measure gender bias across various disciplines. Utilizing this benchmark, along with the list of gender-specific nouns and personal names extracted from the corpus, we evaluated the gender skew in the context of scientific and liberal arts disciplines across six APLMs. These models included: AraBERT, CAMeLBERT-CA, CAMeLBERT-MSA, GigaBERT, MAR-BERT, and ARBERT. The outcomes revealed a higher bias skew toward personal names, indicating that the presence of gender associations in the training corpus reinforced gender bias in APLMs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3404668",
            "Date of Publication": "23 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wafa Alrajhi",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia",
                    "Department of Computer Science, College of Computer and Information Science, Imam Mohammad Ibn Saud Islamic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Hend S. Al-Khalifa",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Abdulmalik S. Al-Salman",
                "labs": [
                    "Department of Computer Science, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Encoding",
                "Bidirectional control",
                "Benchmark testing",
                "Standards",
                "Internet",
                "Complexity theory",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Arabic pretrained language models (APLMs)",
                "BERT",
                "gender bias",
                "large models",
                "quantifying bias"
            ]
        }
    },
    {
        "Title": "Distilling Wisdom: A Review on Optimizing Learning From Massive Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10942372/",
        "Abstract": "In the era of Large Language Models (LLMs), Knowledge Distillation (KD) enables the transfer of capabilities from proprietary LLMs to open-source models. This survey provides a detailed discussion of the basic principles, algorithms, and implementation methods of knowledge distillation. It explores KD’s impact on LLMs, emphasizing its utility in model compression, performance enhancement, and self-improvement. Through the analysis of practical examples such as DistilBERT, TinyBERT, and MobileBERT, the paper demonstrates how knowledge distillation can markedly enhance the efficiency and applicability of large language models in real-world scenarios. The discussion encompasses the varied applications of KD across multiple domains, including industrial systems, embedded systems, Natural Language Processing (NLP), multi-modal processing, and vertical domains, such as medicine, law, science, finance, and materials science. This survey outlines current KD methodologies and future research directions, highlighting its role in advancing AI technologies and fostering innovation across different sectors.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3554586",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dingzong Zhang",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Devi Listiyani",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Priyanka Singh",
                "labs": [
                    "School of Electrical Engineering and Computer Science, The University of Queensland, Brisbane, QLD, Australia"
                ]
            },
            {
                "name": "Manoranjan Mohanty",
                "labs": [
                    "School of Electrical Engineering and Computer Science, Carnegie Mellon University in Qatar, Ar-Rayyan, Qatar"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Large language models",
                "Computational modeling",
                "Surveys",
                "Natural language processing",
                "Predictive models",
                "Artificial intelligence",
                "Technological innovation",
                "Encoding",
                "Context modeling"
            ],
            "Author Keywords": [
                "Artificial intelligence (AI)",
                "large language model (LLM)",
                "knowledge distillation (KD)",
                "optimization"
            ]
        }
    },
    {
        "Title": "A Theoretical Foundation for Syntactico-Semantic Pattern Recognition",
        "Link": "https://ieeexplore.ieee.org/document/9547263/",
        "Abstract": "Conventionally syntactic pattern recognition tasks have been driven by grammars defining a syntactic structure. Syntactic Pattern recognition tasks were primarily relying on the ability of parsing algorithms to recognize the patterns in the input data. These algorithms essentially were dependent on the syntactic grammars defining the patterns. Context free grammars, a type of grammars have been particularly well studied for pattern recognition tasks to be solved by computer efficiently. Some of the key pattern recognition tasks had applications in Natural Language Processing (NLP). Though context free grammars are well suited for capturing rigid patterns and unambiguous patterns, there was a need to encapsulate the uncertainty aspects involved in some pattern recognition processes. Probabilistic context free grammars can well handle the need to capture uncertainty in the processes but not in a true sense they are able to capture the uncertainty associated with the semantic context governing the domain in which the pattern recognition processes are being attempted at. The paper formally puts forth an approach for syntactico-semantic pattern recognition. The syntactico-semantic pattern recognition attempts to capture the semantic context and the uncertainties involved thereof along with probabilistic reasoning. The approach consists of integration mapping between probabilistic context free grammar (PCFG) and Multi Entity Bayesian network (MEBN), a first-order logic for modeling probabilistic knowledge bases. Additionally, the paper outlines a modified version of the CYK parser algorithm for the defined mapping between PCFG and MEBN with a method to ensure the properness and consistency of such PCFG along with its key application, disambiguation of PP (Prepositional Phrase) attachment. The theoretical foundation proposed has been validated by a proof-of-concept implementation of the modified CYK algorithm for syntactico-semantic reasoning in Java with promising ability to disambiguate PP attachment uses cases of New York Times and Wikipedia corpus dataset samples.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2021.3115445",
            "Date of Publication": "23 September 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Shrinivasan Patnaikuni",
                "labs": [
                    "Department of Computer Science and Engineering, Walchand Institute of Technology, Solapur, India"
                ]
            },
            {
                "name": "Sachin Gengaje",
                "labs": [
                    "Department of Computer Science and Engineering, Walchand Institute of Technology, Solapur, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Grammar",
                "Probabilistic logic",
                "Semantics",
                "Random variables",
                "Cognition",
                "Uncertainty",
                "Pattern recognition"
            ],
            "Author Keywords": [
                "Syntactic pattern recognition",
                "probabilistic reasoning",
                "MEBN"
            ]
        }
    },
    {
        "Title": "A Novel Lightweight CNN for Constrained IoT Devices: Achieving High Accuracy With Parameter Efficiency on the MSTAR Dataset",
        "Link": "https://ieeexplore.ieee.org/document/10737056/",
        "Abstract": "Convolutional neural networks (CNNs) have revolutionized fields such as image classification, natural language processing (NLP), and object detection. Remote sensing is no exception, particularly synthetic aperture radar (SAR) image analysis, where it addresses the challenge of classifying inherently noisy and indistinct images. Traditionally, this task relied heavily on manual intervention, making it time-intensive. With automation becoming increasingly critical, research has shifted toward deep learning techniques. However, many existing approaches are computationally intensive and require substantial memory resources. In this study, we present a lightweight CNN specifically designed for SAR applications, tested on the moving and stationary target acquisition and recognition (MSTAR) dataset. Our model surpasses previous studies by demonstrating higher accuracy while utilizing significantly fewer parameters. This novel architecture achieves an optimal balance between accuracy and computational efficiency. This is particularly useful in a resource-constrained environment in many real-world applications. More specifically, our proposed CNN model demonstrates robust performance across various scenarios, achieving an accuracy of 99.7% in classifying the three target classes under standard operating conditions (SOCs). Furthermore, when extended to classify ten classes, our proposed model outperforms several baseline algorithms from state-of-the-art literature. This research attempts to achieve a trade-off between model performance and model size, contributing to the development of CNNs suitable for resource-limited applications, particularly targeting IoT deployments. The findings present a practical solution for situations that prioritize both accuracy and resource conservation, thereby advancing discussions on efficient model design.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3487313",
            "Date of Publication": "28 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Noor Rahman",
                "labs": [
                    "Department of Computer Science and Information Technology, Virtual University of Pakistan, Peshawar Campus, Lahore, Pakistan"
                ]
            },
            {
                "name": "Muzammil Khan",
                "labs": [
                    "Department of Computer and Software Technology, University of Swat, Swat, Khyber Pakhtunkhwa, Pakistan"
                ]
            },
            {
                "name": "Israr Ullah",
                "labs": [
                    "Department of Computer Science and Information Technology, Virtual University of Pakistan, Peshawar Campus, Lahore, Pakistan"
                ]
            },
            {
                "name": "Do-Hyeun Kim",
                "labs": [
                    "Department of Computer Engineering, Jeju National University, Jeju, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Accuracy",
                "Target recognition",
                "Convolutional neural networks",
                "Internet of Things",
                "Computational modeling",
                "Radar polarimetry",
                "Synthetic aperture radar",
                "Computer architecture",
                "Training"
            ],
            "Author Keywords": [
                "Automatic target recognition (ATR)",
                "CNN",
                "synthetic aperture radar (SAR)",
                "image classification",
                "Internet of Things (IoT)"
            ]
        }
    },
    {
        "Title": "Zero-BertXGB: An Empirical Technique for Abstract Classification in Systematic Reviews",
        "Link": "https://ieeexplore.ieee.org/document/10845770/",
        "Abstract": "Abstract classification in systematic reviews (SRs) is a crucial step in evidence synthesis but is often time-consuming and labour-intensive. This study evaluates the effectiveness of various Machine Learning (ML) models and embedding techniques in automating this process. Five diverse datasets are utilized: Aceves-Martins (2021), comprising 1,258 excluded and 230 included abstracts on the utilization of animal models in depressive behaviour studies; Bannach-Brown (2016), with 896 excluded and 73 included abstracts focusing on the methodological rigour of environmental health systematic reviews; Meijboom (2021), containing 599 excluded and 32 included abstracts on the retransitioning of Etanercept in rheumatic disease patients; Menon (2022), with 896 excluded and 73 included abstracts on environmental health reviews; and a custom Clinical Review Paper Abstract (CRPA) dataset, featuring 500 excluded and 50 included abstracts. A significant research gap in abstract classification has been identified in previous literature, particularly in comparing Large Language Models (LLMs) with traditional ML and Natural Language Processing (NLP) techniques regarding scalability, adaptability, computational efficiency, and real-time application. Addressing this gap, this study employs GloVe for word embedding via matrix factorization, FastText for character n-gram representation, and Doc2Vec for capturing paragraph-level semantics. A novel Zero-BertXGB technique is introduced, integrating a transformer-based language model, zero-shot learning, and an ML classifier to enhance abstract screening and classification into “Include” or “Exclude” categories. This approach leverages contextual understanding and precision for efficient abstract processing. The Zero-BertXGB technique is compared against other prominent LLMs, including BERT, PaLM, LLaMA, GPT-3.5, and GPT-4, to validate its effectiveness. The Zero-BertXGB model achieved accuracy values of 99.3% for Aceves-Martins2021, 92.6% for Bannach-Brown2016, 85.7% for Meijboom2021, 94.1% for Menon2022, and 98.8% for CRPA. The findings indicate that the Zero-BertXGB model, alongside other LLMs, can deliver reliable results with minimal human intervention, enhancing abstract screening efficiency and potentially revolutionizing systematic review workflows.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3531778",
            "Date of Publication": "20 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mohammad Shariful Islam",
                "labs": [
                    "Department of Computer Science and Telecommunication Engineering, Noakhali Science and Technology University, Noakhali, Bangladesh"
                ]
            },
            {
                "name": "Mohammad Abu Tareq Rony",
                "labs": [
                    "Department of Statistics, Noakhali Science and Technology University, Noakhali, Bangladesh"
                ]
            },
            {
                "name": "Md Rasel Hossain",
                "labs": [
                    "Department of Statistics, Noakhali Science and Technology University, Noakhali, Bangladesh"
                ]
            },
            {
                "name": "Samah Alshathri",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box, 84428, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Walid El-Shafai",
                "labs": [
                    "Computer Science Department, Automated Systems and Soft Computing Laboratory (ASSCL), Prince Sultan University, Riyadh, Saudi Arabia",
                    "Department of Electronics and Electrical Communications Engineering, Faculty of Electronic Engineering, Menoufia University, Menouf, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Biological system modeling",
                "Systematic literature review",
                "Accuracy",
                "Transformers",
                "Encoding",
                "Bidirectional control",
                "Nearest neighbor methods",
                "Detectors",
                "Databases",
                "Classification algorithms"
            ],
            "Author Keywords": [
                "Abstract classification",
                "machine learning",
                "natural language processing",
                "zero-BertXGB methods",
                "large language models"
            ]
        }
    },
    {
        "Title": "Enhanced Emotion-Aware Conversational Agent: Analyzing User Behavioral Status for Tailored Reponses in Chatbot Interactions",
        "Link": "https://ieeexplore.ieee.org/document/10854433/",
        "Abstract": "While chatbots are increasingly popular for communication, their effectiveness is limited by their difficulty in understanding users’ emotions. To address this, this study proposes a new hybrid chatbot model called “TEBC-Net” (Text Emotion Bert CNN Network), which combines text and video analysis to interpret user emotions and generate more empathetic responses. At the core of TEBC-Net is a multi-modal emotion analysis system. One component uses Bidirectional Encoder Representations from Transformers (BERT), a well-regarded model in natural language processing (NLP), achieving an 87.21% accuracy rate in detecting emotional cues from text inputs. The second component captures users’ facial expressions through webcam footage. It begins by detecting faces using a pre-trained classifier like Haarcascade. Then, to improve emotion recognition, it preprocesses the image through brightness adjustments and contrast enhancement with Automatic CLAHE and dual gamma correction. This processed image is analyzed by a Convolutional Neural Network (CNN) model trained specifically for emotion recognition, reaching 74.14% accuracy by assigning probabilities to different emotions. By integrating insights from both text and video analysis, TEBC-Net gains a comprehensive understanding of the user’s emotional state and intent. This combined data then informs the chatbot’s response generation module, enabling it to craft responses that are both empathetic and more directly aligned with the user’s emotional needs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3534197",
            "Date of Publication": "27 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "S. Abinaya",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "K. S. Ashwin",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            },
            {
                "name": "A. Sherly Alphonse",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Emotion recognition",
                "Encoding",
                "Bidirectional control",
                "Convolutional neural networks",
                "Accuracy",
                "Faces",
                "Classification algorithms",
                "Transformers",
                "Training"
            ],
            "Author Keywords": [
                "Chatbot",
                "bidirectional encoder representations from transformers",
                "natural language processing",
                "emotion recognition",
                "automatic CLAHE with dual gamma correction",
                "convolutional neural network"
            ]
        }
    },
    {
        "Title": "The Applicability of LLMs in Generating Textual Samples for Analysis of Imbalanced Datasets",
        "Link": "https://ieeexplore.ieee.org/document/10683735/",
        "Abstract": "In machine learning class imbalance is a pressing issue, where the model is biased towards the majority classes and underperforms in the minority classes. In textual data, the natural language processing (NLP) model bias significantly reduces overall accuracy, along with poor performance in minority classes. This paper investigates and compares the performance of transformer-based models, such as Multi-head Attention with the data levels and algorithmic levels approaches and BERT (Bidirectional Encoder Representations from Transformers) with LLM-based data augmentation. The research utilized the approaches, such as Random Over Sampler, Synthetic Minority Over-sampling Technique (SMOTE), SMOTEENN, data augmentation at word level, class weights, L2 regularization and leveraging GPT-3.5-Turbo’s for data augmentation to create additional data samples in imbalance dataset. The results from the experiment demonstrate that the LLM-based data augmentation with Multi-head Attention and BERT in the Myers-Briggs Type Indicator (MBTI) dataset (a highly skewed dataset) achieves the highest precision, recall and F1 score of 0.76 across terms. It indicates that the LLM-based data augmentation has significant improvements in dealing with class imbalance and improves the model’s accuracy in minority class types in the MBTI dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3463400",
            "Date of Publication": "18 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Saroj Gopali",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            },
            {
                "name": "Faranak Abri",
                "labs": [
                    "Department of Computer Science, San Jose State University, San Jose, CA, USA"
                ]
            },
            {
                "name": "Akbar Siami Namin",
                "labs": [
                    "Department of Computer Science, Texas Tech University, Lubbock, TX, USA"
                ]
            },
            {
                "name": "Keith S. Jones",
                "labs": [
                    "Department of Psychological Sciences, Texas Tech University, Lubbock, TX, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Transformers",
                "Context modeling",
                "Data augmentation",
                "Machine learning",
                "Encoding",
                "Psychology",
                "Large language models",
                "Natural language processing",
                "Bidirectional control"
            ],
            "Author Keywords": [
                "Multi-head attention",
                "BERT",
                "LLM",
                "GPT 3.5-turbo",
                "imbalance dataset",
                "Myers-Briggs type indicators"
            ]
        }
    },
    {
        "Title": "Systematic Literature Review of Topic Labeling",
        "Link": "https://ieeexplore.ieee.org/document/11015466/",
        "Abstract": "The rapid growth of textual data on the web has led researchers to develop methods in Natural Language Processing (NLP) to process, understand, and identify topics. Among these methods, Topic Modeling helps extract relevant topics, represented as clusters of words. However, interpreting these clusters into meaningful topics remains a challenge. This limitation has led to further research into topic labeling, an approach for assigning comprehensive and semantically meaningful labels to topic modeling results, ensuring that they are interpretable and understandable from a human perspective. In this paper, we present a Systematic Literature Review (SLR) on topic labeling. This review explores its definition, geographical and time distribution, methodologies, datasets, evaluation methods, successes, and challenges. This paper presents an SLR on topic labeling, synthesizing insights from 41 high-quality studies. It serves as a rich source of information for researchers interested in investigating different approaches for discovering topics within textual data. It addresses the various aspects of topic labeling and includes discussions that highlight the challenges of this approach, encouraging further research in this field.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3573521",
            "Date of Publication": "26 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Salma Mekaoui",
                "labs": [
                    "Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland"
                ]
            },
            {
                "name": "Ilham Chaker",
                "labs": [
                    "Laboratory of Intelligent Systems and Applications, Faculty of Sciences and Technology, Sidi Mohamed Ben Abdellah University, Fes, Morocco"
                ]
            },
            {
                "name": "Arsalane Zarghili",
                "labs": [
                    "Laboratory of Intelligent Systems and Applications, Faculty of Sciences and Technology, Sidi Mohamed Ben Abdellah University, Fes, Morocco"
                ]
            },
            {
                "name": "Nikola S. Nikolov",
                "labs": [
                    "Department of Computer Science and Information Systems, University of Limerick, Limerick, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Labeling",
                "Systematic literature review",
                "Search problems",
                "Probabilistic logic",
                "Computational modeling",
                "Databases",
                "Data models",
                "Context modeling",
                "Usability",
                "Semantics"
            ],
            "Author Keywords": [
                "Systematic literature review",
                "topic labeling",
                "topic labeling",
                "topic modeling",
                "topic modeling"
            ]
        }
    },
    {
        "Title": "TURSpider: A Turkish Text-to-SQL Dataset and LLM-Based Study",
        "Link": "https://ieeexplore.ieee.org/document/10753591/",
        "Abstract": "This paper introduces TURSpider, a novel Turkish Text-to-SQL dataset developed through human translation of the widely used Spider dataset, aimed at addressing the current lack of complex, cross-domain SQL datasets for the Turkish language. TURSpider incorporates a wide range of query difficulties, including nested queries, to create a comprehensive benchmark for Turkish Text-to-SQL tasks. The dataset enables cross-language comparison and significantly enhances the training and evaluation of large language models (LLMs) in generating SQL queries from Turkish natural language inputs. We fine-tuned several Turkish-supported LLMs on TURSpider and evaluated their performance in comparison to state-of-the-art models like GPT-3.5 Turbo and GPT-4. Our results show that fine-tuned Turkish LLMs demonstrate competitive performance, with one model even surpassing GPT-based models on execution accuracy. We also apply the Chain-of-Feedback (CoF) methodology to further improve model performance, demonstrating its effectiveness across multiple LLMs. This work provides a valuable resource for Turkish NLP and addresses specific challenges in developing accurate Text-to-SQL models for low-resource languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3498841",
            "Date of Publication": "15 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ali Bugra Kanburoglu",
                "labs": [
                    "Department of Computer Engineering, Işık University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Faik Boray Tek",
                "labs": [
                    "Department of Artificial Intelligence and Data Engineering, Istanbul Technical University, Istanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Structured Query Language",
                "Accuracy",
                "Error analysis",
                "Large language models",
                "Benchmark testing",
                "Cognition",
                "Encoding"
            ],
            "Author Keywords": [
                "Text-to-SQL",
                "LLM",
                "large language models",
                "Turkish",
                "dataset",
                "TURSpider"
            ]
        }
    },
    {
        "Title": "Enhancing DNN Computational Efficiency via Decomposition and Approximation",
        "Link": "https://ieeexplore.ieee.org/document/10813351/",
        "Abstract": "The increasing computational demands of emerging deep neural networks (DNNs) are fueled by their extensive computation intensity across various tasks, placing a significant strain on resources. This paper introduces DART, an adaptive microarchitecture that enhances area, power, and energy efficiency of DNN accelerators through approximated computations and decomposition, while preserving accuracy. DART improves DNN efficiency by leveraging adaptive resource allocation and simultaneous multi-threading (SMT). It exploits two prominent attributes of DNNs: resiliency and sparsity, of both magnitude and bit-level. Our microarchitecture decomposes the Multiply-and-Accumulate (MAC) into fine-grained elementary computational resources. Additionally, DART employs an approximate representation that leverages dynamic and flexible allocation of decomposed computational resources through SMT (Simultaneous Multi-Threading), thereby enhancing resource utilization and optimizing power consumption. We further improve efficiency by introducing a new Temporal SMT (tSMT) technique, which suggests processing computations from temporally adjacent threads by expanding the computational time window for resource allocation. Our simulation analysis, using a systolic array accelerator as a case study, indicates that DART can achieve more than 30% reduction in area and power, with an accuracy degradation of less than 1% in state-of-the-art DNNs in vision and natural language processing (NLP) tasks, compared to conventional processing elements (PEs) using 8-bit integer MAC units.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3521980",
            "Date of Publication": "24 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ori Schweitzer",
                "labs": [
                    "Faculty of Electrical and Computer Engineering, Technion—Israel Institute of Technology, Haifa, Israel"
                ]
            },
            {
                "name": "Uri Weiser",
                "labs": [
                    "Faculty of Electrical and Computer Engineering, Technion—Israel Institute of Technology, Haifa, Israel"
                ]
            },
            {
                "name": "Freddy Gabbay",
                "labs": [
                    "Faculty of Sciences, Institute of Applied Physics, The Hebrew University of Jerusalem, Jerusalem, Israel"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computational modeling",
                "Computer architecture",
                "Artificial neural networks",
                "Transformers",
                "Resilience",
                "Instruction sets",
                "Hardware",
                "Accuracy",
                "Resource management",
                "Quantization (signal)"
            ],
            "Author Keywords": [
                "Approximate computing",
                "computer architectures",
                "deep neural networks",
                "machine learning accelerators"
            ]
        }
    },
    {
        "Title": "Trans-Border Trusted Data Spaces: A General Framework Supporting Trustworthy International Data Circulation",
        "Link": "https://ieeexplore.ieee.org/document/10883955/",
        "Abstract": "In today’s interconnected global landscape, the seamless circulation of data across borders has emerged as a pivotal factor underpinning the global economy, scientific research, and technological advancements. It is imperative to enable a secure data-sharing ecosystem that ensures trustworthiness, which, in the cross-border context, refers to traceability, accountability, and multiparty compliance. However, a significant challenge remains: the lack of a universally applicable framework tailored to these scenarios, one could provide a trust foundation and corresponding assurances. To address this, we have taken “traceable, accountable, and multiparty compliant data-sharing” as design principles and propose a Trans-border Trusted Data Spaces (TTDS) framework. TTDS adopts the International Data Spaces (IDS) information model used in EU data-sharing projects to ensure interoperability and leverage the existing tools and standards to establish trustworthiness of participant identities. Building upon this, the framework provides traceability and accountability for data usage through security features including IP layer traffic monitoring, zero-trust identity management, smart contracts, etc. It also offers multi-party compliance support through a natural language processing (NLP) based rule interpretation framework. Compared to existing data-sharing frameworks, TTDS provides a more reliable and general “infrastructure” tailored to the specific needs of cross-border scenarios. In this paper, we present the functional and technical architecture as well as the core components of TTDS. And then propose a system implementation based on IPv6 for the more urgently needed aspects of data traceability, empirically demonstrating its effectiveness in achieving robust traceability and provided effective evidence to support accountability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3541295",
            "Date of Publication": "13 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Chi Zhang",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Yan Liu",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Mudi Xu",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Xingxing Yang",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Peng Li",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Changshui Yang",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Qiang Liu",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Xinning Xiong",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            },
            {
                "name": "Pan Chen",
                "labs": [
                    "Fnetlink Technology Company Ltd., Shenzhen, China"
                ]
            },
            {
                "name": "Wenyong Wang",
                "labs": [
                    "School of Computer Science and Engineering, Faculty of Innovation Engineering, Macau University of Science and Technology, Macau, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Computational modeling",
                "Protection",
                "Computer architecture",
                "Ecosystems",
                "Blockchains",
                "Standards",
                "Scalability",
                "Europe",
                "Differential privacy"
            ],
            "Author Keywords": [
                "Trans-border",
                "trusted data spaces",
                "data sharing infrastructure",
                "traceable",
                "accountable",
                "regulatory compliance"
            ]
        }
    },
    {
        "Title": "A Seamless ChatGPT Knowledge Plug-in for the Labour Market",
        "Link": "https://ieeexplore.ieee.org/document/10731911/",
        "Abstract": "In today’s rapidly evolving labor market, the emergence of new roles and the decline of traditional ones have led to a complex landscape of job titles and skill requirements. This complexity often causes ambiguity and confusion, affecting both novices and experienced professionals. To address this, extensive international efforts have produced reference databases of jobs and skills, such as ESCO and O*NET. However, the challenge remains to make this information easily accessible and interpretable for users with varying levels of expertise. To address the challenge above, this paper introduces a Knowledge Plug-in for ChatGPT, designed to serve as an intuitive, user-friendly interface between workers and these authoritative databases. By harnessing the power of natural language processing (NLP), the plug-in enables a seamless question-answering experience, effectively masking the underlying complexity with a carefully engineered architecture. Furthermore, generative AI enhances the user experience by providing relevant information in domains extending beyond the traditional scope of employment. An initial user study demonstrates the plug-in’s effectiveness in improving the usability and accuracy of job-related queries. We detail the development, architecture, and validation of this innovative tool, highlighting its potential impact on the future of employment search and career development.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3485111",
            "Date of Publication": "23 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rubén Alonso",
                "labs": [
                    "R2M Solution s.r.l., Pavia, Italy",
                    "Programa de Doctorado, Centro de Automática y Robótica, Universidad Politécnica de Madrid-CSIC, Madrid, Spain"
                ]
            },
            {
                "name": "Danilo Dessí",
                "labs": [
                    "Department of Computer Science, College of Computing and Informatics, University of Sharjah, Sharjah, United Arab Emirates"
                ]
            },
            {
                "name": "Antonello Meloni",
                "labs": [
                    "Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy"
                ]
            },
            {
                "name": "Marco Murgia",
                "labs": [
                    "Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy"
                ]
            },
            {
                "name": "Diego Reforgiato Recupero",
                "labs": [
                    "Department of Mathematics and Computer Science, University of Cagliari, Cagliari, Italy"
                ]
            },
            {
                "name": "Giuseppe Scarpi",
                "labs": [
                    "R2M Solution s.r.l., Pavia, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Databases",
                "Semantics",
                "Recruitment",
                "Engineering profession",
                "Taxonomy",
                "Structured Query Language",
                "Social networking (online)",
                "Resumes",
                "Employment",
                "Large language models",
                "Natural language processing",
                "Knowledge based systems",
                "Professional aspects",
                "Question answering (information retrieval)",
                "Query processing"
            ],
            "Author Keywords": [
                "Conversational agents",
                "labor market",
                "large language models",
                "natural language processing",
                "occupational databases"
            ]
        }
    },
    {
        "Title": "Siamese Neural Networks Method for Semantic Requirements Similarity Detection",
        "Link": "https://ieeexplore.ieee.org/document/10697170/",
        "Abstract": "Detecting semantic similarity between textual requirements is a crucial task for various natural language processing (NLP)-based requirements engineering (RE) applications. It is also challenging due to the nature of these requirements, which are written in natural language (NL), include domain knowledge, and often follow pre-defined templates that contain duplicated words. Recently, deep neural networks (DNNs) have shown promising results in measuring semantic similarity between texts. Siamese neural networks (SNNs), a class of DNNs, are widely used for measuring similarity between various data types, demonstrating their capability and independence of language and domain. Nevertheless, SNNs have a limited use in measuring semantic requirements similarity (SRS). In this paper, a novel metric-based learning method is proposed using SNNs that combines a sentence Transformer model (LLM) and long short-term memory (LSTM) networks with a backward network layer to measure semantic similarity between pairs of requirements. The proposed method is evaluated on an annotated SRS dataset that was built based on public datasets (i.e., PROMISE and PURE) and compared with other state-of-the-art methods (i.e., fine-tuning and zero-shot methods) using accuracy, precision, recall, and F1-score classification metrics. The results show that the proposed method achieved an accuracy of 95.42% and an F1-score of 95.71%, outperforming the state-of-the-art methods.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3469636",
            "Date of Publication": "27 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nojoom A. Alnajem",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Manal Binkhonain",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "M. Shamim Hossain",
                "labs": [
                    "Department of Software Engineering, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Transformers",
                "Accuracy",
                "Vectors",
                "Software",
                "Long short term memory",
                "Requirements engineering",
                "Computer architecture",
                "Natural language processing",
                "XML",
                "Artificial intelligence",
                "Neural networks"
            ],
            "Author Keywords": [
                "Artificial intelligence for requirements engineering",
                "large language models",
                "long short-term memory networks",
                "requirements",
                "requirements engineering",
                "requirements similarity",
                "semantic requirements similarity",
                "Siamese neural networks",
                "similarity",
                "transformer models"
            ]
        }
    },
    {
        "Title": "A Hybrid Recommendation Integrating Semantic Learner Modelling and Sentiment Multi-Classification",
        "Link": "https://ieeexplore.ieee.org/document/10246916/",
        "Abstract": "Enhancing virtual learning platforms need to adapt new intelligent mechanisms so that long-term learner experience can be improved. Sentiment Analysis gives us perception on how a specific scientific material is suitable to be recommended to the learner. It depends on the feedback of a similar learner taking many factors under consideration such as preference, knowledge level, and learning pattern. In this work, a hybrid e-learning recommendation system is proposed based on individualization and Sentiment Analysis. A new approach is provided for modelling the semantic user model based on the generated semantic matrix to capture the learner's preferences based on their selections of interest. The extracted semantic matrix is used for text representation by utilizing ConceptNet knowledge base which relies on contextual graph and expanded terms to represent the correlation among terms and materials. On the extracted terms from semantic user model, Word Embeddings-Based-Sentiment Analysis (WEBSA) must recommend the learning materials with highest rating to the learners properly. Variant models of (WEBSA) are proposed relying on Natural Language Processing (NLP) to generate effective vocabulary representations along with the use of qualitative customized Convolutional Neural Network (CNN) for sentiment multi-classification tasks. To validate the language model, two datasets are used, a tailored dataset that has been created by scraping reviews of different e-learning resources, and a public dataset. From the experimental results, it has been found that the lowest error rate is achieved with our customized dataset, where the model named CNN-Specific-Task-CBOWBSA outperforms than others with 89.26% accuracy.",
        "Details": {
            "DOI": "10.13052/jwe1540-9589.2141",
            "Date of Publication": "June 2022",
            "Publisher": "River Publishers",
            "Published In": "Journal of Web Engineering"
        },
        "issn_info": {
            "Print ISSN": "1540-9589",
            "Electronic ISSN": "1544-5976"
        },
        "authors_data": [
            {
                "name": "Rawaa Alatrash",
                "labs": [
                    "Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Rojalina Priyadarshini",
                "labs": [
                    "Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Hadi Ezaldeen",
                "labs": [
                    "Department of Computer Science and Engineering, C.V. Raman Global University, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Akram Alhinnawi",
                "labs": [
                    "Department Computer Science and Engineering, University of Bridgeport, Bridgeport, CT, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Deep learning",
                "Sentiment analysis",
                "Analytical models",
                "Vocabulary",
                "Electronic learning",
                "Semantics",
                "Hidden Markov models"
            ],
            "Author Keywords": [
                "Hybrid recommendation",
                "semantic user modeling",
                "contextual graph",
                "sentiment analysis",
                "word embeddings",
                "deep learning"
            ]
        }
    },
    {
        "Title": "AI and Human Resources in a Literature-Driven Investigation Into Emerging Trends",
        "Link": "https://ieeexplore.ieee.org/document/10992688/",
        "Abstract": "Throughout the years, technology has faced many advancements, the star being the power of Artificial Intelligence (AI), which continues to strike through. This concept has rapidly gained popularity and has raised points of concern in almost every government from the European Union (EU) because of the challenges it possesses in terms of efficiency, decision-making and transparency. This paper revolves around building up an extensive literature review of the academic landscape surrounding the role of AI in Human Resources (HR) in the public sector, analyzing Web of Science publication trends and thematic patterns, spanning 12,121 publications from 2020 to 2024, where both Python and R scripts are applied to extract insights. The findings highlight the relevance of a human-centric approach to AI adoption by addressing ethical, cultural and compliance concerns, with the aid of advanced Natural Language Processing (NLP) techniques, such as Latent Dirichlet Allocation (LDA) for topic modelling and keyword co-occurrence networks for thematic exploration. Moreover, a Hugging Face Named Entity Recognition (NER) model is employed to systematically identify and categorize AI techniques within the analyzed abstracts, providing a foundation for subsequent frequency and trend analyses. The analysis brings out a steady growth in publication volume, with an average of 2,500 papers annually and a significant concentration of research within domains such as neural networks, algorithm optimization and digital transformation. Apart from the interdisciplinary focus of the subject, we aim to shed light on the importance of AI-driven HR strategies in directing administrative insufficiencies of the public sector.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3568338",
            "Date of Publication": "08 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Cristina Iancu",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania",
                    "Doctoral School of Economic Informatics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            },
            {
                "name": "Simona-Vasilica Oprea",
                "labs": [
                    "Department of Economic Informatics and Cybernetics, Bucharest University of Economic Studies, Bucharest, Romania"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial intelligence",
                "Ethics",
                "Bibliometrics",
                "Market research",
                "Economics",
                "Decision making",
                "Semantics",
                "Recruitment",
                "Planning",
                "Manuals"
            ],
            "Author Keywords": [
                "AI role",
                "human resources",
                "latent topics",
                "semantic and bibliometric analysis"
            ]
        }
    },
    {
        "Title": "Diversified Semantic Attention Model for Fine-Grained Entity Typing",
        "Link": "https://ieeexplore.ieee.org/document/9305269/",
        "Abstract": "Fine-grained entity typing, which aims to assign specific types to entity mentions in text, is attracting increasing attention in the field of natural language processing (NLP). However, it is quite a challenging problem due to the highly ambiguous nature of many entity mentions. Most existing entity typing methods based on attention mechanism generally extract the salient features separately from the entity mention and the contextual words. However, these approaches suffer from two main limitations: (1) They ignore the rich information contained by entity mentions when applying the attention mechanisms. (2) They do not consider the diversity of attention processes which can be beneficial in finding the discriminative features. To address these issues, we propose the diversified semantic attention model (DSAM) for fine-grained entity typing, and the main novelties are: (1) It explicitly pursues the diversity of attention and is able to maximally gather discriminative information. (2) It integrates two level attentions—the mention-level attention and the context-level attention— to jointly capture the rich information from mentions and contexts to enhance their mutual promotions. (3) It combines the attention maps constraint and the attention segments constrain to exploit the subtle semantic differences for distinguishing the subtypes. Importantly, the proposed DSAM approach can be trained end-to-end without employing ad-hoc features or post-processing. Extensive experiments using three benchmark datasets demonstrated that our DSAM approach achieves competitive performance compared to the current state-of-the-art methods used for fine-grained entity typing.",
        "Details": {
            "DOI": "10.1109/ACCESS.2020.3046787",
            "Date of Publication": "23 December 2020",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yanfeng Hu",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Xue Qiao",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            },
            {
                "name": "Luo Xing",
                "labs": [
                    "Software Engineering Institute, East China Normal University, Shanghai, China"
                ]
            },
            {
                "name": "Chen Peng",
                "labs": [
                    "Institute of Electronics, Chinese Academy of Sciences, Suzhou, China",
                    "Key Laboratory of Intelligent Aerospace Big Data Application Technology, Suzhou, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Organizations",
                "Task analysis",
                "Feature extraction",
                "Natural language processing",
                "Training"
            ],
            "Author Keywords": [
                "Fine-grained entity typing",
                "diversified semantic attention model (DSAM)",
                "long shot-term memory (LSTM)",
                "mention-aware attention mechanism"
            ]
        }
    },
    {
        "Title": "Improving Transformer Performance for French Clinical Notes Classification Using Mixture of Experts on a Limited Dataset",
        "Link": "https://ieeexplore.ieee.org/document/11023574/",
        "Abstract": "Transformer-based models have shown outstanding results in natural language processing but face challenges in applications like classifying small-scale clinical texts, especially with constrained computational resources. This study presents a customized Mixture of Expert (MoE) Transformer models for classifying small-scale French clinical texts at CHU Sainte-Justine Hospital. The MoE-Transformer addresses the dual challenges of effective training with limited data and low-resource computation suitable for in-house hospital use. Despite the success of biomedical pre-trained models such as CamemBERT-bio, DrBERT, and AliBERT, their high computational demands make them impractical for many clinical settings. Our MoE-Transformer model not only outperforms DistillBERT, CamemBERT, FlauBERT, and Transformer models on the same dataset but also achieves impressive results: an accuracy of 87%, precision of 87%, recall of 85%, and F1-score of 86%. While the MoE-Transformer does not surpass the performance of biomedical pre-trained BERT models, it can be trained at least 190 times faster, offering a viable alternative for settings with limited data and computational resources. Although the MoE-Transformer addresses challenges of generalization gaps and sharp minima, demonstrating some limitations for efficient and accurate clinical text classification, this model still represents a significant advancement in the field. It is particularly valuable for classifying small French clinical narratives within the privacy and constraints of hospital-based computational resources. Clinical and Translational Impact Statement—This study highlights the potential of customized MoE-Transformers in enhancing clinical text classification, particularly for small-scale datasets like French clinical narratives. The MoE-Transformer's ability to outperform several pre-trained BERT models marks a stride in applying NLP techniques to clinical data and integrating into a Clinical Decision Support System in a Pediatric Intensive Care Unit. The study underscores the importance of model selection and customization in achieving optimal performance for specific clinical applications, especially with limited data availability and within the constraints of hospital-based computational resources\nShow Less",
        "Details": {
            "DOI": "10.1109/JTEHM.2025.3576570",
            "Date of Publication": "04 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Journal of Translational Engineering in Health and Medicine"
        },
        "issn_info": {
            "Electronic ISSN": "2168-2372"
        },
        "authors_data": [
            {
                "name": "Thanh-Dung Le",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, University of Quebec, Quebec City, QC, Canada",
                    "Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg"
                ]
            },
            {
                "name": "Philippe Jouvet",
                "labs": [
                    "Research Center at CHU Sainte-Justine, University of Montreal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Rita Noumeir",
                "labs": [
                    "Biomedical Information Processing Laboratory, École de Technologie Supérieure, University of Quebec, Quebec City, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Computational modeling",
                "Biological system modeling",
                "Data models",
                "Brain modeling",
                "Text categorization",
                "Adaptation models",
                "Natural language processing",
                "Accuracy",
                "Predictive models"
            ],
            "Author Keywords": [
                "Clinical natural language processing",
                "cardiac failure",
                "BERT",
                "Transformer",
                "Mixture of Expert"
            ]
        }
    },
    {
        "Title": "Decision Support System for Evaluating Corpus-Based Word Lists for Use in English Language Teaching Contexts",
        "Link": "https://ieeexplore.ieee.org/document/11036742/",
        "Abstract": "The selection of pedagogically relevant vocabulary is a critical aspect of English Language Teaching (ELT), yet traditional corpus-based word lists often rely solely on frequency-based ranking, limiting their effectiveness in real-world learning contexts. This study proposes a Decision Support System (DSS) that integrates corpus linguistics, Natural Language Processing (NLP), and machine learning to generate optimized vocabulary lists tailored for ELT. The DSS enhances word selection accuracy by incorporating contextual relevance, collocational strength, and pedagogical value, surpassing the limitations of static frequency-based models. The experimental evaluation compares DSS performance with traditional frequency-based methods and the academic word list (awl). The results indicate that the DSS achieves significantly higher ranking accuracy (mrr: 0.89, ndcg: 0.85) and improves classification performance (f1-score: 87.3%), ensuring that highly relevant words appear earlier in ranked lists. A case study in general and academic english contexts demonstrates that DSS-generated word lists offer greater usability, stronger contextual fit, and enhanced pedagogical effectiveness, as confirmed by positive teacher feedback (usability score: 4.7/5). Statistical validation using t-tests and anova confirms that DSS ranking improvements are statistically significant (p < 0.001), and effect size analysis (cohen’s d > 0.8) highlights its substantial impact on vocabulary instruction. Despite certain limitations such as corpus dependency and limited multilingual support, the DSS presents a scalable and adaptable solution for data-driven vocabulary selection in ELT. Future enhancements will focus on multilingual capabilities, personalized learning, and hybrid ranking models to further refine the system’s applicability in diverse educational settings.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3579865",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ruoxi Yin",
                "labs": [
                    "Foreign Language Department, Xuzhou Medical University, Xuzhou, Jiangsu, China"
                ]
            },
            {
                "name": "Chunmei Zhu",
                "labs": [
                    "Foreign Language Department, Xuzhou Medical University, Xuzhou, Jiangsu, China"
                ]
            },
            {
                "name": "Jiuyang Zhu",
                "labs": [
                    "Foreign Language Department, Xuzhou Medical University, Xuzhou, Jiangsu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vocabulary",
                "Education",
                "Decision support systems",
                "Linguistics",
                "Natural language processing",
                "Machine learning",
                "Usability",
                "Cognitive load",
                "Adaptation models",
                "Systematics"
            ],
            "Author Keywords": [
                "Decision support system",
                "corpus-based word lists",
                "English language teaching",
                "vocabulary selection",
                "machine learning",
                "pedagogical relevance"
            ]
        }
    },
    {
        "Title": "A Novel Temporal Footprints-Based Framework for Fake News Detection",
        "Link": "https://ieeexplore.ieee.org/document/10741540/",
        "Abstract": "With the evolution of social media platforms, the detection of fake news and misinformation is gaining popularity. Social media platforms are the fastest source of fake news propagation, whereas online news websites contribute to dissemination. In recent studies, the temporal features in text documents have gained valuable consideration from the natural language processing (NLP) research community. This study investigates the importance of temporal features in text documents for detecting fake news. Later, the temporal features are combined with the textual features to increase classifier performance. This research study uses Random Forest (RF) and Bi-LSTM techniques to classify fake news based on temporal features and textual features. A publicly available dataset was used to train and test the model. The experimental results demonstrated that the proposed method achieved 99% accuracy by combining temporal and textual features in fake news detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3490558",
            "Date of Publication": "04 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ali Raza",
                "labs": [
                    "Department of Software Engineering, University of Mianwali, Mianwali, Pakistan",
                    "Department of Computer Science, MY University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Shafiq Ur Rehman Khan",
                "labs": [
                    "Department of Computer Science, Namal University, Mianwali, Pakistan"
                ]
            },
            {
                "name": "Raja Sher Afgun Usmani",
                "labs": [
                    "Department of Computer Science, MY University, Islamabad, Pakistan"
                ]
            },
            {
                "name": "Ashok Kumar Das",
                "labs": [
                    "Center for Security, Theory and Algorithmic Research, International Institute of Information Technology at Hyderabad, Hyderabad, India",
                    "Department of Computer Science and Engineering, College of Informatics, Korea University, Seongbuk, Seoul, South Korea"
                ]
            },
            {
                "name": "Shehzad Ashraf Chaudhry",
                "labs": [
                    "Department of Computer Science and Information Technology, College of Engineering, Abu Dhabi University, Abu Dhabi, United Arab Emirates",
                    "Department of Software Engineering, Faculty of Engineering and Architecture, Nisantasi University, İstanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Fake news",
                "Social networking (online)",
                "Feature extraction",
                "Electronic mail",
                "Internet",
                "Voting",
                "Data models",
                "Bayes methods",
                "Data mining",
                "Computer science"
            ],
            "Author Keywords": [
                "Fake news",
                "machine learning",
                "temporal features",
                "textual features"
            ]
        }
    },
    {
        "Title": "Exploring Topic Coherence With PCC-LDA and BERT for Contextual Word Generation",
        "Link": "https://ieeexplore.ieee.org/document/10713309/",
        "Abstract": "In the field of natural language processing (NLP), topic modeling and word generation are crucial for comprehending and producing texts that resemble human languages. Extracting key phrases is an essential task that aids document summarization, information retrieval, and topic classification. Topic modeling significantly enhances our understanding of the latent structure of textual data. Latent Dirichlet Allocation (LDA) is a popular algorithm for topic modeling, which assumes that every document is a mix of several topics, and each topic will have multiple words. A new model similar to LDA, but a better version called Probabilistic Correlated Clustering Latent Dirichlet Allocation (PCC-LDA) was recently introduced. On the other hand, BERT is an advanced bidirectional pre-trained language model that understands words in a sentence based on the full context to generate more precise and contextually correct words. Topic modeling is a useful way to discover hidden themes or topics within a range of documents aiming to tune better topics from the corpus and enhance topic modeling implementation. The experiments indicated a significant improvement in performance when using this combination approach. Coherence criteria of are utilized to judge whether the words in each topic accord with prior knowledge, which could ensure that topics are interpretable and meaningful. The above results of the topic-level analysis indicate that PCC-LDA consistency topics perform better than LDA and NMF(non-negative matrix factorization Technique) by at least 15.4%,12.9%(\nk=5\n) and up to nearly 12.5% and 11.8% (\nk=10\n) respectively, where k represents the number of topics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3477992",
            "Date of Publication": "10 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sandeep Kumar Rachamadugu",
                "labs": [
                    "Department of Computer Science and Engineering, M. S. Ramaiah University of Applied Sciences, Bengaluru, Karnataka, India",
                    "Department of Computer Science and Engineering, G. Pulla Reddy Engineering College, Autonomous, JNTUA, Ananthapuramu, Andhra Pradesh, India"
                ]
            },
            {
                "name": "T. P. Pushphavathi",
                "labs": [
                    "Department of Computer Science and Engineering, M. S. Ramaiah University of Applied Sciences, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Surbhi Bhatia Khan",
                "labs": [
                    "School of Science, Engineering and Environment, University of Salford, Manchester, U.K.",
                    "University Centre for Research and Development, Chandigarh University, Mohali, Punjab, India",
                    "Adjunct Research Faculty, the Centre for Research Impact and Outcome, Chitkara University, Rajpura, Punjab, India"
                ]
            },
            {
                "name": "Mohammad Alojail",
                "labs": [
                    "Management Information System Department, College of Business Administration, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Coherence",
                "Encoding",
                "Data models",
                "Bidirectional control",
                "Semantics",
                "Data mining",
                "Analytical models",
                "Context modeling",
                "Probabilistic logic",
                "Measurement"
            ],
            "Author Keywords": [
                "BERT",
                "key phrases",
                "LDA",
                "topic coherence",
                "topic modeling"
            ]
        }
    },
    {
        "Title": "TrBot: A Turkish Deep Learning Chatbot Utilizing Seq2Seq Model",
        "Link": "https://ieeexplore.ieee.org/document/10924176/",
        "Abstract": "In Natural Language Processing (NLP) and Artificial Intelligence (AI), chatbots, which are software programs designed to facilitate human-computer interaction through natural language, are becoming increasingly important. However, creating an effective chatbot remains a complex task, as it must accurately interpret user input and generate appropriate responses. This study presents TrBot, a general-purpose Turkish chatbot that utilizes deep learning techniques, specifically a seq2seq model with Long Short-Term Memory (LSTM) layers. This architecture allows TrBot to manage sequential dependencies and effectively generate coherent responses, offering advantages in handling the complex morphological structure of Turkish. In contrast to earlier Turkish chatbots that were application-specific, TrBot is designed for broad conversational use across various topics. In this study, we also proposed and created two comprehensive datasets: a QA dataset with 40,702 entries and a conversation dataset with 304,446 entries, both specifically designed to enhance TrBot’s performance. Trained on these datasets, TrBot achieved an accuracy of 80% on the QA dataset and 70% on the dialog dataset, with BLEU scores of 0.90 and 0.77 respectively, indicating substantial enhancements in response quality. In comparison, a Transformer-based model exhibited reduced training times but achieved lower accuracies of 60% on the QA dataset and 50% on the dialog dataset, with BLEU scores of 0.76 and 0.61 respectively, with the limited size of the datasets and available computational resources. The development of TrBot has significant implications, offering potential benefits in areas such as customer support, language learning, and other fields that require robust Turkish conversational capabilities. This study demonstrates that with adequate data and appropriate modeling techniques, it is possible to create effective conversational agents for complex languages like Turkish, paving the way for further advancements in this domain.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3550852",
            "Date of Publication": "12 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Bilal Babayigit",
                "labs": [
                    "Computer Engineering Department, Erciyes University, Kayseri, Türkiye"
                ]
            },
            {
                "name": "Habibelahi Rahmani",
                "labs": [
                    "Computer Engineering Department, Erciyes University, Kayseri, Türkiye"
                ]
            },
            {
                "name": "Mohammed Abubaker",
                "labs": [
                    "Computer Engineering Department, Erciyes University, Kayseri, Türkiye",
                    "Computer Science Department, Palestine Technical College, Palestine, Gaza"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Oral communication",
                "Deep learning",
                "Transformers",
                "Adaptation models",
                "Artificial intelligence",
                "Training",
                "Long short term memory",
                "Linguistics",
                "Context modeling"
            ],
            "Author Keywords": [
                "Chatbots",
                "deep learning",
                "LSTM",
                "natural language processing",
                "Seq2seq model",
                "Turkish language"
            ]
        }
    },
    {
        "Title": "ChatGPT Versus Modest Large Language Models: An Extensive Study on Benefits and Drawbacks for Conversational Search",
        "Link": "https://ieeexplore.ieee.org/document/10839752/",
        "Abstract": "Large Language Models (LLMs) are effective in modeling text syntactic and semantic content, making them a strong choice to perform conversational query rewriting. While previous approaches proposed NLP-based custom models, requiring significant engineering effort, our approach is straightforward and conceptually simpler. Not only do we improve effectiveness over the current state-of-the-art, but we also curate the cost and efficiency aspects. We explore the use of pre-trained LLMs fine-tuned to generate quality user query rewrites, aiming to reduce computational costs while maintaining or improving retrieval effectiveness. As a first contribution, we study various prompting approaches — including zero, one, and few-shot methods — with ChatGPT (e.g., gpt-3.5-turbo). We observe an increase in the quality of rewrites leading to improved retrieval. We then fine-tuned smaller open LLMs on the query rewriting task. Our results demonstrate that our fine-tuned models, including the smallest with 780 million parameters, achieve better performance during the retrieval phase than gpt-3.5-turbo. To fine-tune the selected models, we used the QReCC dataset, which is specifically designed for query rewriting tasks. For evaluation, we used the TREC CAsT datasets to assess the retrieval effectiveness of the rewrites of both gpt-3.5-turbo and our fine-tuned models. Our findings show that fine-tuning LLMs on conversational query rewriting datasets can be more effective than relying on generic instruction-tuned models or traditional query reformulation techniques.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3529741",
            "Date of Publication": "14 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Guido Rocchietti",
                "labs": [
                    "ISTI-CNR, Pisa, Italy",
                    "Department of Computer Science, University of Pisa, Pisa, Italy"
                ]
            },
            {
                "name": "Cosimo Rulli",
                "labs": [
                    "ISTI-CNR, Pisa, Italy"
                ]
            },
            {
                "name": "Franco Maria Nardini",
                "labs": [
                    "ISTI-CNR, Pisa, Italy"
                ]
            },
            {
                "name": "Cristina Ioana Muntean",
                "labs": [
                    "ISTI-CNR, Pisa, Italy"
                ]
            },
            {
                "name": "Raffaele Perego",
                "labs": [
                    "ISTI-CNR, Pisa, Italy"
                ]
            },
            {
                "name": "Ophir Frieder",
                "labs": [
                    "Georgetown University, Washington, DC, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Chatbots",
                "Oral communication",
                "Cancer",
                "Costs",
                "Computational modeling",
                "Context modeling",
                "Standards",
                "Pipelines",
                "Measurement",
                "Large language models"
            ],
            "Author Keywords": [
                "Conversational search",
                "query rewriting",
                "large language models",
                "instruction-tuned LLMs",
                "fine-tuning"
            ]
        }
    },
    {
        "Title": "Named Entity Recognition in User-Generated Text: A Systematic Literature Review",
        "Link": "https://ieeexplore.ieee.org/document/10597560/",
        "Abstract": "Named Entity Recognition (NER) in social media has received much research attention in the field of natural language processing (NLP) and information extraction. Research on this topic has grown dramatically in recent years. Hence, one of the objectives of this systematic literature review (SLR) is to present the outline techniques, approaches, and methods used to handle NER on X based on English datasets prepared for WNUT (Workshop on User-generated Text). This study could be used to develop more accurate models in the future. This SLR focuses on articles that had been published over the course of eight years, i.e., from July 2015 to the end of 2023. A total of 67 out of 316 articles published during the period were selected having met the set chosen criteria. Based on the analysis of the selected articles, challenges were identified and discussed. In this SLR, we aim to provide a better understanding of current viewpoints and highlight opportunities for research in NER in User-generated Text specifically for English usage on X. It can aid in identifying named entities, such as names, locations, companies, and groups, within a specific informal social media context like X. This research is notable for being the first systematic review that emphasizes the dearth of NER on X based on English datasets prepared for WNUT.The main contribution of this systematic review is a comprehensive study on NER in X messages for social media, entailing its challenges and opportunities. Moreover, new possible research directions are suggested for the researchers.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3427714",
            "Date of Publication": "15 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Naji Esmaail",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia",
                    "Department of Computer Science, Faculty of Sciences, Omar Al-Mukhtar University, Al Bayda, Libya"
                ]
            },
            {
                "name": "Nazlia Omar",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Masnizah Mohd",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Fariza Fauzi",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia"
                ]
            },
            {
                "name": "Zainab Mansur",
                "labs": [
                    "Faculty of Information Science and Technology, Centre for Artificial Intelligence Technology, Universiti Kebangsaan Malaysia, Bangi, Malaysia",
                    "Department of Computer Science, Faculty of Sciences, Omar Al-Mukhtar University, Al Bayda, Libya"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Blogs",
                "Reviews",
                "Systematics",
                "Surveys",
                "Named entity recognition",
                "Databases",
                "Information retrieval",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Named entity recognition",
                "NER",
                "user-generated text",
                "WNUT",
                "X",
                "systematic literature review",
                "SLR",
                "information extraction",
                "natural language processing",
                "social media"
            ]
        }
    },
    {
        "Title": "A Novel Customer Review Analysis System Based on Balanced Deep Review and Rating Differences in User Preference",
        "Link": "https://ieeexplore.ieee.org/document/10669578/",
        "Abstract": "The rapid growth of mobile applications and online e-commerce websites has made it easy to gather information to create an enormous quantity of training data to aid consumers in making decisions about what to purchase. On online shopping sites, a helpful review analysis of user reviews can significantly increase users’ loyalty. People may significantly influence the market value of goods and customer confidence in e-commerce decisions by using ratings, and reviews. One major issue with users’ rating prediction models is that they ignore variations across users that fall inside the user’s preferences or reviews. In this paper, we develop a new balanced helpful recommendation model with quantifying users’ tendencies (BHRQUT)-based on personalized reviews and ratings to predict helpful reviews and improve recommendation accuracy by creating an auxiliary feature that is computed based on actual ratings and predicted ratings. Text sequence processing was acquired by experimental research on the influence of word vector embedding dimension and word frequency of review text, utilizing (NLP). These features were transformed into vectors based on the embedding layer to the balanced (CNN-BiLSTM) model. Experimental evaluations are performed on four review datasets from the 5-score Amazon domain and our model can significantly enhance the accuracy of helpful review text analysis by 97 percent. According to the experimental results when we compared with other deep recommendation approaches concerning multiple metrics and drew from the different experiments, the presented model can enhance the analyzability of user feedback by enhancing decision-making confidence without reducing accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3456562",
            "Date of Publication": "09 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rand Almahmood",
                "labs": [
                    "Department of Computer Engineering, Gazi University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Muhammed Mutlu Yapici",
                "labs": [
                    "Department of Computer Technologies, Elmadag Vocational School, Ankara University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Adem Tekerek",
                "labs": [
                    "Department of Computer Engineering, Faculty of Technology, Gazi University, Ankara, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Reviews",
                "Convolutional neural networks",
                "Recommender systems",
                "Predictive models",
                "Prediction algorithms",
                "Long short term memory",
                "Electronic commerce"
            ],
            "Author Keywords": [
                "Balanced deep model",
                "natural processing language",
                "recommendation system",
                "tendencies-based collaborative filtering algorithm"
            ]
        }
    },
    {
        "Title": "Efficient and Standardized Alarm Rationalization for Cybersecurity Monitoring",
        "Link": "https://ieeexplore.ieee.org/document/10745487/",
        "Abstract": "Threat monitoring in cybersecurity systems is often jeopardized by alarm flooding, which frequently occurs in Security Information and Event Management (SIEM) solutions due to the unnecessary annunciation of numerous logs and event data from a variety of sources, including applications, network devices, firewall logs, and other sources. Cybersecurity operators may become alert fatigued and less able to respond to important occurrences due to the high volume of unnecessary alarms. Hence, for security operators to monitor threats effectively and consistently, alarm rationalization using formal and efficient techniques is needed. This study proposes a new framework for efficiently prioritizing cybersecurity alarms based on the integration of penetration testing findings with well-established industrial standards in alarm management. This is efficiently done by developing a Natural Language Processing (NLP) model to automatically map penetration testing findings to the Adversarial Tactics, Techniques, and Common Knowledge (MITRE ATT&CK) relationships, followed by alarm rationalization based on the industrial alarm management standard ISA 18.2. Verification of the effectiveness of the new integrated approach is demonstrated on a real system, which showed a reduction in the number of critical and high alarms by 38% while conforming to industrial alarm management standards in terms of peak alarm rates, average alarm rates, and healthy alarm priority distribution.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3492264",
            "Date of Publication": "06 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sarah Alabdulhadi",
                "labs": [
                    "Department of Engineering Management, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ali Al-Matouq",
                "labs": [
                    "Department of Engineering Management, Prince Sultan University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Penetration testing",
                "Computer security",
                "Monitoring",
                "Security",
                "Testing",
                "Natural language processing",
                "Semantics",
                "Guidelines",
                "Alarm systems",
                "Computer security",
                "Intrusion detection"
            ],
            "Author Keywords": [
                "Cybersecurity",
                "alarm rationalization",
                "intrusion detection",
                "alarm management",
                "penetration testing"
            ]
        }
    },
    {
        "Title": "In-Vehicle Network Inspector Utilizing Diagnostic Communications and Web Scraping for Estimating ECU Functions and CAN Topology",
        "Link": "https://ieeexplore.ieee.org/document/10384389/",
        "Abstract": "As modern vehicles connect with external networks such as the internet, a lot of research reveals various ways to hack vehicles. Given this background, the UN-R155 regulation requires automakers to conduct incident responses. To make incident response processes accurate and efficient, VSOCs (Vehicle Security Operation Centers) are beneficial. Thus, we anticipate that automakers will adopt VSOCs in their incident response processes. In VSOC analysis, knowledge of ECU (Electronic Control Unit) functions and the in-vehicle network topology in a vehicle plays an important role in exploring impacted areas and determining appropriate measures. However, it is sometimes hard for automakers to provice VSOCs with knowledge because the knowledge is confidential. Even if automakers can provide the knowledge, if automakers keep the design information and the specifications on documents, it is time-consuming and labor-intensive to encode them into a format that is suitable for VSOC analysis. There are many conventional methods to estimate device functions and a network topology in the IT (information technology) domain, which can help SOCs to obtain knowledge. However, they cannot be applied to CAN (Controller Area Network), which is one of the key networks for vehicles, because ECUs and CAN do not support IT domain protocols. There are also conventional CAN analysis tools. However, to apply these tools to modern vehicles, it is necessary to disassemble the vehicles and directly tap into CAN buses. This disassembly process is both time-consuming and labor-intensive. To overcome these problems, we propose a new vehicular-domain-specific method for estimating ECU functions and a CAN topology in a vehicle without the need for vehicle disassembly. Our proposed method utilizes scanning techniques on the basis of vehicular domain protocols, web scraping, and an NLP (natural language processing) technique. Through our evaluation using two actual vehicles, we demonstrate that our proposed method estimates ECU functions and a CAN topology with 75.9% and 86.2% accuracy, respectively.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3351175",
            "Date of Publication": "08 January 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Masaru Matsubayashi",
                "labs": [
                    "NTT Security Holdings Corporation, Chiyoda-ku, Tokyo, Japan"
                ]
            },
            {
                "name": "Takuma Koyama",
                "labs": [
                    "NTT Security Holdings Corporation, Chiyoda-ku, Tokyo, Japan"
                ]
            },
            {
                "name": "Masashi Tanaka",
                "labs": [
                    "NTT Security Holdings Corporation, Chiyoda-ku, Tokyo, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Topology",
                "Network topology",
                "Protocols",
                "Logic gates",
                "Knowledge engineering",
                "Estimation",
                "Regulation",
                "Vehicle dynamics"
            ],
            "Author Keywords": [
                "Controller area network (CAN)",
                "CAN topology",
                "diagnostic communication",
                "electronic control unit (ECU) function",
                "vehicle security"
            ]
        }
    },
    {
        "Title": "Discrimination Bias Detection Through Categorical Association in Pre-Trained Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10719988/",
        "Abstract": "The analysis of the presence of bias, prejudices and unwanted discriminatory behavior in pre-trained neural language models (NLMs), considering the sensitivity of the topic and its public interest, should respect two main criteria: the intuition and the statistical rigor. To the state of the art, there are two main categories of approaches for analyzing bias: those based on the models’ textual output, and those based on the geometric space of the embedded representations calculated by the NLMs. While the first one is intuitive, this kind of analysis is often conducted on simple template sentences, which limit the overall validity of their conclusions in a real-world context. On the contrary, geometric methods are more rigorous but quite more complex to implement and understand for those who are non-experts in Natural Language Processing (NLP). In this paper, we propose a unique method for analyzing bias in pre-trained language models that combines these two aspects. Through a simple classification task, we verify whether the information contained in the embedded representation of words that describes a protected property (such as the religion) can be used to identify a stereotyped property (such as the criminal behavior), requiring only a minimal supervised dataset. We experimentally verify our approach, finding that four widespread Transformer-based models are affected by prejudices of gender, nationality, and religion.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3482010",
            "Date of Publication": "16 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Michele Dusi",
                "labs": [
                    "Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Brescia, Italy"
                ]
            },
            {
                "name": "Nicola Arici",
                "labs": [
                    "Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Brescia, Italy"
                ]
            },
            {
                "name": "Alfonso Emilio Gerevini",
                "labs": [
                    "Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Brescia, Italy"
                ]
            },
            {
                "name": "Luca Putelli",
                "labs": [
                    "Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Brescia, Italy"
                ]
            },
            {
                "name": "Ivan Serina",
                "labs": [
                    "Dipartimento di Ingegneria dell’Informazione, Università degli Studi di Brescia, Brescia, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Context modeling",
                "Transformers",
                "Training",
                "Remuneration",
                "Encoding",
                "Correlation",
                "Bidirectional control",
                "Terrorism",
                "Syntactics",
                "Natural language processing",
                "Information integrity",
                "Large language models"
            ],
            "Author Keywords": [
                "Natural language processing",
                "AI fairness",
                "bias detection",
                "ethics of AI",
                "language models",
                "contextual word embedding"
            ]
        }
    },
    {
        "Title": "Arabic Paraphrase Generation Using Transformer-Based Approaches",
        "Link": "https://ieeexplore.ieee.org/document/10654278/",
        "Abstract": "Paraphrasing, a ubiquitous linguistic practice involving the rephrasing of sentences while preserving their underlying meaning, holds substantial significance across various Natural Language Processing (NLP) applications. This research focuses on the domain of Arabic Paraphrase Generation, aiming to introduce an innovative model capable of generating diverse Arabic paraphrases through experimentation with deep learning model. The proposed model extends beyond conventional baseline approaches, incorporating Transformer-based architectures and ChatGPT models to enhance the richness and variety of generated paraphrases. One notable challenge addressed in this study is the absence of an Arabic parallel paraphrased dataset. Recognizing this gap in existing resources, we propose the creation of an expanded paraphrase corpus, leveraging synthetic artificial data to bolster the paraphrasing generation process. This strategic augmentation aims to not only fill a critical void in the available datasets but also to provide a robust foundation for training and evaluating the performance of the paraphrase generation model. In the experimental phase, various models, including the baseline architecture, and Transformer-based models, are examined to assess their effectiveness in generating meaningful Arabic paraphrases. The results of automatic evaluation reveal that our Fine-tuned GPT-3.5 model surpasses state-of-the-art methods, achieving remarkable scores of 23.69%, 88.30%, and 91.89% in BLEU, BERTScore, and COMET evaluations, respectively. Additionally, the Fine-tuning AraT5v1 model shows around a 2.4% improvement in the BLEU score. Moreover, for human evaluation, Cohen kappa achieved 0.9. These findings highlight the potential of Transformer-based approaches in advancing Arabic Paraphrase Generation and affirm the effectiveness of our proposed model in elevating the quality and diversity of generated paraphrases.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3450931",
            "Date of Publication": "28 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Noora Aref Al-Shameri",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Hend S. Al-Khalifa",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, King Saud University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Transformers",
                "Linguistics",
                "Training",
                "Syntactics",
                "Standards",
                "Chatbots",
                "Encoding",
                "Decoding",
                "Machine translation"
            ],
            "Author Keywords": [
                "Paraphrase generation",
                "ChatGPT",
                "transformers",
                "encoder decoder",
                "modern standard arabic",
                "machine translation",
                "deep learning",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "Automatic Microblog-Oriented Unknown Word Recognition with Unsupervised Method",
        "Link": "https://ieeexplore.ieee.org/document/10855710/",
        "Abstract": "As a prerequisite task in Natural language processing (NLP), Chinese word segmentation (CWS), is challenged by unknown words. Aiming to effectively detect Chinese unknown words, especially the low-frequency unknown words in unstructured microblog data, we modify the usage of Accessor variety (AV) to measure the context environments of core fragments and propose a novel variable, the Independence of strings, which is derived from the internal structure of segments. Our approach is unsupervised without using any manual materials. Due to the lack of manual resources of microblog-oriented unknown words extraction, we use sampling approach to assess the effectiveness of our method. Experimental results suggest our best system beats the baseline system as well as the state-of-the-art system by a significant improvement in F1-measure and the recall of low-frequency unknown words.",
        "Details": {
            "DOI": "10.1049/cje.2017.11.004",
            "Date of Publication": "January 2018",
            "Publisher": "CIE",
            "Published In": "Chinese Journal of Electronics"
        },
        "issn_info": {
            "Electronic ISSN": "2075-5597",
            "Print ISSN": "1022-4653"
        },
        "authors_data": [
            {
                "name": "Degen Huang",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Jing Zhang",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            },
            {
                "name": "Kaiyu Huang",
                "labs": [
                    "School of Computer Science and Technology, Dalian University of Technology, Dalian, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Blogs",
                "Manuals",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Low-frequency unknown words",
                "Information entropy",
                "Independence of strings",
                "Modified usage of Accessor variety (AV)"
            ]
        }
    },
    {
        "Title": "Efficient Estimate of Sentence's Representation Based on the Difference Semantics Model",
        "Link": "https://ieeexplore.ieee.org/document/9594674/",
        "Abstract": "Sentence representation is an important research hotspot in natural language processing (NLP) since it can map the semantics of sentences into semantics vectors, thereby effectively solving complex semantics computing problems. Recently, sentence representations are mainly obtained by indirect means. Specifically, for sentence representations obtained by unsupervised means, they are often calculated by the weighted sum of embeddings of tokens in sentences; for sentence representations obtained by self-supervised or supervised means, they are often derived from intermediate encodings of sentences in prediction tasks. For example, Google's BERT and MUSE respectively use the embedding of [CLS] in the next sentence prediction task and intermediate encodings of sentences in the translation bridge task as sentence representations. In this paper, we use the observed semantics increment feature of sentences to directly model the semantics function of sentences. To be able to use the existing neural network language model to approximate the semantics function, we first implement the first-order Taylor expansion on the semantics function to obtain a difference semantics model and then add it to BERT as a subtask to perform self-supervised fine-tuning. Finally, we get a new sentence representation model S-BERT. S-BERT achieves the state-of-the-art performance on many datasets in Chinese, English, and Vietnamese.",
        "Details": {
            "DOI": "10.1109/TASLP.2021.3123885",
            "Date of Publication": "29 October 2021",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
        },
        "issn_info": {
            "Print ISSN": "2329-9290",
            "Electronic ISSN": "2329-9304"
        },
        "authors_data": [
            {
                "name": "Xianwen Liao",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            },
            {
                "name": "Yongzhong Huang",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            },
            {
                "name": "Yongzhuang Wei",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            },
            {
                "name": "Chenhao Zhang",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            },
            {
                "name": "Fu Wang",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            },
            {
                "name": "Yong Wang",
                "labs": [
                    "Guilin University of Electronic Technology, Guilin City, Guangxi Province, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Task analysis",
                "Bit error rate",
                "Analytical models",
                "Context modeling",
                "Encoding",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Sentence representation",
                "difference semantics model",
                "BERT"
            ]
        }
    },
    {
        "Title": "Natural Language Processing and Machine Learning for Analysis of Radiology Reports: A Systematic Review",
        "Link": "https://ieeexplore.ieee.org/document/11050386/",
        "Abstract": "Radiology reports, as a means of inter-physician and physician-to-patient communication, contain key findings and interpretations from imaging studies that guide diagnosis and treatment. Recent advancements in Artificial Intelligence (AI) technologies and the growing volume of clinical data necessitate efficient approaches for effective data utilisation. Integrating AI technologies can improve data analysis, enhance diagnostic accuracy, and streamline clinical workflows, reducing the burden on physicians. This Systematic Literature Review (SLR) examines the state-of-the-art of Natural Language Processing (NLP) and Machine Learning (ML) techniques, reviewing their diverse applications in radiology report processing, with a focus on automated disease diagnosis. We explored the commonly used approaches and their impact on diagnostic accuracy. We also looked into the availability of publicly accessible datasets that can be used for ML research within the radiology domain. Despite the promising advancements, challenges remain, such as data quality issues, interpretability of models and integrations of these technologies into clinical workflows. This review provides a thorough overview of the current research in this field by analysing existing findings and highlighting areas of improvement. The goal is to provide insights that can inform future studies in report analysis and improve the use of AI techniques in radiology.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3582728",
            "Date of Publication": "25 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Umay Kulsoom",
                "labs": [
                    "School of Computer Science, University of Galway, Galway, Ireland",
                    "ADAPT Research Centre, School of Computer Science, University of Galway, Galway, Ireland"
                ]
            },
            {
                "name": "Frank G. Glavin",
                "labs": [
                    "School of Computer Science, University of Galway, Galway, Ireland"
                ]
            },
            {
                "name": "Malika Bendechache",
                "labs": [
                    "School of Computer Science, University of Galway, Galway, Ireland"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Radiology",
                "Natural language processing",
                "Systematic literature review",
                "Imaging",
                "Medical services",
                "Databases",
                "Libraries",
                "Accuracy",
                "Diagnostic radiography",
                "Data models"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "deep learning",
                "machine learning",
                "multimodal",
                "natural language processing",
                "radiology reports",
                "systematic review"
            ]
        }
    },
    {
        "Title": "Task-Agnostic Adaptive Activation Scaling Network for LLMs",
        "Link": "https://ieeexplore.ieee.org/document/10890995/",
        "Abstract": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP), offering unprecedented capabilities for understanding and generating human-like texts. However, the effectiveness of these models in specific domains often requires fine-tuning, which can be computationally expensive and increases the risk of overfitting. To address these challenges, we introduce Task-Agnostic Adaptive Activation Scaling Network (TAAS-Net), a novel multi-task learning model architecture designed to adapt pre-trained LLMs to new tasks with minimal computational and storage overhead. TAAS-Net leverages an adaptive activation scaling network to enhance parameter efficiency and prevent overfitting, thereby improving model generalization. It incorporates a task-agnostic adaptive activation scaling layer that introduces task-specific, learnable activation scaling vectors, enhancing the model’s adaptability across various tasks. In addition, Low-Rank Adaptation within the attention modules facilitates the transfer of knowledge across different tasks. TAAS-Net’s integration of multi-task learning and parameter-efficient fine-tuning schemes enables efficient fine-tuning in multi-task scenarios, with a reduced parameter count compared to existing methods such as MoE-LoRA and X-LoRA. Our model also handles mixed-task batches during inference, thereby enhancing versatility and operational efficiency. Through a series of experiments on benchmark datasets, including the General Language Understanding Evaluation (GLUE), IMDB, and Agnews, TAAS-Net demonstrated superior performance over existing baselines, underscoring its potential for applications requiring rapid deployment and high accuracy. The architectural design of TAAS-Net streamlines the model adaptation process and reduces resource demands, offering a scalable and resource-efficient solution for adapting LLMs to new tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3542415",
            "Date of Publication": "14 February 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ni Jia",
                "labs": [
                    "Beijing Academy of Science and Technology, Beijing, China",
                    "Beijing Key Laboratory of Traffic Data Mining and Embodied Intelligence, Beijing, China"
                ]
            },
            {
                "name": "Tong Liu",
                "labs": [
                    "Beijing Academy of Science and Technology, Beijing, China",
                    "Beijing Key Laboratory of Traffic Data Mining and Embodied Intelligence, Beijing, China"
                ]
            },
            {
                "name": "Jiadi Chen",
                "labs": [
                    "Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China"
                ]
            },
            {
                "name": "Ying Zhang",
                "labs": [
                    "Beijing Academy of Science and Technology, Beijing, China",
                    "Beijing Key Laboratory of Traffic Data Mining and Embodied Intelligence, Beijing, China"
                ]
            },
            {
                "name": "Song Han",
                "labs": [
                    "Beijing Academy of Science and Technology, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Adaptation models",
                "Computational modeling",
                "Adaptive systems",
                "Multitasking",
                "Training",
                "Vectors",
                "Transformers",
                "Data models",
                "Large language models",
                "Knowledge engineering"
            ],
            "Author Keywords": [
                "Large language models",
                "low-rank adaptation",
                "multi-task learning",
                "parameter-efficient fine-tuning",
                "task-agnostic adaptive activation scaling"
            ]
        }
    },
    {
        "Title": "A Novel Data Augmentation Framework for Arabic Multi-Label Text Classification Using AraBART, AraGPT2, and Borderline-SMOTE",
        "Link": "https://ieeexplore.ieee.org/document/11162525/",
        "Abstract": "Data Augmentation (DA) techniques present solutions for Natural Language Processing (NLP) to address class imbalance and data scarcity. The current solutions for class imbalance, either random oversampling or random undersampling techniques, suffer from several issues. For instance, oversampling leads to overfitting due to replication, whilst under-sampling leads to loss of information due to removals. Meanwhile, traditional DA techniques, including paraphrasing, rule-based, or noising approaches, require strong lexicons. These techniques are also either time-consuming or introduce noise, resulting in incorrect syntactical and semantic contexts. Hence, this paper aims to propose a novel DA framework for Arabic news articles to address the prevailing challenges in Arabic Multi-Label Text Classification (AMLTC). The proposed framework consists of three phases: abstractive summarization using the Arabic Bidirectional and Auto-Regressive Transformer (AraBART) model to introduce new features, data generation with Arabic Generative Pre-trained Transformer (AraGPT2) to create diverse and contextual texts, and data balancing using borderline Synthetic Minority Over-Sampling Technique (BorderlineSMOTE) to achieve an optimal balance. Each phase was evaluated to ensure the quality of the augmented data. Furthermore, a Bidirectional Long Short-Term Memory (BiLSTM) model was used to assess the performance of the augmented dataset (augDS) on a multi-label Arabic RTN news dataset. The results demonstrated that the proposed framework effectively addressed the class imbalance problem by preserving data integrity and significantly improving Multi-Label Text Classification (MLTC) performance compared to the non-augDS, as confirmed by independent and paired t-tests. Specifically, the F1-score increased from 0.54 on the original dataset to 0.90 after augmentation. Overall, this study demonstrates that the proposed framework successfully addresses the issues in Arabic datasets by generating diverse, novel augmented data. Additionally, it enhanced MLTC performance, showcasing its effectiveness.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3609462",
            "Date of Publication": "12 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Samia F. Abdhood",
                "labs": [
                    "Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia",
                    "Faculty of Computers and Information Technology, Hadhramout University, Al Mukalla, Yemen"
                ]
            },
            {
                "name": "Nazlia Omar",
                "labs": [
                    "Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia"
                ]
            },
            {
                "name": "Sabrina Tiun",
                "labs": [
                    "Center for Artificial Intelligence Technology, Faculty of Information Science and Technology, Universiti Kebangsaan Malaysia, Bangi, Selangor, Malaysia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Text categorization",
                "Semantics",
                "Data augmentation",
                "Vectors",
                "Context modeling",
                "Filtration",
                "Diversity reception",
                "Data collection",
                "Bidirectional long short term memory",
                "Translation"
            ],
            "Author Keywords": [
                "AraBART",
                "AraGPT2",
                "class imbalance",
                "data augmentation",
                "multi-label text classification",
                "abstractive summarization"
            ]
        }
    },
    {
        "Title": "Distance Matters: Euclidean Embedding Distances for Improved Language Model Generalization and Adaptability",
        "Link": "https://ieeexplore.ieee.org/document/10613752/",
        "Abstract": "Large language models (LLMs) have revolutionized natural language processing (NLP), enabling machines to process, understand and generate human-like text with high accuracy. However, the current practices in training and evaluating these models often overlook the relationship between the embeddings of training and testing samples, leading to potential overfitting and limited generalization capabilities. This paper introduces a new approach to enhancing the performance, reliability, and generalization of LLMs by curating training and testing samples based on the Euclidean distances between their embeddings. The central hypothesis is that training models on samples with high Euclidean distances between training and testing embeddings, coupled with evaluations spanning diverse distances, will improve the models’ robustness and adaptability to inputs diverging from the training data distribution. The comprehensive evaluation across multiple datasets and architectures shows that models trained on samples with high Euclidean distances from the testing samples generally exhibit superior generalization and robustness compared to those trained on low-distance samples. The proposed evaluation methodology, assessing performance across a range of distances, provides a more reliable measure of a model’s true adaptability. This study provides insights into the relationship between training data diversity and model reliability, paving the way for more robust and generalizable LLMs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3434612",
            "Date of Publication": "29 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sultan Alshamrani",
                "labs": [
                    "Department of Computer Science, Saudi Electronic University, Riyadh, Saudi Arabia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Data models",
                "Adaptation models",
                "Analytical models",
                "Task analysis",
                "Reliability",
                "Euclidean distance"
            ],
            "Author Keywords": [
                "Language models",
                "natural language processing",
                "embeddings",
                "model generalization",
                "model robustness",
                "model performance",
                "data diversity",
                "evaluation",
                "data curation"
            ]
        }
    },
    {
        "Title": "A Novel Backdoor Detection Approach Using Entropy-Based Measures",
        "Link": "https://ieeexplore.ieee.org/document/10637438/",
        "Abstract": "Amidst the recent technological breakthroughs and increased integration of Artificial Intelligence (AI) technologies across various domains, it is imperative to consider the myriad security threats posed by AI. One of the significant attack vectors on AI models is the backdoor attack, which involves maliciously manipulating the model’s behaviour by inserting hidden patterns or triggers into training datasets. In this paper our primary focus is on the defenses for the backdoor attacks mounted via poisoned training datasets. While many backdoor defense mechanisms have been proposed in the context of text, image, and audio domains, a majority of these defense mechanisms focus on training a specific model to detect backdoor triggers. Our current work proposes a novel model agnostic backdoor detection approach that utilizes complexity/entropy-based measures. In this study, we demonstrate the limitations of currently existing entropy measures – Sample Entropy and Approximate Entropy in detecting backdoor triggers in poisoned datasets. Consequently, we propose a novel modification of the Manhattan metric in the Entropy calculation and incorporate it in the complexity measures. This modified approach is shown to successfully detect backdoor triggers in datasets from not only the Natural Language Processing (NLP) domain, but also from the Financial and Geological domains. The effectiveness of the proposed approach was further substantiated with the high F1 scores in the range of 0.92 to 1.00 across the datasets, and with zero false negatives for the real-world datasets from the Financial and the Geological domains.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3444273",
            "Date of Publication": "15 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hema Karnam Surendrababu",
                "labs": [
                    "The University of Trans-Disciplinary Health Sciences and Technology, Bengaluru, Karnataka, India",
                    "School of Conflict and Security Studies, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru, Karnataka, India"
                ]
            },
            {
                "name": "Nithin Nagaraj",
                "labs": [
                    "Consciousness Studies Programme, School of Humanities, National Institute of Advanced Studies, Indian Institute of Science Campus, Bengaluru, Karnataka, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Entropy",
                "Complexity theory",
                "Training",
                "Data models",
                "Computational modeling",
                "Vectors",
                "Time series analysis",
                "Artificial intelligence",
                "Detection algorithms",
                "Data integrity"
            ],
            "Author Keywords": [
                "Data poisoning",
                "backdoor attacks",
                "backdoor defenses",
                "approximate entropy",
                "sample entropy"
            ]
        }
    },
    {
        "Title": "Consumer Document Analytical Accelerator Hardware",
        "Link": "https://ieeexplore.ieee.org/document/10018187/",
        "Abstract": "Document scanning devices are used for visual character recognition, followed by text analytics in the software. Often such character extraction is insecure, and any third party can manipulate the information. On the other hand, near-edge processing devices are restrained by limited resources and connectivity issues. The primary factors that lead to exploring independent hardware devices with natural language processing (NLP) capabilities are latency during cloud processing and computing costs. This paper introduces a hardware accelerator for information retrieval using memristive TF-IDF implementation. In this system, each sentence is represented using a memristive crossbar layer, with each column containing a single word. The number of matching scores for the TF and IDF values was implemented using operational amplifier-based comparator accumulator circuits. The circuit is designed with a 180nm CMOS process, Knowm Multi-Stable Switch memristor model, and WOx device parameters. We compared its performance with that of a standard benchmark dataset. Variability and device-to-device related issues were also taken into consideration in the analysis. This paper concludes with implementing TF-IDF score calculation for applications such as information retrieval and text summarization.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3237463",
            "Date of Publication": "16 January 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aswani Radhakrishnan",
                "labs": [
                    "School of Electronic Systems and Automation, Kerala University of Digital Sciences Innovation and Technology (Digital University Kerala), Thiruvananthapuram, Kerala, India"
                ]
            },
            {
                "name": "Dibyasha Mahapatra",
                "labs": [
                    "School of Electronic Systems and Automation, Kerala University of Digital Sciences Innovation and Technology (Digital University Kerala), Thiruvananthapuram, Kerala, India"
                ]
            },
            {
                "name": "Alex James",
                "labs": [
                    "School of Electronic Systems and Automation, Kerala University of Digital Sciences Innovation and Technology (Digital University Kerala), Thiruvananthapuram, Kerala, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data mining",
                "Information retrieval",
                "Feature extraction",
                "Data models",
                "Analytical models",
                "Memristors",
                "Databases"
            ],
            "Author Keywords": [
                "Natural language processing",
                "TF-IDF",
                "hardware accelerator",
                "memristive systems",
                "memristor",
                "analog computation"
            ]
        }
    },
    {
        "Title": "Enhancing Keyword Search in Relational Databases With Word Embeddings",
        "Link": "https://ieeexplore.ieee.org/document/11016702/",
        "Abstract": "Keyword search in relational databases allows the users to query these databases using natural language keywords, bridging the gap between structured data and intuitive querying. However, ambiguity in user queries as well as the complexities of structured database relationships often complicate the retrieval of relevant results. This paper introduces Key2Vec as a framework for leveraging the Natural Language Processing (NLP) techniques, specifically Word2Vec embeddings, for enhancing the keyword search in relational databases. Key2Vec enhances both the query relevance and the execution efficiency by semantically interpreting the keywords and optimizing the query classes, those categories of user queries which are grouped by their specific objectives and their data requirements. Experimental evaluations, on benchmark databases, demonstrate that Key2Vec improves the accuracy about 25% and reduces the query processing time by 30%, establishing it as a robust solution.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574428",
            "Date of Publication": "28 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Fatemeh Khalifeh",
                "labs": [
                    "Computer Science and Engineering and Information Technology Department, Shiraz University, Shiraz, Iran"
                ]
            },
            {
                "name": "Mohammad Taheri",
                "labs": [
                    "Computer Science and Engineering and Information Technology Department, Shiraz University, Shiraz, Iran"
                ]
            },
            {
                "name": "Eghbal Mansoori",
                "labs": [
                    "Computer Science and Engineering and Information Technology Department, Shiraz University, Shiraz, Iran"
                ]
            },
            {
                "name": "Mostafa Fakhrahmad",
                "labs": [
                    "Computer Science and Engineering and Information Technology Department, Shiraz University, Shiraz, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Relational databases",
                "Semantics",
                "Natural language processing",
                "Keyword search",
                "Motion pictures",
                "Vectors",
                "Query processing",
                "Context modeling",
                "Accuracy",
                "Technological innovation"
            ],
            "Author Keywords": [
                "Relational databases",
                "keyword search",
                "word embedding",
                "Key2Vec",
                "effectiveness",
                "efficiency"
            ]
        }
    },
    {
        "Title": "BioBridge: Unified Bio-Embedding With Bridging Modality in Code-Switched EMR",
        "Link": "https://ieeexplore.ieee.org/document/10693433/",
        "Abstract": "Pediatric Emergency Department (PED) overcrowding presents a significant global challenge, prompting the need for efficient solutions. This paper introduces the BioBridge framework, a novel approach that applies Natural Language Processing (NLP) to Electronic Medical Records (EMRs) in written free-text form to enhance decision-making in PED. In non-English speaking countries, such as South Korea, EMR data is often written in a Code-Switching(CS) format that mixes the native language with English, with most code-switched English words having clinical significance. The BioBridge framework consists of two core modules: “bridging modality in context” and “unified bio-embedding.” The “bridging modality in context” module improves the contextual understanding of bilingual and code-switched EMRs. In the “unified bio-embedding” module, the knowledge of the model trained in the medical domain is injected into the encoder-based model to bridge the gap between the medical and general domains. Experimental results demonstrate that the proposed BioBridge significantly performance traditional machine learning and pre-trained encoder-based models on several metrics, including F1 score, area under the receiver operating characteristic curve (AUROC), area under the precision-recall Curve (AUPRC), and Brier score. Specifically, BioBridge-XLM achieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC, along with a notable 3.04% decrease in the Brier score, demonstrating marked improvements in accuracy, reliability, and prediction calibration over the baseline XLM model. The source code will be made publicly available at https://github.com/jjy961228/BioBridge.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3467251",
            "Date of Publication": "25 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Jangyeong Jeon",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Sangyeon Cho",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Dongjoon Lee",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Changhee Lee",
                "labs": [
                    "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Junyeong Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Natural language processing",
                "Feature extraction",
                "Biological system modeling",
                "Electronic medical records",
                "Training",
                "Encoding",
                "Unified modeling language",
                "Pediatrics",
                "Emergency services"
            ],
            "Author Keywords": [
                "Natural language processing",
                "code-switching",
                "electronic medical record",
                "emergency department",
                "pediatric emergency department"
            ]
        }
    },
    {
        "Title": "G-SQL: A Schema-Aware and Rule-Guided Approach for Robust Natural Language to SQL Translation",
        "Link": "https://ieeexplore.ieee.org/document/11153939/",
        "Abstract": "This paper introduces G-SQL, a schema-aware and rule-guided framework for translating Natural Language Queries (NLQ) into SQL, designed to support users with limited technical expertise. G-SQL bridges the limitations of traditional rule-based and deep learning approaches by combining JSON-based schema serialization with Natural Language Processing (NLP) tools, such as GloVe and Stanford CoreNLP. The system encodes database schemas—including tables, columns, keys, and relationships—into a structured JSON format, enabling efficient and interpretable mapping between query tokens and schema elements. SQL statements are generated using a guided template-driven strategy. Evaluated across three benchmark datasets (IMDB, Yelp, MAS), For easy queries, it achieved 100% execution accuracy on all three datasets. On medium queries, G-SQL reached 95% on IMDB, 85% on Yelp, and 90% on MAS. For hard queries, the accuracy was 78% on IMDB, 65% on Yelp, and 72% on MAS. Finally, on extra-hard queries, G-SQL achieved 55% on IMDB, 45% on Yelp, and 50% on MAS., demonstrating robust performance across varying query complexities.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3607879",
            "Date of Publication": "09 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hassan S. Shalaan",
                "labs": [
                    "Faculty of Computers and Information, Assiut University, Asyut, Egypt"
                ]
            },
            {
                "name": "Tayseer Hassan A. Soliman",
                "labs": [
                    "Faculty of Computers and Information, Assiut University, Asyut, Egypt"
                ]
            },
            {
                "name": "Amr M. AbdelAziz",
                "labs": [
                    "Faculty of Computers and Artificial Intelligence, Beni-Suef University, Beni Suef, Egypt"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Structured Query Language",
                "Semantics",
                "Natural languages",
                "Databases",
                "Deep learning",
                "Accuracy",
                "Translation",
                "Linguistics",
                "Adaptation models",
                "Syntactics"
            ],
            "Author Keywords": [
                "NL2SQL",
                "natural language interface (NLI)",
                "text to SQL",
                "NLIDB",
                "schema-aware translation",
                "semantic parsing",
                "database query generation"
            ]
        }
    },
    {
        "Title": "Optimal Control of Intelligent Vehicle Path Tracking",
        "Link": "https://ieeexplore.ieee.org/document/10947744/",
        "Abstract": "Path tracking control is a core technology of intelligent vehicles, and the accuracy of tracking performance is a key element of this technology. In order to address the issue of low accuracy in traditional methods for solving intelligent vehicle path tracking problems, a fast and high-precision solution method was design. This method discretized the continuous optimal control problem at collocation points and approximated the state and control variables through global interpolation polynomials, thereby transforming the optimal control problem of intelligent vehicle path tracking into a nonlinear programming NLP problem for solution. Finally, the real vehicle test verified the effectiveness of the method. The simulation results and comparison with traditional methods show that this method can solve the intelligent vehicle path tracking problem with high accuracy and has good engineering application potential.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3557215",
            "Date of Publication": "02 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Enhao Wang",
                "labs": [
                    "Department of Engineering, Durham University, Durham, U.K."
                ]
            },
            {
                "name": "Yingjie Liu",
                "labs": [
                    "School of Machinery and Automation, Weifang University, Weifang, Shandong, China"
                ]
            },
            {
                "name": "Chenglian Xie",
                "labs": [
                    "Shandong Industrial Technician College, Weifang, Shandong, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory tracking",
                "Optimal control",
                "Accuracy",
                "Optimization",
                "Mathematical models",
                "Autonomous vehicles",
                "Adaptation models",
                "Vehicle dynamics",
                "Vectors",
                "Computational complexity"
            ],
            "Author Keywords": [
                "Vehicle dynamics",
                "trajectory tracking",
                "optimal control",
                "sparse finite difference"
            ]
        }
    },
    {
        "Title": "Enhancing Hajj and Umrah Services Through Predictive Social Media Classification",
        "Link": "https://ieeexplore.ieee.org/document/10960302/",
        "Abstract": "Each year, millions of individuals embark on the sacred journeys of Hajj and Umrah to Saudi Arabia. Given the diverse needs of these pilgrims and the continuous efforts to enhance their experience, we propose an advanced social media classification system based on predictive deep learning. The primary objective of this system is to efficiently classify and analyze social media content related to Hajj and Umrah services. To improve the effectiveness of this classification model, we introduce a predictive optimization strategy that employs a deep neural network as the learning module and utilizes particle swarm optimization to refine the weighting parameters. Leveraging real-time data from various microblogging platforms Twitter, blogging websites, Facebook, and Instagram, our model classifies individual posts using natural language processing techniques. The classification is based on relevant attributes such as service-level scores. If the dataset contains non-English text, it is first translated into English. Tokenization and preprocessing are then applied to categorize posts into five key areas: religious rites, management, safety, well-being, and services. The labeled posts are subsequently used to train a deep learning model. By incorporating a service-level score algorithm based on the TextBlob NLP library, each post is accurately classified and utilized as a feature in a supervised machine-learning classification system. The model’s performance is evaluated using standard metrics, including F-measure, Precision, and Recall. The ultimate objective is to achieve high-accuracy classification, enabling precise evaluation and improved analysis of social media content related to the pilgrimage experience.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3559204",
            "Date of Publication": "09 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Samia Allaoua Chelloug",
                "labs": [
                    "Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428 Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Mohammed Saleh Ali Muthanna",
                "labs": [
                    "Department of International Business Management, Tashkent State University of Economics, Tashkent, Uzbekistan"
                ]
            },
            {
                "name": "Faisal Jamil",
                "labs": [
                    "School of Computing, Engineering and Intelligent Systems, Ulster University, Londonderry, U.K."
                ]
            },
            {
                "name": "Mehdhar S. A. M. Al-Gaashani",
                "labs": [
                    "School of Resources and Environment, University of Electronic Science and Technology of China, Chengdu, Sichuan, China"
                ]
            },
            {
                "name": "Soha Alhelaly",
                "labs": [
                    "College of Computing and Informatics, Saudi Electronic University, Riyadh, Saudi Arabia"
                ]
            },
            {
                "name": "Ahmed Aziz",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Artificial Intelligence, Benha University, Benha, Egypt",
                    "Engineering School, Central Asian University, Tashkent, Uzbekistan"
                ]
            },
            {
                "name": "Ammar Muthanna",
                "labs": [
                    "Department of Applied Probability and Informatics, Peoples’ Friendship University of Russia (RUDN University), Moscow, Russia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Deep learning",
                "Real-time systems",
                "Natural language processing",
                "Blogs",
                "Accuracy",
                "Web sites",
                "Particle swarm optimization",
                "Optimization",
                "Multimedia communication"
            ],
            "Author Keywords": [
                "Hajj and Umrah management",
                "deep learning optimization",
                "social media classification",
                "predictive modelling",
                "sentiment analysis",
                "information sharing"
            ]
        }
    },
    {
        "Title": "GUniER: GPT-Enhanced Joint Extraction of Entities and Relations Through Integrated Deep Bidirectional Semantics and Unified Modeling",
        "Link": "https://ieeexplore.ieee.org/document/10781386/",
        "Abstract": "Entity and relation extraction are key tasks in natural language processing (NLP) and knowledge graph construction. However, existing methods often overlook the complex interactions between entities and their relations. To address this problem, we propose GUniER, which uses a GPT enhancement module and deep bidirectional semantics to optimize the extraction of entities and relations while significantly reducing computational cost. Specifically, the GPT module unifies relation labels with sentence representations, while the BiGRU model captures deep bidirectional semantics to improve the model’s ability to handle complex relations and long-distance dependencies. Additionally, we introduce a two-dimensional interaction table to better model entity-relation interactions, and a cross-entropy loss function to address class imbalance. Experimental results on both open domain and domain-specific datasets show that GUniER achieves a notable improvement in accuracy and reduces computational time compared to state-of-the-art models. Specifically, GUniER achieved a 2.1% improvement in F1 score on the CNShipNet dataset and demonstrated reduced training and inference times compared to previous models, showcasing its efficiency. Our code and models are available at https://anonymous.4open.science/r/UniER.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3512553",
            "Date of Publication": "09 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dongsheng Wang",
                "labs": [
                    "School of Computer, Jiangsu University of Science and Technology, Zhenjiang, Jiangsu, China"
                ]
            },
            {
                "name": "Liming Wang",
                "labs": [
                    "School of Computer, Jiangsu University of Science and Technology, Zhenjiang, Jiangsu, China"
                ]
            },
            {
                "name": "Kun Tang",
                "labs": [
                    "School of Computer, Jiangsu University of Science and Technology, Zhenjiang, Jiangsu, China"
                ]
            },
            {
                "name": "Qile Bo",
                "labs": [
                    "School of Computer, Jiangsu University of Science and Technology, Zhenjiang, Jiangsu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Semantics",
                "Context modeling",
                "Bidirectional control",
                "Encoding",
                "Accuracy",
                "Computational modeling",
                "Computational efficiency",
                "Noise",
                "Biological system modeling"
            ],
            "Author Keywords": [
                "Entity recognition",
                "relation extraction",
                "knowledge graph",
                "joint extraction",
                "unified modeling"
            ]
        }
    },
    {
        "Title": "CoMSeC: A Comparative Analysis of Various Service Classification Techniques",
        "Link": "https://ieeexplore.ieee.org/document/10807280/",
        "Abstract": "The rapid advancement of Artificial Intelligence (AI) and Machine Learning (ML) has significantly impacted Web Service Classification, a critical task for service discovery, composition, and selection in various applications. Effective service classification improves security, scalability, cost-effectiveness, and other crucial parameters for service selection in specific applications. This paper aims to formulate a novel classification model and conduct a comparative study to analyze the performance of base models with various classical and modern clustering algorithms. We propose a unique approach based on natural language processing (NLP) combining Word2Vec and BERT models to generate high-dimensional embeddings from the service dataset. These embeddings are further processed using Dense Layers for dimensionality reduction and then used as inputs to different clustering algorithms. The results demonstrate that our approach significantly improves the accuracy and efficiency of classification, providing a comprehensive overview of performance across various combinations and highlighting the advantages of our method.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3520341",
            "Date of Publication": "19 December 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Malabika Das",
                "labs": [
                    "School of Computer Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Ansh Sarkar",
                "labs": [
                    "School of Computer Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, Odisha, India"
                ]
            },
            {
                "name": "Sujata Swain",
                "labs": [
                    "School of Computer Engineering, Kalinga Institute of Industrial Technology, Bhubaneswar, Odisha, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Encoding",
                "Bidirectional control",
                "Accuracy",
                "Training",
                "Semantics",
                "Natural language processing",
                "Context modeling",
                "Classification algorithms",
                "Vectors"
            ],
            "Author Keywords": [
                "Service",
                "classification",
                "natural language processing",
                "Word2Vec",
                "BERT",
                "transformers"
            ]
        }
    },
    {
        "Title": "An Eclectic Approach for Enhancing Language Models Through Rich Embedding Features",
        "Link": "https://ieeexplore.ieee.org/document/10584535/",
        "Abstract": "Text processing is a fundamental aspect of Natural Language Processing (NLP) and is crucial for various applications in fields such as artificial intelligence, data science, and information retrieval. It plays a core role in language models. Most text-processing approaches focus on describing and synthesizing, to a greater or lesser degree, lexical, syntactic, and semantic properties of text in the form of numerical vectors that induce a metric space, in which, it is possible to find underlying patterns and structures related to the original text. Since each approach has strengths and weaknesses, finding a single approach that perfectly extracts representative text properties for every task and application domain is hard. This paper proposes a novel approach capable of synthesizing information from heterogeneous state-of-the-art text processing approaches into a unified representation. Encouraging results demonstrate that using this representation in popular machine-learning tasks not only leads to superior performance but also offers notable advantages in memory efficiency and preservation of underlying information of the distinct sources involved in such a representation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3422971",
            "Date of Publication": "04 July 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Edwin Aldana-Bobadilla",
                "labs": [
                    "CONAHCYT, Mexico City, Mexico",
                    "Cinvestav, Unidad Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico"
                ]
            },
            {
                "name": "Victor Jesus Sosa-Sosa",
                "labs": [
                    "Cinvestav, Unidad Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico"
                ]
            },
            {
                "name": "Alejandro Molina-Villegas",
                "labs": [
                    "CONAHCYT, Mexico City, Mexico",
                    "Centro de Investigación en Ciencias de Investigación Geoespacial, Mexico City, Mexico"
                ]
            },
            {
                "name": "Karina Gazca-Hernandez",
                "labs": [
                    "Cinvestav, Unidad Tamaulipas, Ciudad Victoria, Tamaulipas, Mexico"
                ]
            },
            {
                "name": "Jose Angel Olivas",
                "labs": [
                    "Grupo SMILe, Universidad de Castilla-La Mancha, Ciudad Real, Spain"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Feature extraction",
                "Task analysis",
                "Semantics",
                "Transformers",
                "Neurons",
                "Linguistics",
                "Self-organizing feature maps",
                "Natural language processing",
                "Text analysis"
            ],
            "Author Keywords": [
                "Self-organizing map",
                "word embeddings",
                "feature extraction",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "ScaleNet: Scalable and Hybrid Framework for Cyber Threat Situational Awareness Based on DNS, URL, and Email Data Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11058301/",
        "Abstract": "A computer virus or malware is a computer program, but with the purpose of causing harm to the system. This year has witnessed the rise of malware and the loss caused by them is high. Cyber criminals have continually advancing their methods of attack. The existing methodologies to detect the existence of such malicious programs and to prevent them from executing are static, dynamic and hybrid analysis. These approaches are adopted by anti-malware products. The conventional methods of were only efficient till a certain extent. They are incompetent in labeling the malware because of the time taken to reverse engineer the malware to generate a signature. When the signature becomes available, there is a high chance that a significant amount of damage might have occurred. However, there is a chance of detecting the malicious activities quickly by analyzing the events of DNS logs, Emails, and URLs. As these unstructured raw data contains rich source of information, we explore how the large volume of data can be leveraged to create cyber intelligent situational awareness to mitigate advanced cyber threats. Deep learning is a machine learning technique largely used by researchers in recent days. It avoids feature engineering which served as a critical step for conventional machine learning algorithms. It can be used along with the existing automation methods such as rule and heuristics based and machine learning techniques. This work takes the advantage of deep learning architectures to classify and correlate malicious activities that are perceived from the various sources such as DNS, Email, and URLs. Unlike conventional machine learning approaches, deep learning architectures don't follow any feature engineering and feature representation methods. They can extract optimal features by themselves. Still, additional domain level features can be defined for deep learning methods in NLP tasks to enhance the performance. The cyber security events considered in this study are surrounded by texts. To convert text to real valued vectors, various natural language processing and text mining methods are incorporated. To our knowledge, this is the first attempt, a framework that can analyze and correlate the events of DNS, Email, and URLs at scale to provide situational awareness against malicious activities. The developed framework is highly scalable and capable of detecting the malicious activities in near real time. Moreover, the framework can be easily extended to handle large volume of other cyber security events by adding additional resources. These characteristics have made the proposed framework stand out from any other system of similar kind.\nShow Less",
        "Details": {
            "DOI": "10.13052/jcsm2245-1439.823",
            "Date of Publication": "May 2019",
            "Publisher": "River Publishers",
            "Published In": "Journal of Cyber Security and Mobility"
        },
        "issn_info": {
            "Electronic ISSN": "2245-4578",
            "Print ISSN": "2245-1439"
        },
        "authors_data": [
            {
                "name": "R. Vinayakumar",
                "labs": [
                    "Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, India"
                ]
            },
            {
                "name": "K. P. Soman",
                "labs": [
                    "Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, India"
                ]
            },
            {
                "name": "Prabaharan Poornachandran",
                "labs": [
                    "Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, India"
                ]
            },
            {
                "name": "Vysakh S. Mohan",
                "labs": [
                    "Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, India"
                ]
            },
            {
                "name": "Amara Dinesh Kumar",
                "labs": [
                    "Center for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Uniform resource locators",
                "Text mining",
                "Deep learning",
                "Machine learning algorithms",
                "Unsolicited e-mail",
                "Semantics",
                "Feature extraction",
                "Natural language processing",
                "Vectors",
                "Computer crime"
            ],
            "Author Keywords": [
                "cyber security",
                "natural language processing",
                "text mining",
                "machine learning",
                "neural networks",
                "deep learning",
                "big data",
                "cognitive security",
                "distributed and semantic word representation",
                "domain generation algorithms",
                "uniform resource locator",
                "spam",
                "ransomware"
            ]
        }
    },
    {
        "Title": "Partially-Supervised Metric Learning via Dimensionality Reduction of Text Embeddings Using Transformer Encoders and Attention Mechanisms",
        "Link": "https://ieeexplore.ieee.org/document/10536728/",
        "Abstract": "Real-world applications of word embeddings to downstream clustering tasks may experience limitations to performance, due to the high degree of dimensionality of the embeddings. In particular, clustering algorithms do not scale well when applied to highly dimensional data. One method to address this is through the use of dimensionality reduction algorithms (DRA). Current state of the art algorithms for dimensionality reduction (DR) have been demonstrated to contribute to improvements in clustering accuracy and performance. However, the impact that a neural network architecture can have on the current state of the art Parametric Uniform Manifold Approximation and Projection (UMAP) algorithm is yet unexplored. This work investigates, for the first time, the effects of using attention mechanisms in neural networks for Parametric UMAP, through the application of network architectures that have had considerable effect upon the wider machine learning and natural language processing (NLP) fields - namely, the transformer-encoder, and the bidirectional recurrent neural network. We implement these architectures within a semi-supervised metric learning pipeline, with results demonstrating an improvement in the clustering accuracy, compared to conventional DRA techniques, on three out of four datasets, and comparable SoA accuracy on the fourth. To further support our analysis, we also investigate the effects of the transformer-encoder metric-learning pipeline upon the individual class accuracy of downstream clustering, for highly imbalanced datasets. Our analyses indicate that the proposed pipeline with transformer-encoder for parametric UMAP confers a significantly measurable benefit to the accuracy of underrepresented classes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3403991",
            "Date of Publication": "22 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ryan Hodgson",
                "labs": [
                    "Department of Computer Science, Durham University, Durham, U.K."
                ]
            },
            {
                "name": "Jingyun Wang",
                "labs": [
                    "Department of Computer Science, Durham University, Durham, U.K."
                ]
            },
            {
                "name": "Alexandra I. Cristea",
                "labs": [
                    "Department of Computer Science, Durham University, Durham, U.K."
                ]
            },
            {
                "name": "John Graham",
                "labs": [
                    "Reveela Technologies, Newcastle upon Tyne, U.K."
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Dimensionality reduction",
                "Task analysis",
                "Clustering algorithms",
                "Neural networks",
                "Transformers",
                "Measurement",
                "Dimensionality reduction",
                "Supervised learning"
            ],
            "Author Keywords": [
                "Dimensionality reduction",
                "attention mechanisms",
                "clustering",
                "transformer networks",
                "metric learning"
            ]
        }
    },
    {
        "Title": "Automated Cricket Analytics for Player Classification and Commentary Generation",
        "Link": "https://ieeexplore.ieee.org/document/11123473/",
        "Abstract": "Cricket is one of the most popular sports around the world, and there is an increasing demand for intelligent commentary generation and real-time analytics. In this paper, we propose a system called Automated Cricket Analytics for Player Classification and Commentary Generation that uses computer vision and deep learning to analyze cricket match footage using a pre-trained VGG16 model to generate visual features from extracted frames of video input, which are then processed by a bidirectional LSTM-based neural network to generate descriptive commentary. In addition, a custom object detection model is deployed via the Roboflow API that detects which player is doing what (i.e. whether they are a bowler or a batsman) in each frame. The generated textual commentary is further refined using transformer-based NLP pipelines for summarization and grammatical correction prior to text-to-speech synthesis (gTTS). The experimental results show that the model can correctly recognize the role of each player and provide a suitable commentary with high BLEU scores (BLEU-1: 0.877; BLEU-2: 0.818; BLEU-3: 0.798; BLEU-4: 0.712). The average confidence score for the player classification and detection module was over 90%, showing that this system can recognize players correctly in all match frames. This system could be used to create highlights, automate sports broadcasting, or even allow fans to interact with a game.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3598037",
            "Date of Publication": "12 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rithvik Pabbati",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "Bijjula Sai Srujan Reddy",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            },
            {
                "name": "K. Karthik",
                "labs": [
                    "School of Computer Science and Engineering, Vellore Institute of Technology, Vellore, Tamil Nadu, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sports",
                "Videos",
                "Real-time systems",
                "Games",
                "Feature extraction",
                "Automation",
                "Computational modeling",
                "Broadcasting",
                "Transformers",
                "Pipelines"
            ],
            "Author Keywords": [
                "Action recognition",
                "automated sports commentary",
                "BiLSTM",
                "deep learning",
                "convolutional neural network",
                "image captioning",
                "player identification",
                "VGG16"
            ]
        }
    },
    {
        "Title": "Japanese Short Answer Grading for Japanese Language Learners Using the Contextual Representation of BERT",
        "Link": "https://ieeexplore.ieee.org/document/10849551/",
        "Abstract": "The automatization of grading short answers in examinations aims to help teachers grade more efficiently and fairly. The Japanese SIMPLE-O attempts to grade Japanese language learners’ short answers using a dataset from a real examination. Bidirectional encoder representations from transformer (BERT), which has shown potential for natural language processing (NLP) tasks, is implemented to grade answers without fine-tuning due to the small amount of data. Two experiments are conducted in this study. The first experiment attempts to grade based on similarities, while the second classifies the answers as either correct or incorrect. Five BERT models are tested in the system, and two additional sentence BERT (SBERT) and RoBERTa models are tested for the similarity problem. The best Pearson’s correlation for grading with similarities is obtained with the Tohoku BERT Base. The use of hiragana-kanji conversion improves the correlation to 0.615 for BERT and 0.593 for SBERT but does not show much improvement for RoBERTa. In the binary classification experiments, all models have an accuracy above 90%, with Tohoku BERT Large having the best performance. Even without fine-tuning, BERT can be used as an embedding method to perform binary classification with high accuracy.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3532659",
            "Date of Publication": "22 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dyah Lalita Luhurkinanti",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering, Universitas Indonesia, Depok, Indonesia"
                ]
            },
            {
                "name": "Prima Dewi Purnamasari",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering, Universitas Indonesia, Depok, Indonesia"
                ]
            },
            {
                "name": "Takashi Tsunakawa",
                "labs": [
                    "Faculty of Informatics, Shizuoka University, Shizuoka, Japan"
                ]
            },
            {
                "name": "Anak Agung Putri Ratna",
                "labs": [
                    "Department of Electrical Engineering, Faculty of Engineering, Universitas Indonesia, Depok, Indonesia"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Encoding",
                "Bidirectional control",
                "Transformers",
                "Semantics",
                "Reviews",
                "Natural language processing",
                "Deep learning",
                "Vectors",
                "Training",
                "Feature extraction"
            ],
            "Author Keywords": [
                "Automated short answer grading",
                "BERT",
                "SBERT",
                "deep learning",
                "contextual embeddings"
            ]
        }
    },
    {
        "Title": "A Comprehensive Survey on LLM-Powered Recommender Systems: From Discriminative, Generative to Multi-Modal Paradigms",
        "Link": "https://ieeexplore.ieee.org/document/11129085/",
        "Abstract": "Large Language Models (LLMs) have become transformative tools in Natural Language Processing (NLP). They are increasingly being integrated into recommendation systems to address existing limitations such as data sparsity, novelty, cold start, and long-tail challenges. Unlike traditional recommendation techniques that rely on user-item interaction matrices, LLMs provide context-aware reasoning and multi-modal processing capabilities. However, existing research mainly focuses on fine-tuning and prompt engineering strategies without fully exploring hybrid models, retrieval-augmented generation (RAG), graph-enhanced recommendations, and evaluation methodologies. This survey offers a comprehensive and structured examination of LLM-based recommendation systems, categorizing them into discriminative, generative, hybrid, graph-enhanced, and multimodal paradigms. Additionally, we explore adaptive fine-tuning techniques, prompt engineering strategies, and retrieval-augmented generation (RAG) approaches that improve LLM performance in personalized recommendations. We also examine evaluation methodologies, including LLM-as-a-Judge frameworks, benchmark limitations, and fairness considerations. Finally, we present a detailed discussion of open challenges, such as hallucination, scalability, bias, and privacy, highlighting critical research gaps and opportunities for future exploration. This survey aims to guide researchers in navigating the evolving landscape of LLM-driven recommendation systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3599832",
            "Date of Publication": "18 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dina Nawara",
                "labs": [
                    "Department of Electrical, Computer, and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            },
            {
                "name": "Rasha Kashef",
                "labs": [
                    "Department of Electrical, Computer, and Biomedical Engineering, Toronto Metropolitan University, Toronto, ON, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Recommender systems",
                "Surveys",
                "Accuracy",
                "Adaptation models",
                "Automobiles",
                "Real-time systems",
                "Motion pictures",
                "Filtering",
                "Electronic commerce",
                "Collaborative filtering"
            ],
            "Author Keywords": [
                "Large language models (LLMs)",
                "recommendation systems",
                "retrieval-augmented generation (RAG)",
                "discriminative learning",
                "multi-modal paradigms",
                "LLM-as-a-judge",
                "evaluation metrics"
            ]
        }
    },
    {
        "Title": "StegGPT: A Novel Foundation-Model-Based Character-Level Linguistic Steganography Method Utilizing Large Language Models",
        "Link": "https://ieeexplore.ieee.org/document/11008605/",
        "Abstract": "This study addresses the critical need for robust safeguarding of sensitive data stored on personal computing devices and during data transmissions, alongside the increasing need for secure digital interactions. Conventional methodologies for obfuscating data within textual covers exhibit inherent limitations and susceptibility to detection. The primary objective of this investigation is to devise an algorithm that not only ensures secure transmission of information, but also proficiently conceals it from unauthorized access and detection. Using advanced techniques in Natural Language Processing (NLP), Artificial Intelligence (AI), and deep learning within the domain of information security, this study delves into the realm of steganography, revealing the restricted embedding capabilities of conventional language-centric approaches. A comparative analysis pits the newly minted algorithm against contemporaneous approaches, notably cutting-edge neural linguistic steganography (NLS), evaluating their algorithmic capacities in terms of Bits per Word (BpW) and Bits per Character (BpC), along with gauging their security and imperceptibility through metrics like Area Under the Curve (AUC), Equal Error Rate (EER) and Difference of Mean Perplexity (\nΔ\nMP). Findings underscore the marked superiority of the proposed steganography algorithm in embedding capacity metrics, while upholding comparable standards of security and imperceptibility compared to other AI-driven statistical (Markov chain-based) and neural (deep learning-based) techniques. Specifically, the StegGPT algorithm showcases a remarkable 44% increase in Word-level capacity criterion (from 2.97 to 4.27) and 53% increase in Character-level capacity criterion (from 0.51 to 0.78) in comparison to its closest competitor, all while maintaining consistent levels of security and imperceptibility.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3568339",
            "Date of Publication": "21 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Omer Farooq Ahmed Adeeb",
                "labs": [
                    "Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran"
                ]
            },
            {
                "name": "Seyed Jahanshah Kabudian",
                "labs": [
                    "Department of Electrical and Computer Engineering, Razi University, Kermanshah, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Steganography",
                "Linguistics",
                "Artificial intelligence",
                "Long short term memory",
                "Social networking (online)",
                "Faces",
                "Deep learning",
                "Payloads",
                "Logic gates",
                "Information security"
            ],
            "Author Keywords": [
                "Text steganography",
                "data hiding",
                "long short-term memory",
                "generative pre-trained transformer (GPT)",
                "deep learning",
                "Markov chain"
            ]
        }
    },
    {
        "Title": "A Probabilistic Method for Hierarchical Multisubject Classification of Documents Based on Multilingual Subject Term Vocabularies",
        "Link": "https://ieeexplore.ieee.org/document/11095338/",
        "Abstract": "Hierarchical Multilabel Classification (HMC) is a challenging task in information retrieval, especially within scientific textbooks, where the objective is to allocate multiple labels adhering to a hierarchical taxonomy. This research presents a new language neutral methodology for HMC to assess documents as normalised weighted distributions of well-defined subjects across hierarchical levels, based on a hierarchical subject term vocabulary. The proposed approach utilizes Bayesian formulas, in contrast to typical methods that depend on machine learning models, thereby obviating the necessity for resource-intensive training processes at various hierarchical levels. The method integrates refined pre-processing techniques, such as natural language processing (NLP) and filtering of non-distinctive terms, to enhance classification accuracy. It employs Bayesian inference along with real time and cached computations across all hierarchical levels, yielding an effective, time-efficient and interpretable classification method while ensuring scalability for large datasets. Experimental results demonstrate the potency of the algorithm to classify scientific textbooks across hierarchical subject tiers with significant precision and recall and retrieve semantically related scientific textbooks, thereby verifying its efficacy in tasks requiring hierarchical subject classification. This study presents a streamlined, interpretable alternative to model-dependent HMC approaches, rendering it particularly appropriate for real-world applications in educational and scientific fields. Furthermore, in the context of the present study, two public Web User Interfaces were published, the first is founded on Skosmos to illustrate the hierarchical structure of the subject term vocabulary, while the second one employs the HMC method to present in real-time the classification between subjects in English and Greek textual data.",
        "Details": {
            "DOI": "10.1109/OJCS.2025.3592254",
            "Date of Publication": "23 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Open Journal of the Computer Society"
        },
        "issn_info": {
            "Electronic ISSN": "2644-1268"
        },
        "authors_data": [
            {
                "name": "Nikolaos Makris",
                "labs": [
                    "School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece"
                ]
            },
            {
                "name": "Stamatina K. Koutsileou",
                "labs": [
                    "National Technical University of Athens, Athens, Greece"
                ]
            },
            {
                "name": "Nikolaos Mitrou",
                "labs": [
                    "School of Electrical and Computer Engineering, National Technical University of Athens, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Vocabulary",
                "Training",
                "Multi label classification",
                "Accuracy",
                "Probabilistic logic",
                "Decision trees",
                "Bayes methods",
                "Vectors",
                "Taxonomy",
                "Probability distribution"
            ],
            "Author Keywords": [
                "Academic textbooks",
                "classification algorithms",
                "controlled vocabularies",
                "digital libraries",
                "document relevance",
                "hierarchical multisubject classification",
                "HMC",
                "KALLIPOS project",
                "Springer ebooks",
                "statistical natural language processing",
                "subject headings"
            ]
        }
    },
    {
        "Title": "Mixture of Experts for Depression and Anxiety Disorder Prediction From Textual and Non-Textual Social Media Data",
        "Link": "https://ieeexplore.ieee.org/document/11050409/",
        "Abstract": "In Natural Language Processing (NLP) and related fields, computational models of mental health screening aim to detect early signs of mental health issues based on an individual’s behaviour on social media. Models of this kind, which are mostly devoted to depression disorders and to the English language, present many open research questions. First, since context-free social media data are prone to noise, the task may involve processing large amounts of data with little or no relation to mental health, which may hinder both model efficiency and accuracy. Second, existing work has been largely devoted to text processing, even though social media also include a wide range of non-textual information, which may be useful predictors of mental health as well. Finally, existing models are usually validated in a single domain, often involving one dataset of a particular text genre and language, and it is not clear whether their results may generalise to other scenarios. Based on these observations, the present work introduces a number of computational models for the prediction of depression and anxiety disorder using large language models (LLM) to handle noisy, context-free social media data. Our models combine textual and non-textual information with the aid of mixture of experts (MoE), and are evaluated in both the Twitter/X domain in Portuguese and in the Reddit domain in English using both machine learning metrics and human assessment provided by mental health specialists. Results show a number of improvements over the previous work and suggest new lines of investigation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583259",
            "Date of Publication": "25 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Wesley Ramos Dos Santos",
                "labs": [
                    "School of Arts, Sciences, and Humanities, University of São Paulo (USP), São Paulo, Brazil"
                ]
            },
            {
                "name": "Ivandré Paraboni",
                "labs": [
                    "School of Arts, Sciences, and Humanities, University of São Paulo (USP), São Paulo, Brazil"
                ]
            },
            {
                "name": "Elton Hiroshi Matsushima",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Camila Azevedo Da Silva",
                "labs": [
                    "Graduate Program in Neurology and Neuroscience, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Emily Samara De Moura Meira",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "João Victor Rodrigues Ferreira Guimarães",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Julia Da Silva Lins",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Laura Enham De Azeredo",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Luiz Guilherme Cerqueira Nunes",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            },
            {
                "name": "Vittória Thiengo Silveira Moreira Rego",
                "labs": [
                    "Laboratório de Estudos do Comportamento Humano e Animal (LECHA), Institute of Psychology, Universidade Federal Fluminense (UFF), Niterói, Rio de Janeiro, Brazil"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Mental health",
                "Depression",
                "Computational modeling",
                "Anxiety disorders",
                "Blogs",
                "Chatbots",
                "Predictive models",
                "Biological system modeling",
                "Data models"
            ],
            "Author Keywords": [
                "Anxiety",
                "depression",
                "mental health",
                "natural language processing",
                "social media analysis"
            ]
        }
    },
    {
        "Title": "Chip Implementation of Two New VCII-Based Voltage/Transimpedance-Mode KHN-Equivalent Biquads",
        "Link": "https://ieeexplore.ieee.org/document/10976647/",
        "Abstract": "This paper presents two new VCII-based Kerwin-Huelsman-Newcomb (KHN) equivalent biquad circuits, each comprising three second-generation voltage conveyors (VCIIs), two grounded capacitors, and five resistors. Either voltage mode (VM) or trans-impedance mode (TIM) can operate in each proposed circuit configuration. Transfer function analysis using a VM inverting bandpass (IBP) filter yields two additional non-inverting/inverting KHN biquad transfer functions for the two proposed VM/TIM KHN-equivalent biquads. The first proposed VM/TIM KHN-equivalent biquad can simultaneously implement an IBP filter, a non-inverting low-pass (NLP) filter, and an inverting high-pass (IHP) filter. In contrast, the second proposed VM/TIM KHN-equivalent biquad can simultaneously implement an IBP filter, an inverting low-pass (ILP) filter, and a non-inverting high-pass (NHP) filter. Each proposed VM/TIM KHN-equivalent biquad features three low-impedance voltage outputs in the designed circuit, eliminating the need for additional voltage buffers (VBs) in the circuit measurements. The two proposed KHN-equivalent biquads are integrated into a single chip, occupying a total area of 1.44 mm2. This technology uses the TSMC\n0.18 μ\nm 1P6M CMOS process, with the chip operating at a supply voltage of ±0.9 V. The measured power dissipation of the first KHN-equivalent biquad is 2.7 mW, while the measured power dissipation of the second one is 3.24 mW. The measured spurious-free dynamic range (SFDR) of the first KHN-equivalent biquad is 41.18 dBc, while the measured SFDR of the second one is 40.94 dBc. With an input voltage of 1.2 Vpp, the measured total harmonic distortion (THD) values for both KHN-equivalent biquads are below 1 %. The proposed two KHN-equivalent biquads have the advantages of high density, system integration, efficiency, low cost, low power consumption, and effective utilization of chip layout area. Simulations and on-chip measurements are carried out for both KHN-equivalent biquads to validate the theoretical design and demonstrate their on-chip feasibility.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3564555",
            "Date of Publication": "25 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hua-Pin Chen",
                "labs": [
                    "Department of Electronic Engineering, Ming Chi University of Technology, Taishan, New Taipei, Taiwan"
                ]
            },
            {
                "name": "San-Fu Wang",
                "labs": [
                    "Department of Electronic Engineering, National Chin-Yi University of Technology, Taichung, Taiwan"
                ]
            },
            {
                "name": "Ming-Jin-Yu",
                "labs": [
                    "Department of Electronic Engineering, Ming Chi University of Technology, Taishan, New Taipei, Taiwan"
                ]
            },
            {
                "name": "Liang-Yen Chen",
                "labs": [
                    "Department of Electrical Engineering, Chang Gung University, Taoyuan, Taiwan"
                ]
            },
            {
                "name": "Yu-Hsi Chen",
                "labs": [
                    "Department of Electrical Engineering, National Formosa University, Yunlin, Huwei, Taiwan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Circuits",
                "Band-pass filters",
                "Power harmonic filters",
                "Semiconductor device measurement",
                "Voltage measurement",
                "Layout",
                "Transfer functions",
                "Information filters",
                "Passband",
                "Matched filters"
            ],
            "Author Keywords": [
                "Integrated circuit",
                "voltage/transimpedance-mode KHN biquads",
                "analog circuit design",
                "chip design"
            ]
        }
    },
    {
        "Title": "Generative Models as a Complex Systems Science: How Can We Make Sense of Large Language Model Behavior?",
        "Link": "https://ieeexplore.ieee.org/document/11060600/",
        "Abstract": "Coaxing out desired behavior from pretrained models, while avoiding undesirable ones, has redefined Natural Language Processing (NLP) and is reshaping how we interact with computers. What was once a scientific engineering discipline—in which building blocks are stacked one on top of the other—is arguably already a complex systems science—in which emergent behaviors are sought out to support previously unimagined use cases. Despite the ever increasing number of benchmarks that measure task performance, we lack explanations of what behaviors language models exhibit that allow them to complete these tasks in the first place. We argue for a systematic effort to decompose language model behavior into categories that explain cross-task performance, to guide mechanistic explanations and help future-proof analytic research.",
        "Details": {
            "DOI": "10.23919/JSC.2025.0009",
            "Date of Publication": "30 June 2025",
            "Publisher": "TUP",
            "Published In": "Journal of Social Computing"
        },
        "issn_info": {
            "Electronic ISSN": "2688-5255"
        },
        "authors_data": [
            {
                "name": "Ari Holtzman",
                "labs": [
                    "University of Chicago, Chicago, IL, USA"
                ]
            },
            {
                "name": "Peter West",
                "labs": [
                    "University of Chicago, Chicago, IL, USA"
                ]
            },
            {
                "name": "Luke Zettlemoyer",
                "labs": [
                    "University of Chicago, Chicago, IL, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Analytical models",
                "Social computing",
                "Systematics",
                "Computational modeling",
                "Machine learning",
                "Predictive models",
                "Transformers",
                "Natural language processing",
                "Data models",
                "Complex systems"
            ],
            "Author Keywords": [
                "language model behavior",
                "emergent properties in ai system",
                "interpretability and analysis method"
            ]
        }
    },
    {
        "Title": "Development of OCR Service for Page-Level Recognition for Camera-Captured Document Images",
        "Link": "https://ieeexplore.ieee.org/document/11007558/",
        "Abstract": "The emergence of Large Language Models (LLMs) has driven significant advancements in Natural Language Processing (NLP) and introduced new text-related applications, such as Visual Question Answering (VQA). As a result, there is a growing need for Optical Character Recognition (OCR) systems that can extract textual contents from document images for LLM applications. However, most existing methods have primarily focused on scene text or well-structured document images, and typically limit text detection and recognition to the word level. In this paper, we propose a novel OCR framework capable of detecting and recognizing text at both the text-line and text-block levels. Specifically, we design a new deep neural network (DNN) to replace the Connected Component (CC) extraction and state estimation processes used in conventional methods. Despite being trained solely on synthetic datasets, the proposed OCR system performs robust text detection and layout analysis. Furthermore, we propose a recognition metric to evaluate content preservation in OCR systems and introduce a new OCR benchmark consisting of camera-captured document images. Our method demonstrates superior performance on this benchmark, outperforming existing OCR APIs.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3572001",
            "Date of Publication": "20 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Junyoung Park",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea",
                    "FuriosaAI, Seoul, South Korea"
                ]
            },
            {
                "name": "Wonjun Kang",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea",
                    "FuriosaAI, Seoul, South Korea"
                ]
            },
            {
                "name": "Seonji Park",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Keuntek Lee",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Hyung Il Koo",
                "labs": [
                    "FuriosaAI, Seoul, South Korea",
                    "Department of Electrical and Computer Engineering, Ajou University, Suwon, South Korea"
                ]
            },
            {
                "name": "Nam Ik Cho",
                "labs": [
                    "Department of Electrical and Computer Engineering, INMC, Seoul National University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Optical character recognition",
                "Text detection",
                "Text recognition",
                "Layout",
                "Benchmark testing",
                "Image recognition",
                "Training",
                "Synthetic data",
                "Accuracy",
                "Tensors"
            ],
            "Author Keywords": [
                "Document image processing",
                "layout analysis",
                "optical character recognition",
                "scene text detection"
            ]
        }
    },
    {
        "Title": "Developing Effective Techniques for the Recognition of Shanghai Dialect Text",
        "Link": "https://ieeexplore.ieee.org/document/11053757/",
        "Abstract": "Recognizing Shanghai dialect text is crucial for preserving local dialects, yet research on its automatic distinction from Standard Mandarin remains limited. We construct a carefully balanced dataset specifically for the task of Shanghai dialect recognition and propose a two-stage approach for automatic language classification. In the first stage, we employ Jieba tokenization to retain dialect-specific lexical nuances, ensuring essential semantic and syntactic distinctions are captured. Next, we independently train both a BERT-Chinese-Based classifier and a traditional Support Vector Machine classifier for dialect recognition. The BERT model leverages powerful contextual representations to capture subtle differences between Shanghai dialect and Standard Mandarin, while the Support Vector Machine serves as a conventional baseline. Extensive experiments comparing the two approaches revealed that, although the Support Vector Machine can adequately perform the classification task, the BERT-Based classifier achieves significantly higher accuracy and is more sensitive to the nuanced linguistic features of the dialect. Further analysis through attention visualization reveals how the model specifically attends to unique dialectal features, highlighting distinctive lexical and structural differences between Shanghai dialect and Mandarin text. To the best of our knowledge, this study is the first to apply NLP techniques for language classification between Shanghai dialect and Standard Mandarin, emphasizing the potential for automated dialect recognition as an effective method for dialect documentation and preservation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3583708",
            "Date of Publication": "27 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Yida Bao",
                "labs": [
                    "Department of Mathematics, Statistics, and Computer Science, University of Wisconsin-Stout, Menomonie, WI, USA"
                ]
            },
            {
                "name": "Zheng Zhang",
                "labs": [
                    "Department of Computer Science Information Systems, Murray State University, Murray, KY, USA"
                ]
            },
            {
                "name": "Mohammad Arifuzzaman",
                "labs": [
                    "Department of Mathematics, Statistics, and Computer Science, University of Wisconsin-Stout, Menomonie, WI, USA"
                ]
            },
            {
                "name": "Tran Duc Le",
                "labs": [
                    "Department of Mathematics, Statistics, and Computer Science, University of Wisconsin-Stout, Menomonie, WI, USA"
                ]
            },
            {
                "name": "Qi Li",
                "labs": [
                    "Department of Mathematics and Computer Science, Fisk University, Nashville, TN, USA"
                ]
            },
            {
                "name": "Masuzyo Mwanza",
                "labs": [
                    "Department of Mathematics and Statistics, Auburn University, Auburn, AL, USA"
                ]
            },
            {
                "name": "Jiaqing Lin",
                "labs": [
                    "Shanghai Pudong Foreign Language School, Shanghai, China"
                ]
            },
            {
                "name": "Philippe Gaillard",
                "labs": [
                    "Department of Biostatistics, Data Science, and Epidemiology, Augusta University, Augusta, GA, USA"
                ]
            },
            {
                "name": "Jiafeng Ye",
                "labs": [
                    "LAF-NERC, Shanghai Jiao Tong University, Shanghai, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Support vector machines",
                "Cultural differences",
                "Phonetics",
                "Accuracy",
                "Text recognition",
                "Standards",
                "Urban areas",
                "Global communication",
                "Vocabulary",
                "Translation"
            ],
            "Author Keywords": [
                "BERT",
                "support vector machine",
                "cultural heritage preservation",
                "Jieba",
                "Shanghai dialect"
            ]
        }
    },
    {
        "Title": "Protocol-Agnostic and Packet-Based Intrusion Detection Using a Multi-Layer Deep-Learning Architecture at the Network Edge",
        "Link": "https://ieeexplore.ieee.org/document/10942348/",
        "Abstract": "Intrusion Detection (ID) faces multiple challenges, including the diversity of intrusion types and the risk of false positives and negatives. In an edge computing context, resource constraints further complicate the process, particularly during the training phase, which is computationally intensive. This paper presents a novel approach to ID in network traffic within edge computing environments using a Neural Network (NN) model. The proposed model is designed to align with the layered structure of network packets and has been trained and evaluated on the widely used CIC-IDS2017 cybersecurity dataset. Its protocol-agnostic design and customized preprocessing method enable it to efficiently detect network attacks across multiple protocols while preserving the original packet structure. Unlike existing approaches that transform packets into alternative representations such as images or NLP-based techniques, which introduce additional overhead, our method processes packets directly, eliminating the need for complex components like Recurrent Neural Networks (RNNs) or convolutional layers. Our model is optimized for edge computing by employing a centralized training approach that minimizes resource consumption while allowing flexible deployment on edge devices. Experimental results demonstrate that our approach outperforms existing methods in terms of accuracy, F1-score, recall, and precision when evaluated on a real-world dataset. This work highlights the potential of deep learning in enhancing network security while respecting edge computing constraints.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3555201",
            "Date of Publication": "26 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Rodolphe Picot",
                "labs": [
                    "Department of Computer Engineering, École Polytechnique de Montréal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Felipe Gohring de Magalhães",
                "labs": [
                    "Department of Computer Engineering, École Polytechnique de Montréal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Ahmad Shahnejat Bushehri",
                "labs": [
                    "Department of Computer Engineering, École Polytechnique de Montréal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Maroua Ben Atti",
                "labs": [
                    "Humanitas Solutions, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Gabriela Nicolescu",
                "labs": [
                    "Department of Computer Engineering, École Polytechnique de Montréal, Montreal, QC, Canada"
                ]
            },
            {
                "name": "Alejandro Quintero",
                "labs": [
                    "Department of Computer Engineering, École Polytechnique de Montréal, Montreal, QC, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Artificial neural networks",
                "Protocols",
                "Computational modeling",
                "Training",
                "Edge computing",
                "Telecommunication traffic",
                "Data models",
                "Scalability",
                "Computer architecture",
                "Deep learning"
            ],
            "Author Keywords": [
                "Intrusion detection",
                "edge computing",
                "neural network",
                "preprocessing",
                "deep-learning"
            ]
        }
    },
    {
        "Title": "A Statistical Analysis of the Relationship Between Meme Stocks and Social Media",
        "Link": "https://ieeexplore.ieee.org/document/10948426/",
        "Abstract": "Meme stocks, driven by viral social media trends, have added new complexities to financial markets. Prior studies have explored meme stock price dynamics and investor sentiment, but the interplay between social media activity and market movements, along with the structural and linguistic features of online discussions, remains understudied. To address this, we integrate econometric and NLP-based techniques, combining correlation analysis, Granger causality testing, BSADF-based bubble detection, and textual analysis. Our results reveal a strong correlation between trading volume and social media engagement, with Granger causality confirming a feedback loop between market fluctuations and online discussions. BSADF analysis demonstrates that social media-based detection complements price-based methods by identifying explosive periods they may miss. Additionally, network analysis indicates that meme stock discussions exhibit distinct structural patterns, while linguistic analysis highlights unique word choices and emoji usage. Sentiment analysis shows that bullish sentiment dominates during speculative surges, reinforcing the emotionally driven nature of meme stock trading. These findings provide investors with a complementary tool for risk assessment by integrating sentiment with traditional market indicators, while helping regulators monitor online sentiment to identify early signs of speculative excess and market instability.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3557460",
            "Date of Publication": "03 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Seungju Lee",
                "labs": [
                    "Department of Industrial Engineering, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Yunyoung Lee",
                "labs": [
                    "Department of Artificial Intelligence and Data Science, Sejong University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jaewook Lee",
                "labs": [
                    "Department of Industrial Engineering, Seoul National University, Seoul, South Korea",
                    "Institute of Engineering Research, Seoul National University, Seoul, South Korea"
                ]
            },
            {
                "name": "Hoki Kim",
                "labs": [
                    "Department of Industrial Security, Chung-Ang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Correlation",
                "Linguistics",
                "Cause effect analysis",
                "Explosives",
                "Surges",
                "Statistical analysis",
                "Electronic mail",
                "Media",
                "Investment"
            ],
            "Author Keywords": [
                "Behavioral finance",
                "investor sentiment",
                "meme stocks",
                "natural language processing",
                "social media"
            ]
        }
    },
    {
        "Title": "Named Entity Recognition and News Article Classification: A Lightweight Approach",
        "Link": "https://ieeexplore.ieee.org/document/11148234/",
        "Abstract": "This paper introduces TinyGreekNewsBERT, a 14.1 M-parameter distilled Transformer that performs both Named Entity Recognition (NER) and multiclass news-topic classification in Greek. We first compile and annotate a 20 000 article corpus with 32 IOB2 entity labels and 19 thematic categories, accompanied by a transparent, reproducible preprocessing pipeline. On this benchmark, TinyGreekNewsBERT reaches 81% micro F1 for NER and 78% classification accuracy, coming within five percentage points of GreekBERT (86% / 83%) while delivering comparable performance to mBERT (82% / 77%) and approaching XLM-RoBERTa (85% / 82%). Crucially, compared with GreekBERT, our model is\n8×\nsmaller, requires\n15×\nfewer FLOPs (1.3 BFLOPs at 128 tokens), and yields a median CPU latency of 14.7 ms per article, a\n10×\nspeed-up that makes it the first genuinely edge-deployable solution for Greek NER and news classification. Because the distillation and training pipeline is language-agnostic, the approach can be ported to other mid-resource languages and domains, offering a cost-effective path to multilingual, real-time NLP systems.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3605709",
            "Date of Publication": "03 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Ioannis Katranis",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Christos Troussas",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Akrivi Krouska",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Phivos Mylonas",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Cleo Sgouropoulou",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Transformers",
                "Pipelines",
                "Named entity recognition",
                "Computational modeling",
                "Vocabulary",
                "Tagging",
                "Real-time systems",
                "Benchmark testing",
                "Training"
            ],
            "Author Keywords": [
                "Distilled transformer",
                "edge-deployable model",
                "multiclass news-topic classification",
                "named entity recognition"
            ]
        }
    },
    {
        "Title": "Research on Dual-Channel Transformer English Translation Model Based on Cross-Layer Semantic Fusion",
        "Link": "https://ieeexplore.ieee.org/document/11145035/",
        "Abstract": "The rapid advancement of computational sciences has created a pressing demand for innovative methodologies in the field of natural language processing (NLP), especially within the domain of machine translation. As a cornerstone of global communication, machine translation plays a crucial role in bridging linguistic barriers, facilitating intercultural exchange, and enabling access to information across languages. However, conventional translation models often encounter significant limitations when tasked with capturing the nuanced semantics and intricate contextual dependencies inherent in human language. These challenges are particularly evident in complex linguistic scenarios, where shallow representations and limited context modeling result in reduced translation fidelity. To address these persistent issues, we propose a novel translation architecture that integrates hierarchical function estimation with latent-variable encoding mechanisms. This approach enhances the model’s ability to comprehend and generate contextually and semantically rich translations. Central to our method is a multi-path encoder design, which conditions latent variables on both local word-level cues and global sentence-level structures, thereby enriching the contextual awareness of the system. We employ a deep Gaussian process framework to effectively model intricate and non-linear dependencies within language structures. To further refine the latent representations, we introduce a spectral regularization technique that aligns them with the underlying manifold structure of the data. This promotes geometric coherence and smoothness in the learned translations, improving both fluency and accuracy. Comprehensive experimental evaluations across multiple benchmarks demonstrate that our model consistently outperforms state-of-the-art baselines, particularly in preserving semantic integrity across a range of diverse linguistic settings. This contribution represents a meaningful step forward in the development of computational models that deepen machine understanding of natural language.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3604031",
            "Date of Publication": "29 August 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Qian Cui",
                "labs": [
                    "Changchun Vocational and Technical College, Changchun, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Translation",
                "Semantics",
                "Linguistics",
                "Adaptation models",
                "Cross layer design",
                "Transformers",
                "Syntactics",
                "Context modeling",
                "Encoding",
                "Computer architecture"
            ],
            "Author Keywords": [
                "Semantic representation",
                "latent-variable encoding",
                "deep Gaussian processes",
                "spectral regularization",
                "machine translation"
            ]
        }
    },
    {
        "Title": "JailbreakTracer: Explainable Detection of Jailbreaking Prompts in LLMs Using Synthetic Data Generation",
        "Link": "https://ieeexplore.ieee.org/document/11036671/",
        "Abstract": "The emergence of Large Language Models (LLMs) has revolutionized natural language processing (NLP), enabling remarkable advancements across various applications. However, these models remain susceptible to adversarial prompts, commonly referred to as jailbreaks, which exploit their vulnerabilities to bypass ethical and safety constraints. These prompts manipulate LLMs to produce harmful or forbidden outputs, posing serious ethical and security challenges. In this study, we propose JailbreakTracer, a novel framework leveraging synthetic data generation and Explainable AI (XAI) to detect and classify jailbreaking prompts. We first construct two comprehensive datasets: a Toxic Prompt Classification Dataset, combining real-world and synthetic jailbreak prompts, and a Forbidden Question Reasoning Dataset, categorizing forbidden queries into 13 distinct scenarios with clear reasoning labels. Synthetic toxic prompts are generated using a fine-tuned GPT model, achieving an attack success rate of 95.1%, effectively addressing the class imbalance. Using transformer-based architectures, we train classifiers that achieved 97.25% accuracy in detecting jailbreak prompts and 100% accuracy in categorizing forbidden questions. Our approach integrates XAI techniques, such as LIME, to ensure interpretability and transparency in the model’s predictions. Extensive evaluations demonstrate the efficacy of JailbreakTracer in detecting and reasoning about jailbreak prompts, providing a critical step toward enhancing the safety and accountability of LLMs. The dataset and code are available on GitHub: https://github.com/faiyazabdullah/JailbreakTracer",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3579996",
            "Date of Publication": "16 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Md. Faiyaz Abdullah Sayeedi",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Maaz Bin Hossain",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Kamrul Hassan",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Sabrina Afrin",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Molla Md. Sabit Hossain",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh"
                ]
            },
            {
                "name": "Md. Shohrab Hossain",
                "labs": [
                    "Department of Computer Science and Engineering, United International University, Dhaka, Bangladesh",
                    "Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Ethics",
                "Cognition",
                "Synthetic data",
                "Natural language processing",
                "Artificial intelligence",
                "Adaptation models",
                "Security",
                "Robustness",
                "Prevention and mitigation",
                "Passwords"
            ],
            "Author Keywords": [
                "Natural language processing",
                "large language models",
                "jailbreaking",
                "text classification",
                "synthetic data",
                "generative AI",
                "explainable AI"
            ]
        }
    },
    {
        "Title": "Analyzing the Robustness of Vision & Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10526392/",
        "Abstract": "We present an approach to evaluate the robustness of pre-trained vision and language (V&L) models to noise in input data. Given a source image/text, we perturb it using standard computer vision (CV) / natural language processing (NLP) techniques and feed it to a V&L model. To track performance changes, we explore the problem of visual questions answering (VQA). Overall, we utilize 5 image and 9 text perturbation techniques and probe three Transformer-based V&L models followed by a broad analysis of their behavior and a detailed comparison. We discovered several key findings regarding the performance of the models in relation to the impact of various perturbations. These discrepancies in performance can be attributed to differences in their architectures and learning objectives. Last, but not least, we perform an empirical study to assess whether the attention mechanism of V&L Transformers learns to align modalities. We hypothesize, that attention weights for related objects and words, should be on average higher than for random object/word pairs. However, our study shows that, unlike is believed for machine translation models, V&L models do not learn alignment at all or exhibit less evidence to do so. This may support the intuition that V&L Transformers overfit to either of the modalities.",
        "Details": {
            "DOI": "10.1109/TASLP.2024.3399061",
            "Date of Publication": "09 May 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
        },
        "issn_info": {
            "Print ISSN": "2329-9290",
            "Electronic ISSN": "2329-9304"
        },
        "authors_data": [
            {
                "name": "Alexander Shirnin",
                "labs": [
                    "HSE University, Moskva, Russian Federation"
                ]
            },
            {
                "name": "Nikita Andreev",
                "labs": [
                    "CAIT, Applied AI Institute, Moskva, Russian Federation"
                ]
            },
            {
                "name": "Sofia Potapova",
                "labs": [
                    "SmallTalk2Me, Covina, CA, USA"
                ]
            },
            {
                "name": "Ekaterina Artemova",
                "labs": [
                    "HSE University, Moskva, Russian Federation"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Transformers",
                "Data models",
                "Computational modeling",
                "Visualization",
                "Robustness",
                "Analytical models"
            ],
            "Author Keywords": [
                "Visual question answering",
                "robustness",
                "black-box interpretation",
                "attention mechanism",
                "spurious correlations"
            ]
        }
    },
    {
        "Title": "Embedding and Clustering Multi-Entity Sequences",
        "Link": "https://ieeexplore.ieee.org/document/10506524/",
        "Abstract": "Core to much of modern deep learning is the notion of representation learning, learning representations of things that are useful for performing some task(s) related to those things. Encoder-only language models, for example, learn representations of language useful for performing language-related tasks, often classification. While fruitful in many applications, inherent is the assumption that only one classification is to be made for a particular input. This poses challenges when multiple classifications are to be made about different portions of a single record, such as emotion recognition in conversation (ERC) where the objective is to classify the emotion in each utterance of a dialog. Existing methods for this task typically either involve redundant computation, non-trivial post-processing outside of the core language model backbone, or both. To address this, we generalize recent work for deriving player-specific embeddings from multi-player sequences of events in sport for domain-agnostic application while also enabling it to leverage inter-entity relationships. Seeing the efficacy of the method in regression and classification tasks, we explore how it can be used to cluster player representations, proposing a novel approach for distribution-aware deep-clustering in the absence of labels. We demonstrate how the proposed methods yield state-of-the-art performance on the disparate tasks of ERC in Natural Language Processing (NLP), long-tail partial-label-learning (LT-PLL) in Computer Vision (CV), and player form clustering in sports analytics.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3391820",
            "Date of Publication": "22 April 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Connor Heaton",
                "labs": [
                    "College of Information Sciences and Technology, The Pennsylvania State University, State College, Pennsylvania, PA, USA"
                ]
            },
            {
                "name": "Prasenjit Mitra",
                "labs": [
                    "College of Information Sciences and Technology, The Pennsylvania State University, State College, Pennsylvania, PA, USA",
                    "L3S Research Center, Leibniz University Hannover, Hannover, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Sports",
                "Heating systems",
                "Computational modeling",
                "Statistics",
                "Social factors",
                "Emotion recognition",
                "Representation learning",
                "Labeling"
            ],
            "Author Keywords": [
                "Representation learning",
                "long-tail partial-label-learning",
                "emotion recognition in conversation",
                "sports analytics"
            ]
        }
    },
    {
        "Title": "Knowledge Graph Completion With Pattern-Based Methods",
        "Link": "https://ieeexplore.ieee.org/document/10832468/",
        "Abstract": "Knowledge graphs (KGs) are popularly used to develop several intelligent applications. Revealing valuable knowledge hidden in these graphs opened up a branch of research, known as KG reasoning, aiming at predicting the missing links. Some methods take advantage of external information such as entity description but at the cost of more computational complexity. Besides, most of the current techniques focus solely on local information in the KG. However, the learning process can utilise valuable global information in the entire graph. In this paper, we propose a Pattern-based Knowledge Graph Completion (PKGC) method that consists of three phases. The first phase utilizes multi-source information and expands the KG using entity description as external information with efficient Natural Language Processing (NLP) techniques. In the second phase, we mine frequent patterns from the expanded KG, extract connections between them and assign entities to the patterns that construct the abstraction layer. Based on the extracted patterns, connections, and entity assignments, a flow network is constructed on the abstraction layer in the third phase. We use global internal information, namely patterns, by adapting the minimum-cost circulation problem to the flow network. This way the links in a larger neighborhood are involved in the inference. We conducted experiments on the link prediction task and evaluated the training time on two benchmark datasets, WordNet and Freebase. Experiments have demonstrated that the proposed method is superior to the state-of-the-art methods and that pattern extraction is effective for knowledge graph completion tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3525586",
            "Date of Publication": "07 January 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Maryam Sabet",
                "labs": [
                    "Computer Engineering Department, Yazd University, Yazd, Iran",
                    "Department of Computer Science and Engineering and IT, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran"
                ]
            },
            {
                "name": "Mohammadreza Pajoohan",
                "labs": [
                    "Computer Engineering Department, Yazd University, Yazd, Iran"
                ]
            },
            {
                "name": "Mohammad Reza Moosavi",
                "labs": [
                    "Department of Computer Science and Engineering and IT, School of Electrical and Computer Engineering, Shiraz University, Shiraz, Iran"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cognition",
                "Knowledge graphs",
                "Vectors",
                "Semantics",
                "Tail",
                "Translation",
                "Natural language processing",
                "Training",
                "Tensors",
                "Surveys"
            ],
            "Author Keywords": [
                "Frequent pattern mining",
                "flow network",
                "knowledge graph completion",
                "minimum-cost circulation problem"
            ]
        }
    },
    {
        "Title": "Extraction-Augmented Generation of Scientific Abstracts Using Knowledge Graphs",
        "Link": "https://ieeexplore.ieee.org/document/10929048/",
        "Abstract": "Graph-to-text generation for specialized tasks, such as scientific abstract generation, is challenging due to the limited availability of structured knowledge graphs and the need to balance semantic accuracy with paragraph coherence. This motivates our proposal of an Extraction-Augmented Scientific Abstract Generation (EASAG) model which includes the processes of self-extraction, graph fusion, and abstract generation. The model performs self-determination of entities, followed by fine-grained extraction for each entity, predicting the target entity by specifying relations to construct semantic triples. The accumulated triples are then represented more logically through knowledge fusion using two proposed methods: Multi-hop Longest Subchain (MLS) and Label Ordering (LO). The former focuses on uncovering the core logical chain of the content, while the latter functionally segments sequences within the knowledge graph. Experimental results indicate that our model improves the quality of generated scientific abstracts through knowledge richness and the integration of discrete information. The two knowledge fusion methods are designed to enhance specific aspects, with one focusing on semantic accuracy and the other on maintaining paragraph structure integrity. Through fine-grained extraction, we reconstructed the Abstract Generation Dataset (AGENDA) and the newly developed ACL Abstract Graph Dataset (ACL-AGD) containing the latest Natural Language Processing (NLP) research, both datasets composed of graph-abstract pairs. Analysis reveals that these datasets exhibit richer relations, enhanced graph connectivity, and a more uniform distribution of relations.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3551756",
            "Date of Publication": "17 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Haotong Wang",
                "labs": [
                    "Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan"
                ]
            },
            {
                "name": "Yves Lepage",
                "labs": [
                    "Graduate School of Information, Production and Systems, Waseda University, Kitakyushu, Japan"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge graphs",
                "Semantics",
                "Data mining",
                "Accuracy",
                "Coherence",
                "Natural language processing",
                "Graph neural networks",
                "Focusing",
                "Computational modeling",
                "Retrieval augmented generation"
            ],
            "Author Keywords": [
                "Extraction-augmented generation",
                "scientific abstract",
                "knowledge graphs",
                "datasets"
            ]
        }
    },
    {
        "Title": "LSV-MAE: A Masked-Autoencoder Pre-Training Approach for Large-Scale 3D Point Cloud Data",
        "Link": "https://ieeexplore.ieee.org/document/11105382/",
        "Abstract": "Masked language modeling (MLM) and masked image modeling (MIM) pretraining paradigms have achieved remarkable success in both natural language processing (NLP) and computer vision (CV). However, extending MIM to large-scale outdoor point cloud data presents significant challenges due to the inherent sparsity and wide spatial coverage of such data. To address this issue, we develop a masked autoencoding pre-training model, LSV-MAE, making it possible to train detection models on large-volume unlabeled point cloud data. Our approach pre-trains the backbone to reconstruct masked voxel features extracted by PointNN. To enhance the feature extraction capability of the encoder, the point cloud is voxelized with different voxel sizes at different pre-training stages. Meanwhile, to avoid the effect of masking key points, the masked voxel features are re-integrated into the decoder during pretraining. To verify the proposed approach, experiments are conducted on well-known datasets, showing that our method not only can avoid tedious labeling work but improve the detection accuracy by up to 18%, compared with that using the model without pre-training, across datasets of different sizes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3594614",
            "Date of Publication": "31 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Nuo Cheng",
                "labs": [
                    "Process Optimization Group, Technische Universität Ilmenau, Ilmenau, Germany"
                ]
            },
            {
                "name": "Chuanyu Luo",
                "labs": [
                    "Process Optimization Group, Technische Universität Ilmenau, Ilmenau, Germany"
                ]
            },
            {
                "name": "Han Li",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Sikun Ma",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Shengguang Lei",
                "labs": [
                    "LiangDao GmbH, Berlin, Germany"
                ]
            },
            {
                "name": "Pu Li",
                "labs": [
                    "Process Optimization Group, Technische Universität Ilmenau, Ilmenau, Germany"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Point cloud compression",
                "Feature extraction",
                "Image reconstruction",
                "Decoding",
                "Autoencoders",
                "Three-dimensional displays",
                "Object detection",
                "Training",
                "Data models",
                "Autonomous vehicles"
            ],
            "Author Keywords": [
                "Pre-training",
                "autonomous driving",
                "point cloud",
                "transformer",
                "KITTI",
                "nuScenes"
            ]
        }
    },
    {
        "Title": "Meta Lifelong-Learning With Selective and Task-Aware Adaptation",
        "Link": "https://ieeexplore.ieee.org/document/10433528/",
        "Abstract": "Meta-learning has been applied to lifelong language learning due to its ability to find an optimal model for efficient adaptation to any learned tasks. Generally, meta lifelong-learning partially stores samples from seen tasks in a memory and selects some of them to train the model, refresh the knowledge, and adapt the model for inference. However, the sample selection for these steps was usually done in a sub-optimal manner in existing work. Hence, we propose MeLSTA (Meta Lifelong-Learning with Selective and Task-Aware Adaptation) to effectively select the samples based on task identifiers and the adaptation scores reflecting the model behavior after adaptation. The results show that MeLSTA enhances the accuracy by 1.2% over the state-of-the-art while significantly shrinking the training duration by over 6 times. Additionally, our in-depth analysis reveals the strengths and limitations of MeLSTA and existing work, providing useful insights for future designs of meta lifelong-learning for NLP.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3365663",
            "Date of Publication": "13 February 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Thanapapas Horsuwan",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand"
                ]
            },
            {
                "name": "Piyawat Lertvittayakumjorn",
                "labs": [
                    "Google LLC, Mountain View, CA, USA"
                ]
            },
            {
                "name": "Kasidis Kanwatchara",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand"
                ]
            },
            {
                "name": "Boonserm Kijsirikul",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand"
                ]
            },
            {
                "name": "Peerapon Vateekul",
                "labs": [
                    "Department of Computer Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Task analysis",
                "Adaptation models",
                "Metalearning",
                "Training",
                "Inference algorithms",
                "Prediction algorithms",
                "Optimization",
                "Text categorization",
                "Learning systems"
            ],
            "Author Keywords": [
                "Catastrophic forgetting",
                "lifelong learning",
                "meta-adaptation",
                "meta-learning",
                "meta lifelonglearning",
                "relation detection",
                "text classification"
            ]
        }
    },
    {
        "Title": "Machine Learning and Data Science in Social Sciences: Methods, Applications, and Future Directions",
        "Link": "https://ieeexplore.ieee.org/document/11031403/",
        "Abstract": "Artificial intelligence (AI) is transforming social science research by enabling scalable data analysis, predictive modeling, and causal inference, thereby reshaping the methodological foundations of fields such as political science, economics, and psychology. This survey examines the application of key AI techniques, particularly machine learning (ML), natural language processing (NLP), network science, and explainable AI (XAI), in addressing domain-specific challenges in empirical research. Emphasis is placed on methodological integration, including bias mitigation, fairness-aware learning, causal discovery, and model interpretability. While these tools enhance analytical capacity, they raise critical concerns about algorithmic bias, transparency, and ethical accountability. We review current strategies for responsible AI deployment, including regulatory frameworks, human-centered design principles, and privacy-preserving methods. By synthesizing methodological advances and cross-cutting challenges, this study provides a focused and interdisciplinary roadmap for the rigorous and equitable use of AI in social science research.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3578906",
            "Date of Publication": "12 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Elias Dritsas",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            },
            {
                "name": "Maria Trigka",
                "labs": [
                    "Department of Informatics and Computer Engineering, University of West Attica, Athens, Greece"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social sciences",
                "Artificial intelligence",
                "Analytical models",
                "Ethics",
                "Predictive models",
                "Surveys",
                "Economics",
                "Data models",
                "Market research",
                "Data science"
            ],
            "Author Keywords": [
                "Artificial intelligence",
                "social science research",
                "causal inference",
                "explainable AI",
                "ethical AI governance"
            ]
        }
    },
    {
        "Title": "Real Time Asthma Disease Detection and Identification Technique from Speech Signals Using Hybrid Dense Convolutional Neural Network",
        "Link": "https://ieeexplore.ieee.org/document/10972376/",
        "Abstract": "Recently, asthma patients are severely suffering COVID-19 disease, thus the asthma has become one of the dangerous diseases in the world. Further, asthma is occurring in all age groups, which causing huge loss to patient's health. The primary way to detect the asthma in humans is done by their speech signals, as the asthma severity is increases, which manipulates the properties of speech signal. The conventional methods are failed to extract the maximum features from the speech signals, which resulted in low classification performance. Thus, this article is focused on implementation of real time asthma disease detection and identification technique from speech signals using Multi-Feature Extraction, Selection with Hybrid Classifiers (MFESHC). Initially, speech signals are preprocessed by using Maximum likelihood estimation based spread spectrum analysis (MLE-SSA) method. Then, Improved prefix Beam Search (IPBS) based natural language processing (NLP) method is used to extract and select the best features from the preprocessed speech signals. Then, hybrid dense convolutional neural networks (HDCNN) are used to classify the type of asthma such as normal, stridor, wheezes and rattle classes. Further, Modified Crow Search (MCS) is used to optimize the losses generated in the HDCNN model. The simulation results shows that the proposed MFESHC method resulted in superior performance as compared to state of art approaches because the MCS effectively reduced the losses in the model.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.1967",
            "Date of Publication": "November 2023",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Md. Asim Iqbal",
                "labs": [
                    "Dept. of E.C.E, Annamalai University, Tamil Nadu, India"
                ]
            },
            {
                "name": "K. Devarajan",
                "labs": [
                    "Dept. of E.C.E, Annamalai University, Tamil Nadu, India"
                ]
            },
            {
                "name": "Syed Musthak Ahmed",
                "labs": [
                    "Dept. of E.C.E, SR University, Warangal, Telangana, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Training",
                "Art",
                "Biological system modeling",
                "Feature extraction",
                "Real-time systems",
                "Natural language processing",
                "Convolutional neural networks",
                "Asthma",
                "Diseases",
                "Testing"
            ],
            "Author Keywords": [
                "Asthma detection",
                "improved beam search",
                "MFESHC",
                "modified crow search",
                "deep neural network"
            ]
        }
    },
    {
        "Title": "Converse Attention Knowledge Transfer for Low-Resource Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10638678/",
        "Abstract": "In recent years, great success has been achieved in many tasks of natural language processing (NLP), e.g., named entity recognition (NER), especially in the high-resource language, i.e., English, thanks in part to the considerable amount of labeled resources. More labeled resources, better word representations. However, most low-resource languages do not have such an abundance of labeled data as high-resource English, leading to poor performance of NER in these low-resource languages due to poor word representations. In the paper, we propose converse attention network (CAN) to augment word representations in low-resource languages from the high-resource language, improving the performance of NER in low-resource languages by transferring knowledge learned in the high-resource language. CAN first translates sentences in low-resource languages into high-resource English using an attention-based translation module. In the process of translation, CAN obtains the attention matrices that align word representations of high-resource language space and low-resource language space. Furthermore, CAN augments word representations learned in low-resource language space with word representations learned in high-resource language space using the attention matrices. Experiments on four low-resource NER datasets show that CAN achieves consistent and significant performance improvements, which indicates the effectiveness of CAN.",
        "Details": {
            "DOI": "10.26599/IJCS.2023.9100014",
            "Date of Publication": "19 August 2024",
            "Publisher": "TUP",
            "Published In": "International Journal of Crowd Science"
        },
        "issn_info": {
            "Electronic ISSN": "2398-7294"
        },
        "authors_data": [
            {
                "name": "Shengfei Lyu",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Linghao Sun",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Huixiong Yi",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Yong Liu",
                "labs": [
                    "School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore"
                ]
            },
            {
                "name": "Huanhuan Chen",
                "labs": [
                    "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China"
                ]
            },
            {
                "name": "Chunyan Miao",
                "labs": [
                    "School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Knowledge engineering",
                "Named entity recognition",
                "Task analysis",
                "Knowledge transfer"
            ],
            "Author Keywords": [
                "named entity recognition (NER)",
                "low-resource NER",
                "converse attention network",
                "knowledge transfer",
                "transfer learning"
            ]
        }
    },
    {
        "Title": "OWNER — Toward Unsupervised Open-World Named Entity Recognition",
        "Link": "https://ieeexplore.ieee.org/document/10930473/",
        "Abstract": "Named Entity Recognition (NER) is a crucial task in Natural Language Processing (NLP), traditionally addressed through supervised learning, which requires extensive annotated corpora. This requirement poses challenges, particularly in specialized domains with limited labeled data. In response, the field has shifted towards lower-resource approaches, such as few-shot and zero-shot learning, which reduce the dependency on annotated data. However, even zero-shot models require prior knowledge of entity types, limiting their applicability in exploratory scenarios. In this context, we introduce OWNER, our unsupervised and open-world NER model, designed to operate without annotated documents or predefined entity types. OWNER leverages Encoder-only Language Models like BERT to infer and organize entities into dynamic entity types through a two-step process: mention detection and entity typing. Mention detection employs a BIO sequence labeling approach to locate entities, while entity typing uses BERT-based embeddings, refined through contrastive learning, for clustering and naming entity types. This method allows OWNER to automatically identify and structure unknown entity types, offering advantages for exploratory dataset analysis and knowledge graph construction. Our experimental evaluation on 13 domain-specific datasets demonstrates that OWNER surpasses existing LLM-based open-world NER models and remains competitive with more supervised and closed-world zero-shot models. OWNER’s architecture provides a lightweight, easily deployable solution that advances the state of the art in unsupervised and open-world NER. The source code of OWNER is publicly available at https://github.com/alteca/OWNER, facilitating future research in this domain.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3552122",
            "Date of Publication": "17 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pierre-Yves Genest",
                "labs": [
                    "Alteca, Villeurbanne, France",
                    "INSA Lyon, CNRS, LIRIS, UMR5205, Université Claude Bernard Lyon 1, Villeurbanne, France"
                ]
            },
            {
                "name": "Pierre-Edouard Portier",
                "labs": [
                    "Caisse d’Epargne Rhône Alpes, Lyon, France"
                ]
            },
            {
                "name": "Előd Egyed-Zsigmond",
                "labs": [
                    "INSA Lyon, CNRS, LIRIS, UMR5205, Université Claude Bernard Lyon 1, Villeurbanne, France"
                ]
            },
            {
                "name": "Martino Lovisetto",
                "labs": [
                    "Alteca, Villeurbanne, France"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Named entity recognition",
                "Bidirectional control",
                "Biological system modeling",
                "Labeling",
                "Computer architecture",
                "Vectors",
                "Contrastive learning",
                "Source coding",
                "Predictive models",
                "Metalearning"
            ],
            "Author Keywords": [
                "Named entity recognition",
                "open information extraction",
                "open-world named entity recognition",
                "unsupervised named entity recognition"
            ]
        }
    },
    {
        "Title": "Forecasting Transmission Line Loss Using a Cluster-Based Refinement Framework and Scheduled Outage Data",
        "Link": "https://ieeexplore.ieee.org/document/11087224/",
        "Abstract": "Transmission line loss forecasting is an important power system forecasting task, yet, existing methods often overlook qualitative operational data such as scheduled outages, which directly impact network topology and losses. This paper introduces a new framework that integrates scheduled outage reports with a two-stage cluster-based refinement solution to enhance forecasting accuracy. First, we process and utilize outage data in a way that preserves its temporal and contextual relevance, using Natural Language Processing (NLP) technique. This addresses a key gap in prior works that relies solely on quantitative inputs. Next, the proposed framework employs an initial baseline model in the first stage, followed by cluster-refinement using submodels trained on grouped data patterns. The proposed framework is applied to 24 hour ahead forecasts of transmission losses on an IEEE-118 bus test system, and in Alberta, Canada. We compare the results to benchmark methods from existing state-of-the-art transmission loss forecasting models. Our findings indicate that the proposed framework offers an accurate forecasting solution, outperforming the benchmark techniques. Moreover, these results highlight the value of integrating qualitative information into forecasting models for more accurate and reliable predictions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3591059",
            "Date of Publication": "21 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Gideon Egharevba",
                "labs": [
                    "Department of Electrical and Software Engineering, University of Calgary, Calgary, AB, Canada"
                ]
            },
            {
                "name": "Arne Dankers",
                "labs": [
                    "Department of Electrical and Software Engineering, University of Calgary, Calgary, AB, Canada"
                ]
            },
            {
                "name": "Hamidreza Zareipour",
                "labs": [
                    "Department of Electrical and Software Engineering, University of Calgary, Calgary, AB, Canada"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Forecasting",
                "Propagation losses",
                "Predictive models",
                "Accuracy",
                "Training",
                "Data models",
                "Power transmission lines",
                "Power systems",
                "Network topology",
                "Vectors"
            ],
            "Author Keywords": [
                "Forecasting",
                "transmission line losses",
                "scheduled outage data",
                "text embeddings",
                "large language models",
                "natural language processing",
                "CatBoost",
                "clustering",
                "DBSCAN",
                "Manhattan distance",
                "cluster-based refinement",
                "transformer-based sequential denoising auto-encoder (TSDAE)",
                "Hungarian algorithm"
            ]
        }
    },
    {
        "Title": "Big Data Analytics in Library Services With AI: Personalized Content Recommendations and Catalog Optimization",
        "Link": "https://ieeexplore.ieee.org/document/11003903/",
        "Abstract": "This paper presents an AI-driven framework designed to enhance user engagement and optimize catalog management in digital libraries. The framework integrates Variational Autoencoder (VAE)-based personalized recommendations with Adam optimizer and Lookahead mechanism for catalog optimization. The VAE model effectively learns latent representations of user-item interactions, providing personalized content recommendations. For catalog optimization, the Adam optimizer with Lookahead stabilizes convergence and refines inventory selection, leading to more efficient resource allocation and reduced costs. Experimental results from a large-scale dataset demonstrate that the proposed approach outperforms traditional methods, achieving significant improvements in recommendation accuracy and user engagement. It reduces the number of low-demand items while enhancing overall catalog efficiency. The proposed framework provides a scalable and adaptable solution for digital libraries, ensuring both user satisfaction and effective resource management. Future work will explore hybrid models incorporating Natural Language Processing (NLP) to improve content understanding and further enhance recommendation quality.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3570200",
            "Date of Publication": "14 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Pinjia Hu",
                "labs": [
                    "Department of Reading Promotion, Ningbo Library, Ningbo, China"
                ]
            },
            {
                "name": "Yichi Zhang",
                "labs": [
                    "School of International Studies, University of Nottingham Ningbo China, Ningbo, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Libraries",
                "Optimization",
                "Resource management",
                "Recommender systems",
                "Costs",
                "Accuracy",
                "Predictive models",
                "Mathematical models",
                "Bayes methods",
                "Autoencoders"
            ],
            "Author Keywords": [
                "Variational autoencoder (VAE)",
                "catalog optimization",
                "Adam optimizer",
                "Lookahead mechanism",
                "personalized recommendations",
                "digital libraries"
            ]
        }
    },
    {
        "Title": "A Multimodal Transformer-Based Fusion Model for Enhanced Relations Extraction From Texts",
        "Link": "https://ieeexplore.ieee.org/document/11154973/",
        "Abstract": "Transformer models are significantly advancing the field of natural language processing (NLP), particularly in tasks such as the extraction of concepts and relationships from texts. However, while various studies employ single transformer models for one or both tasks and achieve performance improvements, there remain some limitations. A single model may struggle to optimize for both tasks simultaneously, resulting in poor performance in one or both areas. Furthermore, a single model may experience increased computational and memory demands when used for both tasks, as it must process and retain both entity-level and relation-level features. This can lead to inefficiencies and poor performance, especially on large or complex datasets. Moreover, when a single transformer model handles both tasks, errors in concept extraction can directly affect relation extraction, as the latter relies on accurate identification of entities. To address these limitations, this study introduces a novel Multimodal Transformer-based Fusion (MTF) model that integrates token-level representations and entity representations from different transformer models for enhanced relation classification. The proposed MTF model employs a fused cross-attention mechanism to effectively integrate these heterogeneous representations within the transformer encoder, leveraging complementary linguistic and entity-specific information. Through a structured tokenization process, we generate unified token and entity embeddings, enabling the model to learn a more distinctive representation space for improved relational understanding. The proposed MTF model is evaluated on five transformer-based architectures using the Conll04 and NYT benchmark datasets. The transformer-based architectures include three models for concept extration, namely, BERT, DistilBERT and RoBERTa, and two models for relation extraction, namely, LUKE and mLUKE. The comparison of individual model results reveal RoBERTa and mLuke as the best performing models for concept extraction and relation extraction, respectively. On both tasks, fusing the best two performing models results in the proposed MTF model outperforming the best individual models in terms of precision, recall, and F1 score. Furthermore, a comparative analysis of the results with related studies, shows the superior performance of the proposed MTF model with higher accuracy, precision, recall, and F1-score of 96.86%, 96.89%, 96.86%, 96.87%, respectively.\nShow Less",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3608576",
            "Date of Publication": "10 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tsitsi Zengeya",
                "labs": [
                    "School of Agriculture and Science, University of KwaZulu-Natal, Pietermaritzburg, South Africa"
                ]
            },
            {
                "name": "Kenny Emmanuel Naidoo",
                "labs": [
                    "School of Agriculture and Science, University of KwaZulu-Natal, Pietermaritzburg, South Africa"
                ]
            },
            {
                "name": "Jean Vincent Fonou-Dombeu",
                "labs": [
                    "School of Agriculture and Science, University of KwaZulu-Natal, Pietermaritzburg, South Africa"
                ]
            },
            {
                "name": "Mandlenkosi Gwetu",
                "labs": [
                    "Department of Industrial Engineering, University of Stellenbosch, Stellenbosch, South Africa"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Transformers",
                "Feature extraction",
                "Computational modeling",
                "Accuracy",
                "Encoding",
                "Ontologies",
                "Computer architecture",
                "Bidirectional control",
                "Pipelines",
                "Semantics"
            ],
            "Author Keywords": [
                "Concept extraction",
                "relation extraction",
                "multimodal transformer-based fusion",
                "LUKE",
                "RoBERTa",
                "fused cross-attention mechanism"
            ]
        }
    },
    {
        "Title": "Exploring Text Similarity in Human and AI-Generated Scientific Abstracts: A Comprehensive Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10977950/",
        "Abstract": "Text similarity is a crucial area of study that evaluates how similar texts are both semantically and syntactically. As data volumes increase, understanding the similarities and relationships between texts becomes essential, particularly in natural language processing (NLP) tasks such as text generation, summarization, and classification. This study examines the similarities between human-written scientific abstracts, AI-paraphrased abstracts, and AI-generated abstracts. Various methods, including cosine similarity, Word2Vec, and BERT, were evaluated based on mean, median, and standard deviation metrics. Among these, Word2Vec and FastText achieved the highest mean similarity scores (0.930), while BERT demonstrated superior performance with the highest median (0.841) and the lowest standard deviation (0.019) in the ‘Human-Paraphrased’ category, showing consistent results across datasets. Additionally, the research investigates the implications of these similarities for text analysis and ethical standards, comparing various techniques for measuring text similarity and analysing their effectiveness. The findings offer valuable insights into the application areas of text similarity analysis.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3564867",
            "Date of Publication": "28 April 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Tugba Celikten",
                "labs": [
                    "Department of Computer Engineering, İzmir Katip Çelebi University, İzmir, Türkiye",
                    "Department of Software Engineering, Manisa Celal Bayar University, Manisa, Türkiye"
                ]
            },
            {
                "name": "Aytug Onan",
                "labs": [
                    "Department of Computer Engineering, İzmir Katip Çelebi University, İzmir, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Vectors",
                "Plagiarism",
                "Natural language processing",
                "Standards",
                "Biological system modeling",
                "Radiology",
                "Ethics",
                "Accuracy",
                "Transformers"
            ],
            "Author Keywords": [
                "Human-like text generation",
                "plagiarism detection",
                "semantic text similarity",
                "text similarity",
                "text similarity methods"
            ]
        }
    },
    {
        "Title": "Efficient Management of Safety Documents Using Text-Based Analytics to Extract Safety Attributes From Construction Accident Reports",
        "Link": "https://ieeexplore.ieee.org/document/11023522/",
        "Abstract": "The time-intensive extraction of insights from textual safety documents using conventional methods causes delays and inaccuracies, hindering proactive incident prevention in construction projects. While the architecture of large language models (LLMs) were well-studied, their deployment efficiencies were often overlooked. This study proposes DistilBERT as a more efficient text management method for extracting safety text from construction safety documents. To maintain the relevance of the extracted safety text, a dataset of 5,224 construction accident cases from 73 projects across the Euro-Asia region was compiled, where incidents were analyzed through detailed questionnaires to identify safety attributes, with term frequency-inverse document frequency (TF-IDF) analysis applied for validation. When benchmarked against conventional NLP methods and state-of-the-art LLMs such as BERT, RoBERTa, and XLNet, DistilBERT demonstrated comparable accuracy with significantly reduced computational time. Specifically, DistilBERT achieved an accuracy of 79% in severity scale classification with an F1 score of 0.72, while reducing processing time by approximately 50% compared to BERT (from 2,918.28 seconds to 1,492.08 seconds). By offering rapid inference speeds with negligible accuracy trade-offs, DistilBERT emerges as a practical tool for automating safety text extraction, making it ideal for settings with limited computational capabilities and urgent decision-making requirements. This study examines how DistilBERT can be integrated into construction safety management systems without modifying the underlying platforms. Future work should focus on API creation, secure machine learning pipelines, and optimized deployment of LLMs, particularly in complex contexts.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3576442",
            "Date of Publication": "04 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Vedat Toğan",
                "labs": [
                    "Civil Engineering Department, Karadeniz Technical University, Trabzon, Türkiye"
                ]
            },
            {
                "name": "Fatemeh Mostofi",
                "labs": [
                    "Civil Engineering Department, Karadeniz Technical University, Trabzon, Türkiye"
                ]
            },
            {
                "name": "Onur Behzat Tokdemir",
                "labs": [
                    "Civil Engineering Department, Istanbul Technical University, Istanbul, Türkiye"
                ]
            },
            {
                "name": "Fethi Kadioğlu",
                "labs": [
                    "Civil Engineering Department, Istanbul Technical University, Istanbul, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Safety",
                "Accuracy",
                "Accidents",
                "Safety management",
                "Feature extraction",
                "Computational modeling",
                "Adaptation models",
                "Text mining",
                "Injuries",
                "Data models"
            ],
            "Author Keywords": [
                "Construction industry",
                "decision making",
                "machine learning",
                "natural language processing",
                "project management",
                "safety management",
                "transfer learning",
                "transformers"
            ]
        }
    },
    {
        "Title": "LLM-Based Persona-Driven Text Data Augmentation",
        "Link": "https://ieeexplore.ieee.org/document/11170443/",
        "Abstract": "Illicit online communication, such as drug-dealing dialogues, is increasingly conducted through covert, context dependent language patterns that evade traditional detection techniques in South Korea. However, developing reliable AI based detection systems remains challenging due to the scarcity of real world training data in such sensitive domains. This paper proposes a novel persona-driven data augmentation framework using Large Language Model(LLM) to generate realistic synthetic drug-dealing dialogues. By encoding domain specific buyer and seller personas along with linguistic behaviour rules, the method produces contextually coherent and semantically diverse dialogues that reflect authentic communication styles. Evaluation results demonstrate that the augmented data preserves key stylistic features (high cosine similarity), maintains lexical diversity (TTR), improves fluency (perplexity), and enhances coherence and lexical richness (ROUGE-L), outperforming traditional augmentation method. Furthermore, statistical validation confirms the semantic consistency and stability of the generated data. These findings highlight the viability of LLM-based augmentation in low-resource, high-risk domains and suggest its potential transferability to other specialized NLP applications requiring context-preserving generation.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3611636",
            "Date of Publication": "18 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Hyeon Seong Jeong",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Han Kyeong Ko",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Soo Yong Park",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            },
            {
                "name": "Taehoon Kim",
                "labs": [
                    "Graduate School of Metaverse, Sogang University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data augmentation",
                "Data models",
                "Translation",
                "Linguistics",
                "Semantics",
                "Drugs",
                "Planning",
                "Ontologies",
                "Knowledge graphs",
                "Training data"
            ],
            "Author Keywords": [
                "Data augmentation",
                "dialogue systems",
                "illicit communications",
                "large language model (LLM)",
                "persona modelling"
            ]
        }
    },
    {
        "Title": "Research Progress and Prospects of Pre-Training Technology for Electromagnetic Signal Analysis",
        "Link": "https://ieeexplore.ieee.org/document/10937215/",
        "Abstract": "The pre-training technology can overcome the problem of label dependence and improve the generalization ability of the model, it has achieved remarkable results in natural language processing (NLP) and computer vision (CV), and extensive exploration has been carried out in the analysis of time series data (TS) and spatio-temporal data (STD). Electromagnetic signal is a special time series, and the time series analysis pre-training technology has important reference significance for the electromagnetic signal analysis pre-training. Therefore, this survey compares and analyzes the time series data and electromagnetic signals, summarizes time series analysis pre-training methods, and reviews the research progress of electromagnetic signal analysis pre-training technology. The open source data of electromagnetic signals are comprehensively summarized, which provides a massive data basis for the construction of the pre-training basic model for electromagnetic signal analysis, and the performances of the pre-training technology for electromagnetic signal analysis are evaluated. In addition, the challenges and future development directions of electromagnetic signal analysis pre-training technology are analyzed.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3553739",
            "Date of Publication": "21 March 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xuemin Lu",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Qizhen Li",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Huimin Long",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Lianggang Wang",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Xianming Liang",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Wenjie Chen",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Xihui Zhang",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Xiangyu Zeng",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            },
            {
                "name": "Yong Liu",
                "labs": [
                    "Southwest Institute of Electronic Technology, Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Electromagnetics",
                "Time series analysis",
                "Signal analysis",
                "Data models",
                "Semantics",
                "Analytical models",
                "Deep learning",
                "Wireless communication",
                "Correlation",
                "Time-frequency analysis"
            ],
            "Author Keywords": [
                "Electromagnetic signal analysis",
                "time series analysis",
                "pre-training technology",
                "self-supervised learning"
            ]
        }
    },
    {
        "Title": "A Hybrid Deep Learning-Machine Learning Stacking Model for Yemeni Arabic Dialect Sentiment Analysis",
        "Link": "https://ieeexplore.ieee.org/document/11097878/",
        "Abstract": "With the rise of online communities, Yemeni Arabic has gained increasing exposure to written social media content. Nevertheless, sentiment analysis studies have largely centered on Modern Standard Arabic (MSA) and other regional varieties (e.g., Egyptian, Levantine, Gulf), leaving the Yemeni dialect understudied, with insufficient specialized resources. This study bridges this gap by introducing the largest sentiment-annotated corpus for the Yemeni Arabic dialect, consisting of 45,862 manually labeled Facebook comments collected from the Facebook pages of the main telecommunications companies in Yemen (Yemen Telecom, Yemen Mobile, YOU, and Sabafon). These comments comprise user feedback on public service matters related to these companies. Multiple reviewers annotated the data to ensure reliability, with disagreements resolved through discussion. Moreover, we constructed a novel Yemeni dialect sentiment lexicon, classifying words/phrases according to polarity. We systematically evaluate sentiment analysis approaches, including lexicon-based, machine learning, deep learning, and hybrid, in terms of user sentiment regarding Yemeni telecom services. This study implemented different advanced deep-learning models in our dataset to demonstrate superior performance compared to other methods. The experimental results indicate a hybrid approach that combines advanced deep learning models with a stacked approach, leveraging deep networks for hierarchical feature extraction and RF/LinearSVC as meta-learners, achieving the highest accuracies of 94.71% and 94.28%, respectively. This study provides a preliminary reference for sentiment analysis in low-resource Arabic dialects such as Yemeni. It highlights the effectiveness of stacked feature engineering and meta-learning in dialectal NLP tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3593204",
            "Date of Publication": "28 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Alaa Abdulkareem Hameed Brihi",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Information Technology, Sana’a University, Sanaa, Yemen"
                ]
            },
            {
                "name": "Mossa Ghurab",
                "labs": [
                    "Department of Computer Science, Faculty of Computer and Information Technology, Sana’a University, Sanaa, Yemen"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Sentiment analysis",
                "Lexicon",
                "Social networking (online)",
                "Deep learning",
                "Machine learning",
                "Accuracy",
                "Long short term memory",
                "Feature extraction",
                "Linguistics",
                "Radio frequency"
            ],
            "Author Keywords": [
                "Sentiment analysis",
                "Yemeni Arabic dialect",
                "deep learning",
                "machine learning",
                "lexicon-based",
                "hybrid approach",
                "stacked feature"
            ]
        }
    },
    {
        "Title": "Social Media Insights About COVID-19 in Portugal: A Text Mining Approach",
        "Link": "https://ieeexplore.ieee.org/document/10967374/",
        "Abstract": "The rapid spread of COVID-19 around the world had a significant impact on daily life. As in other countries, measures were taken in Portugal to combat the exponential increase of cases, such as curfews and the use of masks. Thus, in parallel with the direct consequences on health and the healthcare sector, the pandemic also caused changes in human behavior from a sociological viewpoint. The objective of this dissertation is to attain a perception of the reality concerning COVID-19. For this purpose, real-time data was extracted from three sources, two of them being social media platforms - Twitter and Reddit - and the other one being Público, a Portuguese online newspaper. The adopted approach, based on topic modelling and sentiment analysis, was validated within the Portugal context, concerning data over a period of one year, but it can equally be employed in similar situations and other countries and provide decision-making support. After the data extracting, it was prepared for application of natural language processing (NLP) tools specific to the Portuguese language, which can represent a challenge due to the lexical richness. With the gathered information, a dashboard was built, with the purpose of gaining insights on the COVID-19 pandemic in Portugal. It was concluded that the topics discussed on social media reflect the events related to the pandemic. In a final stage, these dashboards were evaluated by public health experts, who highlighted the potential of the results obtained. The data and dashboards will be made available to the scientific community upon request.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.19117",
            "Date of Publication": "January 2023",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Carolina Ferraz Marreiros",
                "labs": [
                    "Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisboa, Portugal"
                ]
            },
            {
                "name": "João Bone",
                "labs": [
                    "Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisboa, Portugal",
                    "Select Data, Anaheim, CA, USA"
                ]
            },
            {
                "name": "Joao C. Ferreira",
                "labs": [
                    "Inov Inesc Inovação, Instituto de Novas Tecnologias, Lisbon, Portugal",
                    "Instituto Universitário de Lisboa (ISCTE-IUL), ISTAR, Lisboa, Portugal"
                ]
            },
            {
                "name": "Ricardo Ribeiro",
                "labs": [
                    "INESC-ID: INESC-ID Lisboa, Portugal",
                    "Iscte-Instituto Universitário de Lisboa, Portugal"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "COVID-19",
                "Text mining",
                "Sentiment analysis",
                "Analytical models",
                "Pandemics",
                "Social networking (online)",
                "Decision making",
                "Blogs",
                "Real-time systems",
                "Public healthcare"
            ],
            "Author Keywords": [
                "Social media",
                "COVID-19",
                "natural language processing",
                "sentiment analysis",
                "topic modeling",
                "public opinion"
            ]
        }
    },
    {
        "Title": "A Cross-Cultural/Lingual Natural Language Processing Analysis of Disability Awareness on Social Media",
        "Link": "https://ieeexplore.ieee.org/document/11037675/",
        "Abstract": "This paper examines cross-lingual and cross-cultural variations in disability discourse on social media, specifically on X (formerly Twitter). Despite the growing presence of disability-related discussions online, empirical evidence remains limited regarding the perception, accessibility, and advocacy for people with disabilities in non-English-speaking countries of the Global South. Utilizing Natural Language Processing (NLP), this research analyzes three years of Arabic and English disability-related posts, incorporating two hashtags, #peoplewithdisabilities and #disability. The study investigates posting behaviors, engagement patterns, sentiment, and empathy-driven linguistic differences, while also assessing the cultural factors shaping these narratives. The findings show that there are notable linguistic and thematic differences between the posts in English and Arabic across different continents. They also highlight how these relate to disability theories and offer insights for policy makers and advocates on how to effectively study, track, and design for disability awareness in the global south.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3580608",
            "Date of Publication": "17 June 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Zainab Almeraj",
                "labs": [
                    "Information Science Department, College of Life Sciences, Kuwait University, Safat, Kuwait"
                ]
            },
            {
                "name": "Fatemah Husain",
                "labs": [
                    "Information Science Department, College of Life Sciences, Kuwait University, Safat, Kuwait"
                ]
            },
            {
                "name": "Rosa I. Arriaga",
                "labs": [
                    "School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "People with disabilities",
                "Natural language processing",
                "Translation",
                "Linguistics",
                "Cultural differences",
                "Blogs",
                "Autism",
                "Mental health",
                "Predictive models"
            ],
            "Author Keywords": [
                "Social media",
                "X/Twitter trends",
                "disability",
                "awareness",
                "empathy",
                "mindset",
                "cross-culture",
                "cross-language",
                "Arabic",
                "English",
                "Linguistic analysis",
                "text mining"
            ]
        }
    },
    {
        "Title": "Chinese Legal Case Similarity Matching Based on Text Importance Extraction",
        "Link": "https://ieeexplore.ieee.org/document/11062845/",
        "Abstract": "Similarity case matching can effectively enhance the efficiency of case adjudication and promote judicial fairness. Recent advances in natural language processing (NLP), particularly those based on deep learning technologies, have significantly enhanced the intelligent development of similar case judgments. The BERT model can efficiently extract features from legal texts by utilizing self-attention mechanisms, thereby facilitating subsequent matching tasks. However, traditional BERT models are often constrained by the input text length. To achieve better comparison results for long case descriptions, an iterative unsupervised clustering method is employed to evaluate the importance of legal case texts during contrastive learning. This results in extracted texts that align more closely with cluster centers in the feature space, thus becoming more representative. Extracting key information and retaining important legal texts can reduce the input length for the BERT model, thereby improving its performance. The selected case statement text is fed into a model based on the BERT framework for similarity case matching. Compared to inputting the original case statement text, the approach proposed in the paper can more effectively retain critical information about the case. The accuracy of our method on the test set is 75.08%, outperforming all existing methods on the public CAIL2019-SCM dataset.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3585265",
            "Date of Publication": "02 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Aman Fan",
                "labs": [
                    "Shaanxi University of International Trade & Commerce, Xi’an, Shaanxi, China"
                ]
            },
            {
                "name": "Shaoxi Wang",
                "labs": [
                    "Northwestern Polytechnical University, Xi’an, Shaanxi, China"
                ]
            },
            {
                "name": "Yanchuan Wang",
                "labs": [
                    "Northwestern Polytechnical University, Xi’an, Shaanxi, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Law",
                "Feature extraction",
                "Encoding",
                "Natural language processing",
                "Bidirectional control",
                "Semantics",
                "Accuracy",
                "Data mining",
                "Training",
                "Contrastive learning"
            ],
            "Author Keywords": [
                "Similarity case matching",
                "deep learning",
                "unsupervised clustering",
                "contrastive learning"
            ]
        }
    },
    {
        "Title": "Online News-Based Economic Sentiment Index",
        "Link": "https://ieeexplore.ieee.org/document/10705082/",
        "Abstract": "The accurate prediction of industry trends has become increasingly challenging because of unforeseen events. To address this challenge, this study proposes a deep learning approach to generate an economic sentiment index by integrating Natural Language Processing (NLP) models and image-clustering techniques. We first employ sampling techniques to create standardized online news datasets. Feature engineering techniques from the Korean Bidirectional Encoder Representations from Transformers (KoBERT) model are then used to generate relevance and sentiment scores for the textual data. Further, to enhance visualization and clustering, we transform the textual data into joint plot images, which are grouped into distinct clusters based on news categories. Finally, using Multi-criteria Decision Analysis, the various scores and cluster information are synthesized to generate the final economic sentiment index. This approach improves visualization and enhances the interpretability of the generated index. The proposed algorithm is applied to construct a new economic sentiment index for the Information and Communications Technology (ICT) industry in South Korea.",
        "Details": {
            "DOI": "10.1109/TBDATA.2024.3474211",
            "Date of Publication": "04 October 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Transactions on Big Data"
        },
        "issn_info": {
            "Electronic ISSN": "2332-7790"
        },
        "authors_data": [
            {
                "name": "Nathaniel Kang",
                "labs": [
                    "Department of Statistics, Data Science, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Dongeun Min",
                "labs": [
                    "Department of Statistics, Data Science, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Yonghun Cho",
                "labs": [
                    "Department of Statistics, Data Science, Yonsei University, Seoul, South Korea"
                ]
            },
            {
                "name": "Dong-Whan Ko",
                "labs": [
                    "Korea National Defense University, Nonsan-si, South Korea"
                ]
            },
            {
                "name": "Hyun Hak Kim",
                "labs": [
                    "Department of Economics, Kookmin University, Seoul, South Korea"
                ]
            },
            {
                "name": "Joon Yeon Choeh",
                "labs": [
                    "Department of Software, Sejong University, Seoul, South Korea"
                ]
            },
            {
                "name": "Jongho Im",
                "labs": [
                    "Department of Statistics, Data Science, Yonsei University, Seoul, South Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Economics",
                "Indexes",
                "Biological system modeling",
                "Industries",
                "Accuracy",
                "Sentiment analysis",
                "Surveys",
                "Real-time systems",
                "Deep learning",
                "Data models"
            ],
            "Author Keywords": [
                "Data fusion",
                "deep learning",
                "economic index",
                "forecasting",
                "KoBERT"
            ]
        }
    },
    {
        "Title": "Enhance Social Network Bullying Detection Using Multi-Teacher Knowledge Distillation With XGBoost Classifier",
        "Link": "https://ieeexplore.ieee.org/document/11017628/",
        "Abstract": "Cyberbullying remains a pressing issue in Thai social media, especially among teenagers. While many studies have explored deep learning approaches for sentiment analysis or toxicity detection, the detection of cyberbullying—especially in the Thai language—remains underexplored. This study introduces a novel framework that enhances cyberbullying detection by integrating Multi-Teacher Knowledge Distillation (MTKD) with an XGBoost classifier, specifically adapted for Thai-language social media posts. Unlike prior work that relies solely on neural models, this research demonstrates how distilled soft labels from diverse teacher models can be effectively transferred to a lightweight and interpretable XGBoost student model. A key contribution of this study is the successful adaptation of XGBoost, traditionally used for structured/tabular data, for a natural language classification task by using rich semantic features extracted via pre-trained NLP models. Additionally, although the selected datasets (Wisesight, Thai Toxic Tweet, and 40 Thai Children Stories) are often used for sentiment analysis, we reframe and preprocess them for the purpose of cyberbullying classification by focusing on toxic, harmful, or aggressive linguistic patterns. Our framework achieved strong classification performance—92.5%, 90.5%, and 91.0% accuracy across the three datasets—demonstrating its robustness and practical application in Thai-language cyberbullying detection.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3574679",
            "Date of Publication": "29 May 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sathit Prasomphan",
                "labs": [
                    "Department of Computer and Information Science, Faculty of Applied Science, King Mongkut’s University of Technology North Bangkok, Bangkok, Thailand"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Cyberbullying",
                "Feature extraction",
                "Convolutional neural networks",
                "Classification algorithms",
                "Blogs",
                "Accuracy",
                "Machine learning",
                "Neural networks",
                "Deep learning",
                "Transformers"
            ],
            "Author Keywords": [
                "Cyberbullying",
                "multi-teacher model",
                "knowledge distillation",
                "soft targets",
                "student model",
                "XGBoost Classifier"
            ]
        }
    },
    {
        "Title": "DSG-KD: Knowledge Distillation From Domain-Specific to General Language Models",
        "Link": "https://ieeexplore.ieee.org/document/10677014/",
        "Abstract": "The use of pre-trained language models fine-tuned to address specific downstream tasks is a common approach in natural language processing (NLP). However, acquiring domain-specific knowledge via fine-tuning is challenging. Traditional methods involve pretraining language models using vast amounts of domain-specific data before fine-tuning for particular tasks. This study investigates emergency/non-emergency classification tasks based on electronic medical record (EMR) data obtained from pediatric emergency departments (PEDs) in Korea. Our findings reveal that existing domain-specific pre-trained language models underperform compared to general language models in handling N-lingual free-text data characteristics of non-English-speaking regions. To address these limitations, we propose a domain knowledge transfer methodology that leverages knowledge distillation to infuse general language models with domain-specific knowledge via fine-tuning. This study demonstrates the effective transfer of specialized knowledge between models by defining a general language model as the student model and a domain-specific pre-trained model as the teacher model. In particular, we address the complexities of EMR data obtained from PEDs in non-English-speaking regions, such as Korea, and demonstrate that the proposed method enhances classification performance in such contexts. The proposed methodology not only outperforms baseline models on Korean PED EMR data, but also promises broader applicability in various professional and technical domains. In future works, we intend to extend this methodology to include diverse non-English-speaking regions and address additional downstream tasks, with the aim of developing advanced model architectures using state-of-the-art KD techniques. The code is available in https://github.com/JoSangYeon/DSG-KD.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3457850",
            "Date of Publication": "11 September 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Sangyeon Cho",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Jangyeong Jeon",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Dongjoon Lee",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Changhee Lee",
                "labs": [
                    "Department of Artificial Intelligence, Korea University, Seoul, Republic of Korea"
                ]
            },
            {
                "name": "Junyeong Kim",
                "labs": [
                    "Department of Artificial Intelligence, Chung-Ang University, Seoul, Republic of Korea"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Data models",
                "Knowledge transfer",
                "Biomedical imaging",
                "Predictive models",
                "Transformers",
                "Training",
                "Solid modeling",
                "Electronic medical records",
                "Natural language processing"
            ],
            "Author Keywords": [
                "Bilingual medical data analysis",
                "emergency room electronic health records",
                "code switching",
                "knowledge distillation",
                "multilingual language models",
                "natural language processing"
            ]
        }
    },
    {
        "Title": "A Multi-Layer Hybrid Deep Learning Model for Toxic Comment Detection in Assamese",
        "Link": "https://ieeexplore.ieee.org/document/11174272/",
        "Abstract": "The present research proposes a highly precise technique for detecting toxic comments in Assamese, a low-resource language that is a member of the Eastern Indo-Aryan family. As a low-resource language, Assamese encounters specific challenges such dialectal differences, incorrect spellings, frequent code-mixing with English, and a lack of resources with annotations. A custom-built dataset of 100,000 Assamese social media comments was gathered and split equally between toxic and non-toxic categories in order to solve the lack of labelled data. The article presents a multi-layer hybrid deep learning model that integrates multi-scale Convolutional Neural Networks (CNN), bidirectional LSTM (BiLSTM), and bidirectional GRU (BiGRU). A thorough grid search utilising several optimisers and activation functions was used to create and optimise two hybrid architectures: CNN-BiLSTM-BiGRU and BiGRU-BiLSTM-CNN. Among them, the CNN-BiLSTM-BiGRU model outperformed present approaches for Assamese and other structurally related languages, reaching 94.25% accuracy and an F1- score of 0.93%. This work not only produces strong analytical findings, but it also makes a novel contribution in developing and evaluating models for Assamese toxic comment detection under real-world linguistic and resource constraints, providing a solid foundation and valuable insights for furthering NLP research in other under resourced languages.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3612497",
            "Date of Publication": "22 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mandira Neog",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            },
            {
                "name": "Nomi Baruah",
                "labs": [
                    "Dibrugarh University, Dibrugarh, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Social networking (online)",
                "Accuracy",
                "Deep learning",
                "Convolutional neural networks",
                "Computer architecture",
                "Bidirectional long short term memory",
                "Toxicology",
                "Feature extraction",
                "Computational modeling",
                "Tuning"
            ],
            "Author Keywords": [
                "CNN",
                "GRU",
                "BiLSTM",
                "Assamese",
                "hybrid"
            ]
        }
    },
    {
        "Title": "Rendezvous Trajectory Planning for Air-Launched UAV Swarms Using Wind Energy",
        "Link": "https://ieeexplore.ieee.org/document/10745495/",
        "Abstract": "Air-launched deployments of Unmanned Aerial Vehicle (UAV) swarms cause a broad spatial distribution among members, resulting inconsistencies in potential energy and wind conditions during flight. To optimize flight performance during swarm rendezvous, this paper proposes a trajectory planning method that enables members harvest wind energy. Integrate wind energy harvesting strategies for single vehicles with the spatial-temporal coordination of the swarm system. This strategy efficiently manages wind, mechanical, and electrical energies, thereby extending their endurance and range. This method is formulated using the Optimal Control Problem (OCP) framework, considering the dynamics of the swarm system. To ensure control input continuity and trajectory feasibility, the method incorporates constraints on thrust and its increment, which reduces the number of collocation points and lessens computational burden when the OCP is converted into a Nonlinear Programming (NLP) problem for solving. The optimal trajectory of a single UAV is employed as the initial guess to accelerate convergence and enhance solution global optimality. The trajectory planning results demonstrate that, to achieve mechanical energy consistency during the rendezvous process, members with differing initial potential energies after air-launch employ independent wind energy harvesting strategies to compensate for trajectory energy costs. This method optimally plans collaborative trajectories for multiple vehicles within spatiotemporal constraints, significantly broadening their reachable domain. The comprehensive management of energy reserves from air-launched vehicles, including potential and electrical energy, along with the harvesting of wind energy, can significantly extend the range and endurance of air-launched swarm missions.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3492200",
            "Date of Publication": "06 November 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Xiangsheng Wang",
                "labs": [
                    "School of Aeronautic Science and Engineering, Beihang University, Beijing, China"
                ]
            },
            {
                "name": "Tielin Ma",
                "labs": [
                    "Institute of Unmanned System, Beihang University, Beijing, China"
                ]
            },
            {
                "name": "Ligang Zhang",
                "labs": [
                    "Institute of Unmanned System, Beihang University, Beijing, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Trajectory",
                "Autonomous aerial vehicles",
                "Wind energy",
                "Trajectory planning",
                "Aerodynamics",
                "Planning",
                "Vehicle dynamics",
                "Atmospheric modeling",
                "Costs",
                "Potential energy",
                "Swarm robotics",
                "Energy consumption"
            ],
            "Author Keywords": [
                "Swarm robots",
                "trajectory planning",
                "wind energy",
                "UAV",
                "optimal control",
                "energy consumption"
            ]
        }
    },
    {
        "Title": "Improving Semantic Parsing and Text Generation Through Multi-Faceted Data Augmentation",
        "Link": "https://ieeexplore.ieee.org/document/11104098/",
        "Abstract": "The increasing use of large language models has heightened the demand for more extensive datasets in natural language processing (NLP). While various augmentation techniques are being employed to enhance data quantity, many introduce noise or struggle with structurally complex inputs like Discourse Representation Structures (DRS). This study introduces novel data augmentation techniques for both semantic parsing (Text-to-DRS) and text generation (DRS-to-Text), emphasizing enhancements such as named entity augmentation, lexical substitutions utilizing WordNet, and grammatical transformations through changes in tense. The proposed methods led to a considerable expansion of the Parallel Meaning Bank (PMB) dataset, ensuring semantic accuracy and contextual relevance. The augmentation increased both gold and silver instances by a factor of 9, resulting in over 1.3 million new examples. We evaluated four transformer models (byT5, mT5, T5, and mBART) using this augmented dataset. Experimental evaluations revealed substantial improvements across multiple performance metrics. Notably, for semantic parsing, we observed a 17.65% increase in SMATCH (F1) score, and among different evaluation measures for text generation, we have improvements of 14.38% in BLEU score and 6.43% in METEOR score. The observed improvements highlight the effectiveness of our proposed augmentation methodologies in boosting model capabilities for complex neural semantic parsing and generation tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3593857",
            "Date of Publication": "30 July 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Muhammad Saad Amin",
                "labs": [
                    "Dipartimento di Informatica, Università di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Luca Anselma",
                "labs": [
                    "Dipartimento di Informatica, Università di Torino, Turin, Italy"
                ]
            },
            {
                "name": "Alessandro Mazzei",
                "labs": [
                    "Dipartimento di Informatica, Università di Torino, Turin, Italy"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Data augmentation",
                "Data models",
                "Analytical models",
                "Training",
                "Transformers",
                "Context modeling",
                "Robustness",
                "Gold",
                "Computational modeling"
            ],
            "Author Keywords": [
                "Discourse representation structure (DRS)",
                "DRS semantic parsing",
                "formal meaning representation",
                "multi-faceted DRS augmentation",
                "text generation from DRS"
            ]
        }
    },
    {
        "Title": "A Comparative Study of Contemporary Learning Paradigms in Bug Report Priority Detection",
        "Link": "https://ieeexplore.ieee.org/document/10654280/",
        "Abstract": "The increasing complexity of software development demands efficient automated bug report priority classification, and recent advancements in deep learning hold promise. This paper presents a comparative study of contemporary learning paradigms, including BERT, vector databases, large language models (LLMs), and a simple novel learning paradigm, contrastive learning for BERT. Utilizing datasets from bug reports, movie reviews, and app reviews, we evaluate and compare the performance of each approach. We find that transformer encoder-only models outperform in classification tasks measured by the precision, recall, and F1 score transformer decoder-only models despite an order of magnitude gap between the number of parameters. The novel use of contrastive learning for BERT demonstrates promising results in capturing subtle nuances in text data. This work highlights the potential of advanced NLP techniques for automated bug report priority classification and underscores the importance of considering multiple factors when developing models for this task. The paper’s main contributions are a comprehensive evaluation of various learning paradigms, such as vector databases and LLMs, an introduction of contrastive learning for BERT, an exploration of applicability to other text classification tasks, and a contrastive learning procedure that exploits ordinal information between classes.",
        "Details": {
            "DOI": "10.1109/ACCESS.2024.3451125",
            "Date of Publication": "28 August 2024",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Eyüp Halit Yilmaz",
                "labs": [
                    "Department of Computer Engineering, Middle East Technical University, Ankara, Türkiye"
                ]
            },
            {
                "name": "İsmail Hakki Toroslu",
                "labs": [
                    "Department of Computer Engineering, Middle East Technical University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Ömer Köksal",
                "labs": [
                    "University of Doha for Science and Technology, Doha, Qatar"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Computer bugs",
                "Software",
                "Task analysis",
                "Contrastive learning",
                "Encoding",
                "Bidirectional control",
                "Natural language processing",
                "Classification algorithms",
                "Software engineering"
            ],
            "Author Keywords": [
                "Bug triaging",
                "contrastive learning",
                "machine learning",
                "natural language processing",
                "software bug report classification",
                "software engineering"
            ]
        }
    },
    {
        "Title": "A Hybrid Approach Based Diet Recommendation System Using ML and Big Data Analytics",
        "Link": "https://ieeexplore.ieee.org/document/10966184/",
        "Abstract": "Recommendations are useful suggestions used by people from all walks of life. However, the usage of recommender systems plays a vital role in modern applications. They are found in different domains such as E-commerce. Concerning the health care industry, recommendations play a very crucial role. This industry has significance as it is linked to the lives of people and their well-being. Human health depends on the diet followed. Keeping this fact in mind, in this paper, we investigated healthy diet recommendations. The recommender systems that are existing in healthcare focused a little in this area. From the literature, it is understood that most of the frameworks on health recommendations are theoretical in nature. As food decides health, it is to be given paramount importance. In this paper, we proposed a hybrid mechanism based on Artificial Intelligence (AI) for big data analytics. Particularly we used Machine Learning (ML) for generating healthy diet recommendations. The proposed system is known as Hybrid Recommender System (HRS). It involves a hybrid approach with Natural Language Processing (NLP) and machine learning. An algorithm named Intelligent Recommender for Healthy Diet (IR-HD) is proposed to analyze data and provide healthy diet recommendations. IR-HD could generate recommendations on a healthy diet and outperform existing models. Python data science platform is used to implement the recommender system. The results of experiments showed that the system is capable of providing quality recommendations and it has performance improvement over the state of the art.",
        "Details": {
            "DOI": "10.13052/jmm1550-4646.1864",
            "Date of Publication": "November 2022",
            "Publisher": "River Publishers",
            "Published In": "Journal of Mobile Multimedia"
        },
        "issn_info": {
            "Electronic ISSN": "1550-4654",
            "Print ISSN": "1550-4646"
        },
        "authors_data": [
            {
                "name": "Muhib Anwar Lambay",
                "labs": [
                    "CSE Dept, B.S. Abdur Rahman Crescent Institute of Science and Technology, Chennai, India"
                ]
            },
            {
                "name": "S. Pakkir Mohideen",
                "labs": [
                    "CSE Dept, B.S. Abdur Rahman Crescent Institute of Science and Technology, Chennai, India"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Industries",
                "Machine learning algorithms",
                "Multimedia systems",
                "Medical services",
                "Machine learning",
                "Big Data",
                "Data science",
                "Natural language processing",
                "Electronic commerce",
                "Recommender systems"
            ],
            "Author Keywords": [
                "Healthcare recommendations",
                "recommender system",
                "intelligent healthcare recommendation system",
                "healthy diet recommender"
            ]
        }
    },
    {
        "Title": "A Text Similarity Measurement Based on Semantic Fingerprint of Characteristic Phrases",
        "Link": "https://ieeexplore.ieee.org/document/10848260/",
        "Abstract": "Text similarity measurements are the basis for measuring the degree of matching between two or more texts. Traditional large-scale similarity detection methods based on a digital fingerprint have the advantage of high detection speed, which are only suitable for accurate detection. We propose a method of Chinese text similarity measurement based on feature phrase semantics. Natural language processing (NLP) technology is used to pre-process text and extract the keywords by the Term frequency-Inverse document frequency (TF-IDF) model and further screen out the feature words. We get the exact meaning of a word and semantic similarities between words and a HowNet semantic dictionary. We substitute concepts to get the feature phrases and generate a semantic fingerprint and calculate similarity. The experimental results indicate that the method proposed is superior in similarity detection in terms of its accuracy rate, recall rate, and\nF\n-value to the traditional and digital fingerprinting method.",
        "Details": {
            "DOI": "10.1049/cje.2019.12.011",
            "Date of Publication": "March 2020",
            "Publisher": "CIE",
            "Published In": "Chinese Journal of Electronics"
        },
        "issn_info": {
            "Electronic ISSN": "2075-5597",
            "Print ISSN": "1022-4653"
        },
        "authors_data": [
            {
                "name": "Shanchen Pang",
                "labs": [
                    "College of Computer and Communication Engineering, China University of Petroleum, Qingdao, China"
                ]
            },
            {
                "name": "Jiamin Yao",
                "labs": [
                    "College of Computer and Communication Engineering, China University of Petroleum, Qingdao, China"
                ]
            },
            {
                "name": "Ting Liu",
                "labs": [
                    "Weihai Science and Technology Bureau, Weihai, China"
                ]
            },
            {
                "name": "Hua Zhao",
                "labs": [
                    "College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, China"
                ]
            },
            {
                "name": "Hongqi Chen",
                "labs": [
                    "College of Intelligence and Computing, Tianjin University, Tianjin, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Accuracy",
                "Dictionaries",
                "Semantics",
                "Fingerprint recognition",
                "Feature extraction",
                "Natural language processing",
                "Frequency measurement"
            ],
            "Author Keywords": [
                "Term frequency-Inverse document frequency(TF-IDF) model",
                "Semantic fingerprint",
                "Similarity",
                "Characteristic phrases"
            ]
        }
    },
    {
        "Title": "Data Augmentation for Text Classification Using Autoencoders",
        "Link": "https://ieeexplore.ieee.org/document/11164557/",
        "Abstract": "Deep learning models have greatly improved various natural language processing tasks. However, their effectiveness depends on large data sets, which can be difficult to acquire. To mitigate this challenge, data augmentation techniques are employed to artificially expand the training data by generating synthetic samples. By enriching the dataset, data augmentation enhances model generalization, reduces overfitting, and improves model performance. This paper investigates the effectiveness of employing autoencoders for text data augmentation to enhance the performance of text classification models. The research compares four types of autoencoders which are Traditional Autoencoder (AE), Adversarial Autoencoder (AAE), Denoising Adversarial Autoencoder (DAAE), and Variational Autoencoder (VAE). Basic text preprocessing techniques, which are lowercasing, removal of non-alphanumeric characters and removal of stop words, are applied to all documents. Additionally, label-based filtering is applied, where the outputs of autoencoders that contradict the predictions of BERT are eliminated. The experiments are conducted using the SST-2 sentiment classification dataset, which consists of 7,791 training instances and 1,821 test instances. To better analyze the impact of data augmentation methods, experiments are also performed on smaller subsets of 100, 200, 400, and 1,000 instances. Data augmentation is applied at ratios of 1:1, 1:2 and 1:4 for these subsets. The results demonstrate that AE-based data augmentation methods, particularly at a 1:1 ratio, achieve better accuracy than the baseline models. This underscores the potential of autoencoders in improving text classification outcomes in NLP tasks.",
        "Details": {
            "DOI": "10.1109/ACCESS.2025.3610157",
            "Date of Publication": "15 September 2025",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Mustafa Cataltas",
                "labs": [
                    "Department of Computer Engineering, Konya Technical University, Konya, Türkiye"
                ]
            },
            {
                "name": "Ilyas Cicekli",
                "labs": [
                    "Department of Computer Engineering, Hacettepe University, Ankara, Türkiye"
                ]
            },
            {
                "name": "Nurdan Akhan Baykan",
                "labs": [
                    "Department of Computer Engineering, Konya Technical University, Konya, Türkiye"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Autoencoders",
                "Data augmentation",
                "Text categorization",
                "Data models",
                "Training",
                "Noise reduction",
                "Semantics",
                "Decoding",
                "Deep learning",
                "Vectors"
            ],
            "Author Keywords": [
                "Autoencoders",
                "data augmentation",
                "deep learning",
                "text classification"
            ]
        }
    },
    {
        "Title": "Semantic Sentence Matching Based on Multiple Parallelly Organized Interaction Layers at Various Granularity Combinations With Two-Stage Aggregation Strategy",
        "Link": "https://ieeexplore.ieee.org/document/10253944/",
        "Abstract": "Semantic sentence matching plays an essential role in resolving many problems in natural language processing (NLP) field, it has gained increasing research focus and shown great improvements in recent years. However, most currently existing researches are for English sentence matching, research on Chinese semantic matching are relatively less. Moreover, due to the rather complicated contextual expressions and grammatical structure of Chinese language, many existing models are still unable to quite effectively capture interaction information between sentences. Thus, in this work, we attempt to propose a novel deep model to better address Chinese semantic sentence matching. Specifically, the convolutional neural networks with various kernel sizes are first employed for the multi-granular contextual encoding of sentences, combined with multiple different cross-sentence alignment mechanisms, the semantic interactions can be more clearly and profoundly performed at various granularity combinations between sentences. Additionally, rather than serially stacking multiple interaction layers, we organize multiple interaction layers in a parallel manner, and by further introduction of attention pooling, the semantically aligned sentence attentive vectors would be adaptively aggregated from both perspectives of alignment mechanisms and granularity combinations, thus more stable and effective sentence interactive features can be extracted while attempting to alleviate potential sentence alignment error propagation issue existed in hierarchically stacked interaction structure. Finally, extensive experiments are conducted to evaluate the performance of our model, the experimental results demonstrate that our proposed approach outperforms many state-of-the-art models on sentence matching and is capable of gaining a more accurate understanding of semantic relationships between Chinese sentences.",
        "Details": {
            "DOI": "10.1109/ACCESS.2023.3315840",
            "Date of Publication": "18 September 2023",
            "Publisher": "IEEE",
            "Published In": "IEEE Access"
        },
        "issn_info": {
            "Electronic ISSN": "2169-3536"
        },
        "authors_data": [
            {
                "name": "Dian Wang",
                "labs": [
                    "Second Research Institute of Civil Aviation Administration of China, Chengdu, China",
                    "School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, China"
                ]
            },
            {
                "name": "Jing Li",
                "labs": [
                    "Second Research Institute of Civil Aviation Administration of China, Chengdu, China",
                    "Chengdu Civil Aviation Technology Development Company Ltd., Chengdu, China"
                ]
            }
        ],
        "keywords": {
            "IEEE Keywords": [
                "Semantics",
                "Feature extraction",
                "Task analysis",
                "Convolutional neural networks",
                "Context modeling",
                "Aggregates",
                "Stacking",
                "Image matching"
            ],
            "Author Keywords": [
                "Semantic matching",
                "cross attention",
                "deep interaction",
                "vector aggregation"
            ]
        }
    }
]